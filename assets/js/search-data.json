{
  
    
        "post0": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.‚Ü© . 2. This is the other footnote. You can even have a link!‚Ü© .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " ‚Ä¢ Feb 20, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Python for Research Q & A üñãÔ∏è",
            "content": ". . Background . Python is getting more and more popular, not only in the field of computer science, but also in the diverse fields when it comes to computation, working with digital resources and data presentation. This notebook aims to give users some basic knowledge about the potential of Python programming language in the context of humanity research. . . Presumption: Not applicable . . . Although Python is a programming language, it is different from other low-level programming languages by being more user-friendly and more close to a interpreter than machine code. It is for general purpose and also relatively beginner-friendly. . Python is not only more readable, it also has less structural rules and usually much shorter. Compared to other languages such as JavaScript, Python has not so much low-level language like syntax so its learning curve is not as steep. . General-purpose Language . Although you might have read other tutorials telling you how you can use very diverse tools to achieve fancy tasks that you wish to perform. You also have to realize that how much time will you need to master that languages or tools before tasks can be done. . Let&#39;s assume that you are not a real web developer here and data analysis or visualization is not your primary profession. It means, you are not making your living by making charts and websites, and for you making creative and fancy new charts is not as important as making a not so time-consuming and presentable bar chart which display your results to the audience or in your paper. . Most often, what you need is then much more simple functionalities which a fancy tool can overkill. You also need to consider that not all digital tools are open and free, so using multiple of them can cost you time and money. . For Qualitative Research . Although Python is a programming language and is often associated with computing and numbers, it can help you with qualitative research too! It includes many functionalities to work with text resources. Although you do not need to do calculation on them, sometimes you do want to find a pattern in them, look for the keywords, or just get them into digital text. . . Data Input . Python can help you to get your qualitative sources. Let&#39;s say you want to look into BDK (Bukkyo Dendo Kyokai) Database for the A Biography of Sakyamuni. And you want to get the text file of certain chapters. What you can do is to use Python to scrap the text and load it in a file for you. Or let&#39;s say you want to have all the Buddhist texts having a particular keywords, then you can filter the text using Python. . . Data Analysis . So now you got the text. But you want to see how does certain keywords distributed inside your text(s), or what is the associated sentiment of the text(s). Then you can perform NLP in Python. Or if you have a database of Buddhist temples and want to analysis what regions are they mostly located in, then you can perform some geospatial analysis in Python too. . . Data Presentation . Let&#39;s say now you got your results already, and you need to present them either in a paper, in a PowerPoint or make a simple webpage that you can shared with your colleagues or your audience. You can also make both static and interactive charts/ text visualization using Python. They can be either a bar chart for comparison, a word cloud for showing key words, or a map showing geolocations of objects. . . Checking out some galleries: . PLOTLY . | SEABORN . | . What can Python do for me? . Python can indeed handle a large variety of tasks, from get data for you (web scraping), to analysis your data (text analysis), to present your results (data visualization). Its high speed allow you to scan and work with a large amount of data and search for the ones that you are interested in! You can then either analyse them with Python or continue by yourself to read the information retrieved. Or Python simply let you present what you have in mind, like a time line, in a digital format. . Geospatial Data ?? . For example, you might have read about Mapbox.js, Leaflet.js, R or GIS for analysing geospatial data, making choropleths and interactive graphics. But Python can do it too using Plotly, Folium and Geoopandas! . Interactive Bubble Chart ?? . Then you read about D3.js for making an interactive bubble chart. But Python can get it done too using Plotly. . Text Optical Recognition (OCR) ?? . Then you read about doing OCR, but Python get give you a ride too using pytesseract. You can even work on it without the need for Bash or Comment Line. . Data Cleaning ?? Manipulation ?? . Then you read about other digital tools for data cleaning and manipulation. You realize you need them too. But you can stick with Python: Pandas library can get the job done! . Data Mining ?? Web Scraping ?? . Then you think of getting information from a digital database? The door of Python Beautiful Soup is open for you! . Web Application ?? App ?? . Want to make a simple web application or app to host your data visualization or presentation? Try out Dash from Plotly which can be run in Python too! . . . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: December 2021 . . . . References: . https://www.bitdegree.org/tutorials/python-vs-javascript/ . https://towardsdatascience.com/a-complete-guide-to-an-interactive-geographical-map-using-python-f4c5197e23e0 .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/jupyter/2020/01/31/Python_Research_Q&A_Basics.html",
            "relUrl": "/jupyter/2020/01/31/Python_Research_Q&A_Basics.html",
            "date": " ‚Ä¢ Jan 31, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Introduction to Jupyter notebooks",
            "content": ". What is Jupyter? . The Jupyter Project is an open source effort that evolved from the IPython project to support interactive data science and computing. Besides Python, it also supports many different programming languages including R and Julia. . Components of Jupyter Notebook . Jupyter Notebook IDE: The application that launches in a web browser like Firefox or Safari and is the environment where you write and run your code. . | Jupyter Notebook Files(.ipynb): The file format that you can use to store code and markdown text for individual projects and workflows. . | Kernels: A kernel runs your code in a specific programming language. In this tutorial, Python kernel is used within the Jupyter Notebook IDE. . | . Jupyter Notebook User Interface . After you create a new notebook file (.ipynb), you will be presented with notebook name, menu bar, tool bar and a code cell as default starting cell. . Notebook Name: if you click at the notebook name, you could rename the file. . | Menu Bar: presents all functions and settings of the notebook file. . | Tool Bar: presents the most used tools as icons. . | Code Cell: it is the default type of cell when you create a new cell; if you want to transfer it to a markdown cell, you could use the drop down box in tool bar or a keyboard shortcut. . | . . . 1. Headers . Note: The more # the title holds, the smaller the title will be. . # This is a Title in Markdown . ## This is a Subtitle in Markdown . ### This is a smaller subtitle in Markdown . . will be rendered as: . This is a Title in Markdown . This is a Subtitle in Markdown . This is a smaller subtitle in Markdown . . . 2. Lists . * This is a bullet list . * This is a bullet list . * This is a bullet list . . 1. This is a numbered list . 2. This is a numbered list . 3. This is a numbered list . . will be rendered as: . This is a bullet list | This is a bullet list | This is a bullet list | . This is a numbered list | This is a numbered list | This is a numbered list | Tip: To render list, you should leave a blank space between 1. and the following texts. . . . 3. Bold and Italic . *These are italic words.* . **These are bold words.** . ***These are bold AND italic words.*** . . will be rendered as . . These are italic words. . These are bold words. . These are bold AND italic words. . . . . 4. Highlight Code . If you want to highlight a funciton or some code in a plain text, you add one backtick on each side of the text (`). . Here is some highlighted text! . . . . 5. Horizontal Lines . You can also create a horizontal line to highlight a block of markdown syntax. . . *** . Here is some important text! . *** . . will be rendered as: . . . Here is some important text! . . . Tip: The *s on both side of the texts should be at the line above and the line below the texts. . . . 6. Hyperlinks . You can use HTML in Markdown cells to create hyperlinks redirecting to other websites. For example, the following syntax. . More infos about our data cube program can be found at &lt;a href=&quot;https://datacube.remote-sensing.org/&quot;&gt;this website&lt;/a&gt; . . will be rendered as: . More infos about our data cube program can be found at this website . . . 7. Images . You can also render images in Markdown cells using the following syntax: . ![alternative text here](url-to-image-here) . . For example, . ![Fotograph of Philip is here](https://i.imgur.com/VGPeJ6s.jpg) . . will be redered like: . . Or if the image need to be resize: . &lt;div&gt; . &lt;img src=https://i.imgur.com/VGPeJ6s.jpg width=&quot;200&quot;&gt; . &lt;/div&gt; . . will be rendered as: . Note: The texts in the rectangle brackets (e.g. &quot;Fotograph of Philip is here&quot;) will appear when the image fails to load. . . . . 8. LaTex . Jupyter notebook markdown cell also supports LaTex. So that the markdown cells interpret your texts as LaTex, surround your input texts with $ signs. . For instance, $c=a+b$ will be rendered as . $c=a+b$ . If you want your texts be centered in the cell, surround your input texts with two $ signs. . For instance, $$C_{g}= frac{H}{ frac{ pi}{2}*Cl_{p}}$$ will be rendered as . $$C_{g}= frac{H}{ frac{ pi}{2}*Cl_{p}}$$ . . and . . |Uppercase| LaTeX |Lowercase| LaTeX | . ||-||-| . |$ Delta$ | Delta|$ delta$ | delta| . |$ Omega$ | Omega|$ omega$ | omega| . . will be rendered as: . . Uppercase LaTeX Lowercase LaTeX . $ Delta$ | Delta | $ delta$ | delta | . $ Omega$ | Omega | $ omega$ | omega | . . 9. Table . A table can be constructed using | (pipe symbol) and ‚Äî (dash) to mark columns and rows. The first row of the table defines the headers, and the next row defines the alignment of each column. . . For instance, . | Stretch/Untouched | ProbDistribution | Accuracy | . | | | | . | Stretched | Gaussian | .843 | . . will be rendered as: . Stretch/Untouched ProbDistribution Accuracy . Stretched | Gaussian | .843 | . The widths of the columns can also be changed by adding an empty row at the end with defined width. . . | Stretch/Untouched | ProbDistribution | Accuracy | . | | | | . | Stretched | Gaussian | .843 | . |&lt;img width=200/&gt;|&lt;img width=200/&gt;|&lt;img width=200/&gt;| . . will be rendered as: . . Stretch/Untouched ProbDistribution Accuracy . Stretched | Gaussian | .843 | . | | | . What is Colab? . So now we learnt about Jupyter Notebook, then what is Colab? Colab notebooks are Jupyter notebooks that are hosted by Colab. Therefore, the operations are highly similar and it allows you to write and execute Python in your browser, with . Zero configuration required | Free access to GPUs | Easy sharing | . There are limits in the available memory but they are generally sufficient if you are not performing particularly demanding tasks. One of the benefits using Colab is that you do not need to worried about dependencies as much for downloading Python tools and libraries. Many of the libraries are available in the Colab environment by default, eg. Pandas. . To import a library that&#39;s not in Colaboratory by default, you can also use !pip install or !apt-get install. . For example, . !pip install cartopy import cartopy . Collecting cartopy Downloading Cartopy-0.20.1.tar.gz (10.8 MB) |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10.8 MB 5.1 MB/s Installing build dependencies ... done Getting requirements to build wheel ... error WARNING: Discarding https://files.pythonhosted.org/packages/fc/59/aa52698e3838f4cd0e7eaa75bd86837e9e0b05041dbdaee3cda2fffced06/Cartopy-0.20.1.tar.gz#sha256=91f87b130e2574547a20cd634498df97d797abd12dcfd0235bc0cdbcec8b05e3 (from https://pypi.org/simple/cartopy/) (requires-python:&gt;=3.7). Command errored out with exit status 1: /usr/bin/python3 /usr/local/lib/python3.7/dist-packages/pip/_vendor/pep517/in_process/_in_process.py get_requires_for_build_wheel /tmp/tmpvn613tgl Check the logs for full command output. Downloading Cartopy-0.20.0.tar.gz (10.8 MB) |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10.8 MB 20.5 MB/s Installing build dependencies ... done Getting requirements to build wheel ... error WARNING: Discarding https://files.pythonhosted.org/packages/0f/c0/58453b036e79046d211f083880d58dcce787e7e07647ac25dc46c6555099/Cartopy-0.20.0.tar.gz#sha256=eae58aff26806e63cf115b2bce9477cedc4aa9f578c5e477b2c25cfa404f2b7a (from https://pypi.org/simple/cartopy/) (requires-python:&gt;=3.7). Command errored out with exit status 1: /usr/bin/python3 /usr/local/lib/python3.7/dist-packages/pip/_vendor/pep517/in_process/_in_process.py get_requires_for_build_wheel /tmp/tmpcxegil_v Check the logs for full command output. Downloading Cartopy-0.19.0.post1.tar.gz (12.1 MB) |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12.1 MB 19.6 MB/s Installing build dependencies ... done Getting requirements to build wheel ... done Preparing wheel metadata ... done Requirement already satisfied: shapely&gt;=1.5.6 in /usr/local/lib/python3.7/dist-packages (from cartopy) (1.8.0) Collecting pyshp&gt;=2 Downloading pyshp-2.1.3.tar.gz (219 kB) |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219 kB 48.7 MB/s Requirement already satisfied: numpy&gt;=1.13.3 in /usr/local/lib/python3.7/dist-packages (from cartopy) (1.19.5) Building wheels for collected packages: cartopy, pyshp Building wheel for cartopy (PEP 517) ... done Created wheel for cartopy: filename=Cartopy-0.19.0.post1-cp37-cp37m-linux_x86_64.whl size=12516269 sha256=983da772a11f3cba2d78a180f9a2d0136b8d43ba98219da421e264ca5b01d995 Stored in directory: /root/.cache/pip/wheels/98/01/f7/bd10aeb96fe4b518cde5f7c4f5e12c7202f85b7353a5017847 Building wheel for pyshp (setup.py) ... done Created wheel for pyshp: filename=pyshp-2.1.3-py3-none-any.whl size=37325 sha256=1c8e9a249f1f0ed81fac1f63ab6c703038812764fe6dd1b67b62e911ebaab64e Stored in directory: /root/.cache/pip/wheels/43/f8/87/53c8cd41545ba20e536ea29a8fcb5431b5f477ca50d5dffbbe Successfully built cartopy pyshp Installing collected packages: pyshp, cartopy Successfully installed cartopy-0.19.0.post1 pyshp-2.1.3 . Also, because Colab is a cloud environment, you cannot directly assess files in your local environment. If you want to import files, there are two options: . Data Import . Option 1: Upload Files . Remarks: The file name in line pd.read_csv() need to be exactly the same as the name of the file you uploaded to not run into errors. . from google.colab import files # use the google.colab library uploaded = files.upload() # upload it, click choose file after running this cell and pick the file # read your file depends on the file format # Let&#39;s say you have a csv, then you can read them using Pandas (you will learn more about Pandas later) import io import pandas as pd df = pd.read_csv(io.BytesIO(uploaded[&#39;yourfile.csv&#39;])) df # now your data is stored in this data frame . Option 2: Access Files from Google Drive . One of the cons using upload option is that you can only upload one file at a time and it might take sometimes if your files are large. Let&#39;s say your colleague share you a file from Google Drive and you have a copy of it in the Drive. It is probably not the best way to download them to your computer and upload them in Colab again. . What you can do is to directly use files on the drive. . After running the following code, you still need to sign in to your Google Account, and click Allow to permit access to your own Google Drive. . from google.colab import drive drive.mount(&#39;/content/drive/&#39;) . Mounted at /content/drive/ . After successful connection, you can see &quot;Mounted at / content/drive/&quot; under the cell. . Then, you can check your directory. . !ls . drive sample_data . Where to search for your files depends on where do you store them. Let&#39;s say you stored your file inside Google Drive with a folder call yourfolder. You can check if the files are there by: . . Remark: Be carefule there is no space between My and Drive . print(os.popen(&#39;ls /content/drive/MyDrive/yourfolder&#39;).read()) . Your files should appear under the cell after run. . Then you can open your file using the path. You can specify your path in a raw string r&quot;path&quot;. . Then you can open them using different methods depending on the data format. The following example is a Geotiff file and it can be opened using gdal (You do not need to know much about it for now). . path = r&quot;/content/drive/MyDrive/yourfolder/boundary.tif&quot; # import library import gdal # open file ds = gdal.Open(path, gdal.GA_ReadOnly) . # import library import pandas as pd # define your path path = r&quot;/content/drive/MyDrive/yourfolder/city.csv&quot; # open file df = pd.read_csv(path) df # now your data is stored in this data frame . Data Export . It is basically very similar when you need to output a file. . Option: Directly Download Files . Remarks: The file name in the second and third line need to be exactly the same to not run into errors. . from google.colab import files # import library; only need to be done once for the whole notebook df.to_csv(&#39;temple_location.csv&#39;, encoding=&#39;utf_8_sig&#39;, index=False) # suppose df is the dataframe you want to export files.download(&#39;temple_location.csv&#39;) # run this code and the file will be directly downloaded . What you can also do it to run only: . from google.colab import files # import library; only need to be done once for the whole notebook df.to_csv(&#39;temple_location.csv&#39;, encoding=&#39;utf_8_sig&#39;, index=False) # suppose df is the dataframe you want to export # by default they will be in /content . and then click the bar on the left side with the folder icon (Files). Then you can also search for your files in the directory and click on the three dots and then click download. . It is generally recommanded to modify a file already existed in the Google Drive but not to create new files in Google Drive. . . . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: December 2021 . . . . References: . https://colab.research.google.com/?utm_source=scs-index .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/jupyter/2020/01/30/JupyterNotebook_Colab_Basics.html",
            "relUrl": "/jupyter/2020/01/30/JupyterNotebook_Colab_Basics.html",
            "date": " ‚Ä¢ Jan 30, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Introduction to Python Programming (Example from Â≠üÊµ©ÁÑ∂ËØóÂÖ®ÈõÜ)",
            "content": "Here the examples used is Chinese texts from this link. . List . The following is a review of Python basics with presumptions of knowledge in w3school from Python intro to Python Arrays. The following is the a subset of titles from Â≠üÊµ©ÁÑ∂ËØóÂÖ®ÈõÜ Âç∑‰∏ÄÁôæ‰∫îÂçÅ‰πù. . String &quot;&quot; is used to save the titles in variables. Pay attention that in Python capital letters and spacing matters. So for example, &quot;CHINA&quot; is not equal to &quot;China&quot;. True and False in Python is called boolean. It is a way to express binary result. . &quot;China&quot; == &quot;China&quot; # == means &quot;is it equal to?&quot; (the opposite is !=) . True . &quot;CHINA&quot; == &quot;China&quot; # This is the way how comments can be written. They will not impacts the code structure itself . False . first = &quot;‰ªéÂº†‰∏ûÁõ∏Ê∏∏ÂçóÁ∫™ÂüéÁåéÔºåÊàèËµ†Ë£¥Ëø™Âº†ÂèÇÂÜõ&quot; second = &quot;ÁôªÊ±ü‰∏≠Â≠§Â±øÔºåËµ†ÁôΩ‰∫ëÂÖàÁîüÁéãËø•&quot; third = &quot;ÊôöÊò•ÂçßÁóÖÂØÑÂº†ÂÖ´&quot; fourth = &quot;ÁßãÁôªÂÖ∞Â±±ÂØÑÂº†‰∫î&quot; fifth = &quot;ÂÖ•Â≥°ÂØÑÂºü&quot; . We can also put them in a list, which is a method to store multiple items in a single variable. There are much more ways to store information that we can retrieve later but list is the most simple form. Also, all text without &quot;&quot; in Python will be understood as a variable and it might cause errors if it is not one. . Be careful, there are some key words that we cannot used to store variables as they are reserved. To understand more about key words: https://www.w3schools.com/python/python_ref_keywords.asp . list_ = [first, second, third, fourth, fifth] . Then we can print them out. . list_ . [&#39;‰ªéÂº†‰∏ûÁõ∏Ê∏∏ÂçóÁ∫™ÂüéÁåéÔºåÊàèËµ†Ë£¥Ëø™Âº†ÂèÇÂÜõ&#39;, &#39;ÁôªÊ±ü‰∏≠Â≠§Â±øÔºåËµ†ÁôΩ‰∫ëÂÖàÁîüÁéãËø•&#39;, &#39;ÊôöÊò•ÂçßÁóÖÂØÑÂº†ÂÖ´&#39;, &#39;ÁßãÁôªÂÖ∞Â±±ÂØÑÂº†‰∫î&#39;, &#39;ÂÖ•Â≥°ÂØÑÂºü&#39;] . Slicing and Basic Manipulation . Sometime we only wish to retrieve selected items. By slicing, we can easily access them. Python start from 0 so [0] always mean the first item. We can also use negetive values, in which the order counted in the reverse order. The last item indicated will be excluded from selection (eg. [0:2] means the 3rd item is excluded). . print(list_[0]) # first element only . ‰ªéÂº†‰∏ûÁõ∏Ê∏∏ÂçóÁ∫™ÂüéÁåéÔºåÊàèËµ†Ë£¥Ëø™Âº†ÂèÇÂÜõ . print(list_[0:2]) # first two elements only . [&#39;‰ªéÂº†‰∏ûÁõ∏Ê∏∏ÂçóÁ∫™ÂüéÁåéÔºåÊàèËµ†Ë£¥Ëø™Âº†ÂèÇÂÜõ&#39;, &#39;ÁôªÊ±ü‰∏≠Â≠§Â±øÔºåËµ†ÁôΩ‰∫ëÂÖàÁîüÁéãËø•&#39;] . print(list_[-1]) # last item . Êπñ‰∏≠ÊóÖÊ≥äÔºåÂØÑÈòé‰πùÂè∏Êà∑Èò≤ . Using text (inside &quot;&quot;) some of the operation cannot be done as using numbers (eg. division). However, there are multiple ways we can manipulate them. . . For example, we can add them togehter. . add = list_[-1] + &quot;,&quot; + list_[-1] add . &#39;ÂÖ•Â≥°ÂØÑÂºü,ÂÖ•Â≥°ÂØÑÂºü&#39; . We can subtract text (in an indirect way). . add.replace(&quot;,ÂÖ•Â≥°ÂØÑÂºü&quot;,&quot;&quot;) # replace &quot;,ÂÖ•Â≥°ÂØÑÂºü&quot; with nothing &quot;&quot; . &#39;ÂÖ•Â≥°ÂØÑÂºü&#39; . We can also repeat them. . list_[-1] * 10 # * ten times . &#39;ÂÖ•Â≥°ÂØÑÂºüÂÖ•Â≥°ÂØÑÂºüÂÖ•Â≥°ÂØÑÂºüÂÖ•Â≥°ÂØÑÂºüÂÖ•Â≥°ÂØÑÂºüÂÖ•Â≥°ÂØÑÂºüÂÖ•Â≥°ÂØÑÂºüÂÖ•Â≥°ÂØÑÂºüÂÖ•Â≥°ÂØÑÂºüÂÖ•Â≥°ÂØÑÂºü&#39; . We can also insert more items into the list. Let&#39;s put the 6th title into position 5 (Python start from 0). . list_.insert(5, &#39;Êπñ‰∏≠ÊóÖÊ≥äÔºåÂØÑÈòé‰πùÂè∏Êà∑Èò≤&#39;) list_ . [&#39;‰ªéÂº†‰∏ûÁõ∏Ê∏∏ÂçóÁ∫™ÂüéÁåéÔºåÊàèËµ†Ë£¥Ëø™Âº†ÂèÇÂÜõ&#39;, &#39;ÁôªÊ±ü‰∏≠Â≠§Â±øÔºåËµ†ÁôΩ‰∫ëÂÖàÁîüÁéãËø•&#39;, &#39;ÊôöÊò•ÂçßÁóÖÂØÑÂº†ÂÖ´&#39;, &#39;ÁßãÁôªÂÖ∞Â±±ÂØÑÂº†‰∫î&#39;, &#39;ÂÖ•Â≥°ÂØÑÂºü&#39;, &#39;Êπñ‰∏≠ÊóÖÊ≥äÔºåÂØÑÈòé‰πùÂè∏Êà∑Èò≤&#39;] . ## Numpy Array | . We can also put them in numpy array, which make many manipulation easier and faster, but first we need to import the library. It is applied to all functionalities not included in the base library. . After import the numpy library, it is imported as np and later when we need to call a function from the library, eg. min(), we can type np.min(). The item we put in () is called arguments. They are the inputs to compute the outputs. When we use functions, we have to be careful what arguments are needed (sometimes they are compulsory, sometimes they are not necessary, sometimes they are optional but there will be always a default option). . import numpy as np # import library. When we write real code, all libraries will typically be imported all together at the beginning . arr = np.array(list_) arr . array([&#39;‰ªéÂº†‰∏ûÁõ∏Ê∏∏ÂçóÁ∫™ÂüéÁåéÔºåÊàèËµ†Ë£¥Ëø™Âº†ÂèÇÂÜõ&#39;, &#39;ÁôªÊ±ü‰∏≠Â≠§Â±øÔºåËµ†ÁôΩ‰∫ëÂÖàÁîüÁéãËø•&#39;, &#39;ÊôöÊò•ÂçßÁóÖÂØÑÂº†ÂÖ´&#39;, &#39;ÁßãÁôªÂÖ∞Â±±ÂØÑÂº†‰∫î&#39;, &#39;ÂÖ•Â≥°ÂØÑÂºü&#39;], dtype=&#39;&lt;U17&#39;) . Do you see dtype=&#39;&lt;U17&#39;? It means datatype of the elements in the Numpy array. The U indicates that the elements are Unicode strings; Unicode is the standard Python uses to represent strings. . . In fact, it is important when we write code because if the action can be performed always depends on data types. To better understand data type: https://realpython.com/python-data-types/ . . ## Data Type | . If we want to check the data type of any objects, we can use type(). . type(100) # integer . int . type(&quot;list_&quot;) # string . str . type(list_) # list . list . type(np.array(list_)) # array . numpy.ndarray . Other Operations using Numpy Array . We can manipulate the text, for example, by getting the title with the most characters. . sort_arr = sorted(list_,key=len,reverse=False) # first we sort them by length (key = len), default in ascending order sort_arr . [&#39;ÂÖ•Â≥°ÂØÑÂºü&#39;, &#39;ÊôöÊò•ÂçßÁóÖÂØÑÂº†ÂÖ´&#39;, &#39;ÁßãÁôªÂÖ∞Â±±ÂØÑÂº†‰∫î&#39;, &#39;Êπñ‰∏≠ÊóÖÊ≥äÔºåÂØÑÈòé‰πùÂè∏Êà∑Èò≤&#39;, &#39;ÁôªÊ±ü‰∏≠Â≠§Â±øÔºåËµ†ÁôΩ‰∫ëÂÖàÁîüÁéãËø•&#39;, &#39;‰ªéÂº†‰∏ûÁõ∏Ê∏∏ÂçóÁ∫™ÂüéÁåéÔºåÊàèËµ†Ë£¥Ëø™Âº†ÂèÇÂÜõ&#39;] . sort_arr[-1] . &#39;‰ªéÂº†‰∏ûÁõ∏Ê∏∏ÂçóÁ∫™ÂüéÁåéÔºåÊàèËµ†Ë£¥Ëø™Âº†ÂèÇÂÜõ&#39; . We can for example count the number of titles using len(). . len(arr) . 5 . We can also put condition into array. For example, let&#39;s get item with over 5 characters. . # To review list comprehension: https://www.w3schools.com/python/python_lists_comprehension.asp arr_len = [len(i) for i in arr] arr_len . [17, 13, 7, 7, 4] . arr_len = np.array(arr_len) . Get arr with arr_len in the correponding position larger than 5. . To better understand the basic operators: https://www.tutorialspoint.com/python/python_basic_operators.htm . arr[arr_len &gt; 5] # slicing with conditions . array([&#39;‰ªéÂº†‰∏ûÁõ∏Ê∏∏ÂçóÁ∫™ÂüéÁåéÔºåÊàèËµ†Ë£¥Ëø™Âº†ÂèÇÂÜõ&#39;, &#39;ÁôªÊ±ü‰∏≠Â≠§Â±øÔºåËµ†ÁôΩ‰∫ëÂÖàÁîüÁéãËø•&#39;, &#39;ÊôöÊò•ÂçßÁóÖÂØÑÂº†ÂÖ´&#39;, &#39;ÁßãÁôªÂÖ∞Â±±ÂØÑÂº†‰∫î&#39;, &#39;Êπñ‰∏≠ÊóÖÊ≥äÔºåÂØÑÈòé‰πùÂè∏Êà∑Èò≤&#39;], dtype=&#39;&lt;U17&#39;) . Let&#39;s look at the minimum length of titles. . np.min(arr_len) . 4 . Or maximum. . np.max(arr_len) . 17 . Basic Plotting . We can also do some basic plotting using matplotlib. But we first need to import the library. . Understanding more about matplotlib: https://www.youtube.com/watch?v=qErBw-R2Ybk . ### Histogram | . import matplotlib.pyplot as plt # Histogram plt.hist(arr_len, bins=[2, 5, 10, 20], width=1) . (array([1., 2., 3.]), array([ 2, 5, 10, 20]), &lt;a list of 3 Patch objects&gt;) . It might not be helpful using little titles, but the principle is the same if we have thousands of items. . It can be demonstrated by creating some random numbers. . lengths = np.arange(0,30) lengths . array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]) . import random # choose 1000 samples times another 1000 samples list2_ = np.array(random.choices(lengths, k=1000))*np.array(random.choices(lengths, k=1000)) list2_ . import matplotlib.pyplot as plt plt.hist(list2_) . (array([347., 182., 129., 89., 78., 60., 42., 43., 17., 13.]), array([ 0. , 84.1, 168.2, 252.3, 336.4, 420.5, 504.6, 588.7, 672.8, 756.9, 841. ]), &lt;a list of 10 Patch objects&gt;) . ### Bar Chart | . We can improve the layout of the plot, such as adding xlabel, ylabel, a title, and change colors and so on. . plt.figure(figsize=(12,5)) # define the size of the plot plt.hist(list2_, color=&quot;green&quot;, orientation=&#39;horizontal&#39;) # color is an argument for color, this time we make it horizontal plt.grid(color=&#39;r&#39;, linestyle=&#39;--&#39;, linewidth=0.25, alpha=0.8) # add grid lines plt.ylabel(&quot;Numbers&quot;) plt.xlabel(&quot;Frequency&quot;) plt.title(&quot;Title&quot;, fontsize=18) . Text(0.5, 1.0, &#39;Title&#39;) . There are also many more different types for plotting. For example: . plt.bar([1,2,3,4,5], arr_len, width=0.5) plt.xlabel(&quot;ID&quot;) plt.ylabel(&quot;Lengths&quot;) . Text(0, 0.5, &#39;Lengths&#39;) . ### Line Chart | . Year = [1920,1930,1940,1950,1960,1970,1980,1990,2000,2010] Rate = [9.8,12,8,7.2,6.9,7,6.5,6.2,5.5,6.3] plt.plot(Year, Rate, color=&quot;red&quot;) plt.xlabel(&quot;Year&quot;) plt.ylabel(&quot;Rate&quot;) plt.grid(alpha=0.5) # alpha means transparency (0 to 1), the higher, the more visible . ### Table | . fig, ax = plt.subplots(figsize=(20,6)) # Hide axes ax.xaxis.set_visible(False) ax.yaxis.set_visible(False) ax.axis(&#39;tight&#39;) ax.axis(&#39;off&#39;) # Table data = np.random.random((5,3)) label=(&quot;1997&quot;, &quot;1998&quot;, &quot;1999&quot;) ax.table(cellText=data,colLabels=label,loc=&#39;center&#39;) . &lt;matplotlib.table.Table at 0x7f72c6afccd0&gt; .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/jupyter/2020/01/29/Python_Introduction_Basics.html",
            "relUrl": "/jupyter/2020/01/29/Python_Introduction_Basics.html",
            "date": " ‚Ä¢ Jan 29, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Good Coding Practice üñãÔ∏è",
            "content": ". . Background . Although programming is probably not your primary profession, it is always nice to have good coding practice to avoid unnecessary mistakes and misunderstandings in your projects. Some of the practices are more relevant for professional programmers, but here we mention the more relevant one for users who mostly code for fixed-term research projects. . . Presumption: Not applicable . . . 1) Documentation . RECORD WHAT YOU HAVE DONE &#128195; . Documentation is important. Although you might be really sure what you are doing when you code, most of the time it is not anymore the case when you wake up another morning, after busy time working on other projects or after a nice family trip. Do not need to mentioned if you are looking at your own code from last year. Do always document them, either by writing a comment with #, &quot;&quot;&quot; &quot;&quot;&quot;, or use a Jupyter Notebook and add more texts! . And sometimes you might have a project together with your colleagues, and they also need to understand what you are doing. Or if you are always working alone, then one day you colleagues want to get some insights from the code you wrote. You are not gonna show them and explain everything to them. . So make use of comments! When we write comments, we do not write what is done, we write what is the purpose. For example, if you create a new dataframe with two columns from the old dataframe, it is better to write &quot;extract coordinates and name from historical sites&quot; than &quot;create new dataframe&quot;, bacause the later comment do not give enough context and new information to the readers. . 2) Consistency . KEEP THINGS EASY TO REMEMBER &#129504; . You might not realize it but consistency fits your brain that always search for patterns! If you write your code in a consistent way, it can save you a lot of time running into unnecessary mistakes. . For example, if you name your five dataframes as . dataframe1 | dataframe2 | DataFrame3 | Dataframe4 | Dataframe_5 | . You might forget how did you name your dataframe later, and write dataframe3, or Dataframe_4, which all will run into errors. Consistency applies particularly to capital letters because we have learnt Python is case-sensitive. . You might think you can check it out everytime but it is not handy if you have tens of those variables. It is better that you name them in a consistent way from the first place. . Like: . df1 | df2 | df3 | df4 | df5 | . It also apply when you are writing code instead of naming variable. Because you always have multiple ways to get things done. Stick with the way that is simple and straight-forward! . For example, you have data from three years: . df_2018 = [9.8, 12.6, 15.8] | df_2019 = [5.6, 17.6, 25.1] | df_2020 = np.array([6.5, 11.3, 13.5]) | . . While df_2018 and df_2019 are lists, df_2020 is a Numpy array. Although both data types will work, they are different types and you might not remember it later, and run into errors because you thought the operations that works for df_2018 will also works for df_2020. . So stay consistent! . 3) Naming . KEEP THINGS CLEAN . Also it is important how you name the objects. If you have one dataframe for China, one for Korea and one for Japan. You want to name them in a more informative way, not . df1 | df2 | df3 | . but . df_china | df_japan | df_korea | . . There are different conventions too you would follow, particularly when it comes to combining words. Because Python do not support spaces in variable, you cannot name a data frame &quot;South Korea Data Frame&quot;, but the letters need to be combined in some ways. . . &#128043; Camel Case . Camel case combines words by capitalizing all words following the first word and removing the space, as follows: . Raw: user login count . Camel Case: userLoginCount . . &#128104; Pascal Case . Pascal case combines words by capitalizing all words (even the first word) and removing the space, as follows: . Raw: user login count . Pascal Case: UserLoginCount . . &#128013; Snake Case . Snake case combines words by replacing each space with an underscore (_) and, in the all caps version, all letters are capitalized, as follows: . Raw: user login count . Snake Case: user_login_count . Snake Case (All Caps): USER_LOGIN_COUNT . . &#129369; Kebab Case . Kebab case combines words by replacing each space with a dash (-), as follows: . Raw: user login count . Kebab Case: user-login-count . . There is not the best way how to name your variable, either &quot;dateFrame&quot; or &quot;data-frame&quot;, the more important is that they are used in a consistent way. Also pay attention that abbreviations are recommanded to keep things short but not too much that all others cannot really understand. . 4) Correct Broken Code . GET THINGS FIXED &#128295; . Sometimes things do not work the way we want, they are called bugs. They might not come to your immediate concerns but mark them down and get them fixed as soon as possible. You might even forget in what ways it is broken if you do not fix them timely and it can get worse. . 5) Readability . KEEP THINGS CLEAN, CONCISE AND SIMPLE &#128007; . This is simple. If code does not work, throw them away and do not keep mess. . For example, instead of writing code like below: . urban_history = [&quot;Hong Kong Government Reports Online 1841-1942&quot;,&quot;Policing the Shanghai International Settlement, 1894-1945&quot;,&quot;Virtual Cities Project&quot;] social_history = [&quot;China Families&quot;] # Manchukuo = [&quot;Chinese Posters in Harvard-Yenching Manchukuo Collection&quot;] # try without first # urban_history.insert(social_history,2) (does not work) # # print(urban_history.append(social_history)) (does not work either) urban_history + social_history # this is fine . [&#39;Hong Kong Government Reports Online 1841-1942&#39;, &#39;Policing the Shanghai International Settlement, 1894-1945&#39;, &#39;Virtual Cities Project&#39;, &#39;China Families&#39;] . Keep your &quot;Working Table&quot; clean like this: . urban_history = [&quot;Hong Kong Government Reports Online 1841-1942&quot;,&quot;Policing the Shanghai International Settlement, 1894-1945&quot;,&quot;Virtual Cities Project&quot;] social_history = [&quot;China Families&quot;] # calculation urban_history + social_history . [&#39;Hong Kong Government Reports Online 1841-1942&#39;, &#39;Policing the Shanghai International Settlement, 1894-1945&#39;, &#39;Virtual Cities Project&#39;, &#39;China Families&#39;] . Clean code also mean that your code is readable. For example, try to avoid many operations in one line. Although it also works, it make things hard to read. If there are any small typos, it is often not so easy to spot. . Like: . (NOT recommanded) . import pandas as pd (pd.DataFrame(data={&#39;Name&#39;: [&quot;Hong Kong Government Reports Online 1841-1942&quot;,&quot;Policing the Shanghai International Settlement, 1894-1945&quot;,&quot;Virtual Cities Project&quot;] , &#39;History&#39;: [&quot;urban&quot;,&quot;urban&quot;,&quot;urban&quot;]})).head(1) . Name History . 0 Hong Kong Government Reports Online 1841-1942 | urban | . import pandas as pd (pd.DataFrame(data={&#39;Name&#39;: [&quot;Hong Kong Government Reports Online 1841-1942&quot;,&quot;Policing the Shanghai International Settlement, 1894-1945&quot;,&quot;Virtual Cities Project&quot;] , &#39;History&#39;: [&quot;urban&quot;,&quot;urban&quot;,&quot;urban&quot;]]})).head(1) . File &#34;&lt;ipython-input-10-5139c64437bf&gt;&#34;, line 5 , &#39;History&#39;: [&#34;urban&#34;,&#34;urban&#34;,&#34;urban&#34;]]})).head(1) ^ SyntaxError: invalid syntax . (recommanded) . import pandas as pd # type of history hist_type = [&quot;urban&quot;,&quot;urban&quot;,&quot;urban&quot;] # set up datframe d = {&#39;Name&#39;: urban_history, &#39;History&#39;: hist_type} df = pd.DataFrame(data=d) df.head(1) . Name History . 0 Hong Kong Government Reports Online 1841-1942 | urban | . Happy Coding! . . (Quoted from The Zen of Python, by Tim Peters) . Beautiful is better than ugly. . Explicit is better than implicit. . Simple is better than complex. . Complex is better than complicated. . Readability counts. . If the implementation is hard to explain, it‚Äôs a bad idea. . . . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: December 2021 . . . . References: . https://data-flair.training/blogs/python-best-practices/ . https://betterprogramming.pub/string-case-styles-camel-pascal-snake-and-kebab-case-981407998841 .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/jupyter/2020/01/28/Coding_Practice_Basics.html",
            "relUrl": "/jupyter/2020/01/28/Coding_Practice_Basics.html",
            "date": " ‚Ä¢ Jan 28, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Debugging and Understanding Errors üêû",
            "content": ". . Background . A bug occurs when things do not work the way you want it to, even though Python only give what you ask for. It is because we have a different understandings compared to the programming languages. To resolve this, we need to find out the sources of errors and adjust our code accordingly. In this notebook you will learn different approach to resolve potential issues and some tips to avoid them from happening. . . Presumption: . https://www.w3schools.com/python/python_try_except.asp . https://www.tutorialsteacher.com/python/error-types-in-python . . . 1) Understand Error Messages . As you have seen from the link above, there are many different types of errors in Python which is meant to be helpful to tell user &quot;what is wrong?&quot;. But some errors might be more common than the others. Let&#39;s look at some common errors. . Let&#39;s say you want to add a second collection to the first one (collection). But instead of &quot;collection&quot;, you wrote &quot;Collection&quot;. . In this case Python tells you . NameError: name &#39;Collection&#39; is not defined . It is because Python is searching for &quot;Collection&quot; and cannot find one. . Name Error: Raised when a variable is not found in the local or global scope. . What you need to do it just correct the name. . collection = [&quot;Chinese Posters in Harvard-Yenching Manchukuo Collection&quot;] Collection + [&quot;Linked Archive of Asian Postcards&quot;] . NameError Traceback (most recent call last) &lt;ipython-input-3-cba7c442d3f4&gt; in &lt;module&gt;() 1 collection = [&#34;Chinese Posters in Harvard-Yenching Manchukuo Collection&#34;] 2 -&gt; 3 Collection + [&#34;Linked Archive of Asian Postcards&#34;] NameError: name &#39;Collection&#39; is not defined . Error occurs too when the library is not imported before use. . np.max([1,2]) . NameError Traceback (most recent call last) &lt;ipython-input-6-9be6f90ccf89&gt; in &lt;module&gt;() -&gt; 1 np.arange(1,5) NameError: name &#39;np&#39; is not defined . Or when you have one item in list while you are asking for the second one (Remember Python starts with 0). You get: . IndexError: list index out of range . Index Error: Raised when the index of a sequence is out of range. . Then you need to correct the index. . collection = [&quot;Chinese Posters in Harvard-Yenching Manchukuo Collection&quot;] collection[1] . IndexError Traceback (most recent call last) &lt;ipython-input-4-e10b1e230939&gt; in &lt;module&gt;() 1 collection = [&#34;Chinese Posters in Harvard-Yenching Manchukuo Collection&#34;] 2 -&gt; 3 collection[1] IndexError: list index out of range . There is also Type Error: Raised when a function or operation is applied to an object of an incorrect type. . It occurs because np.max() looks for a number and we input a string. . import numpy as np np.max([3]) # this works . 3 . import numpy as np np.max([collection]) . TypeError Traceback (most recent call last) &lt;ipython-input-11-9da63d4b2b0e&gt; in &lt;module&gt;() 1 import numpy as np -&gt; 2 np.max([collection]) &lt;__array_function__ internals&gt; in amax(*args, **kwargs) /usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py in amax(a, axis, out, keepdims, initial, where) 2704 &#34;&#34;&#34; 2705 return _wrapreduction(a, np.maximum, &#39;max&#39;, axis, None, out, -&gt; 2706 keepdims=keepdims, initial=initial, where=where) 2707 2708 /usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py in _wrapreduction(obj, ufunc, method, axis, dtype, out, **kwargs) 85 return reduction(axis=axis, out=out, **passkwargs) 86 &gt; 87 return ufunc.reduce(obj, axis, dtype, out, **passkwargs) 88 89 TypeError: cannot perform reduce with flexible type . Another error that is really common is that when you type something grammatically wrong in the Python sense. . Syntax Error: Raised by the parser when a syntax error is encountered. . collection = [&quot;Chinese Posters in Harvard-Yenching Manchukuo Collection&quot;] collection[0) # it should be [0], not[0) . File &#34;&lt;ipython-input-18-011172c21475&gt;&#34;, line 3 collection[0) ^ SyntaxError: invalid syntax . 2) Spot the Sources of Errors . In order to make errors easier to spot, it is always a good practice if you run only a small chunk of code in a time. For example, you call separate a long chunk of code into different cells. . Every cell can be used for one main action, for example: . . . . . Another way to spot errors in code is that try to reduce the code you have. For example: . Let&#39;s say you want to find out the length of the first advertisement in the list (ÂïÜÂãôÂç∞Êõ∏È§®ÁôºË°åÊõ∏ÁõÆ‰ªãÁ¥π), and you built a function for it. But instead of 11 characters, you get 2. . Although there is no problems running this code, as it is not giving you what you want, it is also a bug. . What you can do is to reduce the code and to see if things work the way you want. . ad = [&quot;ÂïÜÂãôÂç∞Êõ∏È§®ÁôºË°åÊõ∏ÁõÆ‰ªãÁ¥π&quot;,&quot;Â•≥ÁïåÂØ∂„ÄÅÈùûÊ¥≤Ê®πÁöÆ‰∏∏„ÄÅÂä©ËÇ∫ÂëºÂê∏È¶ôËÜ†„ÄÅÂÆ∂ÊôÆÈ≠öËÇùÊ≤π„ÄÅÊ∏ÖË°ÄËß£ÊØíÊµ∑Ê≥¢Ëó•„ÄÅÁ¥ç‰ΩõË£úÂ§©Ê±Å„ÄÅËâØ‰∏π(‰∫îÊ¥≤Â§ßËó•Êàø)&quot;] import re # this you will learn in the notebook web scrapping so you do not need to understand everything for now def number_of_character(text): list_ = list(text) # list() is used to split words into a list of characters length = len(list_) # len() is to check the length return length number_of_character(ad) . 2 . Let&#39;s check the first step: Can we use list to split the characters as we want? . list(ad) . [&#39;ÂïÜÂãôÂç∞Êõ∏È§®ÁôºË°åÊõ∏ÁõÆ‰ªãÁ¥π&#39;, &#39;Â•≥ÁïåÂØ∂„ÄÅÈùûÊ¥≤Ê®πÁöÆ‰∏∏„ÄÅÂä©ËÇ∫ÂëºÂê∏È¶ôËÜ†„ÄÅÂÆ∂ÊôÆÈ≠öËÇùÊ≤π„ÄÅÊ∏ÖË°ÄËß£ÊØíÊµ∑Ê≥¢Ëó•„ÄÅÁ¥ç‰ΩõË£úÂ§©Ê±Å„ÄÅËâØ‰∏π(‰∫îÊ¥≤Â§ßËó•Êàø)&#39;] . And we realize, we want to split ÂïÜÂãôÂç∞Êõ∏È§®ÁôºË°åÊõ∏ÁõÆ‰ªãÁ¥π, but this is not done! . list(&quot;advertisement&quot;) # this is what we want, to split characters . [&#39;a&#39;, &#39;d&#39;, &#39;v&#39;, &#39;e&#39;, &#39;r&#39;, &#39;t&#39;, &#39;i&#39;, &#39;s&#39;, &#39;e&#39;, &#39;m&#39;, &#39;e&#39;, &#39;n&#39;, &#39;t&#39;] . And then we might find out, it only work if we use ad[0] instead. . list(ad[0]) . [&#39;ÂïÜ&#39;, &#39;Âãô&#39;, &#39;Âç∞&#39;, &#39;Êõ∏&#39;, &#39;È§®&#39;, &#39;Áôº&#39;, &#39;Ë°å&#39;, &#39;Êõ∏&#39;, &#39;ÁõÆ&#39;, &#39;‰ªã&#39;, &#39;Á¥π&#39;] . ad = [&quot;ÂïÜÂãôÂç∞Êõ∏È§®ÁôºË°åÊõ∏ÁõÆ‰ªãÁ¥π&quot;,&quot;Â•≥ÁïåÂØ∂„ÄÅÈùûÊ¥≤Ê®πÁöÆ‰∏∏„ÄÅÂä©ËÇ∫ÂëºÂê∏È¶ôËÜ†„ÄÅÂÆ∂ÊôÆÈ≠öËÇùÊ≤π„ÄÅÊ∏ÖË°ÄËß£ÊØíÊµ∑Ê≥¢Ëó•„ÄÅÁ¥ç‰ΩõË£úÂ§©Ê±Å„ÄÅËâØ‰∏π(‰∫îÊ¥≤Â§ßËó•Êàø)&quot;] import re # this you will learn in the notebook web scrapping so you do not need to understand everything for now def number_of_character(text): list_ = list(text) length = len(list_) return length number_of_character(ad[0]) . 11 . 3) Google and stackoverflow . Sometimes errors are not so clear to you. What you can do is to copy the errors and Google them. Stackoverflow is also another website that can be really helpful. . collection = [&quot;Chinese Posters in Harvard-Yenching Manchukuo Collection&quot;, &quot;Linked Archive of Asian Postcards&quot;] typ = [1,0] collection[typ] . TypeError Traceback (most recent call last) &lt;ipython-input-13-9eca3a76ef67&gt; in &lt;module&gt;() 2 typ = [1,0] 3 -&gt; 4 collection[typ] TypeError: list indices must be integers or slices, not list . Then you might find out what you need to select collection item from typ is to use Numpy array instead of list. . collection = np.array([&quot;Chinese Posters in Harvard-Yenching Manchukuo Collection&quot;, &quot;Linked Archive of Asian Postcards&quot;]) typ = np.array([1,0]) collection[typ] . array([&#39;Linked Archive of Asian Postcards&#39;, &#39;Chinese Posters in Harvard-Yenching Manchukuo Collection&#39;], dtype=&#39;&lt;U56&#39;) . 4) Use Try and Except . In order to avoid errors, what we can also do is to use try and except. It means asking Python to try something out, if it does not work, then do Plan B instead of giving you errors. . Be careful that this method only appy if the errors come from unexpected outliners in inputs. It will not give you any meaningful results if the errors lie in your code itself. . . It works as follow: . try: . (do plan a) # &lt;- indented block . except: . (do plan b) # &lt;- indented block . try: print(1+1) except: print(0) . 2 . . For example, the same function work well for the first and second item, but there is a typo in the third item, so that it is not a string, but an integer. . In this case, the function will not work as it expects a string. . collection = [&quot;Chinese Posters in Harvard-Yenching Manchukuo Collection&quot;, &quot;Linked Archive of Asian Postcards&quot;, 4] . def number_of_character(text): list_ = list(text) length = len(list_) return length number_of_character(collection[2]) . TypeError Traceback (most recent call last) &lt;ipython-input-50-b4200bdffa93&gt; in &lt;module&gt;() 4 return length 5 -&gt; 6 number_of_character(collection[2]) &lt;ipython-input-50-b4200bdffa93&gt; in number_of_character(text) 1 def number_of_character(text): -&gt; 2 list_ = list(text) 3 length = len(list_) 4 return length 5 TypeError: &#39;int&#39; object is not iterable . What we can do is to set up a Plan B: . If the words cannot be split, then use an empty list ([]). . . OUR PLAN B . except: . list_ = [] . def number_of_character(text): try: list_ = list(text) except: list_ = [] length = len(list_) return length number_of_character(collection[2]) . 0 . Now, we do not get the same error anymore. It is particularly useful when we are automating the task: because if we want going through thousands of documents, we do not want the code to crash because of one little typo. . 5) Check Documentation . If the errors come from your code itself, the easiest way to inspect the problems is to check the documentation of the function you used. If you are using Jupyter Notebook, you can always highlight the function you typed and the documentation of this function will appear, illustrating what inputs are expected. . You can also choose to directly Google the function and check the examples. For exmaple, if the following error occurs, by searching the reverse function &quot;python reverse()&quot; we can see from the documentation that the list is expected before the function ad(), not inside the (). . reverse(ad) ad . NameError Traceback (most recent call last) &lt;ipython-input-20-e88da2471207&gt; in &lt;module&gt;() 1 # error -&gt; 2 reverse(ad) 3 ad NameError: name &#39;reverse&#39; is not defined . ad.reverse() ad . [&#39;Â•≥ÁïåÂØ∂„ÄÅÈùûÊ¥≤Ê®πÁöÆ‰∏∏„ÄÅÂä©ËÇ∫ÂëºÂê∏È¶ôËÜ†„ÄÅÂÆ∂ÊôÆÈ≠öËÇùÊ≤π„ÄÅÊ∏ÖË°ÄËß£ÊØíÊµ∑Ê≥¢Ëó•„ÄÅÁ¥ç‰ΩõË£úÂ§©Ê±Å„ÄÅËâØ‰∏π(‰∫îÊ¥≤Â§ßËó•Êàø)&#39;, &#39;ÂïÜÂãôÂç∞Êõ∏È§®ÁôºË°åÊõ∏ÁõÆ‰ªãÁ¥π&#39;] . . . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: December 2021 . . . . References: . https://www.tutorialsteacher.com/python/error-types-in-python .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/jupyter/2020/01/27/Debugging_and_Understanding_Errors_Basics.html",
            "relUrl": "/jupyter/2020/01/27/Debugging_and_Understanding_Errors_Basics.html",
            "date": " ‚Ä¢ Jan 27, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "Functions and Loops",
            "content": ". . For a larger chunk of text analysis, the workflow might get longer and longer which can be unhandy and prone to mistakes. Both functions and loops are ways to &quot;ask for repeated computation&quot;, either by looping through what you have or refering back to code you already wrote (the function). . This notebook aims to introduce users how to use functions and loops in Python using basic text exmaple from the humanity discipline. It aims to provide users basic skills to automate small chunks of text analysis using text resources. . . Presumption: . Functions . Loops . Enumerate . . It is also recommanded that the user has some basic understandings already with Python. . . . ## Functions | . In Python, a function is a group of related statements that performs a specific task. . Functions break our tasks into smaller chunks and make it more manageable. Furthermore, it avoids repetition and makes the code reusable. It is very helful when the workflow (task) need to be repeated done (Get information from a long list of document or webpages) so the user do not need to specify everything for multiple times to execute the task. It is also less prone to mistakes as users do not need to code everytime. . A function is started with the keyword def. Once the function is defined, it can be called by typing the function name with appropriate parameters. . . Remark: . Both # and &quot;&quot;&quot; &quot;&quot;&quot; in the code are comments and will not run in Python. . . Example of a function: . import datetime # define funciton def getTime(n): # name and input &quot;&quot;&quot; This function acquire future days from now &quot;&quot;&quot; day = datetime.datetime.now() + datetime.timedelta(days=n) # action return str(day) # output # call function getTime(1) . &#39;2021-12-10 20:06:05.499284&#39; . &#23142;&#22899;&#38620;&#35468;&#24291;&#21578; (Advertisements from Chinese Womens Magazine) . This is the subset of the advertisements published in Â©¶Â•≥ÈõúË™å1915Âπ¥ Á¨¨01Êúü. . Let&#39;s say we want to know if the advertistment is published form a ÂÖ¨Âè∏. . ad = [&quot;ÂïÜÂãôÂç∞Êõ∏È§®ÁôºË°åÊõ∏ÁõÆ‰ªãÁ¥π&quot;,&quot;Â•≥ÁïåÂØ∂„ÄÅÈùûÊ¥≤Ê®πÁöÆ‰∏∏„ÄÅÂä©ËÇ∫ÂëºÂê∏È¶ôËÜ†„ÄÅÂÆ∂ÊôÆÈ≠öËÇùÊ≤π„ÄÅÊ∏ÖË°ÄËß£ÊØíÊµ∑Ê≥¢Ëó•„ÄÅÁ¥ç‰ΩõË£úÂ§©Ê±Å„ÄÅËâØ‰∏π(‰∫îÊ¥≤Â§ßËó•Êàø)&quot;,&quot;Ê≥∞Ë±êÁΩêÈ†≠È£üÂìÅÊúâÈôêÂÖ¨Âè∏Ë£ΩÈÄ†Âª†ÊîùÂΩ±&quot;,&quot;Ê≠¶ÈÄ≤ËéäËã£Âè≤Â•≥Â£´ËèäËä±ÂØíËèúÂØ´Áîü&quot;,&quot;‰∏≠ËèØÁúºÈè°ÂÖ¨Âè∏&quot;,&quot;‰∏≠Â∞áÊπØ(Êù±‰∫ûÂÖ¨Âè∏Á∂ìÁêÜÊâπÁôº)&quot;] . import re # this you will learn in the notebook web scrapping so you do not need to understand everything for now def ad_check(text): # but you need to know the function start with def, the name of the function, and a () with/ without argument(s) inside. pattern = re.compile(r&#39;ÂÖ¨Âè∏&#39;) # inside the function you need to indent every line (with a tab) match = any(pattern.findall(text)) # you somehow get to the result (desired output) return match # and you return them (typically in a variable) . Now we can apply the function using our ad list. We can only pass a string in the function so we need to slice the item. For example, we can check on the first advertisement in list. . ad_check(ad[0]) . False . It returns False, a boolean meaning the word &quot;ÂÖ¨Âè∏&quot; cannot be found. Now we check on the third item. . ad_check(ad[2]) . True . True is returned, meaning the keyword is found. So now we do not need to type the whole function everytime we want to check for an ad. . . ## Loops | . In fact, we can even automate all ads using a loop. A loop can be very simple, but can get complicated if multiple elements are looped in parallel or when it is nested (loop inside another loop). . Here we use a simple for loop: it is started with a &quot;for (something) in (something):&quot;, and followed by the next line(s) (all operations needed). All lines under the loop needed to be indented. . It basically tells Python: . . For the item (i) in my list (ad), . apply the function using input item (i) . and print the result before the next round (item) . for i in ad: # i is the item you name, ad is our list print(ad_check(i)) # action . False False True False True True . Sometime when we loop, we do not want to loop using the item itself, but the index of our item (For example, here let&#39;s say we want to print the index of the company found). Then we can do it in the following way: . len(ad) # first we found the len of our list . 6 . np.arange(len(ad)) # then we generate a sequence with the same length . array([0, 1, 2, 3, 4, 5]) . This is then the index we loop through instead of the item. . . Remark: . ad_check(ad[i]) is the same as ad_check(ad[i]) == True but the first way is more efficient to run in Python. . (ad_check(ad[i])) == (ad_check(ad[i]) == True) . True . for i in np.arange(len(ad)): # loop tho index if ad_check(ad[i]): # provide a condition: only print when it is true print(i,&quot;. &quot;,ad[i]) # print the index and the item . 2 . Ê≥∞Ë±êÁΩêÈ†≠È£üÂìÅÊúâÈôêÂÖ¨Âè∏Ë£ΩÈÄ†Âª†ÊîùÂΩ± 4 . ‰∏≠ËèØÁúºÈè°ÂÖ¨Âè∏ 5 . ‰∏≠Â∞áÊπØ(Êù±‰∫ûÂÖ¨Âè∏Á∂ìÁêÜÊâπÁôº) . Nonetheless, print the results is not very helpful because it is not stored in a variable and we cannot recall them. A helpful way is to stored them in another list. . Before we try to store them into our list, we need to first define it, as an empty list. . check_list = [] # define our output list for i in ad: # for loop again check_list.append(ad_check(i)) # now we use append (adding element at the end of the list) to put our result every round . check_list . [False, False, True, False, True, True] . Now we know the keyword is found in 3rd, 5th, 6th ads. We can print out the company ads. This can be better done using numpy array. so we will first convert both lists to arrays. . import numpy as np # always need to import library first ad = np.array(ad) # convert using np.array() check_list = np.array(check_list) ad[check_list] # slice ad using checklist, it only works when the check_list consists boolean (True and False, or 1 and 0) . array([&#39;Ê≥∞Ë±êÁΩêÈ†≠È£üÂìÅÊúâÈôêÂÖ¨Âè∏Ë£ΩÈÄ†Âª†ÊîùÂΩ±&#39;, &#39;‰∏≠ËèØÁúºÈè°ÂÖ¨Âè∏&#39;, &#39;‰∏≠Â∞áÊπØ(Êù±‰∫ûÂÖ¨Âè∏Á∂ìÁêÜÊâπÁôº)&#39;], dtype=&#39;&lt;U46&#39;) . We also need to be careful that looping is considered an inefficient way to get things done in Python, so if we can get the job done without loop, then it is better we do it without. . . ## Enumerate | . Sometimes, we do not only want to loop through the items, but also the indices of the item so we want do some further operations. In the above example we use a loop of index to print all the items with &quot;ÂÖ¨Âè∏&quot;. . 2 . Ê≥∞Ë±êÁΩêÈ†≠È£üÂìÅÊúâÈôêÂÖ¨Âè∏Ë£ΩÈÄ†Âª†ÊîùÂΩ± 4 . ‰∏≠ËèØÁúºÈè°ÂÖ¨Âè∏ 5 . ‰∏≠Â∞áÊπØ(Êù±‰∫ûÂÖ¨Âè∏Á∂ìÁêÜÊâπÁôº) . However, we can use enumerate() instead which is a more efficient approach. It provides us two numbers: the first one is index starting from 0, another one is the item itself. . for count, value in enumerate(ad): print(count, value) . 0 ÂïÜÂãôÂç∞Êõ∏È§®ÁôºË°åÊõ∏ÁõÆ‰ªãÁ¥π 1 Â•≥ÁïåÂØ∂„ÄÅÈùûÊ¥≤Ê®πÁöÆ‰∏∏„ÄÅÂä©ËÇ∫ÂëºÂê∏È¶ôËÜ†„ÄÅÂÆ∂ÊôÆÈ≠öËÇùÊ≤π„ÄÅÊ∏ÖË°ÄËß£ÊØíÊµ∑Ê≥¢Ëó•„ÄÅÁ¥ç‰ΩõË£úÂ§©Ê±Å„ÄÅËâØ‰∏π(‰∫îÊ¥≤Â§ßËó•Êàø) 2 Ê≥∞Ë±êÁΩêÈ†≠È£üÂìÅÊúâÈôêÂÖ¨Âè∏Ë£ΩÈÄ†Âª†ÊîùÂΩ± 3 Ê≠¶ÈÄ≤ËéäËã£Âè≤Â•≥Â£´ËèäËä±ÂØíËèúÂØ´Áîü 4 ‰∏≠ËèØÁúºÈè°ÂÖ¨Âè∏ 5 ‰∏≠Â∞áÊπØ(Êù±‰∫ûÂÖ¨Âè∏Á∂ìÁêÜÊâπÁôº) . The following code give use exactly the same result as the above example: . In this case, both codes do not seem to make a difference, however, in other case, using enumerate() is much more efficient and allows use to write much shorter code. . for count, value in enumerate(ad): if ad_check(value): print(count, &#39;.&#39;, value) . 2 . Ê≥∞Ë±êÁΩêÈ†≠È£üÂìÅÊúâÈôêÂÖ¨Âè∏Ë£ΩÈÄ†Âª†ÊîùÂΩ± 4 . ‰∏≠ËèØÁúºÈè°ÂÖ¨Âè∏ 5 . ‰∏≠Â∞áÊπØ(Êù±‰∫ûÂÖ¨Âè∏Á∂ìÁêÜÊâπÁôº) . . . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: December 2021 . . . . References: . https://mhdb.mh.sinica.edu.tw/fnzz/view.php?book=1501&amp;str=%E5%A9%A6%E5%A5%B3 .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/jupyter/2020/01/26/FunctionsNLoops_Basics.html",
            "relUrl": "/jupyter/2020/01/26/FunctionsNLoops_Basics.html",
            "date": " ‚Ä¢ Jan 26, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "List Comprehension",
            "content": ". Presumption: . List Comprehension . Dictionary . Tuples . zip() . . Below we use a short list of local gazetteers from LoGaRT as our example. . gazetteer = [&quot;Â§©‰∏ã‰∏ÄÁµ±Âøó(Êòé)&quot;,&quot;Â§ßÊòé‰∏ÄÁµ±Âøó(Êòé)&quot;,&quot;ÂòâÂñÑÁ∏£Âøó(Êòé)&quot;,&quot;ÈõçÂ§ßË®òÂçóÁïøÂøó(Êòé)&quot;,&quot;‰∏äÊµ∑Á∏£Âøó(Êòé)&quot;,&quot;ÂÖ®ÈÅºÂøó(Êòé)&quot;,&quot;Âñ¨‰∏âÁü≥ËÄÄÂ∑ûÂøó(Êòé)&quot;,&quot;ÂÆ£Â∫úÈéÆÂøó(Êòé)&quot;,&quot;Èõ≤ÂçóÈÄöÂøó(Êòé)&quot;,&quot;Â§ßÊòé‰∏ÄÁµ±ÂøóËºØÈåÑ(Êòé)&quot;,&quot;Èõ≤‰∏≠ÈÉ°Âøó(Ê∏Ö)&quot;] . import re # this you will learn in the notebook web scrapping so you do not need to understand everything for now def str_check(text): # but you need to know the function start with def, the name of the function, and a () with/ without argument(s) inside. pattern = re.compile(r&#39;Êòé&#39;) # inside the function you need to indent every line (with a tab) match = any(pattern.findall(text)) # you somehow get to the result (desired output) return match # and you return them (typically in a variable) . Suppose we need all the local gazetteers from Êòé only. What we can do is to build a function (there is another easier option using Pandas but now we stick with this function). And then we can print all results which fit the condition. . . The structure of list comprehension is: . [ ] &lt;- in a list &lt;- key components . (name1) for (name2) in &lt;- for and in are keywords, (name2) is the variable name to be assigned for the item in loop, (name1) is the output you want, which should be expressed in terms of (name1) . (list) &lt;- the variable which stores all the items or the list to be loop through . if (condition) &lt;- add a condition, this part is optional . . Remarks: (name1) and (name2) can be the same but do not need to be . [x for x in gazetteer if str_check(x)] # if ad_check(x) is the same as if ad_check(x) == True . [&#39;Â§©‰∏ã‰∏ÄÁµ±Âøó(Êòé)&#39;, &#39;Â§ßÊòé‰∏ÄÁµ±Âøó(Êòé)&#39;, &#39;ÂòâÂñÑÁ∏£Âøó(Êòé)&#39;, &#39;ÈõçÂ§ßË®òÂçóÁïøÂøó(Êòé)&#39;, &#39;‰∏äÊµ∑Á∏£Âøó(Êòé)&#39;, &#39;ÂÖ®ÈÅºÂøó(Êòé)&#39;, &#39;Âñ¨‰∏âÁü≥ËÄÄÂ∑ûÂøó(Êòé)&#39;, &#39;ÂÆ£Â∫úÈéÆÂøó(Êòé)&#39;, &#39;Èõ≤ÂçóÈÄöÂøó(Êòé)&#39;, &#39;Â§ßÊòé‰∏ÄÁµ±ÂøóËºØÈåÑ(Êòé)&#39;] . We can also save the list to another new list. . ming_gazetteer = [x for x in gazetteer if str_check(x)] ming_gazetteer . [&#39;Â§©‰∏ã‰∏ÄÁµ±Âøó(Êòé)&#39;, &#39;Â§ßÊòé‰∏ÄÁµ±Âøó(Êòé)&#39;, &#39;ÂòâÂñÑÁ∏£Âøó(Êòé)&#39;, &#39;ÈõçÂ§ßË®òÂçóÁïøÂøó(Êòé)&#39;, &#39;‰∏äÊµ∑Á∏£Âøó(Êòé)&#39;, &#39;ÂÖ®ÈÅºÂøó(Êòé)&#39;, &#39;Âñ¨‰∏âÁü≥ËÄÄÂ∑ûÂøó(Êòé)&#39;, &#39;ÂÆ£Â∫úÈéÆÂøó(Êòé)&#39;, &#39;Èõ≤ÂçóÈÄöÂøó(Êòé)&#39;, &#39;Â§ßÊòé‰∏ÄÁµ±ÂøóËºØÈåÑ(Êòé)&#39;] . We can also change the outputs: for example, instead of the item itself, we want to get the lengths of the strings which fit the same condition: . [len(x) for x in gazetteer if str_check(x)] . [8, 8, 7, 9, 7, 6, 9, 7, 7, 10] . [x for x in gazetteer if str_check(x)] . [&#39;Â§©‰∏ã‰∏ÄÁµ±Âøó(Êòé)&#39;, &#39;Â§ßÊòé‰∏ÄÁµ±Âøó(Êòé)&#39;, &#39;ÂòâÂñÑÁ∏£Âøó(Êòé)&#39;, &#39;ÈõçÂ§ßË®òÂçóÁïøÂøó(Êòé)&#39;, &#39;‰∏äÊµ∑Á∏£Âøó(Êòé)&#39;, &#39;ÂÖ®ÈÅºÂøó(Êòé)&#39;, &#39;Âñ¨‰∏âÁü≥ËÄÄÂ∑ûÂøó(Êòé)&#39;, &#39;ÂÆ£Â∫úÈéÆÂøó(Êòé)&#39;, &#39;Èõ≤ÂçóÈÄöÂøó(Êòé)&#39;, &#39;Â§ßÊòé‰∏ÄÁµ±ÂøóËºØÈåÑ(Êòé)&#39;] . We can also combine list comprehension with any functions from any library. For example, we want to get the piyin of the items in our list. We can use library pinyin for that. . ! pip install pinyin # install library import pinyin # import library . [pinyin.get(x, format=&quot;strip&quot;, delimiter=&quot; &quot;) for x in gazetteer] # get the pinyin for all items . [&#39;tian xia yi tong zhi ( ming )&#39;, &#39;da ming yi tong zhi ( ming )&#39;, &#39;jia shan xian zhi ( ming )&#39;, &#39;yong da ji nan ji zhi ( ming )&#39;, &#39;shang hai xian zhi ( ming )&#39;, &#39;quan liao zhi ( ming )&#39;, &#39;qiao san shi yao zhou zhi ( ming )&#39;, &#39;xuan fu zhen zhi ( ming )&#39;, &#39;yun nan tong zhi ( ming )&#39;, &#39;da ming yi tong zhi ji lu ( ming )&#39;, &#39;yun zhong jun zhi ( qing )&#39;] . [pinyin.get(x, format=&quot;strip&quot;, delimiter=&quot; &quot;) for x in gazetteer if str_check(x)] # get the pinyin for all items from ming . [&#39;tian xia yi tong zhi ( ming )&#39;, &#39;da ming yi tong zhi ( ming )&#39;, &#39;jia shan xian zhi ( ming )&#39;, &#39;yong da ji nan ji zhi ( ming )&#39;, &#39;shang hai xian zhi ( ming )&#39;, &#39;quan liao zhi ( ming )&#39;, &#39;qiao san shi yao zhou zhi ( ming )&#39;, &#39;xuan fu zhen zhi ( ming )&#39;, &#39;yun nan tong zhi ( ming )&#39;, &#39;da ming yi tong zhi ji lu ( ming )&#39;] . Apart from that, we can also combine the index using enumerate() (we have learnt it from the previous lesson). . Remember that enumerate() return two values as we need two names between the keywords &quot;for&quot; and &quot;in&quot;! . [print(index,pinyin.get(item, format=&quot;strip&quot;, delimiter=&quot; &quot;)) for index, item in enumerate(gazetteer)] # get the pinyin with indices for all items . 0 tian xia yi tong zhi ( ming ) 1 da ming yi tong zhi ( ming ) 2 jia shan xian zhi ( ming ) 3 yong da ji nan ji zhi ( ming ) 4 shang hai xian zhi ( ming ) 5 quan liao zhi ( ming ) 6 qiao san shi yao zhou zhi ( ming ) 7 xuan fu zhen zhi ( ming ) 8 yun nan tong zhi ( ming ) 9 da ming yi tong zhi ji lu ( ming ) 10 yun zhong jun zhi ( qing ) . [None, None, None, None, None, None, None, None, None, None, None] . [print(index,pinyin.get(item, format=&quot;strip&quot;, delimiter=&quot; &quot;)) for index, item in enumerate(gazetteer) if index in [1,3]] . 1 da ming yi tong zhi ( ming ) 3 yong da ji nan ji zhi ( ming ) . [None, None] . [print(index,pinyin.get(item, format=&quot;strip&quot;, delimiter=&quot; &quot;)) for index, item in enumerate(gazetteer) if index not in [0]] . 1 da ming yi tong zhi ( ming ) 2 jia shan xian zhi ( ming ) 3 yong da ji nan ji zhi ( ming ) 4 shang hai xian zhi ( ming ) 5 quan liao zhi ( ming ) 6 qiao san shi yao zhou zhi ( ming ) 7 xuan fu zhen zhi ( ming ) 8 yun nan tong zhi ( ming ) 9 da ming yi tong zhi ji lu ( ming ) 10 yun zhong jun zhi ( qing ) . [None, None, None, None, None, None, None, None, None, None] . There are numerous options what we can do using list comprehension. Another example demonsrating the functionality of list comprehension is word frequency count: searching for the keywords which appears in the top frequencies. . First, we join all the items to a single list and then split all Chinese character using list() after removing () using replace(). . string = &#39;&#39;.join(gazetteer) # join all items in list to a single string string = string.replace(&quot;(&quot;, &quot;&quot;).replace(&quot;)&quot;, &quot;&quot;) # replace &quot;(&quot; and &quot;)&quot; to nothing &quot;&quot; wordlist = list(string) # split all Chinese characters wordlist[:5] # print first 5 characters . [&#39;Â§©&#39;, &#39;‰∏ã&#39;, &#39;‰∏Ä&#39;, &#39;Áµ±&#39;, &#39;Âøó&#39;] . Now we use list comprehension to count all characters. . wordfreq = [wordlist.count(w) for w in wordlist] # list comprehension to count all characters # print the single string print(&quot;String n&quot; + string +&quot; n&quot;) # n means new line # print a list of all characters print(&quot;List n&quot; + str(wordlist) + &quot; n&quot;) # print frequencies print(&quot;Frequencies n&quot; + str(wordfreq) + &quot; n&quot;) # print zip objects by combining characters and occurences print(&quot;Pairs n&quot; + str(list(zip(wordlist, wordfreq)))) . String Â§©‰∏ã‰∏ÄÁµ±ÂøóÊòéÂ§ßÊòé‰∏ÄÁµ±ÂøóÊòéÂòâÂñÑÁ∏£ÂøóÊòéÈõçÂ§ßË®òÂçóÁïøÂøóÊòé‰∏äÊµ∑Á∏£ÂøóÊòéÂÖ®ÈÅºÂøóÊòéÂñ¨‰∏âÁü≥ËÄÄÂ∑ûÂøóÊòéÂÆ£Â∫úÈéÆÂøóÊòéÈõ≤ÂçóÈÄöÂøóÊòéÂ§ßÊòé‰∏ÄÁµ±ÂøóËºØÈåÑÊòéÈõ≤‰∏≠ÈÉ°ÂøóÊ∏Ö List [&#39;Â§©&#39;, &#39;‰∏ã&#39;, &#39;‰∏Ä&#39;, &#39;Áµ±&#39;, &#39;Âøó&#39;, &#39;Êòé&#39;, &#39;Â§ß&#39;, &#39;Êòé&#39;, &#39;‰∏Ä&#39;, &#39;Áµ±&#39;, &#39;Âøó&#39;, &#39;Êòé&#39;, &#39;Âòâ&#39;, &#39;ÂñÑ&#39;, &#39;Á∏£&#39;, &#39;Âøó&#39;, &#39;Êòé&#39;, &#39;Èõç&#39;, &#39;Â§ß&#39;, &#39;Ë®ò&#39;, &#39;Âçó&#39;, &#39;Áïø&#39;, &#39;Âøó&#39;, &#39;Êòé&#39;, &#39;‰∏ä&#39;, &#39;Êµ∑&#39;, &#39;Á∏£&#39;, &#39;Âøó&#39;, &#39;Êòé&#39;, &#39;ÂÖ®&#39;, &#39;ÈÅº&#39;, &#39;Âøó&#39;, &#39;Êòé&#39;, &#39;Âñ¨&#39;, &#39;‰∏â&#39;, &#39;Áü≥&#39;, &#39;ËÄÄ&#39;, &#39;Â∑û&#39;, &#39;Âøó&#39;, &#39;Êòé&#39;, &#39;ÂÆ£&#39;, &#39;Â∫ú&#39;, &#39;ÈéÆ&#39;, &#39;Âøó&#39;, &#39;Êòé&#39;, &#39;Èõ≤&#39;, &#39;Âçó&#39;, &#39;ÈÄö&#39;, &#39;Âøó&#39;, &#39;Êòé&#39;, &#39;Â§ß&#39;, &#39;Êòé&#39;, &#39;‰∏Ä&#39;, &#39;Áµ±&#39;, &#39;Âøó&#39;, &#39;ËºØ&#39;, &#39;ÈåÑ&#39;, &#39;Êòé&#39;, &#39;Èõ≤&#39;, &#39;‰∏≠&#39;, &#39;ÈÉ°&#39;, &#39;Âøó&#39;, &#39;Ê∏Ö&#39;] Frequencies [1, 1, 3, 3, 11, 12, 3, 12, 3, 3, 11, 12, 1, 1, 2, 11, 12, 1, 3, 1, 2, 1, 11, 12, 1, 1, 2, 11, 12, 1, 1, 11, 12, 1, 1, 1, 1, 1, 11, 12, 1, 1, 1, 11, 12, 2, 2, 1, 11, 12, 3, 12, 3, 3, 11, 1, 1, 12, 2, 1, 1, 11, 1] Pairs [(&#39;Â§©&#39;, 1), (&#39;‰∏ã&#39;, 1), (&#39;‰∏Ä&#39;, 3), (&#39;Áµ±&#39;, 3), (&#39;Âøó&#39;, 11), (&#39;Êòé&#39;, 12), (&#39;Â§ß&#39;, 3), (&#39;Êòé&#39;, 12), (&#39;‰∏Ä&#39;, 3), (&#39;Áµ±&#39;, 3), (&#39;Âøó&#39;, 11), (&#39;Êòé&#39;, 12), (&#39;Âòâ&#39;, 1), (&#39;ÂñÑ&#39;, 1), (&#39;Á∏£&#39;, 2), (&#39;Âøó&#39;, 11), (&#39;Êòé&#39;, 12), (&#39;Èõç&#39;, 1), (&#39;Â§ß&#39;, 3), (&#39;Ë®ò&#39;, 1), (&#39;Âçó&#39;, 2), (&#39;Áïø&#39;, 1), (&#39;Âøó&#39;, 11), (&#39;Êòé&#39;, 12), (&#39;‰∏ä&#39;, 1), (&#39;Êµ∑&#39;, 1), (&#39;Á∏£&#39;, 2), (&#39;Âøó&#39;, 11), (&#39;Êòé&#39;, 12), (&#39;ÂÖ®&#39;, 1), (&#39;ÈÅº&#39;, 1), (&#39;Âøó&#39;, 11), (&#39;Êòé&#39;, 12), (&#39;Âñ¨&#39;, 1), (&#39;‰∏â&#39;, 1), (&#39;Áü≥&#39;, 1), (&#39;ËÄÄ&#39;, 1), (&#39;Â∑û&#39;, 1), (&#39;Âøó&#39;, 11), (&#39;Êòé&#39;, 12), (&#39;ÂÆ£&#39;, 1), (&#39;Â∫ú&#39;, 1), (&#39;ÈéÆ&#39;, 1), (&#39;Âøó&#39;, 11), (&#39;Êòé&#39;, 12), (&#39;Èõ≤&#39;, 2), (&#39;Âçó&#39;, 2), (&#39;ÈÄö&#39;, 1), (&#39;Âøó&#39;, 11), (&#39;Êòé&#39;, 12), (&#39;Â§ß&#39;, 3), (&#39;Êòé&#39;, 12), (&#39;‰∏Ä&#39;, 3), (&#39;Áµ±&#39;, 3), (&#39;Âøó&#39;, 11), (&#39;ËºØ&#39;, 1), (&#39;ÈåÑ&#39;, 1), (&#39;Êòé&#39;, 12), (&#39;Èõ≤&#39;, 2), (&#39;‰∏≠&#39;, 1), (&#39;ÈÉ°&#39;, 1), (&#39;Âøó&#39;, 11), (&#39;Ê∏Ö&#39;, 1)] . In order to produce more useful outputs to inspect the keywords, we can combine functions and list comprehensions to output a dictionary. Click here if you need to review how to build a function. . def wordListToFreqDict(wordlist): &quot;&quot;&quot; This function convert a word list to dictionary displaying frequencies of character occurences &quot;&quot;&quot; wordfreq = [wordlist.count(p) for p in wordlist] # same as what we did above return dict(list(zip(wordlist,wordfreq))) # return a dictionary of zip objects word_count = wordListToFreqDict(wordlist) . Let&#39;s look at our dictionary word_count. . word_count . {&#39;‰∏Ä&#39;: 3, &#39;‰∏â&#39;: 1, &#39;‰∏ä&#39;: 1, &#39;‰∏ã&#39;: 1, &#39;‰∏≠&#39;: 1, &#39;ÂÖ®&#39;: 1, &#39;Âçó&#39;: 2, &#39;ÂñÑ&#39;: 1, &#39;Âñ¨&#39;: 1, &#39;Âòâ&#39;: 1, &#39;Â§ß&#39;: 3, &#39;Â§©&#39;: 1, &#39;ÂÆ£&#39;: 1, &#39;Â∑û&#39;: 1, &#39;Â∫ú&#39;: 1, &#39;Âøó&#39;: 11, &#39;Êòé&#39;: 12, &#39;Êµ∑&#39;: 1, &#39;Ê∏Ö&#39;: 1, &#39;Áïø&#39;: 1, &#39;Áü≥&#39;: 1, &#39;Áµ±&#39;: 3, &#39;Á∏£&#39;: 2, &#39;ËÄÄ&#39;: 1, &#39;Ë®ò&#39;: 1, &#39;ËºØ&#39;: 1, &#39;ÈÄö&#39;: 1, &#39;ÈÅº&#39;: 1, &#39;ÈÉ°&#39;: 1, &#39;ÈåÑ&#39;: 1, &#39;ÈéÆ&#39;: 1, &#39;Èõç&#39;: 1, &#39;Èõ≤&#39;: 2} . However, as we can see, the data seems to be a bit messy. It would be much easier to read if we order the keywords by frequency. We can do this by building another small function to sort the values. . def sortFreqDict(freqdict): &quot;&quot;&quot; This function sort dictionary by keyword frequencies &quot;&quot;&quot; aux = [(freqdict[key], key) for key in freqdict] # convert dictionary back to a list of tuples aux.sort() # sort the values aux.reverse() # reverse the values so the items are in descending order return aux # return sorted list sortFreqDict(word_count)[:5] # apply our function and print the first 5 items in list . [(12, &#39;Êòé&#39;), (11, &#39;Âøó&#39;), (3, &#39;Áµ±&#39;), (3, &#39;Â§ß&#39;), (3, &#39;‰∏Ä&#39;)] . . . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: December 2021 . . . . References: . https://gist.github.com/acrymble/1065661 .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/jupyter/2020/01/25/List_Comprehension_Basics.html",
            "relUrl": "/jupyter/2020/01/25/List_Comprehension_Basics.html",
            "date": " ‚Ä¢ Jan 25, 2020"
        }
        
    
  
    
        ,"post8": {
            "title": "Pandas Numerical Operation",
            "content": ". Here is another Pandas tutorial doing non-text analysis. . . Presumptions: . Not applicable. . . import io import pandas as pd import requests # read data url = &#39;https://examples.opendatasoft.com/explore/dataset/world-heritage-unesco-list/download/?format=csv&amp;timezone=Europe/Berlin&amp;lang=en&amp;use_labels_for_header=true&amp;csv_separator=%3B&#39; df = pd.read_csv(url, sep=&quot;;&quot;) . df.head(2) # head() is used for viewing the first few rows of data . Name (EN) Name (FR) Short description (EN) Short Description (FR) Justification (EN) Justification (FR) Date inscribed Danger list Longitude Latitude Area hectares Category Country (EN) Country (FR) Continent (EN) Continent (FR) Geographical coordinates . 0 Architectural, Residential and Cultural Comple... | Ensemble architectural, r√©sidentiel et culture... | The Architectural, Residential and Cultural Co... | L‚Äôensemble architectural, r√©sidentiel et cultu... | Criterion (ii): The architectural, residential... | Crit√®re (ii) : L‚Äôensemble architectural, r√©sid... | 2005-01-01 | NaN | 26.69139 | 53.22278 | 0.0 | Cultural | Belarus | B√©larus | Europe and North America | Europe et Am√©rique du nord | 53.22278,26.69139 | . 1 Rock Paintings of the Sierra de San Francisco | Peintures rupestres de la Sierra de San Francisco | From c. 100 B.C. to A.D. 1300, the Sierra de S... | Dans la r√©serve d&#39;El Vizca√≠no, en Basse-Califo... | NaN | NaN | 1993-01-01 | NaN | -112.91611 | 27.65556 | 182600.0 | Cultural | Mexico | Mexique | Latin America and the Caribbean | Am√©rique latine et Cara√Øbes | 27.65556,-112.91611 | . df[&quot;Country (EN)&quot;] # selecting one column . 0 Belarus 1 Mexico 2 Romania 3 Italy 4 Belgium,France ... 1047 Bosnia and Herzegovina,Croatia,Serbia,Montenegro 1048 China 1049 United Kingdom of Great Britain and Northern I... 1050 Chad 1051 France Name: Country (EN), Length: 1052, dtype: object . By typing .values, we can convert one column in the Pandas dataframe to Numpy array. . country_arr = df[&quot;Country (EN)&quot;].values # to numpy country_arr . array([&#39;Belarus&#39;, &#39;Mexico&#39;, &#39;Romania&#39;, ..., &#39;United Kingdom of Great Britain and Northern Ireland&#39;, &#39;Chad&#39;, &#39;France&#39;], dtype=object) . import numpy as np unique_name = np.unique(country_arr) # the list of country. np.unique() return values only one time no matter how many times do they appear unique_name[:3] # check the first three countries only . array([&#39;Afghanistan&#39;, &#39;Albania&#39;, &#39;Algeria&#39;], dtype=object) . china_site = df[df[&quot;Country (EN)&quot;] == &quot;China&quot;] china_site.head(1) . Name (EN) Name (FR) Short description (EN) Short Description (FR) Justification (EN) Justification (FR) Date inscribed Danger list Longitude Latitude Area hectares Category Country (EN) Country (FR) Continent (EN) Continent (FR) Geographical coordinates . 5 Sichuan Giant Panda Sanctuaries - Wolong, Mt S... | Sanctuaires du grand panda du Sichuan - Wolong... | Sichuan Giant Panda Sanctuaries, home to more ... | Les Sanctuaires du grand panda du Sichuan abri... | NaN | NaN | 2006-01-01 | NaN | 103.0 | 30.833333 | 924500.0 | Natural | China | Chine | Asia and the Pacific | Asie et pacifique | 30.8333333333,103.0 | . china_site[&#39;Name (EN)&#39;].count() . 49 . china_site = china_site[[&quot;Name (EN)&quot;,&quot;Date inscribed&quot;,&quot;Category&quot;]] # select multiple columns in a list [] china_site = china_site.rename(columns={&quot;Name (EN)&quot;: &quot;name&quot;, &quot;Date inscribed&quot;: &quot;date&quot;, &quot;Category&quot;: &quot;type&quot;}) # rename the columns for easy reading china_site.head(1) # check the updates . name date type . 5 Sichuan Giant Panda Sanctuaries - Wolong, Mt S... | 2006-01-01 | Natural | . Date Time . Pandas dataframe also support datetime for time series analysis. But first, we need to read the column as date time. . china_site[&#39;date&#39;] = pd.to_datetime(china_site[&quot;date&quot;]) . china_site[&#39;year&#39;] = pd.DatetimeIndex(china_site[&#39;date&#39;]).year china_site = china_site.drop(columns=[&#39;date&#39;]) china_site.head(1) . name type year . 5 Sichuan Giant Panda Sanctuaries - Wolong, Mt S... | Natural | 2006 | . UNESCO Sites . count_df = china_site.groupby(&quot;year&quot;)[&quot;name&quot;].count().reset_index(name=&quot;count&quot;) count_df . year count . 0 1987 | 6 | . 1 1990 | 1 | . 2 1992 | 3 | . 3 1994 | 4 | . 4 1996 | 2 | . 5 1997 | 3 | . 6 1998 | 2 | . 7 1999 | 2 | . 8 2000 | 4 | . 9 2001 | 1 | . 10 2003 | 1 | . 11 2004 | 1 | . 12 2005 | 1 | . 13 2006 | 2 | . 14 2007 | 2 | . 15 2008 | 2 | . 16 2009 | 1 | . 17 2010 | 2 | . 18 2011 | 1 | . 19 2012 | 2 | . 20 2013 | 2 | . 21 2014 | 1 | . 22 2015 | 1 | . 23 2016 | 2 | . ### Cumulative totals of the heritage sites | . count_df[&quot;total&quot;] = count_df[&quot;count&quot;].cumsum() . ### Set Index | . count_df = count_df.set_index(&quot;year&quot;) count_df.head() . count total . year . 1987 6 | 6 | . 1990 1 | 7 | . 1992 3 | 10 | . 1994 4 | 14 | . 1996 2 | 16 | . Visualization . import matplotlib.pyplot as plt count_df.total.plot(color=&quot;red&quot;) plt.xlabel(&quot;Year&quot;) plt.ylabel(&quot;Number of UNESCO sites&quot;) plt.title(&quot;Increasing number of UNESCO sites in China&quot;) . Text(0.5, 1.0, &#39;Increasing number of UNESCO sites in China&#39;) . data = {&quot;Year&quot;: count_df.index.values, &quot;Total Sites&quot;: count_df.total.values} df = pd.DataFrame(data) fig, ax = plt.subplots(1, 1) # Hide axes ax.xaxis.set_visible(False) ax.yaxis.set_visible(False) ax.axis(&#39;tight&#39;) ax.axis(&#39;off&#39;) ax.table(cellText=df.values, colLabels=df.keys(), loc=&#39;center&#39;) plt.show() . from google.colab import files df.to_csv(&#39;UNESCO.csv&#39;, encoding=&#39;utf_8_sig&#39;, index=False) files.download(&#39;UNESCO.csv&#39;) . print(df.to_latex(index=False)) . begin{tabular}{rr} toprule Year &amp; Total Sites midrule 1987 &amp; 6 1990 &amp; 7 1992 &amp; 10 1994 &amp; 14 1996 &amp; 16 1997 &amp; 19 1998 &amp; 21 1999 &amp; 23 2000 &amp; 27 2001 &amp; 28 2003 &amp; 29 2004 &amp; 30 2005 &amp; 31 2006 &amp; 33 2007 &amp; 35 2008 &amp; 37 2009 &amp; 38 2010 &amp; 40 2011 &amp; 41 2012 &amp; 43 2013 &amp; 45 2014 &amp; 46 2015 &amp; 47 2016 &amp; 49 bottomrule end{tabular} . top_10 = df.groupby(df[&quot;Country (EN)&quot;]).count().sort_values(by=[&#39;Name (EN)&#39;], ascending=False).head(10) top_10 . Name (EN) Name (FR) Short description (EN) Short Description (FR) Justification (EN) Justification (FR) Date inscribed Danger list Longitude Latitude Area hectares Category Country (FR) Continent (EN) Continent (FR) Geographical coordinates . Country (EN) . China 49 | 49 | 49 | 49 | 18 | 18 | 49 | 0 | 49 | 49 | 48 | 49 | 49 | 49 | 49 | 49 | . Italy 47 | 47 | 47 | 47 | 28 | 28 | 47 | 1 | 47 | 47 | 47 | 47 | 47 | 47 | 47 | 47 | . Spain 41 | 41 | 41 | 41 | 17 | 17 | 41 | 0 | 41 | 41 | 39 | 41 | 41 | 41 | 41 | 41 | . France 38 | 38 | 38 | 38 | 8 | 9 | 38 | 0 | 38 | 38 | 38 | 38 | 38 | 38 | 38 | 38 | . Germany 35 | 35 | 35 | 35 | 13 | 12 | 35 | 1 | 35 | 35 | 34 | 35 | 35 | 35 | 35 | 35 | . Mexico 34 | 34 | 34 | 34 | 10 | 10 | 34 | 0 | 34 | 34 | 33 | 34 | 34 | 34 | 34 | 34 | . India 33 | 33 | 33 | 33 | 8 | 6 | 33 | 2 | 33 | 33 | 32 | 33 | 33 | 33 | 33 | 33 | . United Kingdom of Great Britain and Northern Ireland 27 | 27 | 27 | 27 | 9 | 9 | 27 | 2 | 27 | 27 | 27 | 27 | 27 | 27 | 27 | 27 | . Russian Federation 21 | 21 | 21 | 21 | 9 | 9 | 21 | 0 | 21 | 21 | 21 | 21 | 21 | 21 | 21 | 21 | . Iran (Islamic Republic of) 21 | 21 | 21 | 21 | 4 | 4 | 21 | 1 | 21 | 21 | 20 | 21 | 21 | 21 | 21 | 21 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; sub_cnty = top_10.index.values sub_cnty . array([&#39;China&#39;, &#39;Italy&#39;, &#39;Spain&#39;, &#39;France&#39;, &#39;Germany&#39;, &#39;Mexico&#39;, &#39;India&#39;, &#39;United Kingdom of Great Britain and Northern Ireland&#39;, &#39;Russian Federation&#39;, &#39;Iran (Islamic Republic of)&#39;], dtype=object) . sub_cnty = np.where(sub_cnty == &quot;United Kingdom of Great Britain and Northern Ireland&quot;, &quot;United Kingdom&quot;, sub_cnty) sub_cnty = np.where(sub_cnty == &#39;Iran (Islamic Republic of)&#39;, &quot;Iran&quot;, sub_cnty) . df = df[[&#39;Country (EN)&#39;,&quot;Name (EN)&quot;,&quot;Date inscribed&quot;,&quot;Category&quot;]] # select multiple columns in a list [] df = df.rename(columns={&quot;Country (EN)&quot;: &quot;country&quot;,&quot;Name (EN)&quot;: &quot;name&quot;, &quot;Date inscribed&quot;: &quot;date&quot;, &quot;Category&quot;: &quot;type&quot;}) # rename the columns for easy reading . top_df = df[df[&#39;country&#39;].isin(sub_cnty)].groupby([&#39;country&#39;,&#39;date&#39;]).count()[&#39;name&#39;].reset_index() top_df . country date name . 0 China | 1987-01-01 | 6 | . 1 China | 1990-01-01 | 1 | . 2 China | 1992-01-01 | 3 | . 3 China | 1994-01-01 | 4 | . 4 China | 1996-01-01 | 2 | . ... ... | ... | ... | . 195 United Kingdom of Great Britain and Northern I... | 2004-01-01 | 1 | . 196 United Kingdom of Great Britain and Northern I... | 2006-01-01 | 1 | . 197 United Kingdom of Great Britain and Northern I... | 2009-01-01 | 1 | . 198 United Kingdom of Great Britain and Northern I... | 2015-01-01 | 1 | . 199 United Kingdom of Great Britain and Northern I... | 2016-01-01 | 1 | . 200 rows √ó 3 columns . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; pivot = top_df.pivot(index=&#39;date&#39;, columns=&#39;country&#39;, values=&#39;name&#39;) pivot = pivot.fillna(0) pivot . country China France Germany India Iran (Islamic Republic of) Italy Mexico Russian Federation Spain United Kingdom of Great Britain and Northern Ireland . date . 1978-01-01 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1979-01-01 0.0 | 5.0 | 0.0 | 0.0 | 3.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1980-01-01 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1981-01-01 0.0 | 5.0 | 2.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1982-01-01 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1983-01-01 0.0 | 3.0 | 1.0 | 4.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1984-01-01 0.0 | 0.0 | 1.0 | 2.0 | 0.0 | 0.0 | 0.0 | 0.0 | 5.0 | 0.0 | . 1985-01-01 0.0 | 1.0 | 1.0 | 3.0 | 0.0 | 0.0 | 0.0 | 0.0 | 5.0 | 0.0 | . 1986-01-01 0.0 | 0.0 | 1.0 | 4.0 | 0.0 | 0.0 | 0.0 | 0.0 | 4.0 | 7.0 | . 1987-01-01 6.0 | 0.0 | 1.0 | 3.0 | 0.0 | 2.0 | 6.0 | 0.0 | 1.0 | 2.0 | . 1988-01-01 0.0 | 1.0 | 0.0 | 1.0 | 0.0 | 0.0 | 2.0 | 0.0 | 1.0 | 3.0 | . 1989-01-01 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1990-01-01 1.0 | 0.0 | 1.0 | 0.0 | 0.0 | 1.0 | 0.0 | 3.0 | 0.0 | 0.0 | . 1991-01-01 0.0 | 2.0 | 1.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 1.0 | 0.0 | . 1992-01-01 3.0 | 1.0 | 1.0 | 0.0 | 0.0 | 0.0 | 1.0 | 3.0 | 0.0 | 0.0 | . 1993-01-01 0.0 | 0.0 | 2.0 | 2.0 | 0.0 | 1.0 | 3.0 | 1.0 | 3.0 | 0.0 | . 1994-01-01 4.0 | 0.0 | 2.0 | 0.0 | 0.0 | 1.0 | 1.0 | 1.0 | 0.0 | 0.0 | . 1995-01-01 0.0 | 1.0 | 1.0 | 0.0 | 0.0 | 4.0 | 0.0 | 1.0 | 0.0 | 2.0 | . 1996-01-01 2.0 | 1.0 | 3.0 | 0.0 | 0.0 | 4.0 | 2.0 | 2.0 | 2.0 | 0.0 | . 1997-01-01 3.0 | 1.0 | 0.0 | 0.0 | 0.0 | 10.0 | 1.0 | 0.0 | 3.0 | 1.0 | . 1998-01-01 2.0 | 2.0 | 1.0 | 0.0 | 0.0 | 3.0 | 2.0 | 0.0 | 2.0 | 0.0 | . 1999-01-01 2.0 | 1.0 | 2.0 | 1.0 | 0.0 | 1.0 | 2.0 | 1.0 | 2.0 | 1.0 | . 2000-01-01 4.0 | 1.0 | 2.0 | 0.0 | 0.0 | 3.0 | 0.0 | 2.0 | 5.0 | 2.0 | . 2001-01-01 1.0 | 1.0 | 1.0 | 0.0 | 0.0 | 1.0 | 0.0 | 1.0 | 1.0 | 3.0 | . 2002-01-01 0.0 | 0.0 | 2.0 | 1.0 | 0.0 | 1.0 | 1.0 | 0.0 | 0.0 | 0.0 | . 2003-01-01 1.0 | 0.0 | 0.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | . 2004-01-01 1.0 | 0.0 | 1.0 | 2.0 | 2.0 | 2.0 | 1.0 | 1.0 | 0.0 | 1.0 | . 2005-01-01 1.0 | 1.0 | 0.0 | 0.0 | 1.0 | 1.0 | 1.0 | 1.0 | 0.0 | 0.0 | . 2006-01-01 2.0 | 0.0 | 1.0 | 0.0 | 1.0 | 1.0 | 1.0 | 0.0 | 1.0 | 1.0 | . 2007-01-01 2.0 | 1.0 | 0.0 | 1.0 | 0.0 | 0.0 | 1.0 | 0.0 | 1.0 | 0.0 | . 2008-01-01 2.0 | 2.0 | 1.0 | 0.0 | 1.0 | 1.0 | 2.0 | 0.0 | 0.0 | 0.0 | . 2009-01-01 1.0 | 0.0 | 0.0 | 0.0 | 1.0 | 1.0 | 0.0 | 0.0 | 1.0 | 1.0 | . 2010-01-01 2.0 | 2.0 | 0.0 | 1.0 | 2.0 | 0.0 | 2.0 | 1.0 | 0.0 | 0.0 | . 2011-01-01 1.0 | 1.0 | 1.0 | 0.0 | 1.0 | 1.0 | 0.0 | 0.0 | 1.0 | 0.0 | . 2012-01-01 2.0 | 1.0 | 1.0 | 1.0 | 2.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | . 2013-01-01 2.0 | 0.0 | 1.0 | 1.0 | 1.0 | 2.0 | 1.0 | 0.0 | 0.0 | 0.0 | . 2014-01-01 1.0 | 1.0 | 1.0 | 2.0 | 1.0 | 1.0 | 0.0 | 1.0 | 0.0 | 0.0 | . 2015-01-01 1.0 | 2.0 | 1.0 | 0.0 | 2.0 | 1.0 | 1.0 | 0.0 | 0.0 | 1.0 | . 2016-01-01 2.0 | 0.0 | 0.0 | 2.0 | 2.0 | 0.0 | 1.0 | 0.0 | 1.0 | 1.0 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; pivot = pivot.cumsum() pivot . country China France Germany India Iran (Islamic Republic of) Italy Mexico Russian Federation Spain United Kingdom of Great Britain and Northern Ireland . date . 1978-01-01 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1979-01-01 0.0 | 5.0 | 1.0 | 0.0 | 3.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1980-01-01 0.0 | 5.0 | 1.0 | 0.0 | 3.0 | 2.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1981-01-01 0.0 | 10.0 | 3.0 | 0.0 | 3.0 | 2.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1982-01-01 0.0 | 11.0 | 3.0 | 0.0 | 3.0 | 3.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1983-01-01 0.0 | 14.0 | 4.0 | 4.0 | 3.0 | 3.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1984-01-01 0.0 | 14.0 | 5.0 | 6.0 | 3.0 | 3.0 | 0.0 | 0.0 | 5.0 | 0.0 | . 1985-01-01 0.0 | 15.0 | 6.0 | 9.0 | 3.0 | 3.0 | 0.0 | 0.0 | 10.0 | 0.0 | . 1986-01-01 0.0 | 15.0 | 7.0 | 13.0 | 3.0 | 3.0 | 0.0 | 0.0 | 14.0 | 7.0 | . 1987-01-01 6.0 | 15.0 | 8.0 | 16.0 | 3.0 | 5.0 | 6.0 | 0.0 | 15.0 | 9.0 | . 1988-01-01 6.0 | 16.0 | 8.0 | 17.0 | 3.0 | 5.0 | 8.0 | 0.0 | 16.0 | 12.0 | . 1989-01-01 6.0 | 16.0 | 8.0 | 18.0 | 3.0 | 5.0 | 8.0 | 0.0 | 16.0 | 12.0 | . 1990-01-01 7.0 | 16.0 | 9.0 | 18.0 | 3.0 | 6.0 | 8.0 | 3.0 | 16.0 | 12.0 | . 1991-01-01 7.0 | 18.0 | 10.0 | 18.0 | 3.0 | 6.0 | 9.0 | 3.0 | 17.0 | 12.0 | . 1992-01-01 10.0 | 19.0 | 11.0 | 18.0 | 3.0 | 6.0 | 10.0 | 6.0 | 17.0 | 12.0 | . 1993-01-01 10.0 | 19.0 | 13.0 | 20.0 | 3.0 | 7.0 | 13.0 | 7.0 | 20.0 | 12.0 | . 1994-01-01 14.0 | 19.0 | 15.0 | 20.0 | 3.0 | 8.0 | 14.0 | 8.0 | 20.0 | 12.0 | . 1995-01-01 14.0 | 20.0 | 16.0 | 20.0 | 3.0 | 12.0 | 14.0 | 9.0 | 20.0 | 14.0 | . 1996-01-01 16.0 | 21.0 | 19.0 | 20.0 | 3.0 | 16.0 | 16.0 | 11.0 | 22.0 | 14.0 | . 1997-01-01 19.0 | 22.0 | 19.0 | 20.0 | 3.0 | 26.0 | 17.0 | 11.0 | 25.0 | 15.0 | . 1998-01-01 21.0 | 24.0 | 20.0 | 20.0 | 3.0 | 29.0 | 19.0 | 11.0 | 27.0 | 15.0 | . 1999-01-01 23.0 | 25.0 | 22.0 | 21.0 | 3.0 | 30.0 | 21.0 | 12.0 | 29.0 | 16.0 | . 2000-01-01 27.0 | 26.0 | 24.0 | 21.0 | 3.0 | 33.0 | 21.0 | 14.0 | 34.0 | 18.0 | . 2001-01-01 28.0 | 27.0 | 25.0 | 21.0 | 3.0 | 34.0 | 21.0 | 15.0 | 35.0 | 21.0 | . 2002-01-01 28.0 | 27.0 | 27.0 | 22.0 | 3.0 | 35.0 | 22.0 | 15.0 | 35.0 | 21.0 | . 2003-01-01 29.0 | 27.0 | 27.0 | 23.0 | 4.0 | 36.0 | 23.0 | 16.0 | 36.0 | 22.0 | . 2004-01-01 30.0 | 27.0 | 28.0 | 25.0 | 6.0 | 38.0 | 24.0 | 17.0 | 36.0 | 23.0 | . 2005-01-01 31.0 | 28.0 | 28.0 | 25.0 | 7.0 | 39.0 | 25.0 | 18.0 | 36.0 | 23.0 | . 2006-01-01 33.0 | 28.0 | 29.0 | 25.0 | 8.0 | 40.0 | 26.0 | 18.0 | 37.0 | 24.0 | . 2007-01-01 35.0 | 29.0 | 29.0 | 26.0 | 8.0 | 40.0 | 27.0 | 18.0 | 38.0 | 24.0 | . 2008-01-01 37.0 | 31.0 | 30.0 | 26.0 | 9.0 | 41.0 | 29.0 | 18.0 | 38.0 | 24.0 | . 2009-01-01 38.0 | 31.0 | 30.0 | 26.0 | 10.0 | 42.0 | 29.0 | 18.0 | 39.0 | 25.0 | . 2010-01-01 40.0 | 33.0 | 30.0 | 27.0 | 12.0 | 42.0 | 31.0 | 19.0 | 39.0 | 25.0 | . 2011-01-01 41.0 | 34.0 | 31.0 | 27.0 | 13.0 | 43.0 | 31.0 | 19.0 | 40.0 | 25.0 | . 2012-01-01 43.0 | 35.0 | 32.0 | 28.0 | 15.0 | 43.0 | 31.0 | 20.0 | 40.0 | 25.0 | . 2013-01-01 45.0 | 35.0 | 33.0 | 29.0 | 16.0 | 45.0 | 32.0 | 20.0 | 40.0 | 25.0 | . 2014-01-01 46.0 | 36.0 | 34.0 | 31.0 | 17.0 | 46.0 | 32.0 | 21.0 | 40.0 | 25.0 | . 2015-01-01 47.0 | 38.0 | 35.0 | 31.0 | 19.0 | 47.0 | 33.0 | 21.0 | 40.0 | 26.0 | . 2016-01-01 49.0 | 38.0 | 35.0 | 33.0 | 21.0 | 47.0 | 34.0 | 21.0 | 41.0 | 27.0 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; import matplotlib.pyplot as plt pivot.plot(figsize=(20,6)) plt.xlabel(&quot;Year&quot;, fontsize=14) plt.ylabel(&quot;Count&quot;, fontsize=14) plt.title(&quot;UNESCO Sites&quot;, fontsize=20) . Text(0.5, 1.0, &#39;UNESCO Sites&#39;) . import seaborn as sns custom_params = {&quot;axes.spines.right&quot;: False, &quot;axes.spines.top&quot;: False} sns.set_theme(style=&quot;ticks&quot;, rc=custom_params, context=&quot;talk&quot;) plt.style.use(&quot;dark_background&quot;) . import matplotlib.pyplot as plt import matplotlib.dates as mdates plt.figure(figsize=(20, 6)) sns.lineplot(data=pivot) plt.title(&quot;UNESCO Sites&quot;, fontsize=28) plt.xlabel(&quot;Year&quot;) plt.ylabel(&quot;Count&quot;) plt.legend(bbox_to_anchor=(1.02, 0.9), loc=2, borderaxespad=0.) plt.tight_layout() . fig, ax = plt.subplots(figsize=(15, 6)) ax.stackplot(pivot.index.values, [pivot[name].values for name in pivot], baseline=&quot;sym&quot;, colors=palette, labels=sub_cnty) ax.axhline(0, color=&quot;red&quot;, ls=&quot;--&quot;, linewidth=.8) plt.title(&quot;UNESCO Sites&quot;, fontsize=25) plt.xlabel(&quot;Year&quot;) plt.ylabel(&quot;Count&quot;) plt.legend(bbox_to_anchor=(1.02, 0.9), loc=2, borderaxespad=0.) plt.tight_layout() . plt.figure(figsize=(24,6)) plt.hlines(y=pivot.index, xmin=0, xmax=pivot[&#39;China&#39;], color=&quot;#FCC700&quot;) plt.plot(pivot[&#39;China&#39;], pivot.index, &quot;o&quot;, markersize=8, color=&quot;#FC4900&quot;) plt.title(&quot;UNESCO Sites in China&quot;, fontsize=26) plt.xlabel(&quot;Count&quot;) plt.ylabel(&quot;Year&quot;) . Text(0, 0.5, &#39;Year&#39;) . . . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: December 2021 . . . . References: . https://examples.opendatasoft.com/explore/dataset/world-heritage-unesco-list/table/ .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/jupyter/2020/01/24/Pandas_NumericalOperation_QuantitativeDataOrganization.html",
            "relUrl": "/jupyter/2020/01/24/Pandas_NumericalOperation_QuantitativeDataOrganization.html",
            "date": " ‚Ä¢ Jan 24, 2020"
        }
        
    
  
    
        ,"post9": {
            "title": "Python Pandas Library",
            "content": ". This notebook aims to intrduce users to Pandas library, an useful tool for tabular data manipulation. What it can be done is similar to Excel but allows users to have a much higher flexibility and to manage huge dataset in efficient manner. . . Presumptions: . https://www.youtube.com/watch?v=vmEHCJofslg&amp;t=2s . https://www.w3schools.com/python/python_dictionaries.asp . . Pandas Series . We have learnt about list, which is a simple way to handle information but Pandas includes many extra features to handle data, such as handling missing data and indexing objects with text. The corresponding form of a list in Pandas is a Pandas series, which acts can also be understood as a column of the Pandas dataframe. A Pandas Series can be created using pd.Series(). . import pandas as pd names = pd.Series([&#39;ÁôªÊ±ü‰∏≠Â≠§Â±øÔºåËµ†ÁôΩ‰∫ëÂÖàÁîüÁéãËø•&#39;, &#39;ÁßãÁôªÂÖ∞Â±±ÂØÑÂº†‰∫î&#39;,&#39; &#39;,&#39;ÂÖ•Â≥°ÂØÑÂºü&#39;]) names . 0 ÁôªÊ±ü‰∏≠Â≠§Â±øÔºåËµ†ÁôΩ‰∫ëÂÖàÁîüÁéãËø• 1 ÁßãÁôªÂÖ∞Â±±ÂØÑÂº†‰∫î 2 3 ÂÖ•Â≥°ÂØÑÂºü dtype: object . Nearly all Python&#39;s built-in string methods are mirrored by a Pandas vectorized string method. Here is a list of Pandas str methods: . . len() | lower() | translate() | islower() | . ljust() | upper() | startswith() | isupper() | . rjust() | find() | endswith() | isnumeric() | . center() | rfind() | isalnum() | isdecimal() | . zfill() | index() | isalpha() | split() | . strip() | rindex() | isdigit() | rsplit() | . rstrip() | capitalize() | isspace() | partition() | . lstrip() | swapcase() | istitle() | rpartition() | . We need to pay attention that although many of the strings method is not applicable in Chinese languages, some functions can still be really helpful. . For example, . names.str.startswith(&#39;Áßã&#39;) # looking for item that start with a character . 0 False 1 True 2 False 3 False dtype: bool . names.str.isspace() # looking for empty space . 0 False 1 False 2 True 3 False dtype: bool . names.str.find(&#39;Áßã&#39;) # look for where (index) is a character . 0 -1 1 0 2 -1 3 -1 dtype: int64 . names.str.split(pat=&quot;&quot;) # split characters . 0 [, Áôª, Ê±ü, ‰∏≠, Â≠§, Â±ø, Ôºå, Ëµ†, ÁôΩ, ‰∫ë, ÂÖà, Áîü, Áéã, Ëø•, ] 1 [, Áßã, Áôª, ÂÖ∞, Â±±, ÂØÑ, Âº†, ‰∫î, ] 2 [, , ] 3 [, ÂÖ•, Â≥°, ÂØÑ, Âºü, ] dtype: object . names.str.extract(&#39;([A-Za-z]+)&#39;, expand=False) # look for letters (this is called regular expression, you will learn about it later) . 0 NaN 1 NaN 2 NaN 3 NaN dtype: object . names.str.findall(r&#39;^[Áßã].*$&#39;) # find item with characters . 0 [] 1 [ÁßãÁôªÂÖ∞Â±±ÂØÑÂº†‰∫î] 2 [] 3 [] dtype: object . There are also some methods that allows convenient operations: . Method Description . get() | Index each element | . slice() | Slice each element | . slice_replace() | Replace slice in each element with passed value | . cat() | Concatenate strings | . repeat() | Repeat values | . normalize() | Return Unicode form of string | . pad() | Add whitespace to left, right, or both sides of strings | . wrap() | Split long strings into lines with length less than a given width | . join() | Join strings in each element of the Series with passed separator | . get_dummies() | extract dummy variables as a dataframe | . names.str[0:1] # get the first character only . 0 Áôª 1 Áßã 2 3 ÂÖ• dtype: object . names.str.split(pat=&#39;Ôºå&#39;).str.get(0) # get first clause . 0 ÁôªÊ±ü‰∏≠Â≠§Â±ø 1 ÁßãÁôªÂÖ∞Â±±ÂØÑÂº†‰∫î 2 3 ÂÖ•Â≥°ÂØÑÂºü dtype: object . We can even get some statistics about the length of our text using describe(). . names.str.len().describe() . count 4.000000 mean 6.250000 std 5.123475 min 1.000000 25% 3.250000 50% 5.500000 75% 8.500000 max 13.000000 dtype: float64 . We can also create a Pandas DataFrame from a dictionary: while the keys will be used as the name of the column in the Pandas DataFrame, the values will be used as the data (rows). . Let&#39;s build a data frame using capital names for Qin and Han dynasties as an example. . dictionary = { &#39;Time&#39;: [&#39;&#39;,&#39;‚Äì 677 BC&#39;,&#39;677 BC ‚Äì&#39;,&#39;‚Äì 383 BC&#39;,&#39;383 BC ‚Äì 250 BC&#39;,&#39;350 BC ‚Äì 207 BC&#39;,&#39;202 BC&#39;,&#39;202 BC ‚Äì 200 BC&#39;,&#39;200 BC ‚Äì 8 BC&#39;], &#39;Dynasty&#39;: [&#39;Qin&#39;,&#39;Qin&#39;,&#39;Qin&#39;,&#39;Qin&#39;,&#39;Qin&#39;,&#39;Qin&#39;,&#39;Han&#39;,&#39;Han&#39;,&#39;Han&#39;], &#39;Capital&#39;: [&#39;Xiquanqiu&#39;,&#39;Pingyang&#39;,&#39;Yong&#39;,&#39;Jingyang&#39;,&#39;Yueyang&#39;,&#39;Xianyang&#39;,&#39;Luoyang&#39;,&#39;Yueyang&#39;,&#39;Changan&#39;] } # remember all column in the data frame have to have the same length df = pd.DataFrame(data=dictionary) # use pd.DataFrame() and put the dict as an argument df . Time Dynasty Capital . 0 | Qin | Xiquanqiu | . 1 ‚Äì 677 BC | Qin | Pingyang | . 2 677 BC ‚Äì | Qin | Yong | . 3 ‚Äì 383 BC | Qin | Jingyang | . 4 383 BC ‚Äì 250 BC | Qin | Yueyang | . 5 350 BC ‚Äì 207 BC | Qin | Xianyang | . 6 202 BC | Han | Luoyang | . 7 202 BC ‚Äì 200 BC | Han | Yueyang | . 8 200 BC ‚Äì 8 BC | Han | Changan | . df = df.set_index(&#39;Time&#39;) # we can also set text as index df . Dynasty Capital . Time . Qin | Xiquanqiu | . ‚Äì 677 BC Qin | Pingyang | . 677 BC ‚Äì Qin | Yong | . ‚Äì 383 BC Qin | Jingyang | . 383 BC ‚Äì 250 BC Qin | Yueyang | . 350 BC ‚Äì 207 BC Qin | Xianyang | . 202 BC Han | Luoyang | . 202 BC ‚Äì 200 BC Han | Yueyang | . 200 BC ‚Äì 8 BC Han | Changan | . To view only the first row: . df.head(1) . Dynasty Capital . Time . Qin | Xiquanqiu | . To view only the last row: . df.tail(1) . Dynasty Capital . Time . 200 BC ‚Äì 8 BC Han | Changan | . In order to understand better the group characteristics, we can also use the groupby option. It is used with a groupby() following with a method(). . For example, we can use groupby(&quot;Dynasty&quot;).count() to count number of rows (number of capital) in each dynasty. . . Remarks: Index cannot be used as the groupby object. . df.groupby(&quot;Dynasty&quot;).count() . Capital . Dynasty . Han 3 | . Qin 6 | . . . Data Manipulation . After understanding what is a Pandas Series and what is a Pandas DataFrame, we can start with some basic manipulation using a data frame. Let&#39;s start with an example to build a Pandas dataframe from a text file. . First, we upload a text and selected titles.txt file. (can be found in the data folder) . from google.colab import files uploaded = files.upload() for f in uploaded.keys(): file = open(f, &#39;r&#39;) titles = file.read() . Upload widget is only available when the cell has been executed in the current browser session. Please rerun this cell to enable. Saving titles.txt to titles (1).txt . Then, we can split the text into paragraphs (separate by two new lines) and sentence (separate by one new line). . titles = titles.split(&quot; n n&quot;) # two new lines titles = [lines.split(&#39; n&#39;) for lines in titles] # one new line, done in a list comprehension . titles[0:2] # check the first two items we have: Âç∑159_1 and Âç∑159_2 . [[&#39;Âç∑159_1 „Äå‰ªéÂº†‰∏ûÁõ∏Ê∏∏ÂçóÁ∫™ÂüéÁåéÔºåÊàèËµ†Ë£¥Ëø™Âº†ÂèÇÂÜõ„ÄçÂ≠üÊµ©ÁÑ∂&#39;, &#39; u3000 u3000‰ªéÁ¶ΩÈùûÂêæ‰πêÔºå‰∏çÂ•Ω‰∫ëÊ¢¶Áî∞„ÄÇÂ≤ÅÊöÆÁôªÂüéÊúõÔºåÂÅè‰ª§‰π°ÊÄùÊÇ¨„ÄÇ&#39;, &#39; u3000 u3000ÂÖ¨ÂçøÊúâÂá†Âá†ÔºåËΩ¶È™ë‰ΩïÁø©Áø©„ÄÇ‰∏ñÁ¶ÑÈáëÂº†Ë¥µÔºåÂÆòÊõπÂπïÂ∫úË¥§„ÄÇ&#39;, &#39; u3000 u3000È°∫Êó∂Ë°åÊùÄÊ∞îÔºåÈ£ûÂàÉ‰∫âÂâ≤È≤ú„ÄÇÂçÅÈáåÂ±äÂÆæÈ¶ÜÔºåÂæÅÂ£∞ÂåùÂ¶ìÁ≠µ„ÄÇ&#39;, &#39; u3000 u3000È´òÊ†áÂõûËêΩÊó•ÔºåÂπ≥Ê•öÊï£Ëä≥ÁÉü„ÄÇ‰ΩïÊÑèÁãÇÊ≠åÂÆ¢Ôºå‰ªéÂÖ¨‰∫¶Âú®ÊóÉ„ÄÇ&#39;], [&#39;Âç∑159_2 „ÄåÁôªÊ±ü‰∏≠Â≠§Â±øÔºåËµ†ÁôΩ‰∫ëÂÖàÁîüÁéãËø•„ÄçÂ≠üÊµ©ÁÑ∂&#39;, &#39; u3000 u3000ÊÇ†ÊÇ†Ê∏ÖÊ±üÊ∞¥ÔºåÊ∞¥ËêΩÊ≤ôÂ±øÂá∫„ÄÇÂõûÊΩ≠Áü≥‰∏ãÊ∑±ÔºåÁªøÁ≠±Â≤∏ÂÇçÂØÜ„ÄÇ&#39;, &#39; u3000 u3000È≤õ‰∫∫ÊΩú‰∏çËßÅÔºåÊ∏îÁà∂Ê≠åËá™ÈÄ∏„ÄÇÂøÜ‰∏éÂêõÂà´Êó∂ÔºåÊ≥õËàüÂ¶ÇÊò®Êó•„ÄÇ&#39;, &#39; u3000 u3000Â§ïÈò≥ÂºÄËøîÁÖßÔºå‰∏≠ÂùêÂÖ¥Èùû‰∏Ä„ÄÇÂçóÊúõÈπøÈó®Â±±ÔºåÂΩíÊù•ÊÅ®Â¶ÇÂ§±„ÄÇ&#39;]] . We can also check how many titles (Âç∑) are there: . len(titles) . 269 . Then construct our dataframe. . import pandas as pd # In case library is not imported df = pd.DataFrame({&quot;content&quot;: titles}) # construct a data frame using a dictionary df.head() . content . 0 [Âç∑159_1 „Äå‰ªéÂº†‰∏ûÁõ∏Ê∏∏ÂçóÁ∫™ÂüéÁåéÔºåÊàèËµ†Ë£¥Ëø™Âº†ÂèÇÂÜõ„ÄçÂ≠üÊµ©ÁÑ∂, „ÄÄ„ÄÄ‰ªéÁ¶ΩÈùûÂêæ‰πêÔºå‰∏çÂ•Ω‰∫ëÊ¢¶Áî∞„ÄÇ... | . 1 [Âç∑159_2 „ÄåÁôªÊ±ü‰∏≠Â≠§Â±øÔºåËµ†ÁôΩ‰∫ëÂÖàÁîüÁéãËø•„ÄçÂ≠üÊµ©ÁÑ∂, „ÄÄ„ÄÄÊÇ†ÊÇ†Ê∏ÖÊ±üÊ∞¥ÔºåÊ∞¥ËêΩÊ≤ôÂ±øÂá∫„ÄÇÂõûÊΩ≠Áü≥‰∏ã... | . 2 [Âç∑159_3 „ÄåÊôöÊò•ÂçßÁóÖÂØÑÂº†ÂÖ´„ÄçÂ≠üÊµ©ÁÑ∂, „ÄÄ„ÄÄÂçóÈôåÊò•Â∞ÜÊôöÔºåÂåóÁ™óÁäπÂçßÁóÖ„ÄÇÊûóÂõ≠‰πÖ‰∏çÊ∏∏ÔºåËçâÊú®‰∏Ä‰Ωï... | . 3 [Âç∑159_4 „ÄåÁßãÁôªÂÖ∞Â±±ÂØÑÂº†‰∫î„ÄçÂ≠üÊµ©ÁÑ∂, „ÄÄ„ÄÄÂåóÂ±±ÁôΩ‰∫ëÈáåÔºåÈöêËÄÖËá™ÊÄ°ÊÇ¶„ÄÇÁõ∏ÊúõËØïÁôªÈ´òÔºåÂøÉÈ£ûÈÄêÈ∏ü... | . 4 [Âç∑159_5 „ÄåÂÖ•Â≥°ÂØÑÂºü„ÄçÂ≠üÊµ©ÁÑ∂, „ÄÄ„ÄÄÂêæÊòî‰∏éÂ∞îËæàÔºåËØª‰π¶Â∏∏Èó≠Èó®„ÄÇÊú™Â∞ùÂÜíÊπçÈô©ÔºåÂ≤ÇÈ°æÂûÇÂ†ÇË®Ä„ÄÇ,... | . We realize the content column is so messy as it contains different information such as which titles, author name and the content itself. So we want to set up different new columns: . . 1) title: The title . 2) content: The text . 3) index: use the text id (eg. 159_1) as index . We can set up new columns by simply writing . df[&quot;name of the new column&quot;] = [what we plan to put in] . What we plan to put in can be for example, a Numpy array with the same length, or just a number (in this case all rows will have the same value). For example, . import numpy as np df[&quot;test&quot;] = 1 df.head() . content test . 0 [Âç∑159_1 „Äå‰ªéÂº†‰∏ûÁõ∏Ê∏∏ÂçóÁ∫™ÂüéÁåéÔºåÊàèËµ†Ë£¥Ëø™Âº†ÂèÇÂÜõ„ÄçÂ≠üÊµ©ÁÑ∂, „ÄÄ„ÄÄ‰ªéÁ¶ΩÈùûÂêæ‰πêÔºå‰∏çÂ•Ω‰∫ëÊ¢¶Áî∞„ÄÇ... | 1 | . 1 [Âç∑159_2 „ÄåÁôªÊ±ü‰∏≠Â≠§Â±øÔºåËµ†ÁôΩ‰∫ëÂÖàÁîüÁéãËø•„ÄçÂ≠üÊµ©ÁÑ∂, „ÄÄ„ÄÄÊÇ†ÊÇ†Ê∏ÖÊ±üÊ∞¥ÔºåÊ∞¥ËêΩÊ≤ôÂ±øÂá∫„ÄÇÂõûÊΩ≠Áü≥‰∏ã... | 1 | . 2 [Âç∑159_3 „ÄåÊôöÊò•ÂçßÁóÖÂØÑÂº†ÂÖ´„ÄçÂ≠üÊµ©ÁÑ∂, „ÄÄ„ÄÄÂçóÈôåÊò•Â∞ÜÊôöÔºåÂåóÁ™óÁäπÂçßÁóÖ„ÄÇÊûóÂõ≠‰πÖ‰∏çÊ∏∏ÔºåËçâÊú®‰∏Ä‰Ωï... | 1 | . 3 [Âç∑159_4 „ÄåÁßãÁôªÂÖ∞Â±±ÂØÑÂº†‰∫î„ÄçÂ≠üÊµ©ÁÑ∂, „ÄÄ„ÄÄÂåóÂ±±ÁôΩ‰∫ëÈáåÔºåÈöêËÄÖËá™ÊÄ°ÊÇ¶„ÄÇÁõ∏ÊúõËØïÁôªÈ´òÔºåÂøÉÈ£ûÈÄêÈ∏ü... | 1 | . 4 [Âç∑159_5 „ÄåÂÖ•Â≥°ÂØÑÂºü„ÄçÂ≠üÊµ©ÁÑ∂, „ÄÄ„ÄÄÂêæÊòî‰∏éÂ∞îËæàÔºåËØª‰π¶Â∏∏Èó≠Èó®„ÄÇÊú™Â∞ùÂÜíÊπçÈô©ÔºåÂ≤ÇÈ°æÂûÇÂ†ÇË®Ä„ÄÇ,... | 1 | . Or this: . df[&quot;test&quot;] = np.arange(0,269) df.head() . content test . 0 [Âç∑159_1 „Äå‰ªéÂº†‰∏ûÁõ∏Ê∏∏ÂçóÁ∫™ÂüéÁåéÔºåÊàèËµ†Ë£¥Ëø™Âº†ÂèÇÂÜõ„ÄçÂ≠üÊµ©ÁÑ∂, „ÄÄ„ÄÄ‰ªéÁ¶ΩÈùûÂêæ‰πêÔºå‰∏çÂ•Ω‰∫ëÊ¢¶Áî∞„ÄÇ... | 0 | . 1 [Âç∑159_2 „ÄåÁôªÊ±ü‰∏≠Â≠§Â±øÔºåËµ†ÁôΩ‰∫ëÂÖàÁîüÁéãËø•„ÄçÂ≠üÊµ©ÁÑ∂, „ÄÄ„ÄÄÊÇ†ÊÇ†Ê∏ÖÊ±üÊ∞¥ÔºåÊ∞¥ËêΩÊ≤ôÂ±øÂá∫„ÄÇÂõûÊΩ≠Áü≥‰∏ã... | 1 | . 2 [Âç∑159_3 „ÄåÊôöÊò•ÂçßÁóÖÂØÑÂº†ÂÖ´„ÄçÂ≠üÊµ©ÁÑ∂, „ÄÄ„ÄÄÂçóÈôåÊò•Â∞ÜÊôöÔºåÂåóÁ™óÁäπÂçßÁóÖ„ÄÇÊûóÂõ≠‰πÖ‰∏çÊ∏∏ÔºåËçâÊú®‰∏Ä‰Ωï... | 2 | . 3 [Âç∑159_4 „ÄåÁßãÁôªÂÖ∞Â±±ÂØÑÂº†‰∫î„ÄçÂ≠üÊµ©ÁÑ∂, „ÄÄ„ÄÄÂåóÂ±±ÁôΩ‰∫ëÈáåÔºåÈöêËÄÖËá™ÊÄ°ÊÇ¶„ÄÇÁõ∏ÊúõËØïÁôªÈ´òÔºåÂøÉÈ£ûÈÄêÈ∏ü... | 3 | . 4 [Âç∑159_5 „ÄåÂÖ•Â≥°ÂØÑÂºü„ÄçÂ≠üÊµ©ÁÑ∂, „ÄÄ„ÄÄÂêæÊòî‰∏éÂ∞îËæàÔºåËØª‰π¶Â∏∏Èó≠Èó®„ÄÇÊú™Â∞ùÂÜíÊπçÈô©ÔºåÂ≤ÇÈ°æÂûÇÂ†ÇË®Ä„ÄÇ,... | 4 | . We can also add a new row: . df.append({&#39;content&#39;: np.nan, &#39;test&#39;: np.nan}, ignore_index=True) # This is temporary only and will not change the data frame itself # np.nan means missing values . content test . 0 [Âç∑159_1 „Äå‰ªéÂº†‰∏ûÁõ∏Ê∏∏ÂçóÁ∫™ÂüéÁåéÔºåÊàèËµ†Ë£¥Ëø™Âº†ÂèÇÂÜõ„ÄçÂ≠üÊµ©ÁÑ∂, „ÄÄ„ÄÄ‰ªéÁ¶ΩÈùûÂêæ‰πêÔºå‰∏çÂ•Ω‰∫ëÊ¢¶Áî∞„ÄÇ... | 0.0 | . 1 [Âç∑159_2 „ÄåÁôªÊ±ü‰∏≠Â≠§Â±øÔºåËµ†ÁôΩ‰∫ëÂÖàÁîüÁéãËø•„ÄçÂ≠üÊµ©ÁÑ∂, „ÄÄ„ÄÄÊÇ†ÊÇ†Ê∏ÖÊ±üÊ∞¥ÔºåÊ∞¥ËêΩÊ≤ôÂ±øÂá∫„ÄÇÂõûÊΩ≠Áü≥‰∏ã... | 1.0 | . 2 [Âç∑159_3 „ÄåÊôöÊò•ÂçßÁóÖÂØÑÂº†ÂÖ´„ÄçÂ≠üÊµ©ÁÑ∂, „ÄÄ„ÄÄÂçóÈôåÊò•Â∞ÜÊôöÔºåÂåóÁ™óÁäπÂçßÁóÖ„ÄÇÊûóÂõ≠‰πÖ‰∏çÊ∏∏ÔºåËçâÊú®‰∏Ä‰Ωï... | 2.0 | . 3 [Âç∑159_4 „ÄåÁßãÁôªÂÖ∞Â±±ÂØÑÂº†‰∫î„ÄçÂ≠üÊµ©ÁÑ∂, „ÄÄ„ÄÄÂåóÂ±±ÁôΩ‰∫ëÈáåÔºåÈöêËÄÖËá™ÊÄ°ÊÇ¶„ÄÇÁõ∏ÊúõËØïÁôªÈ´òÔºåÂøÉÈ£ûÈÄêÈ∏ü... | 3.0 | . 4 [Âç∑159_5 „ÄåÂÖ•Â≥°ÂØÑÂºü„ÄçÂ≠üÊµ©ÁÑ∂, „ÄÄ„ÄÄÂêæÊòî‰∏éÂ∞îËæàÔºåËØª‰π¶Â∏∏Èó≠Èó®„ÄÇÊú™Â∞ùÂÜíÊπçÈô©ÔºåÂ≤ÇÈ°æÂûÇÂ†ÇË®Ä„ÄÇ,... | 4.0 | . ... ... | ... | . 265 [Âç∑160_181 „ÄåÊ∏°ÊµôÊ±üÈóÆËàü‰∏≠‰∫∫Ôºà‰∏ÄÈ¢ò‰ΩúÊµéÊ±üÈóÆÂêåËàü‰∫∫„ÄÇ‰∏Ä‰ΩúÂ¥îÂõΩËæÖËØóÔºâ„ÄçÂ≠üÊµ©ÁÑ∂, „ÄÄ„ÄÄÊΩÆËêΩ... | 265.0 | . 266 [Âç∑160_182 „ÄåÂàùÁßã„ÄçÂ≠üÊµ©ÁÑ∂, „ÄÄ„ÄÄ‰∏çËßâÂàùÁßãÂ§úÊ∏êÈïøÔºåÊ∏ÖÈ£é‰π†‰π†ÈáçÂáÑÂáâ„ÄÇ, „ÄÄ„ÄÄÁÇéÁÇéÊöëÈÄÄËåÖ... | 266.0 | . 267 [Âç∑160_183 „ÄåËøáËûç‰∏ä‰∫∫ÂÖ∞Ëã•„ÄçÂ≠üÊµ©ÁÑ∂, „ÄÄ„ÄÄÂ±±Â§¥Á¶ÖÂÆ§ÊåÇÂÉßË°£ÔºåÁ™óÂ§ñÊó†‰∫∫Ê∞¥È∏üÈ£û„ÄÇ, „ÄÄ„ÄÄÈªÑ... | 267.0 | . 268 [Âç∑160_184 „ÄåÂè•„ÄçÂ≠üÊµ©ÁÑ∂, „ÄÄ„ÄÄÂæÆ‰∫ëÊ∑°Ê≤≥Ê±âÔºåÁñèÈõ®Êª¥Ê¢ßÊ°ê„ÄÇ, „ÄÄ„ÄÄÈÄêÈÄêÊÄÄËâØÈ©≠ÔºåËêßËêßÈ°æ‰πê... | 268.0 | . 269 NaN | NaN | . 270 rows √ó 2 columns . df = df.append({&#39;content&#39;: np.nan, &#39;test&#39;: np.nan}, ignore_index=True) # df = &lt;- now the df is replaced df.tail(1) . content test . 269 NaN | NaN | . We can then drop the row (all missing values) and the column again. . df = df.dropna(how=&quot;any&quot;,axis=&quot;index&quot;) # this is for dropping all missing values in the rows df.tail(1) . content test . 268 [Âç∑160_184 „ÄåÂè•„ÄçÂ≠üÊµ©ÁÑ∂, „ÄÄ„ÄÄÂæÆ‰∫ëÊ∑°Ê≤≥Ê±âÔºåÁñèÈõ®Êª¥Ê¢ßÊ°ê„ÄÇ, „ÄÄ„ÄÄÈÄêÈÄêÊÄÄËâØÈ©≠ÔºåËêßËêßÈ°æ‰πê... | 268.0 | . df = df.drop(columns=&quot;test&quot;) # this is dropping the column named &quot;test&quot; df.head() . content . 0 [Âç∑159_1 „Äå‰ªéÂº†‰∏ûÁõ∏Ê∏∏ÂçóÁ∫™ÂüéÁåéÔºåÊàèËµ†Ë£¥Ëø™Âº†ÂèÇÂÜõ„ÄçÂ≠üÊµ©ÁÑ∂, „ÄÄ„ÄÄ‰ªéÁ¶ΩÈùûÂêæ‰πêÔºå‰∏çÂ•Ω‰∫ëÊ¢¶Áî∞„ÄÇ... | . 1 [Âç∑159_2 „ÄåÁôªÊ±ü‰∏≠Â≠§Â±øÔºåËµ†ÁôΩ‰∫ëÂÖàÁîüÁéãËø•„ÄçÂ≠üÊµ©ÁÑ∂, „ÄÄ„ÄÄÊÇ†ÊÇ†Ê∏ÖÊ±üÊ∞¥ÔºåÊ∞¥ËêΩÊ≤ôÂ±øÂá∫„ÄÇÂõûÊΩ≠Áü≥‰∏ã... | . 2 [Âç∑159_3 „ÄåÊôöÊò•ÂçßÁóÖÂØÑÂº†ÂÖ´„ÄçÂ≠üÊµ©ÁÑ∂, „ÄÄ„ÄÄÂçóÈôåÊò•Â∞ÜÊôöÔºåÂåóÁ™óÁäπÂçßÁóÖ„ÄÇÊûóÂõ≠‰πÖ‰∏çÊ∏∏ÔºåËçâÊú®‰∏Ä‰Ωï... | . 3 [Âç∑159_4 „ÄåÁßãÁôªÂÖ∞Â±±ÂØÑÂº†‰∫î„ÄçÂ≠üÊµ©ÁÑ∂, „ÄÄ„ÄÄÂåóÂ±±ÁôΩ‰∫ëÈáåÔºåÈöêËÄÖËá™ÊÄ°ÊÇ¶„ÄÇÁõ∏ÊúõËØïÁôªÈ´òÔºåÂøÉÈ£ûÈÄêÈ∏ü... | . 4 [Âç∑159_5 „ÄåÂÖ•Â≥°ÂØÑÂºü„ÄçÂ≠üÊµ©ÁÑ∂, „ÄÄ„ÄÄÂêæÊòî‰∏éÂ∞îËæàÔºåËØª‰π¶Â∏∏Èó≠Èó®„ÄÇÊú™Â∞ùÂÜíÊπçÈô©ÔºåÂ≤ÇÈ°æÂûÇÂ†ÇË®Ä„ÄÇ,... | . Now we finally start with our new columns: . Let&#39;s look at one of our data: we can see the first item is the id, title and author name, and the other items are the text. So let&#39;s set the first item as title, and the rest of the items as content. . df[&quot;content&quot;][0] . [&#39;Âç∑159_1 „Äå‰ªéÂº†‰∏ûÁõ∏Ê∏∏ÂçóÁ∫™ÂüéÁåéÔºåÊàèËµ†Ë£¥Ëø™Âº†ÂèÇÂÜõ„ÄçÂ≠üÊµ©ÁÑ∂&#39;, &#39; u3000 u3000‰ªéÁ¶ΩÈùûÂêæ‰πêÔºå‰∏çÂ•Ω‰∫ëÊ¢¶Áî∞„ÄÇÂ≤ÅÊöÆÁôªÂüéÊúõÔºåÂÅè‰ª§‰π°ÊÄùÊÇ¨„ÄÇ&#39;, &#39; u3000 u3000ÂÖ¨ÂçøÊúâÂá†Âá†ÔºåËΩ¶È™ë‰ΩïÁø©Áø©„ÄÇ‰∏ñÁ¶ÑÈáëÂº†Ë¥µÔºåÂÆòÊõπÂπïÂ∫úË¥§„ÄÇ&#39;, &#39; u3000 u3000È°∫Êó∂Ë°åÊùÄÊ∞îÔºåÈ£ûÂàÉ‰∫âÂâ≤È≤ú„ÄÇÂçÅÈáåÂ±äÂÆæÈ¶ÜÔºåÂæÅÂ£∞ÂåùÂ¶ìÁ≠µ„ÄÇ&#39;, &#39; u3000 u3000È´òÊ†áÂõûËêΩÊó•ÔºåÂπ≥Ê•öÊï£Ëä≥ÁÉü„ÄÇ‰ΩïÊÑèÁãÇÊ≠åÂÆ¢Ôºå‰ªéÂÖ¨‰∫¶Âú®ÊóÉ„ÄÇ&#39;] . df[&quot;title&quot;] = df[&quot;content&quot;].str[0] # the first item df[&quot;content&quot;] = df[&quot;content&quot;].str[1:] # second to last item df[&quot;content&quot;] = df[&quot;content&quot;].str.get(0) # get rid of the [] by extracting the first item from list df.head() . content title . 0 ‰ªéÁ¶ΩÈùûÂêæ‰πêÔºå‰∏çÂ•Ω‰∫ëÊ¢¶Áî∞„ÄÇÂ≤ÅÊöÆÁôªÂüéÊúõÔºåÂÅè‰ª§‰π°ÊÄùÊÇ¨„ÄÇ | Âç∑159_1 „Äå‰ªéÂº†‰∏ûÁõ∏Ê∏∏ÂçóÁ∫™ÂüéÁåéÔºåÊàèËµ†Ë£¥Ëø™Âº†ÂèÇÂÜõ„ÄçÂ≠üÊµ©ÁÑ∂ | . 1 ÊÇ†ÊÇ†Ê∏ÖÊ±üÊ∞¥ÔºåÊ∞¥ËêΩÊ≤ôÂ±øÂá∫„ÄÇÂõûÊΩ≠Áü≥‰∏ãÊ∑±ÔºåÁªøÁ≠±Â≤∏ÂÇçÂØÜ„ÄÇ | Âç∑159_2 „ÄåÁôªÊ±ü‰∏≠Â≠§Â±øÔºåËµ†ÁôΩ‰∫ëÂÖàÁîüÁéãËø•„ÄçÂ≠üÊµ©ÁÑ∂ | . 2 ÂçóÈôåÊò•Â∞ÜÊôöÔºåÂåóÁ™óÁäπÂçßÁóÖ„ÄÇÊûóÂõ≠‰πÖ‰∏çÊ∏∏ÔºåËçâÊú®‰∏Ä‰ΩïÁõõ„ÄÇ | Âç∑159_3 „ÄåÊôöÊò•ÂçßÁóÖÂØÑÂº†ÂÖ´„ÄçÂ≠üÊµ©ÁÑ∂ | . 3 ÂåóÂ±±ÁôΩ‰∫ëÈáåÔºåÈöêËÄÖËá™ÊÄ°ÊÇ¶„ÄÇÁõ∏ÊúõËØïÁôªÈ´òÔºåÂøÉÈ£ûÈÄêÈ∏üÁÅ≠„ÄÇ | Âç∑159_4 „ÄåÁßãÁôªÂÖ∞Â±±ÂØÑÂº†‰∫î„ÄçÂ≠üÊµ©ÁÑ∂ | . 4 ÂêæÊòî‰∏éÂ∞îËæàÔºåËØª‰π¶Â∏∏Èó≠Èó®„ÄÇÊú™Â∞ùÂÜíÊπçÈô©ÔºåÂ≤ÇÈ°æÂûÇÂ†ÇË®Ä„ÄÇ | Âç∑159_5 „ÄåÂÖ•Â≥°ÂØÑÂºü„ÄçÂ≠üÊµ©ÁÑ∂ | . df = df.replace(r&#39; n&#39;,&#39; &#39;, regex=True) # replace the next line symbol &#39; n&#39; with empty space df.head() . content title . 0 ‰ªéÁ¶ΩÈùûÂêæ‰πêÔºå‰∏çÂ•Ω‰∫ëÊ¢¶Áî∞„ÄÇÂ≤ÅÊöÆÁôªÂüéÊúõÔºåÂÅè‰ª§‰π°ÊÄùÊÇ¨„ÄÇ | Âç∑159_1 „Äå‰ªéÂº†‰∏ûÁõ∏Ê∏∏ÂçóÁ∫™ÂüéÁåéÔºåÊàèËµ†Ë£¥Ëø™Âº†ÂèÇÂÜõ„ÄçÂ≠üÊµ©ÁÑ∂ | . 1 ÊÇ†ÊÇ†Ê∏ÖÊ±üÊ∞¥ÔºåÊ∞¥ËêΩÊ≤ôÂ±øÂá∫„ÄÇÂõûÊΩ≠Áü≥‰∏ãÊ∑±ÔºåÁªøÁ≠±Â≤∏ÂÇçÂØÜ„ÄÇ | Âç∑159_2 „ÄåÁôªÊ±ü‰∏≠Â≠§Â±øÔºåËµ†ÁôΩ‰∫ëÂÖàÁîüÁéãËø•„ÄçÂ≠üÊµ©ÁÑ∂ | . 2 ÂçóÈôåÊò•Â∞ÜÊôöÔºåÂåóÁ™óÁäπÂçßÁóÖ„ÄÇÊûóÂõ≠‰πÖ‰∏çÊ∏∏ÔºåËçâÊú®‰∏Ä‰ΩïÁõõ„ÄÇ | Âç∑159_3 „ÄåÊôöÊò•ÂçßÁóÖÂØÑÂº†ÂÖ´„ÄçÂ≠üÊµ©ÁÑ∂ | . 3 ÂåóÂ±±ÁôΩ‰∫ëÈáåÔºåÈöêËÄÖËá™ÊÄ°ÊÇ¶„ÄÇÁõ∏ÊúõËØïÁôªÈ´òÔºåÂøÉÈ£ûÈÄêÈ∏üÁÅ≠„ÄÇ | Âç∑159_4 „ÄåÁßãÁôªÂÖ∞Â±±ÂØÑÂº†‰∫î„ÄçÂ≠üÊµ©ÁÑ∂ | . 4 ÂêæÊòî‰∏éÂ∞îËæàÔºåËØª‰π¶Â∏∏Èó≠Èó®„ÄÇÊú™Â∞ùÂÜíÊπçÈô©ÔºåÂ≤ÇÈ°æÂûÇÂ†ÇË®Ä„ÄÇ | Âç∑159_5 „ÄåÂÖ•Â≥°ÂØÑÂºü„ÄçÂ≠üÊµ©ÁÑ∂ | . type(df.title[0]) # title is type of string . str . Now we can set up a new column &quot;id&quot; and then use it as our index using set_index(). . We learnt in the last notebook. ( d+_ d+) means numbers followed by _ followed by numbers again. This is the pattern used for extract from the title column. . df[&quot;id&quot;] = df.title.str.extract(&#39;( d+_ d+)&#39;) df = df.set_index(&quot;id&quot;) df.head() . content title . id . 159_1 ‰ªéÁ¶ΩÈùûÂêæ‰πêÔºå‰∏çÂ•Ω‰∫ëÊ¢¶Áî∞„ÄÇÂ≤ÅÊöÆÁôªÂüéÊúõÔºåÂÅè‰ª§‰π°ÊÄùÊÇ¨„ÄÇ | Âç∑159_1 „Äå‰ªéÂº†‰∏ûÁõ∏Ê∏∏ÂçóÁ∫™ÂüéÁåéÔºåÊàèËµ†Ë£¥Ëø™Âº†ÂèÇÂÜõ„ÄçÂ≠üÊµ©ÁÑ∂ | . 159_2 ÊÇ†ÊÇ†Ê∏ÖÊ±üÊ∞¥ÔºåÊ∞¥ËêΩÊ≤ôÂ±øÂá∫„ÄÇÂõûÊΩ≠Áü≥‰∏ãÊ∑±ÔºåÁªøÁ≠±Â≤∏ÂÇçÂØÜ„ÄÇ | Âç∑159_2 „ÄåÁôªÊ±ü‰∏≠Â≠§Â±øÔºåËµ†ÁôΩ‰∫ëÂÖàÁîüÁéãËø•„ÄçÂ≠üÊµ©ÁÑ∂ | . 159_3 ÂçóÈôåÊò•Â∞ÜÊôöÔºåÂåóÁ™óÁäπÂçßÁóÖ„ÄÇÊûóÂõ≠‰πÖ‰∏çÊ∏∏ÔºåËçâÊú®‰∏Ä‰ΩïÁõõ„ÄÇ | Âç∑159_3 „ÄåÊôöÊò•ÂçßÁóÖÂØÑÂº†ÂÖ´„ÄçÂ≠üÊµ©ÁÑ∂ | . 159_4 ÂåóÂ±±ÁôΩ‰∫ëÈáåÔºåÈöêËÄÖËá™ÊÄ°ÊÇ¶„ÄÇÁõ∏ÊúõËØïÁôªÈ´òÔºåÂøÉÈ£ûÈÄêÈ∏üÁÅ≠„ÄÇ | Âç∑159_4 „ÄåÁßãÁôªÂÖ∞Â±±ÂØÑÂº†‰∫î„ÄçÂ≠üÊµ©ÁÑ∂ | . 159_5 ÂêæÊòî‰∏éÂ∞îËæàÔºåËØª‰π¶Â∏∏Èó≠Èó®„ÄÇÊú™Â∞ùÂÜíÊπçÈô©ÔºåÂ≤ÇÈ°æÂûÇÂ†ÇË®Ä„ÄÇ | Âç∑159_5 „ÄåÂÖ•Â≥°ÂØÑÂºü„ÄçÂ≠üÊµ©ÁÑ∂ | . Now our data frame looks better. But we still want to get rid of the id, author name, and „Äå„Äç. To remove them, we replace them with a string of nothing (&quot;&quot;). Save them back to title column. . df[&#39;title&#39;] = df[&#39;title&#39;].str.replace(&#39;Âç∑( d+_ d+)&#39;, &#39;&#39;).str.replace(&#39;Â≠üÊµ©ÁÑ∂&#39;, &#39;&#39;) df[&#39;title&#39;] = df[&#39;title&#39;].str.replace(&#39;„Äå&#39;, &#39;&#39;).str.replace(&#39;„Äç&#39;, &#39;&#39;) . Let&#39;s have our df2 now by coping &quot;title&quot; and &quot;content&quot; from our df. And set index using index from df. . df2 = (df[[&#39;title&#39;,&#39;content&#39;]]).set_index(df.index) df2.head() . title content . id . 159_1 ‰ªéÂº†‰∏ûÁõ∏Ê∏∏ÂçóÁ∫™ÂüéÁåéÔºåÊàèËµ†Ë£¥Ëø™Âº†ÂèÇÂÜõ | ‰ªéÁ¶ΩÈùûÂêæ‰πêÔºå‰∏çÂ•Ω‰∫ëÊ¢¶Áî∞„ÄÇÂ≤ÅÊöÆÁôªÂüéÊúõÔºåÂÅè‰ª§‰π°ÊÄùÊÇ¨„ÄÇ | . 159_2 ÁôªÊ±ü‰∏≠Â≠§Â±øÔºåËµ†ÁôΩ‰∫ëÂÖàÁîüÁéãËø• | ÊÇ†ÊÇ†Ê∏ÖÊ±üÊ∞¥ÔºåÊ∞¥ËêΩÊ≤ôÂ±øÂá∫„ÄÇÂõûÊΩ≠Áü≥‰∏ãÊ∑±ÔºåÁªøÁ≠±Â≤∏ÂÇçÂØÜ„ÄÇ | . 159_3 ÊôöÊò•ÂçßÁóÖÂØÑÂº†ÂÖ´ | ÂçóÈôåÊò•Â∞ÜÊôöÔºåÂåóÁ™óÁäπÂçßÁóÖ„ÄÇÊûóÂõ≠‰πÖ‰∏çÊ∏∏ÔºåËçâÊú®‰∏Ä‰ΩïÁõõ„ÄÇ | . 159_4 ÁßãÁôªÂÖ∞Â±±ÂØÑÂº†‰∫î | ÂåóÂ±±ÁôΩ‰∫ëÈáåÔºåÈöêËÄÖËá™ÊÄ°ÊÇ¶„ÄÇÁõ∏ÊúõËØïÁôªÈ´òÔºåÂøÉÈ£ûÈÄêÈ∏üÁÅ≠„ÄÇ | . 159_5 ÂÖ•Â≥°ÂØÑÂºü | ÂêæÊòî‰∏éÂ∞îËæàÔºåËØª‰π¶Â∏∏Èó≠Èó®„ÄÇÊú™Â∞ùÂÜíÊπçÈô©ÔºåÂ≤ÇÈ°æÂûÇÂ†ÇË®Ä„ÄÇ | . Finally, we also need to know that conversion between Pandas column and Numpy array is very simple. We can basically call the column and .values. Then we get our array. . For example, we try to convert our title column to array. . df2.title.values[:5] # first 5 items . array([&#39; ‰ªéÂº†‰∏ûÁõ∏Ê∏∏ÂçóÁ∫™ÂüéÁåéÔºåÊàèËµ†Ë£¥Ëø™Âº†ÂèÇÂÜõ&#39;, &#39; ÁôªÊ±ü‰∏≠Â≠§Â±øÔºåËµ†ÁôΩ‰∫ëÂÖàÁîüÁéãËø•&#39;, &#39; ÊôöÊò•ÂçßÁóÖÂØÑÂº†ÂÖ´&#39;, &#39; ÁßãÁôªÂÖ∞Â±±ÂØÑÂº†‰∫î&#39;, &#39; ÂÖ•Â≥°ÂØÑÂºü&#39;], dtype=object) . . . Data Analysis . After performing some basic processing of our data, let&#39;s try to do some analysis based on what we have. Let&#39;s say, we want to understand how the key words of season have been used in the text. How many times have they been used and how are they distributed? At the end we want to use the results to make a bar chart and a dispersion plot using matplotlib. We will learn much more about visualization later, but we now we will stick with the simple plots. . In case we still have rows with missing values, we use dropna() again to clean our data frame. . df2 = df2.dropna(how=&quot;any&quot;,axis=&quot;index&quot;) # this is for dropping all missing values in the rows . Then we calculate the word offset. It is done by geting the length of strings in the content column (.len()) and calculate the cumulative sum of it (.cumsum()). It means that now the values in the rows is not the length of the one title, but the word offset starting from the first character of the first title. We use it as our word offset for the plot later. With (.to_numpy()) we get the list to numpy array. . word_count = df2.content.str.len().cumsum().to_numpy() word_count[:5] . array([ 26, 52, 78, 104, 130]) . Now we want to look for the keywords for every season. We do it using the find() function and convert the list to numpy. The same apply to every season. . spring_count = df2.content.str.find(&#39;Êò•&#39;).to_numpy() # for spring spring_count[:5] . array([-1, -1, 4, -1, -1]) . summer_count = df2.content.str.find(&#39;Â§è&#39;).to_numpy() # for summer summer_count[:5] . array([-1, -1, -1, -1, -1]) . autumn_count = df2.content.str.find(&#39;Áßã&#39;).to_numpy() # for autumn autumn_count[:5] . array([-1, -1, -1, -1, -1]) . winter_count = df2.content.str.find(&#39;ÂÜ¨&#39;).to_numpy() # for winter winter_count[:5] . array([-1, -1, -1, -1, -1]) . Then, we use list comprehension and enumerate() to loop through all items and the index in the array, and save (index + word offset) that is not equal to one. . The value that printed out can be understood as the total word offset of that character starting from the first title. For example, from the next cell we can tell &quot;Êò•&quot; appears in the 82th, 198th, 660th, ... characters. . spring_occur = np.array([v + word_count[i] for i, v in enumerate(spring_count) if v != -1]) # for spring spring_occur . array([ 82, 198, 660, 826, 1094, 1690, 1749, 2077, 2177, 2183, 2333, 2781, 2853, 3302, 3681, 4091, 4249, 4321, 4351, 5190, 5259, 5297, 5765, 5902, 6065, 6523, 6571, 6805, 6821]) . summer_occur = np.array([v + word_count[i] for i, v in enumerate(summer_count) if v != -1]) # for summer summer_occur . array([ 407, 3204, 3897]) . autumn_occur = np.array([v + word_count[i] for i, v in enumerate(autumn_count) if v != -1]) # for autumn autumn_occur . array([ 366, 1949, 2347, 3455, 3743, 5504, 5649, 6850]) . winter_occur = np.array([v + word_count[i] for i, v in enumerate(winter_count) if v != -1]) # for winter winter_occur . array([], dtype=float64) . . . Basic Data Visualization . Afterwards, we have our arrays which store information about the occurences of season keywords. We can make a plot out of it using matplotlib. The dispersion plot we are making is based on scatter plot. We will thus do a scatter plot for every season with custom marker styles. . import matplotlib.pyplot as plt # import library fig, ax = plt.subplots(figsize=(15,3)) # create an empty plot with defined size # in the scatter plot function (plt.scatter()), we need X for 1st argument and Y for 2nd argument. # for X we will put the word offset values for keyword occurence, for Y we will put a constant value from 1 to 4 # because we want the same season in the same row # np.ones() creates 1 with defined shape, in this case the shape is [length of X,1] spring_y = 1*np.ones([len(spring_occur),1]) # all 1 (1*1) summer_y = 2*np.ones([len(summer_occur),1]) # all 2 (2*1) autumn_y = 3*np.ones([len(autumn_occur),1]) # all 3 (3*1) winter_y = 4*np.ones([len(winter_occur),1]) # all 4 (4*1) # scatter plot plt.scatter(spring_occur,spring_y, marker=5, s=100, alpha=0.8) # first scatter plot for spring, alpha is transparency of the markers plt.scatter(summer_occur,summer_y, marker=5, s=100, alpha=0.8) # for summer plt.scatter(autumn_occur,autumn_y, marker=5, s=100, alpha=0.8) # for autumn plt.scatter(winter_occur,winter_y, marker=5, s=100, alpha=0.8) # for winter # set y limits plt.ylim(0.8, 4.5) # we want our y labels as text, not number. so here we define them. plt.yticks(np.arange(0,5,1)) labels = [&#39;&#39;,&#39;Spring&#39;, &#39;Summer&#39;, &#39;Autumn&#39;, &#39;Winter&#39;] ax.set_yticklabels(labels, fontsize=12) # no plot frame is needed plt.box(False) # labels and title plt.xlabel(&quot;Word Offset&quot;, fontsize=14) plt.ylabel(&quot;Season Keywords&quot;, fontsize=14) plt.title(&quot;Lexical Dispersion&quot;, fontsize=16) . Text(0.5, 1.0, &#39;Lexical Dispersion&#39;) . . On another hand, we can also make a bar chart by simply showing the occurence frequency of keywords. . We use count() of the content column from df2 to count the occurence. We need to add sum() to sum up count for all rows, not single row. . spring = int(df2.content.str.count(&#39;Êò•&#39;).sum()) # spring spring . 29 . summer = int(df2.content.str.count(&#39;Â§è&#39;).sum()) # summer summer . 3 . autumn = int(df2.content.str.count(&#39;Áßã&#39;).sum()) # autumn autumn . 8 . winter = int(df2.content.str.count(&#39;ÂÜ¨&#39;).sum()) # winter winter . 0 . Now, we can use our results to make another data frame. We do it because having results in a separate data frame make visualization easier. . count = {&#39;season&#39;: [&quot;spring&quot;, &quot;summer&quot;, &quot;autumn&quot;, &quot;winter&quot;],&#39;count&#39;: [spring, summer, autumn, winter]} season = pd.DataFrame.from_dict(count) # set season as index season = season.set_index(&quot;season&quot;) season.head() . count . season . spring 29 | . summer 3 | . autumn 8 | . winter 0 | . In order to have Chinese characters shown in our plot, we need to download a package and change the font from the Python library. Please just follow the follow code. . !wget -O TaipeiSansTCBeta-Regular.ttf https://drive.google.com/uc?id=1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_&amp;export=download # import library import matplotlib as mpl import matplotlib.pyplot as plt from matplotlib.font_manager import fontManager # change font setting fontManager.addfont(&#39;TaipeiSansTCBeta-Regular.ttf&#39;) mpl.rc(&#39;font&#39;, family=&#39;Taipei Sans TC Beta&#39;) . --2021-12-12 20:09:06-- https://drive.google.com/uc?id=1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_ Resolving drive.google.com (drive.google.com)... 142.250.81.206, 2607:f8b0:4004:82f::200e Connecting to drive.google.com (drive.google.com)|142.250.81.206|:443... connected. HTTP request sent, awaiting response... 302 Moved Temporarily Location: https://doc-0k-9o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/6nfeiuvrhp3la80n9pg1oja3jsktcq6e/1639339725000/02847987870453524430/*/1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_ [following] Warning: wildcards not supported in HTTP. --2021-12-12 20:09:10-- https://doc-0k-9o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/6nfeiuvrhp3la80n9pg1oja3jsktcq6e/1639339725000/02847987870453524430/*/1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_ Resolving doc-0k-9o-docs.googleusercontent.com (doc-0k-9o-docs.googleusercontent.com)... 142.250.73.193, 2607:f8b0:4004:829::2001 Connecting to doc-0k-9o-docs.googleusercontent.com (doc-0k-9o-docs.googleusercontent.com)|142.250.73.193|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 20659344 (20M) [application/x-font-ttf] Saving to: ‚ÄòTaipeiSansTCBeta-Regular.ttf‚Äô TaipeiSansTCBeta-Re 100%[===================&gt;] 19.70M 35.2MB/s in 0.6s 2021-12-12 20:09:11 (35.2 MB/s) - ‚ÄòTaipeiSansTCBeta-Regular.ttf‚Äô saved [20659344/20659344] . Having a Pandas data frame make visualization simple. We can basically call the dataframe with .plot., followed by the type of plot we want to have. For example, a bar chart is (name of dataframe).plot.bar(). . plt.figure(figsize=(18,6)) # bar chart season.plot.bar(rot=0, color=&quot;#830045&quot;) # labels and title plt.xlabel(&quot;Season&quot;, fontsize=15) plt.ylabel(&quot;Occurence&quot;, fontsize=15) plt.title(&quot;Description of season in nÂ≠üÊµ©ÁÑ∂ËØó Âç∑‰∏ÄÁôæ‰∫îÂçÅ‰πù and Âç∑‰∏ÄÁôæÂÖ≠ÂçÅ?&quot;, fontsize=15) # remove legend and add keywords in the x-axis ax = plt.gca() ax.set_xticklabels([&#39;Êò•&#39;,&#39;Â§è&#39;,&#39;Áßã&#39;,&#39;ÂÜ¨&#39;], fontsize=16) ax.get_legend().remove() # adjust spacing in plot plt.tight_layout() . &lt;Figure size 1296x432 with 0 Axes&gt; . . . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: December 2021 . . . . References: . Jieba . Displaying Chinese characters . Python Data Science Handbook .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/jupyter/2020/01/23/Pandas_TextAnalysis_TextOriganization.html",
            "relUrl": "/jupyter/2020/01/23/Pandas_TextAnalysis_TextOriganization.html",
            "date": " ‚Ä¢ Jan 23, 2020"
        }
        
    
  
    
        ,"post10": {
            "title": "Regular Expression",
            "content": ". This notebook aims to introduce users how to use regular expression to extract useful information from text in Python which would be from documents or websites. . Presumption: https://www.youtube.com/watch?v=K8L6KVGG-7o . . Before starting with this tutorial, please watch this video beforehand so that you would already understand: . 1) What is group method in regular expression? . 2) What is a raw string? . 3) How to create a character set? . 4) What is the function of quantifiers? . . . Review . Here is the summary tables from the video: . Syntax Meanings . . | Any Character Except New Line | . d | Digit (0-9) | . D | - Not a Digit (0-9) | . w | - Word Character (a-z, A-Z, 0-9, _) | . W | - Not a Word Character | . s | - Whitespace (space, tab, newline) | . S | - Not Whitespace (space, tab, newline) | . Syntax Meanings . b | Word Boundary | . B | Not a Word Boundary | . ^ | Beginning of a String | . $ | End of a String | . [] | Matches Characters in brackets | . [^ ] | Matches Characters NOT in brackets | . Vertical bar | Either Or | . ( ) | Group | . . Quantifiers Meanings . * | 0 or More | . + | 1 or More | . ? | 0 or One | . {3} | Exact Number | . {3,4} | Range of Numbers (Minimum, Maximum) | . Information Retrieval . ## re | . Before we analysis any text, the relevant information need to be first extracted to exclude all irrelavant information. And sometimes it is not very straight-forward and the text might be mixed with other information, particularly when the text are mined from online sources. . Below we can look at an exmaple of an entry extracted from Historical GIS for Japan. We can see the information are in multiple rows with each row giving different information. If we only aim for one piece of information, it might be easy to copy in one entry but the task gets challenging once we have thousands of them. This is why text mining can be helpful to save us time and effort. . . First of all, we have to import the library. . import re . lord_entry = &quot;&quot;&quot; name: abemasaharu n vernacular name definition kanji: ÈòøÈÉ®Ê≠£Êò• n alternate vernacular name definition hiragana: „ÅÇ„Åπ„Åæ„Åï„ÅØ„Çã n feature type definition feature type: feudal lord Â§ßÂêç daimyo n date range definition date range: 1664 to 1664 n time slice definition valid as: time slice Âπ¥‰ªΩ n present location definition present location: Â≤©ÊßªÂ∏Ç iwatsukishi n point id definition point id: jp_dmy_40 n data source definition data source: JP_CHGIS n feature type definition coordinate type: centroid n feature type definition latitude: 35.93 n feature type definition longitude: 139.70 n admin hierarchy definition admin hierarchy: Ê≠¶ËîµÂõΩ musashi no kuni &quot;&quot;&quot; . Name . Here we can try to get the kanji name of the entry. . From what we have learnt, we can use the group option to get the first group kanji: at the word boundary ( b) followed with space ( s) and everything (regardless of length) behind it. Using pattern1, we have the name we need in the second group. . We will use re.compile() to define our pattern, then use findall() to look for all matches. . pattern1 = re.compile(r&#39;( bkanji: s)(.*)&#39;) match1 = pattern1.findall(lord_entry) # get all matches match1 # print them out . [(&#39;kanji: t&#39;, &#39;ÈòøÈÉ®Ê≠£Êò•&#39;)] . We can then access the first element of list [0] (there is only one element) and second element of the tuple [1]. . match1[0][1] . &#39;ÈòøÈÉ®Ê≠£Êò•&#39; . Alternative: Lookaround . However, we can also use lookaround method from re, which mean we use &quot;kanji:&quot; to identify what we search for (behind the keyword) but we do not select &quot;kanji: &quot; itself because it is not important for us. . . Be careful, space might not be obvious, it is also count as the element in the string by Python so we always need to address them too. . . . Given the string &quot;foobarbarfoo&quot;: . . bar(?=bar) finds the 1st bar (&quot;bar&quot; which has &quot;bar&quot; after it) . bar(?!bar) finds the 2nd bar (&quot;bar&quot; which does not have &quot;bar&quot; after it) . (?&lt;=foo)bar finds the 1st bar (&quot;bar&quot; which has &quot;foo&quot; before it) . (?&lt;!foo)bar finds the 2nd bar (&quot;bar&quot; which does not have &quot;foo&quot; before it) . . They can also be combined: . (?&lt;=foo)bar(?=bar) finds the 1st bar (&quot;bar&quot; with &quot;foo&quot; before it and &quot;bar&quot; after it) . . Here we use (?&lt;=text1)text2 to select text 2 from identifying text 1, in which text 1 is before text 2 in the text. . pattern2 = re.compile(r&#39;(?&lt;=kanji: s).*&#39;) match2 = pattern2.findall(lord_entry) match2 . [&#39;ÈòøÈÉ®Ê≠£Êò•&#39;] . Coordinates . Now, we can try to get the latitude and longitude from the lord (For example, when we need them for making a map in GIS). Since we have already learnt the principle, the code we need is indeed very similar. . #### Latitude | . lat_pattern = re.compile(r&#39;(?&lt;=latitude: s).*&#39;) match = lat_pattern.findall(lord_entry) match . [&#39;35.93&#39;] . We need to be careful here. Normally when we think of coordinates, we expect a floating number. But here what we get (match) is a list. It will cause errors if we later directly use the list for any geospatial operations. So always check the type. . type(match) # it is a list . list . type(match[0]) # we can get the first item of list to remove [], now it is a string . str . We need to further convert the string into float using float(). . type(float(match[0])) . float . lat = float(match[0]) # save the final result to lat lat . 35.93 . Now we get what we need! Let&#39;s do the same for longitude. . #### Longitude | . lon_pattern = re.compile(r&#39;(?&lt;=longitude: s).*&#39;) match = lon_pattern.findall(lord_entry) match # list . [&#39;139.70&#39;] . lon = float(match[0]) lon # float . 139.7 . Chinese Characters . Here is another small text from ÈüìÊÑà. Now for Chinese characters, we can use unicode characters to select a specific type of characters. . . The ranges of Unicode characters which are routinely used for Chinese and Japanese text are: . U+3040 - U+30FF: hiragana and katakana (Japanese only) . | U+3400 - U+4DBF: CJK unified ideographs extension A (Chinese, Japanese, and Korean) . | U+4E00 - U+9FFF: CJK unified ideographs (Chinese, Japanese, and Korean) . | U+F900 - U+FAFF: CJK compatibility ideographs (Chinese, Japanese, and Korean) . | U+FF66 - U+FF9F: half-width katakana (Japanese only) . | . text = &quot;ÊàñÂïèË´´Ë≠∞Â§ßÂ§´ÈôΩÂüéÊñºÊÑàÔºöÂèØ‰ª•ÁÇ∫ÊúâÈÅì‰πãÂ£´‰πéÂìâÔºüÂ≠∏Âª£ËÄåËÅûÂ§öÔºå‰∏çÊ±ÇËÅûÊñº‰∫∫‰πüÔºåË°åÂè§‰∫∫‰πãÈÅìÔºåÂ±ÖÊñºÊôâ‰πãÈÑôÔºåÊôâ‰πãÈÑô‰∫∫Ëñ∞ÂÖ∂Âæ∑ËÄåÂñÑËâØËÄÖÂπæÂçÉ‰∫∫„ÄÇÂ§ßËá£ËÅûËÄåËñ¶‰πãÔºåÂ§©Â≠ê‰ª•ÁÇ∫Ë´´Ë≠∞Â§ßÂ§´„ÄÇ‰∫∫ÁöÜ‰ª•ÁÇ∫ËèØÔºåÈôΩÂ≠ê‰∏çËâ≤Âñú„ÄÇÂ±ÖÊñº‰ΩçÔºå‰∫îÂπ¥Áü£ÔºåË¶ñÂÖ∂Âæ∑Â¶ÇÂú®ÈáéÔºåÂΩºË±à‰ª•ÂØåË≤¥ÁßªÊòìÂÖ∂ÂøÉÂìâÔºÅ&quot; . pattern = re.compile(r&#39;[ u4e00- u9fff]+&#39;) match = pattern.findall(text) match . [&#39;ÊàñÂïèË´´Ë≠∞Â§ßÂ§´ÈôΩÂüéÊñºÊÑà&#39;, &#39;ÂèØ‰ª•ÁÇ∫ÊúâÈÅì‰πãÂ£´‰πéÂìâ&#39;, &#39;Â≠∏Âª£ËÄåËÅûÂ§ö&#39;, &#39;‰∏çÊ±ÇËÅûÊñº‰∫∫‰πü&#39;, &#39;Ë°åÂè§‰∫∫‰πãÈÅì&#39;, &#39;Â±ÖÊñºÊôâ‰πãÈÑô&#39;, &#39;Êôâ‰πãÈÑô‰∫∫Ëñ∞ÂÖ∂Âæ∑ËÄåÂñÑËâØËÄÖÂπæÂçÉ‰∫∫&#39;, &#39;Â§ßËá£ËÅûËÄåËñ¶‰πã&#39;, &#39;Â§©Â≠ê‰ª•ÁÇ∫Ë´´Ë≠∞Â§ßÂ§´&#39;, &#39;‰∫∫ÁöÜ‰ª•ÁÇ∫ËèØ&#39;, &#39;ÈôΩÂ≠ê‰∏çËâ≤Âñú&#39;, &#39;Â±ÖÊñº‰Ωç&#39;, &#39;‰∫îÂπ¥Áü£&#39;, &#39;Ë¶ñÂÖ∂Âæ∑Â¶ÇÂú®Èáé&#39;, &#39;ÂΩºË±à‰ª•ÂØåË≤¥ÁßªÊòìÂÖ∂ÂøÉÂìâ&#39;] . We can also look for every character instead: . pattern = re.compile(r&#39;[ u4e00- u9fff]&#39;) match = pattern.findall(text) match[:5] # print first 5 characters only . [&#39;Êàñ&#39;, &#39;Âïè&#39;, &#39;Ë´´&#39;, &#39;Ë≠∞&#39;, &#39;Â§ß&#39;] . Here is another example entry from Ê∏Ö‰ª£Ê™îÊ°à. Here let&#39;s say we want to extract the time from the document. . text = &quot;&quot;&quot; Êí•Áµ¶ÂêÑÁ®ÆÂ∑•Âå†ÈäÄ‰πæÈöÜ01Âπ¥8Êúà --ÂÖßÂãôÂ∫úÂ•èÈä∑Ê™î Á¨¨1Á≠Ü ‰∫ãÁî±ÔºöÊí•Áµ¶ÂêÑÁ®ÆÂ∑•Âå†ÈäÄ ÂÖßÊñáÔºöÈõçÊ≠£ÂçÅ‰∏âÂπ¥ÂõõÊúàËµ∑Ëá≥ ‰πæÈöÜ ÂÖÉÂπ¥‰∫îÊúàÁµ¶ÁôºÂå†ÂΩπÂ∑•ÂÉπÊâÄÁî®Â§ßÂà∂Èå¢Êï∏ÁõÆ ÈÉé‰∏≠Ê∞∏‰øùÁ≠âÊñáÈñãÊÅ≠Áï´Âù§ÂØßÂÆÆÁ•ûÂÉèÈúÄÁî®Â§ñÂÉ±Áï´Âå†Áï´Áü≠Â∑•‰πùÂçÅ‰∫îÂ∑•ÊØèÂ∑•Èå¢‰∏ÄÁôæ‰∏âÂçÅÂõõÊñáÈ†òÂéªÂ§ßÂà∂Èå¢ÂçÅ‰∫å‰∏≤‰∏ÉÁôæ‰∏â‰∏âÂçÅÊñá ÈäÄÂ∫´ÈÉé‰∏≠ÈÇÅÊ†ºÁ≠âÊìöÊéåÂÑÄÂè∏ÈÉé‰∏≠Ë¨®ÁàæÂæ∑Á≠âÊñáÈñãÊÅ≠ÈÄ†Âù§ÂØßÂÆÆÁ•≠Á•ÄÊâÄÁî®Èè®Ëä±ÈäÄÈ¶ôÁ¢üÂÖ´ÂÄãÁàµÁõ§‰∫åÂÄãÊºèÂ≠ê‰∏ÄÂÄãÊ†ºÊºè‰∏ÄÂÄãÁÆ∏‰∏ÄÈõôÂåô‰∏âÂºµÂ∞èÁ¢ü‰∫åÂçÅÂÄãÈçæÂçÅ‰∏ÄÂÄãÂ§ßÁ¢ó‰∫îÂÄãÂ£∫‰∏ÄÊääÂ§ßÂ∞èÁõ§‰∫åÂçÅÂõõÂÄãÈë≤ÈäÄË£πÊ•†Êú®ËÇâÊßΩÂõõÂÄã‰∏âÈë≤ÁÉèÊú®ÁÆ∏‰∫åÈõôÁï´ÂÉè‰∏äÁî®ÊéõÈá£‰∏âÂàÜ‰∫≠Â≠ê‰∏äÁî®ÈäÄÈù¢Ëëâ‰∏ÄÂàÜÈúÄÁî®Â§ñÂÉ±Èè®Ëä±Âå†Â§ßÂô®Âå†ÂÅöÁü≠Â∑•‰∏ÉÁôæ‰πùÂçÅ‰∏ÄÂ∑•ÂõõÂàÜ‰∫îÂéòÊØèÂ∑•Èå¢‰∏ÄÁôæ‰∏âÂçÅÂõõÊñáÈ†òÂéªÂ§ßÂà∂Èå¢‰∏ÄÁôæÂÖ≠‰∏≤‰∫îÂçÅÂõõÊñá ... ÊôÇÈñìÔºö‰πæÈöÜ01Âπ¥8Êúà ÂÆòÂè∏Ôºö ÂÆòÂì°Ôºö ÂæÆÊç≤È†ÅÊï∏Ôºö173-194 ÂÜäÊï∏Ôºö194 Ë≥áÊñôÂ∫´ÔºöÂÖßÂãôÂ∫úÂ•èÈä∑Ê™îÊ°à &quot;&quot;&quot; . We can also perform a quick retrieval using what we have just learnt. . pattern = re.compile(r&#39;(?&lt;=ÊôÇÈñì.).*&#39;) match = pattern.findall(text) match . [&#39;‰πæÈöÜ01Âπ¥8Êúà&#39;] . Combining with Web Scrapping, which we will learn later, we can then easily get information for text analysis. . . . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: December 2021 . . . . References: . https://github.com/CoreyMSchafer/code_snippets/blob/master/Python-Regular-Expressions/snippets.txt . https://stackoverflow.com/questions/2973436/regex-lookahead-lookbehind-and-atomic-groups . https://stackoverflow.com/questions/43418812/check-whether-a-string-contains-japanese-chinese-characters .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/jupyter/2020/01/22/Regular_Expression_TextExtraction.html",
            "relUrl": "/jupyter/2020/01/22/Regular_Expression_TextExtraction.html",
            "date": " ‚Ä¢ Jan 22, 2020"
        }
        
    
  
    
        ,"post11": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a ‚Äúlevel 1 heading‚Äù in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here‚Äôs a footnote 1. Here‚Äôs a horizontal rule: . . Lists . Here‚Äôs a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes ‚Ä¶and‚Ä¶ . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote.¬†&#8617; . |",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " ‚Ä¢ Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats.¬†&#8617; . |",
          "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ ‚Äúsitemap.xml‚Äù | absolute_url }} | .",
          "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}
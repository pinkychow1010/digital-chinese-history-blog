{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chinese_Keyword_Extraction_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# \"Combining Web Scraping with Keyword Extraction\"\n",
        "> \"Chinese Keyword Extraction using Jieba (II)\"\n",
        "\n",
        "- toc: true \n",
        "- badges: true\n",
        "- comments: true\n",
        "- categories: [level-4, chapter-4, jieba, BeautifulSoup, web-scraping]\n",
        "- image: images/tunnel.jpg"
      ],
      "metadata": {
        "id": "nCmIvi0Kmlbg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keyword extraction is one of the very popular techniques in Natural Language Processing (NLP) and text analysis. [Last time](https://pinkychow1010.github.io/digital-chinese-history-blog/level-4/chapter-4/jieba/text-mining/2022/02/05/Chinese_Keyword_Extraction_1.html) we learnt about how to extract keywords from Chinese text using **Jieba**, this time we will learn how to extract keywords directly from the web using **web scraping technique**. It can be achieved using **BeautifulSoup**, a Python library for pulling data out of HTML and XML files. What is web scraping? Web scraping is an automated process used to download the page (fetching) and copy data from the web. Examples include copying a table or book titles from a website.\n",
        "\n",
        "In this lesson, we will download the Chinese blog **æ—¶å·®æ’­å®¢ï¸±å®—æ•™å­¦ï¼šä¿¡ä»°ï¼Œé­”æ³•ï¼Œèº«ä»½ï¼ŒæƒåŠ›** from **æ¾æ¹ƒæ–°é—»** and extract keywords from the content. You will also learn how to do it with any website you want.\n",
        "\n",
        "> **IMPORTANT**: \n",
        ">\n",
        "> As mentioned in the [instructions](https://pinkychow1010.github.io/digital-chinese-history-blog/about/), you can click on the icon **\"open in Colab\"** to open the script in a **Jupyter notebook** to run the code. It is highly recommended to follow the tutorials in the correct order. \n",
        "\n",
        "# Set Up Environment ğŸŒ² \n",
        "\n",
        "First, we have to set up our cloud environment in **[Colab](https://pinkychow1010.github.io/digital-chinese-history-blog/level-1/chapter-1/jupyter/colab/2020/01/30/JupyterNotebook_Colab_Basics.html)**."
      ],
      "metadata": {
        "id": "j-BRrs3flzu7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Python Library\n",
        "\n",
        "* Download Library\n",
        "\n",
        "We need to download **Jieba** using **pip**."
      ],
      "metadata": {
        "id": "lnWcirdkeu3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install jieba"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKvv9f8AgxoT",
        "outputId": "441eca2a-bc10-4f2a-a8a1-1da399e74ed5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: jieba in /usr/local/lib/python3.7/dist-packages (0.42.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Import Libraries\n",
        "\n",
        "We will then import **Jieba**, **BeautifulSoup** and other libraries we need. ğŸ“š"
      ],
      "metadata": {
        "id": "2pn42IPjew4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import unicode_literals\n",
        "import sys\n",
        "sys.path.append(\"../\")\n",
        "\n",
        "# Jieba for tokenization and keyword extraction\n",
        "import jieba\n",
        "import jieba.posseg\n",
        "import jieba.analyse\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from skimage import filters\n",
        "import time\n",
        "\n",
        "# Open URL\n",
        "from urllib.request import urlopen, Request\n",
        "import ssl\n",
        "\n",
        "# Web scarping\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "GifW9jvKrTTJ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Google Drive\n",
        " \n",
        "* Connect to Google Drive\n",
        "\n",
        "To access resources in your own Google Drive, we need to permit it by running the following code."
      ],
      "metadata": {
        "id": "kly_Lk-Key8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9dM6BimsnGS",
        "outputId": "6cfc62dc-cc96-40f5-d30b-a96d7a8500c8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download Resources using wget\n",
        "\n",
        "In this lesson, there are two materials we need to download from the web. The first one is the Chinese font which we need to display characters in the plot. The second one is a list of Chinese stopwords which we need for tokenization. We can access both of them using **wget**.\n",
        "\n",
        "* Download Chinese Font"
      ],
      "metadata": {
        "id": "_7BUDFkOe0sM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download Chinese font\n",
        "!wget -O TaipeiSansTCBeta-Regular.ttf https://drive.google.com/uc?id=1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_&export=download\n",
        "\n",
        "# after download, we have to add the font into the plotting library\n",
        "# we need matplotlib.font_manager for that\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.font_manager import fontManager\n",
        "\n",
        "fontManager.addfont('TaipeiSansTCBeta-Regular.ttf')\n",
        "mpl.rc('font', family='Taipei Sans TC Beta')"
      ],
      "metadata": {
        "id": "0-uuHPvjj7cf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Download Chinese Stopword List\n",
        "\n",
        "From the github link, we can access the list of stopwords."
      ],
      "metadata": {
        "id": "EJkOSmIUe3BL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://github.com/stopwords-iso/stopwords-zh/blob/master/stopwords-zh.txt -P /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "2PD9Uvmx3rIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Web Scraping Basics ğŸŒ±\n",
        "\n",
        "We have learnt how to extract keywords from strings. What if this time, we do not want to copy the whole text, but directly get the text from the web? It can be done by directly scrapping the text from URLs using **BeautifulSoup** ğŸ¥£. \n",
        "\n",
        "The function BeautifulSoup from the library can parse the HTML code to Python objects. **Data parsing** is a process in which a string of data is converted from one format to another. To start with, we need to pass the web address to variable `url`, then open `url` using **urllib.request** and convert the code with `\"html.parser\"`. We will get the `soup` at the end. \n",
        "\n",
        "In order to extract only text for our analysis, we will remove the HTML tags using **extract()**, following by **get_text()**. To further exclude irrelevant texts from the headers, we can choose to select only the blog content by specifying the **class** of the content using **find()**. To find out the class, we can go to the webpage, open the **developer tool** and use the **inspector** to click on the blog content. We will then find out, the class we need is called **\"newsdetail_content\"**.\n",
        "\n",
        "To guide you through each step of the process, we will first get the text without filtering the data."
      ],
      "metadata": {
        "id": "gwYPieP1GUHP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 1:** Get the HTML without parsing.\n",
        "\n",
        "First, we will solely read the HTML code from the URL. We can see the result includes not only text but also HTML code. All the Chinese characters are also displayed in **UTF-8**."
      ],
      "metadata": {
        "id": "rL03-QXpsPRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read the link using request being sent from the Firefox web browser\n",
        "url = \"https://m.thepaper.cn/newsDetail_forward_13762466\"\n",
        "\n",
        "# this line is needed to avoid running into HTTP error 403 (access denial because of security)\n",
        "req = Request(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
        "html = urlopen(req).read()\n",
        "\n",
        "print(html[500:1000])"
      ],
      "metadata": {
        "id": "0AFUtvcLzVnO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "787a00f9-bb7f-4f65-83c6-59d269cb3851"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'-touch-fullscreen\"/>\\n<meta name=\"Keywords\" content=\"\\xe6\\xbe\\x8e\\xe6\\xb9\\x83\\xef\\xbc\\x8cPaper\\xef\\xbc\\x8cThe Paper\\xef\\xbc\\x8c\\xe7\\x83\\xad\\xe9\\x97\\xae\\xe7\\xad\\x94\\xef\\xbc\\x8c\\xe6\\x96\\xb0\\xe9\\x97\\xbb\\xe8\\xb7\\x9f\\xe8\\xb8\\xaa\\xef\\xbc\\x8c\\xe6\\x94\\xbf\\xe6\\xb2\\xbb\\xef\\xbc\\x8c\\xe6\\x97\\xb6\\xe6\\x94\\xbf\\xef\\xbc\\x8c\\xe6\\x94\\xbf\\xe7\\xbb\\x8f\\xef\\xbc\\x8c\\xe6\\xbe\\x8e\\xe6\\xb9\\x83\\xe6\\x96\\xb0\\xe9\\x97\\xbb\\xef\\xbc\\x8c\\xe6\\x96\\xb0\\xe9\\x97\\xbb\\xef\\xbc\\x8c\\xe6\\x80\\x9d\\xe6\\x83\\xb3\\xef\\xbc\\x8c\\xe5\\x8e\\x9f\\xe5\\x88\\x9b\\xe6\\x96\\xb0\\xe9\\x97\\xbb\\xef\\xbc\\x8c\\xe7\\xaa\\x81\\xe5\\x8f\\x91\\xe6\\x96\\xb0\\xe9\\x97\\xbb\\xef\\xbc\\x8c\\xe7\\x8b\\xac\\xe5\\xae\\xb6\\xe6\\x8a\\xa5\\xe9\\x81\\x93\\xef\\xbc\\x8c\\xe4\\xb8\\x8a\\xe6\\xb5\\xb7\\xe6\\x8a\\xa5\\xe4\\xb8\\x9a\\xef\\xbc\\x8c\\xe4\\xb8\\x9c\\xe6\\x96\\xb9\\xe6\\x97\\xa9\\xe6\\x8a\\xa5\\xef\\xbc\\x8c\\xe4\\xb8\\x9c\\xe6\\x96\\xb9\\xe6\\x8a\\xa5\\xe4\\xb8\\x9a\\xef\\xbc\\x8c\\xe4\\xb8\\x8a\\xe6\\xb5\\xb7\\xe4\\xb8\\x9c\\xe6\\x96\\xb9\\xe6\\x8a\\xa5\\xe4\\xb8\\x9a\" />\\n<meta name=\"Description\" content=\"\\xe6\\xbe\\x8e\\xe6\\xb9\\x83\\xef\\xbc\\x8c\\xe6\\xbe\\x8e\\xe6\\xb9\\x83\\xe6\\x96\\xb0\\xe9\\x97\\xbb\\xef\\xbc\\x8c\\xe6\\xbe\\x8e\\xe6\\xb9\\x83\\xe6\\x96\\xb0\\xe9\\x97\\xbb\\xe7\\xbd\\x91\\xef\\xbc\\x8c\\xe6\\x96\\xb0\\xe9\\x97\\xbb\\xe4\\xb8\\x8e\\xe6\\x80\\x9d\\xe6\\x83\\xb3\\xef\\xbc\\x8c\\xe6\\xbe\\x8e\\xe6\\xb9\\x83\\xe6\\x98\\xaf\\xe6\\xa4\\x8d\\xe6\\xa0\\xb9\\xe4\\xba\\x8e\\xe4\\xb8\\xad\\xe5\\x9b\\xbd\\xe4\\xb8\\x8a\\xe6\\xb5\\xb7\\xe7\\x9a\\x84\\xe6\\x97\\xb6\\xe6\\x94\\xbf\\xe6\\x80\\x9d\\xe6\\x83\\xb3\\xe7\\xb1\\xbb\\xe4\\xba\\x92\\xe8\\x81\\x94\\xe7\\xbd\\x91\\xe5\\xb9\\xb3\\xe5\\x8f\\xb0\\xef\\xbc\\x8c\\xe4\\xbb\\xa5\\xe6\\x9c\\x80\\xe6\\xb4\\xbb\\xe8\\xb7\\x83\\xe7\\x9a\\x84\\xe5\\x8e\\x9f\\xe5\\x88\\x9b\\xe6\\x96\\xb0\\xe9\\x97\\xbb\\xe4\\xb8\\x8e\\xe6\\x9c\\x80\\xe5\\x86\\xb7\\xe9\\x9d\\x99\\xe7\\x9a\\x84\\xe6\\x80\\x9d\\xe6\\x83\\xb3\\xe5\\x88\\x86\\xe6\\x9e\\x90\\xe4\\xb8\\xba\\xe4\\xb8'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 2:** Parse the HTML.\n",
        "\n",
        "After parsing the HTML, the layout gets easier to read. We begin to recognize the Chinese characters, but still with a lot of code."
      ],
      "metadata": {
        "id": "n3SMaLtGTJq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# parse it to BeautifulSoup\n",
        "soup = BeautifulSoup(html, features=\"html.parser\")\n",
        "\n",
        "type(soup)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYn6MsoGx00o",
        "outputId": "e37c6924-9f67-4371-c217-c0abf98d479f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "bs4.BeautifulSoup"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soup_string = str(soup)\n",
        "print(soup_string[:1500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVBh9vtxyODs",
        "outputId": "22a98c2c-1f13-4524-acae-790e5a74202a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<!DOCTYPE html>\n",
            "\n",
            "<html lang=\"cn\">\n",
            "<head>\n",
            "<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n",
            "<meta content=\"zh-CN\" http-equiv=\"content-language\"/>\n",
            "<meta content=\"initial-scale=1.0,minimum-scale=1.0,maximum-scale=1.0,user-scalable=no,viewport-fit=cover\" name=\"viewport\"/>\n",
            "<meta content=\"no\" name=\"apple-mobile-web-app-capable\"/>\n",
            "<meta content=\"black\" name=\"apple-mobile-web-app-status-bar-style\">\n",
            "<meta content=\"telephone=no\" name=\"format-detection\"/>\n",
            "<meta content=\"yes\" name=\"apple-touch-fullscreen\">\n",
            "<meta content=\"æ¾æ¹ƒï¼ŒPaperï¼ŒThe Paperï¼Œçƒ­é—®ç­”ï¼Œæ–°é—»è·Ÿè¸ªï¼Œæ”¿æ²»ï¼Œæ—¶æ”¿ï¼Œæ”¿ç»ï¼Œæ¾æ¹ƒæ–°é—»ï¼Œæ–°é—»ï¼Œæ€æƒ³ï¼ŒåŸåˆ›æ–°é—»ï¼Œçªå‘æ–°é—»ï¼Œç‹¬å®¶æŠ¥é“ï¼Œä¸Šæµ·æŠ¥ä¸šï¼Œä¸œæ–¹æ—©æŠ¥ï¼Œä¸œæ–¹æŠ¥ä¸šï¼Œä¸Šæµ·ä¸œæ–¹æŠ¥ä¸š\" name=\"Keywords\"/>\n",
            "<meta content=\"æ¾æ¹ƒï¼Œæ¾æ¹ƒæ–°é—»ï¼Œæ¾æ¹ƒæ–°é—»ç½‘ï¼Œæ–°é—»ä¸æ€æƒ³ï¼Œæ¾æ¹ƒæ˜¯æ¤æ ¹äºä¸­å›½ä¸Šæµ·çš„æ—¶æ”¿æ€æƒ³ç±»äº’è”ç½‘å¹³å°ï¼Œä»¥æœ€æ´»è·ƒçš„åŸåˆ›æ–°é—»ä¸æœ€å†·é™çš„æ€æƒ³åˆ†æä¸ºä¸¤ç¿¼ï¼Œæ˜¯äº’è”ç½‘æŠ€æœ¯åˆ›æ–°ä¸æ–°é—»ä»·å€¼ä¼ æ‰¿çš„ç»“åˆä½“ï¼Œè‡´åŠ›äºé—®ç­”å¼æ–°é—»ä¸æ–°é—»è¿½è¸ªåŠŸèƒ½çš„å®è·µã€‚\" name=\"Description\"/>\n",
            "<meta content=\"max-age=1700\" http-equiv=\"Cache-control\"/>\n",
            "<meta content=\"on\" http-equiv=\"cleartype\"/>\n",
            "<title>æ—¶å·®æ’­å®¢ï¸±å®—æ•™å­¦ï¼šä¿¡ä»°ï¼Œé­”æ³•ï¼Œèº«ä»½ï¼ŒæƒåŠ›</title>\n",
            "<link href=\"https://file.thepaper.cn/wap/v6/css/reset.css?v=2.1.5\" rel=\"stylesheet\" type=\"text/css\"/>\n",
            "<link href=\"https://file.thepaper.cn/wap/v6/css/swiper-bundle.min.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
            "<link href=\"https://file.thepaper.cn/wap/v6/css/base_v6.css?v=2.1.5\" rel=\"stylesheet\" type=\"text/css\"/>\n",
            "<link href=\"https://file.thepaper.cn/wap/v6/css/homepage_v6.css?v=2.1.5\" rel=\"stylesheet\" type=\"text/css\"/>\n",
            "<link href=\"https://file.thepaper.cn/wap/v6/css/newsdetail_v6.css?v=2.1.5\" rel=\"stylesheet\" type=\"text/css\"/>\n",
            "<script src=\"//7b71.t4m.cn/applink.js\" type=\"text/jav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 3:** Get the text with tags removal and without class selection\n",
        "\n",
        "To clean it up, we need to extract the content using **extract()** and **get_text()**. Now things look much better! Nonetheless, we still need to remove the header texts."
      ],
      "metadata": {
        "id": "2TgH1yEzTahw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# kill all script and style elements\n",
        "for script in soup([\"script\", \"style\"]):\n",
        "    script.extract()    # rip it out\n",
        "\n",
        "# get text\n",
        "text = soup.get_text()"
      ],
      "metadata": {
        "id": "FFKVD9LCIKiW"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[500:1500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQmg3Gf2Jh4M",
        "outputId": "187772b2-bb84-4188-f6a7-648ecb3ae4a0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ç§å®¶åœ°ç†\n",
            "éå¸¸å“\n",
            "æ¥¼å¸‚\n",
            "ç”Ÿæ´»æ–¹å¼\n",
            "æ¾æ¹ƒè”æ’­\n",
            "è§†ç•Œ\n",
            "äº²å­å­¦å ‚\n",
            "åŒ—äº¬å†¬å¥¥\n",
            "æ±½è½¦åœˆ\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "æ€æƒ³å¸‚åœº\n",
            "\n",
            "å»APPå¬\n",
            "\n",
            "\n",
            "æ—¶å·®æ’­å®¢ï¸±å®—æ•™å­¦ï¼šä¿¡ä»°ï¼Œé­”æ³•ï¼Œèº«ä»½ï¼ŒæƒåŠ›\n",
            "æ—¶å·®æ’­å®¢\n",
            "\n",
            "                2021-07-30 12:29Â \n",
            "                \n",
            "                    \n",
            "                        æ¥æºï¼šæ¾æ¹ƒæ–°é—»\n",
            "                    \n",
            "                    \n",
            "                \n",
            "            \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\r\n",
            "            {{newsTimeline.name}}\r\n",
            "        \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\r\n",
            "                        {{item.occurrenceDay}}\r\n",
            "                    \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "{{content.occurrenceTime}}\n",
            "\n",
            " {{content.name}}\n",
            "\n",
            "æŸ¥çœ‹è¯¦æƒ…\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "å…¨éƒ¨å±•å¼€\n",
            "æ”¶èµ·æ—¶é—´çº¿\n",
            "\n",
            "\n",
            "\n",
            "æœ¬æœŸã€Šæ—¶å·®ã€‹æ’­å®¢ï¼Œä¸»æŒäººå¤šä¼¦å¤šå¤§å­¦åŠ©ç†æ•™æˆéƒ­å©·é‚€è¯·åˆ°äº†æ¥è‡ªå®¾å¤•æ³•å°¼äºšå¤§å­¦çš„ç¨‹æ™“æ–‡æ•™æˆã€é¦™æ¸¯å¤§å­¦çš„æçºªæ•™æˆã€å¼—å‰å°¼äºšç†å·¥å¤§å­¦çš„å€ªæ¹›èˆ¸æ•™æˆä»¥åŠèŠåŠ å“¥å¤§å­¦ç¥å­¦é™¢çš„ç¥åŠ¡ç¡•å£«ã€åŒ»é™¢å®—æ•™å¸ˆéƒ‘åˆ©æ˜•ï¼Œä»¥â€œå®—æ•™å­¦ï¼šä¿¡ä»°ï¼Œé­”æ³•ï¼Œèº«ä»½ï¼ŒæƒåŠ›â€ä¸ºé¢˜å±•å¼€è®¨è®ºã€‚å®—æ•™å¹¶ä¸å¤–åœ¨äºæ—¥å¸¸ç”Ÿæ´»ï¼Œè€Œæ˜¯å¼¥æ•£åœ¨ç¤¾ä¼šã€å†å²ã€æ–‡åŒ–ã€æ”¿æ²»ä¸­çš„ç‚¹æ»´ï¼›å®—æ•™å­¦å¸®åŠ©æˆ‘ä»¬åæ€å†å²ï¼ŒåŒæ—¶ç†è§£ä»Šå¤©çš„ä¸–ç•Œã€‚æœ¬æ–‡ä¸ºæ—¶å·®æ’­å®¢ä¸æ¾æ¹ƒæ–°é—»åˆä½œåˆŠå‘çš„æ–‡å­—ç¨¿ï¼Œç”±æ¾æ¹ƒæ–°é—»ï¼ˆwww.thepaper.cnï¼‰è®°è€…é¾šæ€é‡æ•´ç†ã€‚è§‚éŸ³è€æ¯æ´éƒ­å©·ï¼šåœ¨ä»Šå¤©èŠ‚ç›®å¼€å§‹ä¹‹å‰ï¼Œæˆ‘æƒ³å…ˆè¡¨è¾¾ä¸€ä¸‹æ²‰ç—›çš„æ‚¼å¿µï¼Œå‰å‡ å¤©æœ‰ä¸€ä½å®—æ•™å­¦ç•Œçš„å‰è¾ˆï¼Œå°å¤§çš„æ—å¯Œå£«è€å¸ˆï¼ˆ1960-2021ï¼‰å»ä¸–äº†ã€‚æˆ‘æœ¬æ¥å¹¶ä¸æ˜¯ç ”ç©¶ä¸­å›½å®—æ•™çš„ï¼Œä¹Ÿä¸ç ”ç©¶ä¼ ç»Ÿçš„ä¸­å›½æ–‡å²å“²ï¼Œæ‰€ä»¥å¹¶æ²¡æœ‰å’Œæ—è€å¸ˆè§è¿‡é¢ã€‚ä½†æˆ‘ä¸€ç›´ä»ä»–çš„ç ”ç©¶ä¸­å¾—åˆ°çµæ„Ÿï¼Œæ‰€ä»¥éå¸¸æ„Ÿè°¢ä»–ã€‚è¿™ä¸¤å¤©ä¹Ÿåœ¨è„¸ä¹¦ä¸Šï¼Œçœ‹åˆ°å¾ˆå¤šä»–è¿‡å»çš„åŒäº‹å’Œå­¦ç”Ÿå¯¹ä»–çš„çºªå¿µã€‚è™½ç„¶å­¦æœ¯ç•Œå¾ˆå¤šæ—¶å€™æ˜¯ä¸€ä¸ªæœ‰å¤±å…¬æ­£çš„åœ°æ–¹ï¼Œä½†è¿˜æ˜¯æœ‰ä¸€äº›åœ°æ–¹è®©äººè§‰å¾—æ¸©æš–ï¼Œå°±å¥½åƒç‚¹äº®äº†ä¸€ç›ç¯ï¼Œè€Œé‚£ç›ç¯ä¸€ç›´ä¼šäº®ä¸‹å»ã€‚è¿™ä¸€æœŸæˆ‘ä»¬æ¥è°ˆå®—æ•™å­¦ï¼Œä¸åªæ˜¯è°ˆå­¦ç•Œï¼Œä¹Ÿè°ˆå®ƒçš„å®è·µã€‚åœ¨åº§å‡ ä½è™½ç„¶æ˜¯è·¨å­¦ç§‘çš„ç ”ç©¶è€…æˆ–å®è·µè€…ï¼Œä½†ä¹Ÿæ˜¯å®—æ•™å­¦å‡ºèº«ã€‚é‚£æˆ‘ç›¸ä¿¡ï¼Œå¤§å®¶åœ¨å’Œåˆ«äººä»‹ç»è¯´è‡ªå·±ç ”ç©¶å®—æ•™å­¦çš„æ—¶å€™ï¼Œé€šå¸¸ä¼šå¬åˆ°å‡ ä¸ªé—®é¢˜ï¼š\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 4:** Get the text with tags removal and class selection\n",
        "\n",
        "We can remove all irrelevant sessions from the website by specifying the class. We can filter a specific class using **find()**. The class is identified using the developer tools in the browser. Please pay attention: we can only get the **first item** in this class using find(). Another option would be **find_all()** which returns a list of matches. The output is the clean text we were expecting.ğŸŒŸ"
      ],
      "metadata": {
        "id": "Gt1bzemOTmBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = soup.find(\"div\", {\"class\": \"newsdetail_content\"}).get_text()\n",
        "\n",
        "text[:1000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "id": "GmRBGXMkKDEj",
        "outputId": "fe6354df-fd8a-40b6-fc15-d9e60595e748"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'æœ¬æœŸã€Šæ—¶å·®ã€‹æ’­å®¢ï¼Œä¸»æŒäººå¤šä¼¦å¤šå¤§å­¦åŠ©ç†æ•™æˆéƒ­å©·é‚€è¯·åˆ°äº†æ¥è‡ªå®¾å¤•æ³•å°¼äºšå¤§å­¦çš„ç¨‹æ™“æ–‡æ•™æˆã€é¦™æ¸¯å¤§å­¦çš„æçºªæ•™æˆã€å¼—å‰å°¼äºšç†å·¥å¤§å­¦çš„å€ªæ¹›èˆ¸æ•™æˆä»¥åŠèŠåŠ å“¥å¤§å­¦ç¥å­¦é™¢çš„ç¥åŠ¡ç¡•å£«ã€åŒ»é™¢å®—æ•™å¸ˆéƒ‘åˆ©æ˜•ï¼Œä»¥â€œå®—æ•™å­¦ï¼šä¿¡ä»°ï¼Œé­”æ³•ï¼Œèº«ä»½ï¼ŒæƒåŠ›â€ä¸ºé¢˜å±•å¼€è®¨è®ºã€‚å®—æ•™å¹¶ä¸å¤–åœ¨äºæ—¥å¸¸ç”Ÿæ´»ï¼Œè€Œæ˜¯å¼¥æ•£åœ¨ç¤¾ä¼šã€å†å²ã€æ–‡åŒ–ã€æ”¿æ²»ä¸­çš„ç‚¹æ»´ï¼›å®—æ•™å­¦å¸®åŠ©æˆ‘ä»¬åæ€å†å²ï¼ŒåŒæ—¶ç†è§£ä»Šå¤©çš„ä¸–ç•Œã€‚æœ¬æ–‡ä¸ºæ—¶å·®æ’­å®¢ä¸æ¾æ¹ƒæ–°é—»åˆä½œåˆŠå‘çš„æ–‡å­—ç¨¿ï¼Œç”±æ¾æ¹ƒæ–°é—»ï¼ˆwww.thepaper.cnï¼‰è®°è€…é¾šæ€é‡æ•´ç†ã€‚è§‚éŸ³è€æ¯æ´éƒ­å©·ï¼šåœ¨ä»Šå¤©èŠ‚ç›®å¼€å§‹ä¹‹å‰ï¼Œæˆ‘æƒ³å…ˆè¡¨è¾¾ä¸€ä¸‹æ²‰ç—›çš„æ‚¼å¿µï¼Œå‰å‡ å¤©æœ‰ä¸€ä½å®—æ•™å­¦ç•Œçš„å‰è¾ˆï¼Œå°å¤§çš„æ—å¯Œå£«è€å¸ˆï¼ˆ1960-2021ï¼‰å»ä¸–äº†ã€‚æˆ‘æœ¬æ¥å¹¶ä¸æ˜¯ç ”ç©¶ä¸­å›½å®—æ•™çš„ï¼Œä¹Ÿä¸ç ”ç©¶ä¼ ç»Ÿçš„ä¸­å›½æ–‡å²å“²ï¼Œæ‰€ä»¥å¹¶æ²¡æœ‰å’Œæ—è€å¸ˆè§è¿‡é¢ã€‚ä½†æˆ‘ä¸€ç›´ä»ä»–çš„ç ”ç©¶ä¸­å¾—åˆ°çµæ„Ÿï¼Œæ‰€ä»¥éå¸¸æ„Ÿè°¢ä»–ã€‚è¿™ä¸¤å¤©ä¹Ÿåœ¨è„¸ä¹¦ä¸Šï¼Œçœ‹åˆ°å¾ˆå¤šä»–è¿‡å»çš„åŒäº‹å’Œå­¦ç”Ÿå¯¹ä»–çš„çºªå¿µã€‚è™½ç„¶å­¦æœ¯ç•Œå¾ˆå¤šæ—¶å€™æ˜¯ä¸€ä¸ªæœ‰å¤±å…¬æ­£çš„åœ°æ–¹ï¼Œä½†è¿˜æ˜¯æœ‰ä¸€äº›åœ°æ–¹è®©äººè§‰å¾—æ¸©æš–ï¼Œå°±å¥½åƒç‚¹äº®äº†ä¸€ç›ç¯ï¼Œè€Œé‚£ç›ç¯ä¸€ç›´ä¼šäº®ä¸‹å»ã€‚è¿™ä¸€æœŸæˆ‘ä»¬æ¥è°ˆå®—æ•™å­¦ï¼Œä¸åªæ˜¯è°ˆå­¦ç•Œï¼Œä¹Ÿè°ˆå®ƒçš„å®è·µã€‚åœ¨åº§å‡ ä½è™½ç„¶æ˜¯è·¨å­¦ç§‘çš„ç ”ç©¶è€…æˆ–å®è·µè€…ï¼Œä½†ä¹Ÿæ˜¯å®—æ•™å­¦å‡ºèº«ã€‚é‚£æˆ‘ç›¸ä¿¡ï¼Œå¤§å®¶åœ¨å’Œåˆ«äººä»‹ç»è¯´è‡ªå·±ç ”ç©¶å®—æ•™å­¦çš„æ—¶å€™ï¼Œé€šå¸¸ä¼šå¬åˆ°å‡ ä¸ªé—®é¢˜ï¼šä¸€ä¸ªæ˜¯é‚£ä½ æœ‰æ²¡æœ‰å®—æ•™ä¿¡ä»°ï¼Ÿæˆ–è€…ä½ ç ”ç©¶å“ªä¸€ç§å®—æ•™ï¼Ÿä»¥å‰è¿˜ä¼šå¬åˆ°çš„ä¸€ä¸ªé—®é¢˜æ˜¯ï¼Œé‚£ä½ æ¯•ä¸šä¹‹ååšä»€ä¹ˆï¼Œæ˜¯ä¸æ˜¯å‡†å¤‡å‡ºå®¶ç­‰ç­‰ã€‚æˆ‘ä»¥å‰ä¼šå¼€ç©ç¬‘è¯´ï¼Œå¯¹ï¼Œä»¥åå‡ºå®¶ç»™äººç®—å‘½ã€‚å…¶å®ä¸åªæ˜¯å­¦ç•Œä¹‹å¤–ï¼ŒåŒ…æ‹¬å­¦ç•Œä¹‹å†…ï¼Œä¸åŒå­¦ç§‘å¯¹å®—æ•™å­¦é¢†åŸŸéƒ½ä¼šæœ‰ä¸€äº›é™Œç”Ÿï¼Œå› ä¸ºå®ƒç¡®å®æ˜¯ä¸€ä¸ªæ¯”è¾ƒç‰¹æ®Šçš„å­¦ç§‘ã€‚å°±æˆ‘è‡ªå·±è€Œè¨€ï¼Œæˆ‘åšå£«çš„è®­ç»ƒåœ¨çˆ±ä¸å ¡å¤§å­¦çš„ç¥å­¦é™¢ã€‚çˆ±å¤§ç¥å­¦é™¢ä½œä¸ºä¸€ä¸ªæ–°å…´ç§‘ç³»ï¼Œæ¯”è¾ƒæœ‰æŠ—äº‰ç²¾ç¥å’Œåˆ›æ–°ç²¾ç¥ã€‚å®ƒè®¾ç«‹ä¹‹åˆå°±æ˜¯ä¸ºäº†å’Œä¼ ç»Ÿçš„ç¥å­¦æˆ–è€…æ˜¯å’Œå®—æ•™æœ‰å…³çš„å­¦ç§‘å¯¹æŠ—ï¼Œæ‰€ä»¥å®ƒéå¸¸è®²ç©¶ä¸–ä¿—åŒ–å’Œç¤¾ä¼šç§‘å­¦æ–¹æ³•ã€‚æˆ‘è®°å¾—å¤§éƒ¨åˆ†å®—æ•™ç³»çš„å­¦è€…ä¸è®ºç”·å¥³éƒ½æ‰“æ‰®å¾—éå¸¸ä¸ç¾ã€‚åœ¨å¼€ä¼šçš„æ—¶å€™ï¼Œç¾å›½å®—æ•™å­¦ã€å°¤å…¶æ˜¯åœ£ç»ç ”ç©¶çš„å­¦è€…å°¤å…¶ç”·æ€§ä¼šæ‰“æ‰®å¾—éå¸¸é—ªäº®ï¼Œå¤´å‘ç„—è¿‡ã€ç©¿è¥¿è£…ã€å¸¦é¢†å¸¦ã€é‹å­éƒ½æ“¦å¾—å¾ˆäº®ï¼Œä½†æ˜¯è‹±å›½å®—æ•™ç³»çš„è€å¸ˆå°±ç©¿å¾—å¾ˆéšä¾¿ã€‚è€Œå®—æ•™å­¦å­¦ç§‘çš„è®­ç»ƒè®²ç©¶å®—æ•™å’Œç¤¾ä¼šçš„å…³ç³»ã€å®—æ•™å’Œå½“ä¸‹ç¤¾ä¼šçš„å…³ç³»ã€‚è™½ç„¶æˆ‘å½“æ—¶çš„ç ”ç©¶æ˜¯ä»AIäººå·¥æ™ºèƒ½åˆ‡å…¥ï¼Œä½†å…¶å®æ˜¯ç ”ç©¶æ˜¯è‹±å›½çš„ä¸–ä¿—åŒ–çš„æƒ…å†µã€‚å½“ç„¶ï¼Œåœ¨ç¥å­¦é™¢ä¹Ÿä¼šç¢°åˆ°å…¶ä»–ç§‘ç³»çš„åŒå­¦ï¼Œæ¯”å¦‚æœ‰æ—§çº¦ç ”ç©¶ã€æ–°çº¦ç ”ç©¶ï¼Œç¥å­¦ç ”ç©¶ï¼Œç„¶åä¹Ÿæœ‰ä¸€äº›é“å­¦åšå£«æˆ–è€…æ˜¯æ•™ç‰§å­¦çš„å­¦ä½ã€‚é‚£æƒ³è¯·å‡ ä½èŠèŠï¼Œä½ ä»¬çš„ç ”ç©¶èƒŒæ™¯æ˜¯æ€ä¹ˆæ ·çš„ï¼Œä¹Ÿå¯ä»¥è·Ÿ'"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 5:** Keyword Extraction\n",
        "**The final step is exactly what we did in the [last tutorial](https://pinkychow1010.github.io/digital-chinese-history-blog/level-4/chapter-4/jieba/text-mining/2022/02/05/Chinese_Keyword_Extraction_1.html)!** It defines the stopwords and extracts 10 keywords from the text."
      ],
      "metadata": {
        "id": "f5zjBGBvXQlR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords= r\"/content/drive/MyDrive/NLP/stopwords.txt\"\n",
        "url = \"https://m.thepaper.cn/newsDetail_forward_16254733\"\n",
        "\n",
        "jieba.analyse.set_stop_words(stopwords)\n",
        "tags = jieba.analyse.extract_tags(text, topK=10, withWeight=True)"
      ],
      "metadata": {
        "id": "tn3dDW8aXHCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Keywords:**\n",
        "Let's look at our result."
      ],
      "metadata": {
        "id": "6jxHQmGzXe6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tags"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kz4ma5wvXdXg",
        "outputId": "469e49f7-85ba-4deb-d22b-4693bdf207b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('å®—æ•™', 0.2162035113456979),\n",
              " ('ç ”ç©¶', 0.1056884665277731),\n",
              " ('å®—æ•™å­¦', 0.07345268363971678),\n",
              " ('åŸºç£æ•™', 0.061966732508025965),\n",
              " ('å¥³æ€§', 0.05076592702813553),\n",
              " ('ç¥å­¦é™¢', 0.04378034740564733),\n",
              " ('å¤©ä¸»æ•™', 0.040147481422144304),\n",
              " ('ä¼ ç»Ÿ', 0.033391922322156105),\n",
              " ('ç°åœ¨', 0.032659074433310856),\n",
              " ('ç¤¾ä¼š', 0.031786899511790284)]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Writing a Function \n",
        "\n",
        "To simplify the steps, we can condense everything into a short function. If you do not know yet how to build a function, [check it out](https://pinkychow1010.github.io/digital-chinese-history-blog/programming/chapter-1/level-1/2020/01/26/FunctionsNLoops_Basics.html). This function will take an URL, the number of keywords and a stopword list. It will then return the keywords in the list. "
      ],
      "metadata": {
        "id": "tfhxk_nhG6aq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_keywords(url,n,stopwords, withWeight=False):\n",
        "  \"\"\"\n",
        "  This function extract a number of keywords from a webpage after excluding the stopwords\n",
        "  url: str\n",
        "    the webpage\n",
        "  n: int\n",
        "    number of keywords extracted\n",
        "  stopwords: str\n",
        "    a path to the stopword text file\n",
        "  returns: list\n",
        "    list of keywords extracted from the webpage\n",
        "  \"\"\"\n",
        "  req = Request(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
        "  html = urlopen(req).read()\n",
        "  soup = BeautifulSoup(html, features=\"html.parser\")\n",
        "\n",
        "  # kill all script and style elements\n",
        "  for script in soup([\"script\", \"style\"]):\n",
        "      script.extract()    # rip it out\n",
        "\n",
        "  # get text\n",
        "  text = soup.find(\"div\", {\"class\": \"newsdetail_content\"}).get_text()\n",
        "\n",
        "  # exclude stopwords\n",
        "  jieba.analyse.set_stop_words(stopwords)\n",
        "\n",
        "  # get keywords\n",
        "  tags = jieba.analyse.extract_tags(text, topK=n, withWeight=withWeight)\n",
        "  return tags"
      ],
      "metadata": {
        "id": "1WfeuX0-1JHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By applying the function, we get a list of 10 keywords:\n",
        "**'ç ”ç©¶', 'è¯—æ­Œ', 'ä¸­å›½', 'è”¡å®—é½', 'å­¦è€…', 'æ¾æ¹ƒ', 'æ–‡å­¦', 'è¯—å¢ƒ', 'è¯­æ³•', 'æ±‰è¯—'**"
      ],
      "metadata": {
        "id": "2Xtldgl45UXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords= r\"/content/drive/MyDrive/NLP/stopwords.txt\"\n",
        "n = 10\n",
        "url = \"https://m.thepaper.cn/newsDetail_forward_16254733\"\n",
        "\n",
        "extract_keywords(url=url,n=n,stopwords=stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sypreaLM1sB_",
        "outputId": "ee3a8f54-f367-4584-e525-d99ec2c91c1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ç ”ç©¶', 'è¯—æ­Œ', 'ä¸­å›½', 'è”¡å®—é½', 'å­¦è€…', 'æ¾æ¹ƒ', 'æ–‡å­¦', 'è¯—å¢ƒ', 'è¯­æ³•', 'æ±‰è¯—']"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Try it out yourself** ğŸ§"
      ],
      "metadata": {
        "id": "ObEmdUo-zOIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_keywords_general(url,n,stopwords, withWeight=False):\n",
        "  \"\"\"\n",
        "  This function extract a number of keywords from a webpage after excluding the stopwords\n",
        "  url: str\n",
        "    the webpage\n",
        "  n: int\n",
        "    number of keywords extracted\n",
        "  stopwords: str\n",
        "    a path to the stopword text file\n",
        "  returns: list\n",
        "    list of keywords extracted from the webpage\n",
        "  \"\"\"\n",
        "  req = Request(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
        "  html = urlopen(req).read()\n",
        "  soup = BeautifulSoup(html, features=\"html.parser\")\n",
        "\n",
        "  # kill all script and style elements\n",
        "  for script in soup([\"script\", \"style\"]):\n",
        "      script.extract()    # rip it out\n",
        "\n",
        "  # get text\n",
        "  text = soup.get_text()\n",
        "\n",
        "  # exclude stopwords\n",
        "  jieba.analyse.set_stop_words(stopwords)\n",
        "\n",
        "  # get keywords\n",
        "  tags = jieba.analyse.extract_tags(text, topK=n, withWeight=withWeight)\n",
        "  return tags"
      ],
      "metadata": {
        "id": "j4GxeIDTy7Sc"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ¤” Put a URL here â¬‡ï¸"
      ],
      "metadata": {
        "id": "5AAwCc0t1Kri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords= r\"/content/drive/MyDrive/NLP/stopwords.txt\"\n",
        "\n",
        "myKeywords = extract_keywords_general(url=\"https://ctext.org/zh\",n=10,stopwords=stopwords) # Put in any URL you want\n",
        "print(myKeywords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sI7mSAqczJUp",
        "outputId": "c7132699-9715-4ef1-f0a4-809e76513140"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['è³‡æ–™', 'é¡¯ç¤º', 'ä¾†æº', 'æ–‡ç»', 'å­—é«”', 'ä¸­åœ‹', 'åœ–æ›¸é¤¨', 'é€™äº›', 'æœ¬ç«™', 'ç®—ç¶“']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract Keywords from Multiple Blogs\n",
        "\n",
        "Until now, we can only extract keywords for one text at a time. To further automate what we did, we can loop through multiple articles. If you do not know yet how to build a loop, [check it out](https://pinkychow1010.github.io/digital-chinese-history-blog/programming/chapter-1/level-1/2020/01/26/FunctionsNLoops_Basics.html). Please pay attention: as we are going through the webpages using Python, the server might be overloaded with too many requests in a very short time. To avoid potential errors, we can catch the errors using **try** and **except**, and put **time.sleep()** in between using **time** library. We will let the program *sleep* for 5 seconds after scrapping each web address."
      ],
      "metadata": {
        "id": "GzMr7n4gHD0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords= r\"/content/drive/MyDrive/NLP/stopwords.txt\"\n",
        "n = 10\n",
        "keyword_list = []\n",
        "\n",
        "for page in range(10000000,10000010):\n",
        "  url = \"https://m.thepaper.cn/newsDetail_forward_{}\".format(page)\n",
        "  print(url)\n",
        "  time.sleep(5)\n",
        "\n",
        "  try:\n",
        "    keywords = extract_keywords(url=url,n=n,stopwords=stopwords)\n",
        "  except Exceptions:\n",
        "      print(\"Interrupted\")\n",
        "\n",
        "  keyword_list.append(keywords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrDWRalnU8Zd",
        "outputId": "c1f29cd1-010b-4ffd-88fa-ca34b648b536"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://m.thepaper.cn/newsDetail_forward_10000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 1.096 seconds.\n",
            "Prefix dict has been built successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://m.thepaper.cn/newsDetail_forward_10000001\n",
            "https://m.thepaper.cn/newsDetail_forward_10000002\n",
            "https://m.thepaper.cn/newsDetail_forward_10000003\n",
            "https://m.thepaper.cn/newsDetail_forward_10000004\n",
            "https://m.thepaper.cn/newsDetail_forward_10000005\n",
            "https://m.thepaper.cn/newsDetail_forward_10000006\n",
            "https://m.thepaper.cn/newsDetail_forward_10000007\n",
            "https://m.thepaper.cn/newsDetail_forward_10000008\n",
            "https://m.thepaper.cn/newsDetail_forward_10000009\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Export Keyword List**\n",
        "\n",
        "We have appended the keywords to a list **keyword_list** when we loop through the articles. Now, we can access all keywords by looking into our list."
      ],
      "metadata": {
        "id": "tF82e6jL4r2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keyword_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtbRGVE9MmWF",
        "outputId": "5b8d0ad2-d292-41fa-937d-f5ccc82d1890"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['æ‹”èåœ', 'èåœ', 'é‡‡æ‘˜', 'å­©å­', 'èœå›­', 'æ”¶è·', 'å‘¨æœ«ç‰ˆ', 'å®è·µ', 'çƒ­çˆ±åŠ³åŠ¨', 'ç»ˆè§‰'],\n",
              " ['ç»¿è‰²', 'å¾ªç¯', 'æ¹–å—çœ', '10', 'ç¯ä¿', 'ç”Ÿæ€', 'æ´»åŠ¨', 'å…‘æ¢', 'åƒåœ¾', 'åˆ†ç±»'],\n",
              " ['å´é‚®é‚®', 'ä¸‰è½®è½¦', 'å­©å­', 'å°å­™å­', 'äº‹è¿¹', 'å½’ä»', '2019', '12', 'é«˜æ–‡å¨Ÿ', 'å¾®ä¿¡'],\n",
              " ['æµ™å¤§', 'æµ™æ±Ÿå¤§å­¦', 'æ–°äºº', 'è®°è€…å›¢', 'ç¼˜å®š', 'æ˜Ÿæ²³', 'æ¯æ ¡', '2020', '123', 'æå…°å¨Ÿ'],\n",
              " ['æµå—', 'å…¬å®‰', 'æŠ¥å‘Š', 'åŸæ–‡', 'äº¤è­¦', 'æ ‡é¢˜', 'é˜…è¯»'],\n",
              " ['å¹´ä¼š', 'ç¯ä¿', 'æ¹–å—çœ', 'ç¤¾ä¼š', 'è¡ŒåŠ¨è€…', '2020', 'ç”Ÿæ€', 'ç»„ç»‡', 'ç»¿è‰²', 'ç¯å¢ƒæ²»ç†'],\n",
              " ['æ–©è‚‰', 'æµ·å®‰', 'ç‚¸åˆ¶', 'ç™½æ–©', 'ç‚–ç…®', '--', 'è‘±å§œ', 'çŒ´æ€¥', 'éº»è™¾', 'é»„æ¯›'],\n",
              " ['é«˜æ°', 'æ‰§æ³•', 'å­¦æ³•', 'å…¬å®‰', 'å…¬å®‰æœºå…³', 'å¤šé¢æ‰‹', 'å…¨å¸‚', 'æ³•æ²»', 'å¤è®®', 'æ°‘è­¦'],\n",
              " ['æ —å­', 'å¥½é’°', 'ç‚’æ —å­', 'è™¹å£', 'å°è™¹', 'æµ·å®è·¯', 'å¥½å¥½', '00', 'é‡æ —', 'æ¿æ —'],\n",
              " ['æµ·å®‰', 'åšç‰©é¦†', 'é™¶ç“·', 'é¸£è°¢', 'åŒ å¿ƒç‹¬è¿', 'ç¾è½®ç¾å¥‚', 'æ—è£•ç¿”', 'é‚°é¢–', 'å–œæ¬¢', 'å…‰è¾‰ç¿çƒ‚']]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also choose to put the list in a **Pandas** data frame and export it to a **csv** file. If you want to learn more about Pandas, check it out [here](https://pinkychow1010.github.io/digital-chinese-history-blog/level-2/chapter-2/data-manipulation/pandas/2020/01/23/Pandas_TextAnalysis_TextOriganization.html)."
      ],
      "metadata": {
        "id": "6Rx_opZh6i-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(keyword_list)"
      ],
      "metadata": {
        "id": "kv1tPp9xVXEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save each keyword into separate columns as strings."
      ],
      "metadata": {
        "id": "bLd_3agL7JFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.fillna(value=np.nan).astype(str)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "mpkYTxayY_Fg",
        "outputId": "f866d9da-c947-4337-c0ad-f980482c9db2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6e4a2242-7880-4b8a-a492-51e9c31dcf7b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>æ‹”èåœ</td>\n",
              "      <td>èåœ</td>\n",
              "      <td>é‡‡æ‘˜</td>\n",
              "      <td>å­©å­</td>\n",
              "      <td>èœå›­</td>\n",
              "      <td>æ”¶è·</td>\n",
              "      <td>å‘¨æœ«ç‰ˆ</td>\n",
              "      <td>å®è·µ</td>\n",
              "      <td>çƒ­çˆ±åŠ³åŠ¨</td>\n",
              "      <td>ç»ˆè§‰</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ç»¿è‰²</td>\n",
              "      <td>å¾ªç¯</td>\n",
              "      <td>æ¹–å—çœ</td>\n",
              "      <td>10</td>\n",
              "      <td>ç¯ä¿</td>\n",
              "      <td>ç”Ÿæ€</td>\n",
              "      <td>æ´»åŠ¨</td>\n",
              "      <td>å…‘æ¢</td>\n",
              "      <td>åƒåœ¾</td>\n",
              "      <td>åˆ†ç±»</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>å´é‚®é‚®</td>\n",
              "      <td>ä¸‰è½®è½¦</td>\n",
              "      <td>å­©å­</td>\n",
              "      <td>å°å­™å­</td>\n",
              "      <td>äº‹è¿¹</td>\n",
              "      <td>å½’ä»</td>\n",
              "      <td>2019</td>\n",
              "      <td>12</td>\n",
              "      <td>é«˜æ–‡å¨Ÿ</td>\n",
              "      <td>å¾®ä¿¡</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>æµ™å¤§</td>\n",
              "      <td>æµ™æ±Ÿå¤§å­¦</td>\n",
              "      <td>æ–°äºº</td>\n",
              "      <td>è®°è€…å›¢</td>\n",
              "      <td>ç¼˜å®š</td>\n",
              "      <td>æ˜Ÿæ²³</td>\n",
              "      <td>æ¯æ ¡</td>\n",
              "      <td>2020</td>\n",
              "      <td>123</td>\n",
              "      <td>æå…°å¨Ÿ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>æµå—</td>\n",
              "      <td>å…¬å®‰</td>\n",
              "      <td>æŠ¥å‘Š</td>\n",
              "      <td>åŸæ–‡</td>\n",
              "      <td>äº¤è­¦</td>\n",
              "      <td>æ ‡é¢˜</td>\n",
              "      <td>é˜…è¯»</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>å¹´ä¼š</td>\n",
              "      <td>ç¯ä¿</td>\n",
              "      <td>æ¹–å—çœ</td>\n",
              "      <td>ç¤¾ä¼š</td>\n",
              "      <td>è¡ŒåŠ¨è€…</td>\n",
              "      <td>2020</td>\n",
              "      <td>ç”Ÿæ€</td>\n",
              "      <td>ç»„ç»‡</td>\n",
              "      <td>ç»¿è‰²</td>\n",
              "      <td>ç¯å¢ƒæ²»ç†</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>æ–©è‚‰</td>\n",
              "      <td>æµ·å®‰</td>\n",
              "      <td>ç‚¸åˆ¶</td>\n",
              "      <td>ç™½æ–©</td>\n",
              "      <td>ç‚–ç…®</td>\n",
              "      <td>--</td>\n",
              "      <td>è‘±å§œ</td>\n",
              "      <td>çŒ´æ€¥</td>\n",
              "      <td>éº»è™¾</td>\n",
              "      <td>é»„æ¯›</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>é«˜æ°</td>\n",
              "      <td>æ‰§æ³•</td>\n",
              "      <td>å­¦æ³•</td>\n",
              "      <td>å…¬å®‰</td>\n",
              "      <td>å…¬å®‰æœºå…³</td>\n",
              "      <td>å¤šé¢æ‰‹</td>\n",
              "      <td>å…¨å¸‚</td>\n",
              "      <td>æ³•æ²»</td>\n",
              "      <td>å¤è®®</td>\n",
              "      <td>æ°‘è­¦</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>æ —å­</td>\n",
              "      <td>å¥½é’°</td>\n",
              "      <td>ç‚’æ —å­</td>\n",
              "      <td>è™¹å£</td>\n",
              "      <td>å°è™¹</td>\n",
              "      <td>æµ·å®è·¯</td>\n",
              "      <td>å¥½å¥½</td>\n",
              "      <td>00</td>\n",
              "      <td>é‡æ —</td>\n",
              "      <td>æ¿æ —</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>æµ·å®‰</td>\n",
              "      <td>åšç‰©é¦†</td>\n",
              "      <td>é™¶ç“·</td>\n",
              "      <td>é¸£è°¢</td>\n",
              "      <td>åŒ å¿ƒç‹¬è¿</td>\n",
              "      <td>ç¾è½®ç¾å¥‚</td>\n",
              "      <td>æ—è£•ç¿”</td>\n",
              "      <td>é‚°é¢–</td>\n",
              "      <td>å–œæ¬¢</td>\n",
              "      <td>å…‰è¾‰ç¿çƒ‚</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e4a2242-7880-4b8a-a492-51e9c31dcf7b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6e4a2242-7880-4b8a-a492-51e9c31dcf7b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6e4a2242-7880-4b8a-a492-51e9c31dcf7b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     0     1    2    3     4     5     6     7     8     9\n",
              "0  æ‹”èåœ    èåœ   é‡‡æ‘˜   å­©å­    èœå›­    æ”¶è·   å‘¨æœ«ç‰ˆ    å®è·µ  çƒ­çˆ±åŠ³åŠ¨    ç»ˆè§‰\n",
              "1   ç»¿è‰²    å¾ªç¯  æ¹–å—çœ   10    ç¯ä¿    ç”Ÿæ€    æ´»åŠ¨    å…‘æ¢    åƒåœ¾    åˆ†ç±»\n",
              "2  å´é‚®é‚®   ä¸‰è½®è½¦   å­©å­  å°å­™å­    äº‹è¿¹    å½’ä»  2019    12   é«˜æ–‡å¨Ÿ    å¾®ä¿¡\n",
              "3   æµ™å¤§  æµ™æ±Ÿå¤§å­¦   æ–°äºº  è®°è€…å›¢    ç¼˜å®š    æ˜Ÿæ²³    æ¯æ ¡  2020   123   æå…°å¨Ÿ\n",
              "4   æµå—    å…¬å®‰   æŠ¥å‘Š   åŸæ–‡    äº¤è­¦    æ ‡é¢˜    é˜…è¯»   nan   nan   nan\n",
              "5   å¹´ä¼š    ç¯ä¿  æ¹–å—çœ   ç¤¾ä¼š   è¡ŒåŠ¨è€…  2020    ç”Ÿæ€    ç»„ç»‡    ç»¿è‰²  ç¯å¢ƒæ²»ç†\n",
              "6   æ–©è‚‰    æµ·å®‰   ç‚¸åˆ¶   ç™½æ–©    ç‚–ç…®    --    è‘±å§œ    çŒ´æ€¥    éº»è™¾    é»„æ¯›\n",
              "7   é«˜æ°    æ‰§æ³•   å­¦æ³•   å…¬å®‰  å…¬å®‰æœºå…³   å¤šé¢æ‰‹    å…¨å¸‚    æ³•æ²»    å¤è®®    æ°‘è­¦\n",
              "8   æ —å­    å¥½é’°  ç‚’æ —å­   è™¹å£    å°è™¹   æµ·å®è·¯    å¥½å¥½    00    é‡æ —    æ¿æ —\n",
              "9   æµ·å®‰   åšç‰©é¦†   é™¶ç“·   é¸£è°¢  åŒ å¿ƒç‹¬è¿  ç¾è½®ç¾å¥‚   æ—è£•ç¿”    é‚°é¢–    å–œæ¬¢  å…‰è¾‰ç¿çƒ‚"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also put all keywords together in a single column. It is done by applying function **join()** along axis 1 of our DataFrame."
      ],
      "metadata": {
        "id": "ur8mggs37Thf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_join = pd.DataFrame()\n",
        "df_join[\"keywords\"] = df.apply(lambda row: ','.join(row.values.astype(str)), axis=1)\n",
        "df_join"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "_TTOhJezWgvo",
        "outputId": "c81d9fac-db49-4268-c4f3-b0e08937b64f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-79c1a951-e829-42b1-b84c-c0ebedc2fcc3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>æ‹”èåœ,èåœ,é‡‡æ‘˜,å­©å­,èœå›­,æ”¶è·,å‘¨æœ«ç‰ˆ,å®è·µ,çƒ­çˆ±åŠ³åŠ¨,ç»ˆè§‰</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ç»¿è‰²,å¾ªç¯,æ¹–å—çœ,10,ç¯ä¿,ç”Ÿæ€,æ´»åŠ¨,å…‘æ¢,åƒåœ¾,åˆ†ç±»</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>å´é‚®é‚®,ä¸‰è½®è½¦,å­©å­,å°å­™å­,äº‹è¿¹,å½’ä»,2019,12,é«˜æ–‡å¨Ÿ,å¾®ä¿¡</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>æµ™å¤§,æµ™æ±Ÿå¤§å­¦,æ–°äºº,è®°è€…å›¢,ç¼˜å®š,æ˜Ÿæ²³,æ¯æ ¡,2020,123,æå…°å¨Ÿ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>æµå—,å…¬å®‰,æŠ¥å‘Š,åŸæ–‡,äº¤è­¦,æ ‡é¢˜,é˜…è¯»,nan,nan,nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>å¹´ä¼š,ç¯ä¿,æ¹–å—çœ,ç¤¾ä¼š,è¡ŒåŠ¨è€…,2020,ç”Ÿæ€,ç»„ç»‡,ç»¿è‰²,ç¯å¢ƒæ²»ç†</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>æ–©è‚‰,æµ·å®‰,ç‚¸åˆ¶,ç™½æ–©,ç‚–ç…®,--,è‘±å§œ,çŒ´æ€¥,éº»è™¾,é»„æ¯›</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>é«˜æ°,æ‰§æ³•,å­¦æ³•,å…¬å®‰,å…¬å®‰æœºå…³,å¤šé¢æ‰‹,å…¨å¸‚,æ³•æ²»,å¤è®®,æ°‘è­¦</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>æ —å­,å¥½é’°,ç‚’æ —å­,è™¹å£,å°è™¹,æµ·å®è·¯,å¥½å¥½,00,é‡æ —,æ¿æ —</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>æµ·å®‰,åšç‰©é¦†,é™¶ç“·,é¸£è°¢,åŒ å¿ƒç‹¬è¿,ç¾è½®ç¾å¥‚,æ—è£•ç¿”,é‚°é¢–,å–œæ¬¢,å…‰è¾‰ç¿çƒ‚</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79c1a951-e829-42b1-b84c-c0ebedc2fcc3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-79c1a951-e829-42b1-b84c-c0ebedc2fcc3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-79c1a951-e829-42b1-b84c-c0ebedc2fcc3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                keywords\n",
              "0      æ‹”èåœ,èåœ,é‡‡æ‘˜,å­©å­,èœå›­,æ”¶è·,å‘¨æœ«ç‰ˆ,å®è·µ,çƒ­çˆ±åŠ³åŠ¨,ç»ˆè§‰\n",
              "1         ç»¿è‰²,å¾ªç¯,æ¹–å—çœ,10,ç¯ä¿,ç”Ÿæ€,æ´»åŠ¨,å…‘æ¢,åƒåœ¾,åˆ†ç±»\n",
              "2    å´é‚®é‚®,ä¸‰è½®è½¦,å­©å­,å°å­™å­,äº‹è¿¹,å½’ä»,2019,12,é«˜æ–‡å¨Ÿ,å¾®ä¿¡\n",
              "3   æµ™å¤§,æµ™æ±Ÿå¤§å­¦,æ–°äºº,è®°è€…å›¢,ç¼˜å®š,æ˜Ÿæ²³,æ¯æ ¡,2020,123,æå…°å¨Ÿ\n",
              "4       æµå—,å…¬å®‰,æŠ¥å‘Š,åŸæ–‡,äº¤è­¦,æ ‡é¢˜,é˜…è¯»,nan,nan,nan\n",
              "5    å¹´ä¼š,ç¯ä¿,æ¹–å—çœ,ç¤¾ä¼š,è¡ŒåŠ¨è€…,2020,ç”Ÿæ€,ç»„ç»‡,ç»¿è‰²,ç¯å¢ƒæ²»ç†\n",
              "6          æ–©è‚‰,æµ·å®‰,ç‚¸åˆ¶,ç™½æ–©,ç‚–ç…®,--,è‘±å§œ,çŒ´æ€¥,éº»è™¾,é»„æ¯›\n",
              "7       é«˜æ°,æ‰§æ³•,å­¦æ³•,å…¬å®‰,å…¬å®‰æœºå…³,å¤šé¢æ‰‹,å…¨å¸‚,æ³•æ²»,å¤è®®,æ°‘è­¦\n",
              "8        æ —å­,å¥½é’°,ç‚’æ —å­,è™¹å£,å°è™¹,æµ·å®è·¯,å¥½å¥½,00,é‡æ —,æ¿æ —\n",
              "9  æµ·å®‰,åšç‰©é¦†,é™¶ç“·,é¸£è°¢,åŒ å¿ƒç‹¬è¿,ç¾è½®ç¾å¥‚,æ—è£•ç¿”,é‚°é¢–,å–œæ¬¢,å…‰è¾‰ç¿çƒ‚"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To download the data frame as a csv, we can use **to_csv()** and **files.download()**."
      ],
      "metadata": {
        "id": "jGkOnONf7vNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "df_join.to_csv('keywords.csv')\n",
        "files.download('keywords.csv')"
      ],
      "metadata": {
        "id": "6arv01Wf6tnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ‰ \n",
        "Great! Now we have just learnt how to extract keywords from a webpage. This is only the basics to work with a simple webpage. To better understand the potential of BeautifulSoup, I recommand you to further search for BeautifulSoup tutorials on Youtube."
      ],
      "metadata": {
        "id": "weyUeNxp4CIE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "\n",
        "***\n",
        "\n",
        "## **Additional information**\n",
        "\n",
        "This notebook is provided for educational purpose and feel free to report any issue on GitHub.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Author:** Ka Hei, Chow\n",
        "\n",
        "**License:** The code in this notebook is licensed under the [Creative Commons by Attribution 4.0 license](https://creativecommons.org/licenses/by/4.0/).\n",
        "\n",
        "**Last modified:** February 2022"
      ],
      "metadata": {
        "id": "lYN_MPOmnAdc"
      }
    }
  ]
}
{
  
    
        "post0": {
            "title": "Seven Reasons to Learn Python for Historical Research",
            "content": "1) Process Text in any Digital Formats &#128220; . Doing research often requires working with different media formats in this digital age, regardless of what your research interests are. Even you are not working with a large number of data sources, you might either need to work with long texts or sources that offer only in digital formats. Meanwhile, you might want to output your research in a digital format. . Either you might want to write your blog for your projects, or you need to process text in pdf format, Python is a useful tool to READ, PROCESS, and CONVERT between different digital formats. Sometimes you might download historical data in Stata Data File Format (.dta), other times what you have is a large CSV file. When you try to do a specific task, you might search for online tools which often is not free or is not convenient (For example, you might need to process the file one by one). Learning Python enable you to gain multiple skills working with different data formats, including but not limited to txt, XML, csv, xlsx, json, geojson, shp, pdf, and dta. Reading those format is the first step of everything coming after, such as cleaning them or filtering them. . One of the most popular libraries for working with tabular data is Pandas. In contrast to Excel, you can use Pandas to work with CSV files with millions of rows in ease. You do not need to manually select any cells or deal with missing values. Similar to Excel, you can also create graphics from the table using Pandas. The difference is that you have way more controls on the layouts and types of visualization. . Python is one of the programming languages having the most readable syntax and the largest open source community to support and contribute. Programming is not an individual task, it requires resources from others: either to fix a bug, find a realistic solution, or use libraries or code written by someone else. It is why having a large community make it easier to get the job done. . 2) Access Digital Data without Barriers &#128721; . With the growth of digital humanities or digital history, more and more historical sources have been stored and published in a digital format, such as 明清妇女著作 and 中国历代人物传记资料库CBDB. Depending on the website and the nature of the data, the download format will also change (.mdb, csv, etc.). Sometimes the data you are looking for is not systematically stored, which might also require some web scraping, such as grabbing tables on a webpage (In this case you can use beautifulsoup or selenium). No matter how and in what format your data is stored, you can always access them using Python. . Data access does not simply mean copying the resources, but also having them in a structural framework so you can use them effectively. By reading the data in a structured way, you can clean the irrelevant information, filter items that fit your interests without any manual effort. For example, you can clean all the empty rows, or convert your table from long to wide format. Python is even more advantageous when you work with time series or spatial data owing to its powerful libraries Pandas and Geopandas. With the geospatial libraries, you can easily perform geospatial operations and make maps just like in geographic information system (GIS). . 3) Have a Big Picture with Data Collection &#128444;&#65039; . Amid the ongoing information explosion, we do not simply have much more information for the current time, but also much more digitalized data from the past with the emerging digital scholarship projects. Although big data offers us more material to conduct research, often it is not realistic for us to work with a large amount of data, for instance, thousands of novels/ publications. We might solely want to filter very little information from the data pool or have an overview of all materials. We can achieve it by performing topic modelling, counting the frequency of keywords, or computing statistics. . Using machine learning, we can also perform unsupervised clustering on the texts for categorization. The mentioned approaches require different skills in text mining, big data analysis, and NLP. With Python, we can smoothly combine multiple domains in a single script. Learning a new tool always takes time. Hence, the best is to select tools that can reasonably perform most tasks. With the aid of Python, you can easily save time for the redundant tasks. . 4) Understanding Patterns in a Systematical way &#128376;&#65039; . Machine reads differently than human eye. It is also why distant reading or Natural language processing (NLP) can aid with historical text analysis. By aggregating and analyzing massive amounts of data, we can observe the patterns of texts in a large scale, for example, some formal aspects of literature. It aims to have a more abstract view of the texts by visualizing their global features. One of the technique is Term Frequency(TF) — Inverse Dense Frequency(IDF) used to classify text resources. Other techniques include sentiment analysis and text similarity metrics. It can also be combined with different elements such as geospatial maps to visualize geographical information. All these can be easily implemented in Python suiting to your research needs. . 5) Visualize Data from Infographics to Map &#128506;&#65039; . Research using historical data does not end with text analysis. Often, particularly if you are an expert of your data, you need to communicate with the audience, either your coworkers, students, fellow researchers, or the funding agencies. To achieve it, you can create charts for your publication, infographics to put on the social media, or making a simple web application, with interactive figures and maps to allow more involvements from the audience. . Python provides multiple plotting libraries, from Matplotlib, Seaborn to Plotly. Not only can they produce publication-quality figures, but also different types of data visualization. You can decide if you wish to have animation or interactive dashboard. You can even build your web application with embedded text, graphics, and web map. . 6) Customize to your research needs &#128736;&#65039; . The specific tasks for histircal research are diverse, and often there are not yet tools doing what you exactly need. It is a pain when you realize an online tool is a bit deviated from what you expected, as there is often no way to further customize it. For instance, when you try to create a word cloud online, but am not satistified with the color use, the font, or simply that they do not support the language you use. Or you need to filter or clean your data in a way that is not supported. . Using Python, however, there are vast choices for customization as long as you are willing to get your hand dirty. This does not only apply to data visualization, but also data collection and text analysis. Besides, thanks for the large open source community of Python, tools are available even for a relatively small niche, such as performing NLP on classical Chinese. As Python is free and open, once you learn about how to use a library, you can utilize it fully without the need to worry about licenses or subscriptions. You can also save your script, reuse it for another text, and freely share your approach with others without any barriers. . 7) Comparison to Available digital tools . Commercial tools are mostly specialised in a certain domain, and the need of a license makes them difficult to use for reproduction and to share with others. Besides, if you need one task after another, for example, from web scraping to generating word clouds to making a web application for presentation, what you might need to do is jumping from one tool to another. Using open-source programming languages, however, provide you with FLEXIBILITY for CUSTOMIZATION and INTEGRATION so that you can perform all tasks seamlessly. . R is another programming language very popular among researchers, as it is for statistical computing and research. Similar to Python, it has a large community and can perform similar tasks: data wrangling, data visualization, feature selection web scrapping, app and so on. Both of the languages share many tools, for example, spacyr provides a convenient R wrapper around the Python spaCy for distant reading and plotnine is a Python implementation of R ggplot. Many useful libraries also support both languages, for example, Plotly for interactive plotting and Jieba for Chinese NLP. In fact, R and Python can even be bridged together using rpy2 and reticulate. . It needs to be said in advance that both R and Python have their strengths and weaknesses. Different to R, Python is a general-purpose language. It focuses on deployment and production. Hence, while R suits well for ad-hoc analysis, when it comes to building a product from machine learning, or text processing which is often needed before any data analysis can be done, Python can be a better choice. . . . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: January 2022 .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/level-1/chapter-1/background/2022/01/14/_01_20_Reason4Py.html",
            "relUrl": "/level-1/chapter-1/background/2022/01/14/_01_20_Reason4Py.html",
            "date": " • Jan 14, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Hand Drawn Styling Charts with matplotlib",
            "content": "Welcome to the data visualization chapter! After you have done some basic plots using Matplotlib, do you know you can further style your plot beyond the color uses? In this lesson, you will learn how can you make a matplotlib chart with hand drawn style ✍️. To do that you do not need to install any new library. . Let&#39;s try to make a chart using some Chinese historical statistics about taxation and infrastructures (stage station) during Yuan Dynasty (1279-1368) [Source]. . To begin, we need to first import some libraries and install pinyin for converting the Chinese labels. . import matplotlib.pyplot as plt import pandas as pd import numpy as np . ! pip install pinyin import pinyin . We have our locations listed. They are all different Chinese regions in which stage stations are located. Using pinyin.get() we can convert the words into pinyin. . loc_list = [&quot;腹里&quot;,&quot;河南江北&quot;,&quot;辽阳&quot;,&quot;江浙&quot;,&quot;江西&quot;,&quot;湖广&quot;,&quot;陕西&quot;,&quot;四川&quot;,&quot;云南&quot;,&quot;甘肃&quot;] name = [pinyin.get(loc, format=&quot;strip&quot;, delimiter=&quot; &quot;) for loc in loc_list] . Then we will define the type for the stage station, either land transport or water transport. . type_list = np.concatenate((np.repeat(&quot;Lu zhan&quot;,10), np.repeat(&quot;Shui zhan&quot;, 10)), axis=0) . Now, we can construct our data frame. . data = { &quot;Location&quot;: name + name, &quot;Station&quot;: [177,106,120,180,85,100,80,48,74,6,21,90,0,82,69,73,1,84,4,0], &quot;Type&quot;: type_list } df = pd.DataFrame(data=data) df.head() . Location Station Type . 0 fu li | 177 | Lu zhan | . 1 liao yang | 106 | Lu zhan | . 2 he nan | 120 | Lu zhan | . 3 shan xi | 180 | Lu zhan | . 4 si chuan | 85 | Lu zhan | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; We can use seaborn sns.catplot() for making a groupped bar chart easily. We will group the variable using argument hue. For further adjustments, we can add a title, rotate the ticks, and add annotations to the chart. Seaborn is a plotting library based on matplotlib and it is highly compatible with Pandas. This means, you can plot a Pandas dataframe using seaborn which enable users to create stylist chart in different themes. Let&#39;s look at a introduction video. . . Now, Let&#39;s look at how a seaborn chart is like without hand drawn style. . import seaborn as sns sns.set_style(&#39;darkgrid&#39;) # groupped bar chart ax = sns.catplot(x = &quot;Location&quot;, # x variable name y = &quot;Station&quot;, # y variable name hue = &quot;Type&quot;, # group variable name data = df, # dataframe to plot kind = &quot;bar&quot;, height=8) # add a title plt.title(&quot;Count of Stage Stations n in Yuan Dynasty (1279-1368)&quot;,loc=&quot;left&quot;,fontsize=22) # rotate ticks plt.xticks(rotation=30) # add annotations plt.annotate(&#39;FOR WATER TRANSPORT&#39;, xy=(2.9,125), xytext=(4.5,145), arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05, headwidth=20, width=5)) plt.annotate(&#39;FOR LAND TRANSPORT&#39;, xy=(3.1,80), xytext=(4.5,125), arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05, headwidth=20, width=5)) # display plot plt.show() . In fact, we can alter the style of seaborn chart simply using sns.set_style(). Available style includes &quot;darkgrid&quot;,&quot;white&quot;,&quot;ticks&quot;, and &quot;whitegrid&quot;. Let&#39;s look at the same plot in &quot;white&quot; style. . import seaborn as sns sns.set_style(&#39;white&#39;) # groupped bar chart ax = sns.catplot(x = &quot;Location&quot;, # x variable name y = &quot;Station&quot;, # y variable name hue = &quot;Type&quot;, # group variable name data = df, # dataframe to plot kind = &quot;bar&quot;, height=8) # add a title plt.title(&quot;Count of Stage Stations n in Yuan Dynasty (1279-1368)&quot;,loc=&quot;left&quot;,fontsize=22) # rotate ticks plt.xticks(rotation=30) # add annotations plt.annotate(&#39;FOR WATER TRANSPORT&#39;, xy=(2.9,125), xytext=(4.5,145), arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05, headwidth=20, width=5)) plt.annotate(&#39;FOR LAND TRANSPORT&#39;, xy=(3.1,80), xytext=(4.5,125), arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05, headwidth=20, width=5)) # display plot plt.show() . Hand Drawn Style . To plot the chart with hand drawn style, we only need to add plt.xkcd() before the plotting function. Matplotlib xkcd is a sketch-style drawing mode and it will only has effects on things drawn after plt.xkcd() is called. . import seaborn as sns sns.set_style(&#39;white&#39;) # hand drawn chart plt.xkcd() # groupped bar chart ax = sns.catplot(x = &quot;Location&quot;, # x variable name y = &quot;Station&quot;, # y variable name hue = &quot;Type&quot;, # group variable name data = df, # dataframe to plot kind = &quot;bar&quot;, height=8) # add a title plt.title(&quot;Count of Stage Stations n in Yuan Dynasty (1279-1368)&quot;,loc=&quot;left&quot;,fontsize=22) # rotate ticks plt.xticks(rotation=30) # add annotations plt.annotate(&#39;FOR WATER TRANSPORT&#39;, xy=(2.9,125), xytext=(4.5,145), arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05, headwidth=20, width=5)) plt.annotate(&#39;FOR LAND TRANSPORT&#39;, xy=(3.1,80), xytext=(4.5,125), arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05, headwidth=20, width=5)) # display plot plt.show() . We can also try with a different plotting type. Let&#39;s try to do a pie chart using the taxation data from different Chinese regions. The same as above, we need to first creating the pandas data frame, following by the plotting function using plt.subplots() and pie(). As we already use plt.xkcd() above, our plot will be automatically create in the hand drawn style. For the pie function, we will use rotatelabels to avoid label overlapping and labeldistance to define the label locations. . loc_list = [&quot;腹里&quot;,&quot;辽阳&quot;,&quot;河南&quot;,&quot;陕西&quot;,&quot;四川&quot;,&quot;甘肃&quot;,&quot;云南&quot;,&quot;江浙&quot;,&quot;江西&quot;,&quot;湖广&quot;] name = [pinyin.get(loc, format=&quot;strip&quot;, delimiter=&quot; &quot;) for loc in loc_list] # list comprehension to get pinyin for the whole list # create data data = { &quot;Location&quot;: name, &quot;Amount&quot;: [18.75,0.59,21.39,1.86,0.96,0.50,2.29,37.10,9.56,6.97] } # pass data into data frame df = pd.DataFrame(data=data) # plot figure fig1, ax1 = plt.subplots(figsize=(10,10)) # draw pie chart ax1.pie(df.Amount,labels=df.Location, autopct=&#39;%1.1f%%&#39;,labeldistance=1,rotatelabels=True,shadow=True, startangle=90) ax1.axis(&#39;equal&#39;) # Equal aspect ratio ensures that pie is drawn as a circle. # title plt.title(&quot;Yuan Dai Sui Ru Liang Shu n(1279-1368)&quot;, loc=&#39;left&#39;) plt.show() . Great! Now we can style our graphics for more eye-catching presentation of the data. . Previous Lesson: Introduction to Data Visualization . Next Lesson: Simple Bubble Chart . . . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: January 2022 .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/level-3/chapter-3/matplotlib/data-visualization/2022/01/12/Hand_Drawn_Chart.html",
            "relUrl": "/level-3/chapter-3/matplotlib/data-visualization/2022/01/12/Hand_Drawn_Chart.html",
            "date": " • Jan 12, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Bubble Timeline using plotly.express",
            "content": "plotly.express . Hi there! In the last tutorial, we began to explore the potential of plotly.express, which is a wrapper for Plotly.py to allow more interaction in our graphics. Last time we made a simple scatter plot/ bubble chart. This time we will continue with a variation of bubble chart to represent temporal development of the UNESCO inscriptions in different countries. This timeline is characterised by the bubbles along the x-axis with varied sizes and can be used to contrast temporal trends of multiply categories. . In order to create the timeline, we first have to import needed libraries, and read the data into a pandas data frame. . import io import pandas as pd import requests # read data url = &#39;https://examples.opendatasoft.com/explore/dataset/world-heritage-unesco-list/download/?format=csv&amp;timezone=Europe/Berlin&amp;lang=en&amp;use_labels_for_header=true&amp;csv_separator=%3B&#39; df = pd.read_csv(url, sep=&quot;;&quot;) . df.head() . Name (EN) Name (FR) Short description (EN) Short Description (FR) Justification (EN) Justification (FR) Date inscribed Danger list Longitude Latitude Area hectares Category Country (EN) Country (FR) Continent (EN) Continent (FR) Geographical coordinates . 0 Architectural, Residential and Cultural Comple... | Ensemble architectural, résidentiel et culture... | The Architectural, Residential and Cultural Co... | L’ensemble architectural, résidentiel et cultu... | Criterion (ii): The architectural, residential... | Critère (ii) : L’ensemble architectural, résid... | 2005-01-01 | NaN | 26.691390 | 53.222780 | 0.00 | Cultural | Belarus | Bélarus | Europe and North America | Europe et Amérique du nord | 53.22278,26.69139 | . 1 Rock Paintings of the Sierra de San Francisco | Peintures rupestres de la Sierra de San Francisco | From c. 100 B.C. to A.D. 1300, the Sierra de S... | Dans la réserve d&#39;El Vizcaíno, en Basse-Califo... | NaN | NaN | 1993-01-01 | NaN | -112.916110 | 27.655560 | 182600.00 | Cultural | Mexico | Mexique | Latin America and the Caribbean | Amérique latine et Caraïbes | 27.65556,-112.91611 | . 2 Monastery of Horezu | Monastère de Horezu | Founded in 1690 by Prince Constantine Brancova... | Fondé en 1690 par le prince Constantin Brancov... | NaN | NaN | 1993-01-01 | NaN | 24.016667 | 45.183333 | 22.48 | Cultural | Romania | Roumanie | Europe and North America | Europe et Amérique du nord | 45.18333333,24.01666667 | . 3 Mount Etna | Mont Etna | Mount Etna is an iconic site encompassing 19,2... | Ce site emblématique recouvre une zone inhabit... | NaN | NaN | 2013-01-01 | NaN | 14.996667 | 37.756111 | 19237.00 | Natural | Italy | Italie | Europe and North America | Europe et Amérique du nord | 37.7561111111,14.9966666667 | . 4 Belfries of Belgium and France | Beffrois de Belgique et de France | Twenty-three belfries in the north of France a... | Vingt-trois beffrois, situés dans le nord de l... | NaN | NaN | 1999-01-01 | NaN | 3.231390 | 50.174440 | 0.00 | Cultural | Belgium,France | Belgique,France | Europe and North America | Europe et Amérique du nord | 50.17444,3.23139 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Data Cleaning . We need to start with some preprocessing and data cleaning. We will start with subsetting and renaming the columns, followed by a calculation of total UNESCO sites in the &quot;top 10 countries&quot; using groupby() (we do not need this data frame for the plot, only list of the top 10 countries). We will sort the values using sort_vales(by=[&#39;name&#39;]) to order the countries from the most to the least UNESCO sites. . df = df[[&quot;Name (EN)&quot;,&quot;Date inscribed&quot;,&quot;Category&quot;,&quot;Country (EN)&quot;,&quot;Continent (EN)&quot;]] # select multiple columns in a list [] df = df.rename(columns={&quot;Name (EN)&quot;: &quot;name&quot;, &quot;Date inscribed&quot;: &quot;date&quot;, &quot;Category&quot;: &quot;type&quot;, &quot;Country (EN)&quot;: &quot;country&quot;, &quot;Continent (EN)&quot;: &quot;continent&quot;}) # rename the columns for easy reading . top_10 = df.groupby(df[&quot;country&quot;]).count().sort_values(by=[&#39;name&#39;], ascending=False).head(10) top_10 . name date type continent . country . China 49 | 49 | 49 | 49 | . Italy 47 | 47 | 47 | 47 | . Spain 41 | 41 | 41 | 41 | . France 38 | 38 | 38 | 38 | . Germany 35 | 35 | 35 | 35 | . Mexico 34 | 34 | 34 | 34 | . India 33 | 33 | 33 | 33 | . United Kingdom of Great Britain and Northern Ireland 27 | 27 | 27 | 27 | . Russian Federation 21 | 21 | 21 | 21 | . Iran (Islamic Republic of) 21 | 21 | 21 | 21 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Get the top 10 countries as a numpy array. . sub_cnty = top_10.index.values sub_cnty . array([&#39;China&#39;, &#39;Italy&#39;, &#39;Spain&#39;, &#39;France&#39;, &#39;Germany&#39;, &#39;Mexico&#39;, &#39;India&#39;, &#39;United Kingdom of Great Britain and Northern Ireland&#39;, &#39;Russian Federation&#39;, &#39;Iran (Islamic Republic of)&#39;], dtype=object) . With the information of the top 10 countries, we can now delete all the rows from other countries using isin(sub_cnty). We will then group the rows by country and date and count the rows for every country and every year. We will then reset the index. . top_df = df[df[&#39;country&#39;].isin(sub_cnty)].groupby([&#39;country&#39;,&#39;date&#39;]).count()[&#39;name&#39;].reset_index() top_df.head(5) . country date name . 0 China | 1987-01-01 | 6 | . 1 China | 1990-01-01 | 1 | . 2 China | 1992-01-01 | 3 | . 3 China | 1994-01-01 | 4 | . 4 China | 1996-01-01 | 2 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; As we need only the information of year, not the full date, we will create a new column year. We can extrate the year by first interpreting the date column as date time, then take the year values (simply with .year). . top_df[&#39;year&#39;] = pd.DatetimeIndex(top_df[&#39;date&#39;]).year # set up a new year column top_df.head() . country date name year . 0 China | 1987-01-01 | 6 | 1987 | . 1 China | 1990-01-01 | 1 | 1990 | . 2 China | 1992-01-01 | 3 | 1992 | . 3 China | 1994-01-01 | 4 | 1994 | . 4 China | 1996-01-01 | 2 | 1996 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Now we will group by again with the country and year and get the sum (count of inscriptions every year). . group_df = top_df.groupby([&quot;country&quot;,&quot;year&quot;]).sum() . import numpy as np country_list = np.array(group_df.index.get_level_values(0)) year_list = np.array(group_df.index.get_level_values(1)) . As we want need the country and year column not only as index. We will assign the columns again. . group_df[&#39;country&#39;] = country_list group_df[&#39;year&#39;] = year_list . Renaming the name column to count. . group_df = group_df.rename(columns={&quot;name&quot;: &quot;count&quot;}) group_df.head() . count country year . country year . China 1987 6 | China | 1987 | . 1990 1 | China | 1990 | . 1992 3 | China | 1992 | . 1994 4 | China | 1994 | . 1996 2 | China | 1996 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; To improve the visuals, we will simplified the name of UK. . group_df[&#39;country&#39;] = group_df[&#39;country&#39;].str.replace(&#39;United Kingdom of Great Britain and Northern Ireland&#39;,&#39;United Kingdom&#39;) . Data Visualization . To make a interactive scatter plot in plotly.express, we only need to use px.scatter(). It is highly compatible with pandas, so we can input a pandas data frame, and specify x and y (as well as size and color which are optional) with the column names. . Every changes in layout we can change using update_layout(). All the options can be found here. . import plotly.express as px fig = px.scatter(group_df, x=&quot;year&quot;, y=&quot;country&quot;, size=&quot;count&quot;, color=&quot;country&quot;) fig.update_layout(showlegend=False) fig.show() . . . Almost Done! . Good job! Let&#39;s look at our plot. It is interactive so you can pan around and zoom in/ out. If you put your mouse on the bubbles, you will also get information such as the country name and counts at a specific year. It is the default Plotly option. . However, we can also gain control over what information we want to put in the hover labels, as well as the layout (like the font, fontsize and so on). Isn&#39;t it much cooler if we can show names of all UNESCO sites instead of the count?! . Also, we can control to display hover labels for the whole xaxis instead of an individual bubble, which means, we can display all UNESCO sites inscripted in a year! Let&#39;s say we also want to display a moving yaxis too. . Let&#39;s do all the adjustments mentioned above. . . Customization . df.head() . name date type country continent . 0 Architectural, Residential and Cultural Comple... | 2005-01-01 | Cultural | Belarus | Europe and North America | . 1 Rock Paintings of the Sierra de San Francisco | 1993-01-01 | Cultural | Mexico | Latin America and the Caribbean | . 2 Monastery of Horezu | 1993-01-01 | Cultural | Romania | Europe and North America | . 3 Mount Etna | 2013-01-01 | Natural | Italy | Europe and North America | . 4 Belfries of Belgium and France | 1999-01-01 | Cultural | Belgium,France | Europe and North America | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Adjust Data Frame . As we need the information about UNESCO site name this time, we need to make use of df to make a subset for the top 10 countries then merged with our group_df. Let&#39;s go back to df and do some cleaning. First, we add the year column for df too. We group by country and year, and do a transformation here. . It is a bit tricky. The transformation aims to get all the rows with same country and year, and join all the values from [&#39;name&#39;] separated with a comma (,). This transformation is only done to the top 10 countries df[df[&#39;country&#39;].isin(sub_cnty)]. As this is repeatedly done for every row, we will end up with rows that are duplicated, so we will remove them. . df[&#39;year&#39;] = pd.DatetimeIndex(df[&#39;date&#39;]).year # join the site names df[&#39;site&#39;] = df[df[&#39;country&#39;].isin(sub_cnty)].groupby([&#39;country&#39;,&#39;year&#39;])[&#39;name&#39;].transform(lambda x: &#39;, &#39;.join(x)) # remove duplicates df.drop_duplicates() # look at the rows for China df[df[&quot;country&quot;] == &quot;China&quot;].head(5) . name date type country continent year site . 5 Sichuan Giant Panda Sanctuaries - Wolong, Mt S... | 2006-01-01 | Natural | China | Asia and the Pacific | 2006 | Sichuan Giant Panda Sanctuaries - Wolong, Mt S... | . 32 Tusi Sites | 2015-01-01 | Cultural | China | Asia and the Pacific | 2015 | Tusi Sites | . 38 The Great Wall | 1987-01-01 | Cultural | China | Asia and the Pacific | 1987 | The Great Wall, Mausoleum of the First Qin Emp... | . 68 Mausoleum of the First Qin Emperor | 1987-01-01 | Cultural | China | Asia and the Pacific | 1987 | The Great Wall, Mausoleum of the First Qin Emp... | . 72 Chengjiang Fossil Site | 2012-01-01 | Natural | China | Asia and the Pacific | 2012 | Chengjiang Fossil Site, Site of Xanadu | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Make sure only top 10 countries are included. . df_sub = df[df[&#39;country&#39;].isin(sub_cnty)] df_sub.head(1) . name date type country continent year site . 1 Rock Paintings of the Sierra de San Francisco | 1993-01-01 | Cultural | Mexico | Latin America and the Caribbean | 1993 | Rock Paintings of the Sierra de San Francisco,... | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; group_df.head(1) . count country year . country year . China 1987 6 | China | 1987 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; group_df.reset_index(drop=True, inplace=True) . Now, we have the name information from df_sub. We can merge it to our group_df data frame using the keys &quot;country&quot; and &quot;year&quot;. We select only the relevant columns [[&quot;country&quot;,&quot;year&quot;,&quot;site&quot;,&quot;count&quot;]], and call the new data frame final. . final = df_sub.merge(group_df, left_on=[&quot;country&quot;,&quot;year&quot;], right_on=[&quot;country&quot;,&quot;year&quot;]) final = final[[&quot;country&quot;,&quot;year&quot;,&quot;site&quot;,&quot;count&quot;]] final.head() . country year site count . 0 Mexico | 1993 | Rock Paintings of the Sierra de San Francisco,... | 3 | . 1 Mexico | 1993 | Rock Paintings of the Sierra de San Francisco,... | 3 | . 2 Mexico | 1993 | Rock Paintings of the Sierra de San Francisco,... | 3 | . 3 Italy | 2013 | Mount Etna, Medici Villas and Gardens in Tuscany | 2 | . 4 Italy | 2013 | Mount Etna, Medici Villas and Gardens in Tuscany | 2 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Great! Almost everything is ready. We only need to replace the comma with a &lt;br&gt; to make sure every item will be put in a new line in the hover labels. . final.site = final.site.apply(lambda x: x.replace(&#39;, &#39;, &#39;&lt;br&gt;&#39;)) final.site.head() . 0 Rock Paintings of the Sierra de San Francisco&lt;... 1 Rock Paintings of the Sierra de San Francisco&lt;... 2 Rock Paintings of the Sierra de San Francisco&lt;... 3 Mount Etna&lt;br&gt;Medici Villas and Gardens in Tus... 4 Mount Etna&lt;br&gt;Medici Villas and Gardens in Tus... Name: site, dtype: object . Ploting . Now, let&#39;s do our plot again using px.scatter(). . fig = px.scatter(final, x=&quot;year&quot;, y=&quot;country&quot;, size=&quot;count&quot;, color=&quot;country&quot;, custom_data=[&#39;year&#39;, &#39;site&#39;]) # remove legend fig.update_layout(showlegend=False) # show labels for whole x axis fig.update_layout(hovermode=&#39;x&#39;) # change layout for hover labels fig.update_layout( hoverlabel=dict( bgcolor=&quot;white&quot;, font_size=12, font_family=&quot;Rockwell&quot; ) ) # control info for hover labels using custom_data we specified above in pxscatter() # join items with new line &lt;br&gt; fig.update_traces( hovertemplate=&quot;&lt;br&gt;&quot;.join([ &quot;%{y}&quot;, &quot;Site: %{customdata[1]}&quot; ]) ) # add title, x- and y- labels, and a moving line along x axis # change font styles for the texts inside plot (y ticks and so on) fig.update_layout( title={ &#39;text&#39;: &quot;Timeline of UNESCO Inscriptions&quot;, &#39;y&#39;:0.95, &#39;x&#39;:0.5, &#39;xanchor&#39;: &#39;center&#39;, &#39;yanchor&#39;: &#39;top&#39;}, xaxis_title=&quot;Year of Inscription&quot;, yaxis_title=&quot;Top 10 Countries&quot;, xaxis={&#39;showspikes&#39;: True, &#39;spikemode&#39;: &#39;across&#39;, &#39;spikesnap&#39;: &#39;cursor&#39;, &#39;showline&#39;: True, &#39;showgrid&#39;: True}, font=dict( family=&quot;Rockwell&quot;, size=15, color=&quot;black&quot; ) ) # display out plot fig.show() . . . Cool! That&#39;s it! . Now we have an interactive plot with enhanced visuals and all information we need in the labels. Not only can we clearly see the trends of inscriptions in different countries, we can also clearly see the &quot;inscription peak&quot; of some countries (such as 1997 in Italy). We can tell, for example, countries like Russia and China are late players in the field. . Previous Lesson: Simple Bubble Chart . Next Lesson: Coming soon... . . . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: December 2021 . . . . References: . Plotly .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/level-3/chapter-3/plotly.express/data-visualization/2022/01/10/Plotly_Bubble_Timeline.html",
            "relUrl": "/level-3/chapter-3/plotly.express/data-visualization/2022/01/10/Plotly_Bubble_Timeline.html",
            "date": " • Jan 10, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Simple Graphics using Plotly",
            "content": "In the last blog, we have created a bubble chart / scatter plot using Plotly. This time we are trying to make other types of plot: a simple bar chart and a lollipop chart using plotly.express and plotly.graph_objects. The creation of both charts begin with a Pandas data frame. Then we pass the data frame into Plotly for a basic plot, and update the layouts afterwards. The bar chart requires only one plotting action .bar(), whereas the lollipop chart requires two plotting actions: first creating the scatter plot, then with add the &quot;stick&quot; using add_shape(). . Set Up Environment . import pandas as pd import numpy as np import plotly.express as px # library for creating random lengths of &quot;stick&quot; in the chart from random import seed from random import random . Bar Chart . Creating Data Frame . In this example, we create a bar chart based on the records for the type of natural disaster recorded in 《臺灣文獻叢刊》臺灣方志. The data frame is created using a dictionary, created by passing column names and values. . data = { &quot;Type of Natural Disaster&quot;: [&quot;Fire&quot;,&quot;Locust&quot;,&quot;Drought&quot;,&quot;Earthquake&quot;,&quot;Flood&quot;,&quot;Typhoon&quot;,&quot;Storm&quot;], &quot;Number of Record&quot;: [63,81,86,13,138,158,8] } df = pd.DataFrame(data=data) . Plotting . Then we can do the plotting by calling px.bar(). We can pass x, y, title and the figure size into the function. This will allow the creation of a simple bar chart in Plotly using default layout options. If we wish to change any parameters, we can update it using update_layout(). . Here, we will update the hover labels by changing the font size and the background color. We will also adjust the width of the bars. Finally, we pass fig.show() for the display of our plot. . First, we define a set of color for the bars by passing them into a list. . color_discrete_sequence = [&#39;#1f77b4&#39;, # muted blue &#39;#ff7f0e&#39;, # safety orange &#39;#2ca02c&#39;, # cooked asparagus green &#39;#d62728&#39;, # brick red &#39;#9467bd&#39;, # muted purple &#39;#bcbd22&#39;, # curry yellow-green &#39;#e377c2&#39;] # raspberry yogurt pink . Then, we plot the chart. With the title, we can pass the html tag &lt;b&gt; &lt;/b&gt; to style the words (bold), and for the color argument, we use &#39;Type of Natural Disaster&#39;, which mean every single column, we use a different colors. By doing so, a legend will be automatically created to explain the implication of colors. We can disable them later using fig.update_layout(showlegend=False). . fig = px.bar(df, y=&#39;Number of Record&#39;, x=&#39;Type of Natural Disaster&#39;, title=&quot;&lt;b&gt;Disaster Records in 臺灣方志&lt;/b&gt;&quot;, width=1000, height=500, color=&quot;Type of Natural Disaster&quot;,color_discrete_sequence=color_discrete_sequence) . Let&#39;s us disable out legend and adjust the width of the bars. . fig.update_layout(showlegend=False) fig.update_traces(width=0.5) . Then, we will adjust the hover labels before displaying out plot using fig.show(). . fig.update_layout( hoverlabel=dict( bgcolor=&quot;white&quot;, font_size=14, font_family=&quot;Courier New&quot; ) ) fig.show() . . . Lollipop Chart . This time, let&#39;s us work with some qualitative data. We will try to plot a simple time line of the articles 胡適 had published in his life time. We want to label the data with the shorten titles while putting the full titles in our hover labels. . Creating Data Frame . Let&#39;s first create our data frame. In order to have a lollipop chart we need to define the y values. We would like the y values to be different for every titles so we can avoid text overlapping. It can be done using random library and random(). . We will also convert the date column to datetime using pd.to_datetime(). . data = { &quot;date&quot;: [&quot;1919-01-01&quot;,&quot;1917-05-01&quot;,&quot;1918-01-01&quot;,&quot;1919-07-20&quot;,&quot;1924-01-01&quot;,&quot;1929-01-01&quot;,&quot;1929-02-01&quot;,&quot;1929-03-01&quot;,&quot;1929-04-01&quot;,&quot;1930-04-10&quot;,&quot;1959-11-20&quot;], &quot;title&quot;: [&quot;文學改良芻議&quot;,&quot;歷史的文學觀念論&quot;,&quot;建設的文學革命論&quot;,&quot;多研究些問題，少談些主義&quot;,&quot;差不多先生傳&quot;,&quot;人權與約法&quot;,&quot;我們什麼時候才可有憲法—對於建國大綱的疑問&quot;,&quot;知難，行亦不易—孫文先生的「行易知難」說述評&quot;,&quot;新文化運動與國民黨&quot;,&quot;我們走那條路&quot;,&quot;容忍與自由&quot;], &quot;sub&quot;: [&quot;文學改良芻議&quot;,&quot;歷史的文學觀念論&quot;,&quot;建設的文學革命論&quot;,&quot;多研究些問題，少談些主義&quot;,&quot;差不多先生傳&quot;,&quot;人權與約法&quot;,&quot;我們什麼時候才可有憲法&quot;,&quot;知難，行亦不易&quot;,&quot;新文化運動與國民黨&quot;,&quot;我們走那條路&quot;,&quot;容忍與自由&quot;], } df = pd.DataFrame(data=data) df[&#39;date&#39;] = pd.to_datetime(df[&#39;date&#39;], format=&#39;%Y-%m-%d&#39;) df[&#39;y&#39;] = [random() for i in range(len(df.title))] . df . date title sub y . 0 1919-01-01 | 文學改良芻議 | 文學改良芻議 | 0.043649 | . 1 1917-05-01 | 歷史的文學觀念論 | 歷史的文學觀念論 | 0.729784 | . 2 1918-01-01 | 建設的文學革命論 | 建設的文學革命論 | 0.281129 | . 3 1919-07-20 | 多研究些問題，少談些主義 | 多研究些問題，少談些主義 | 0.544732 | . 4 1924-01-01 | 差不多先生傳 | 差不多先生傳 | 0.704270 | . 5 1929-01-01 | 人權與約法 | 人權與約法 | 0.699685 | . 6 1929-02-01 | 我們什麼時候才可有憲法—對於建國大綱的疑問 | 我們什麼時候才可有憲法 | 0.651569 | . 7 1929-03-01 | 知難，行亦不易—孫文先生的「行易知難」說述評 | 知難，行亦不易 | 0.262863 | . 8 1929-04-01 | 新文化運動與國民黨 | 新文化運動與國民黨 | 0.116383 | . 9 1930-04-10 | 我們走那條路 | 我們走那條路 | 0.443837 | . 10 1959-11-20 | 容忍與自由 | 容忍與自由 | 0.266778 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Plotting . This time, we create the figure using plotly.graph_objects. We can draw the sticks using fig.add_shape(type=&#39;line&#39;). It will be put in a loop so we can draw mulitple sticks for every row instead. x0, x1, y0, y1 mean the coordinates of the shape. As it is a line, x0 equals x1, and y0 and y1 refers to the beginning (always 0) and ending point (depends on y column) of the stick. Other options include the color of the sticks. . import plotly.graph_objects as go fig = go.Figure() # Draw lines for i in range(0, len(df)): fig.add_shape(type=&#39;line&#39;, # draw line x0 = df[&quot;date&quot;][i], y0 = 0, # our line x1 = df[&quot;date&quot;][i], y1 = df[&quot;y&quot;][i], opacity=0.65, # transparency line=dict(color=&#39;darkblue&#39;, width = 5)) # line color and width . Then we will plot the dots using fig.add_trace(go.Scatter()). We will use the text to indicate the static labels and customdata indicate the full titles. mode=&quot;markers+text&quot; means both markers and static labels will be shown. We will also use other customization options and html tags for our hovertemplate. . fig.add_trace(go.Scatter(x = df[&quot;date&quot;], y = df[&quot;y&quot;], text=df[&quot;sub&quot;], # static labels customdata=df[&quot;title&quot;], # hover labels mode=&quot;markers+text&quot;, # display static labels hovertemplate = # what to shown in hover labels &#39;&lt;extra&gt;&lt;br&gt;&lt;b&gt;Date&lt;/b&gt;: %{x}&lt;br&gt;&lt;/extra&gt;&#39;+ &#39;&lt;extra&gt;&lt;b&gt;%{customdata}&lt;/b&gt;&lt;/extra&gt;&#39;, textposition=&quot;top center&quot;, marker_color =&#39;darkblue&#39;, # layout for the dots marker_size = 16)) . Then, we add a title to our plot, and change other options including template, figure size, and y range. We will also disable y axis and ticks, as well as adjust layout for x axis and ticks. . fig.update_layout(title_text = &quot;胡適 文章與期刊&quot;, title_font_size = 30) fig.layout.template = &quot;simple_white&quot; # layout template fig.update_layout(width=1250, height=400) # figure size fig.update_layout(yaxis_visible=False, yaxis_showticklabels=False) # y axis and ticks fig.update_layout(yaxis_range=[0,1.5]) # y range fig.update_xaxes(tickfont_size=24, ticks=&quot;outside&quot;, ticklen=20, tickwidth=5) # x axis and ticks fig.show() # diaply plot . . . Previous Lesson: Simple Bubble Chart using plotly.express . Next Lesson: Coming soon... . . . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: December 2021 . . . . References: . Plotly .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/level-3/chapter-3/plotly/data-visualization/2022/01/09/Simple_Plotly_Chart.html",
            "relUrl": "/level-3/chapter-3/plotly/data-visualization/2022/01/09/Simple_Plotly_Chart.html",
            "date": " • Jan 9, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "Simple Bubble Chart using plotly.express",
            "content": ". . Plotly&#39;s Python graphing library makes interactive, publication-quality graphs. Compared to the static graphics, Plotly can not only embed more information using the hover tools, it also allow zooming and panning so users can easily look into the details of the graphics. Users can create Plotly graphics in Python using either plotly.graph_objects or plotly.express. While the first option allows more customization for graphical elements, The later option allows a much simpler syntax so it is also easier to learn. . This notebook aims to demonstrate users some simple functionalities of plotly.express library for making simple but interactive bubble charts. To start with the tutorial, users need to have some knowledge of matplotlib and understand the basic grammer of making a plot. In this tutorial, we will use a simple example of some basic statistics of Chinese dynasties, including the year range, territory area, population and maximum longevity of emperors. The statistics are found online with no guarantee of preciseness. It is purely used for plotting demonstration purpose. . . Presumptions: . . Set Up Environment . First, we set up the environment by importing the libraries. . import plotly.express as px import numpy as np import pandas as pd . Then, we will use a dictionary to create a Pandas data frame dyn_df. . dyn = { &quot;dynasty&quot;: [&quot;Qin&quot;,&quot;Han&quot;,&quot;Jin&quot;,&quot;Sui&quot;,&quot;Md Tang&quot;,&quot;S Song&quot;,&quot;Yuan&quot;,&quot;Ming&quot;,&quot;Qing&quot;], # name of dynasty &quot;year&quot;: np.array([-221,2,280,581,726,1223,1341,1570,1887]), # year of begin &quot;area&quot;: 10000*np.array([360,609,543,467,1237,200,1372,997,1316]), # territory &quot;pop&quot;: 10000*np.array([4500,6500,2200,4450,8050,8060,8500,6000,37700]), # population &quot;max emperor longevity&quot;: np.array([50,70,55,64,82,81,79,71,89]) # maximum emperor longevity } dyn_df = pd.DataFrame(data=dyn) # create data frame . Then we look at the first few rows. . dyn_df.head() . dynasty year area pop max emperor longevity . 0 Qin | -221 | 3600000 | 45000000 | 50 | . 1 Han | 2 | 6090000 | 65000000 | 70 | . 2 Jin | 280 | 5430000 | 22000000 | 55 | . 3 Sui | 581 | 4670000 | 44500000 | 64 | . 4 Md Tang | 726 | 12370000 | 80500000 | 82 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Using plotly.express (px) allows the uses of shorter code to make a plot. To create a scatter plot, we only need to input the data frame dyn_df, the columns (variables) for x, y axis, size of the markers, hover names (which information will appear when you point your mouse to the markers) and color of the markers. The argument size_max define the relative size of the bubbles. Typing fig.show() allow the figure to be displayed. . As you can see, a legend will be automatically created on the right side of our plot, and population in the y axis will be displayed in the format of million for better visuals. . fig = px.scatter(dyn_df, x=&quot;year&quot;, y=&quot;pop&quot;, size=&quot;area&quot;, color=&quot;dynasty&quot;, hover_name=&quot;dynasty&quot;, size_max=60) fig.show() . . . The plot looks fine, but there are still many parameters which can be adjusted. First, we want to try out a different theme (plotly_dark) for our figure. Then, we want to create a title, change some colors in layout, and color the bubbles by max emperor longevity. . Also, it would be nice if we can view the name of dynasty on the bubbles instead. Finally, to make the different between dynasties in y axis more distinct, we can use a log scale for the y axis. . To do all those, all we need to do is to customize many parameters of the scatter fucntion and use update_layout. Remember the hierarchy of the parameters is important as we need to, for example, put parameters that belong to xaxis into a single dict. . fig = px.scatter(dyn_df, x=&quot;year&quot;, y=&quot;pop&quot;, size=&quot;area&quot;, color=&quot;max emperor longevity&quot;,opacity=0.85, # changing the color parameter hover_name=&quot;dynasty&quot;, size_max=70, template=&quot;plotly_dark&quot;, title=&quot;Chinese Dynasty Comparison&quot;, # use template option width=1000, height=450, # set size of our plot text=dyn_df.dynasty.values ) fig.update_layout( title=&#39;&lt;b&gt;Chinese Dynasty Comparison&lt;/b&gt;&#39;, # add a title xaxis=dict( title=&#39;Year (CE)&#39;, # x label gridcolor=&#39;rgba(255, 255, 255, 0.6)&#39;, # color for grid gridwidth=0.5, # width of grid line ), yaxis=dict( title=&#39;Population Size&#39;, # y label type=&quot;log&quot;, gridcolor=&#39;rgba(255, 255, 255, 0.6)&#39;, gridwidth=0.5 ), font=dict( family=&quot;Courier New, monospace&quot;, # font style size=18, # font size color=&quot;white&quot; # font color ) ) fig.show() # display plot . . . However, we can also choose to reduce our plot to one dimension so it looks more like a original time line. . dyn_df.head() . dynasty year area pop max emperor longevity . 0 Qin | -221 | 3600000 | 45000000 | 50 | . 1 Han | 2 | 6090000 | 65000000 | 70 | . 2 Jin | 280 | 5430000 | 22000000 | 55 | . 3 Sui | 581 | 4670000 | 44500000 | 64 | . 4 Md Tang | 726 | 12370000 | 80500000 | 82 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; To do this, the main thing we need to change is the y axis. We can, for example, add a new column and set it to 0 for all rows. . dyn_df[&#39;y&#39;] = 0 . Now, we make the new plot again. This time, we want to show more hover info to the readers. We can do it in plotly.express by add custom_data (input columns) and call them using hovertemplate. For example, %{customdata[0]} means the first custom_data which is &quot;dynasty&quot; in this case (if there is only one custom_data, you can write %{customdata} instead). . Pay attention to the difference between customdata and custom_data. Be careful that it will not work the same way in plotly.graph_objects. . fig = px.scatter(dyn_df, x=&quot;year&quot;, y=&quot;y&quot;, # x and y marker location, use column name inside the dataframe size=&quot;area&quot;,opacity=0.85, # marker transparancy hover_name=&quot;dynasty&quot;, size_max=40, # marker size custom_data=[&#39;dynasty&#39;, &#39;area&#39;], # extra hover info template=&quot;simple_white&quot;, title=&quot;Chinese Territory over Time&quot;, # template and plot title width=900, height=300, # plot size text=dyn_df.dynasty.values # the dynasty will be displayed on the bubbles ) fig.update_traces( hovertemplate=&#39;&lt;i&gt;Dynasty&lt;/i&gt;: %{customdata[0]}&#39;+ &#39;&lt;br&gt;&#39; + # what we want to show in labels: you can use HTML tag here. Eg. &lt;br&gt; means next line &#39;&lt;i&gt;Territory&lt;/i&gt;: %{customdata[1]} km²&#39; # &lt;i&gt; means in italic ) fig.update_traces( marker=dict( color=&#39;#0073AE&#39;, # change marker color opacity=0.5, line=dict( color=&#39;gray&#39;, width=1) ) ) fig.update_layout(showlegend=False) # we have our text so we can turn off the legend fig.update_yaxes(visible=False) # no y axis needed fig.update_layout(yaxis_range=[0,0]) # limit y axis range fig.update_layout(hovermode=&quot;x&quot;) # how the plot react with hover # the style of hover labels can be customized too fig.update_layout( hoverlabel=dict( bgcolor=&quot;white&quot;, # background color font_size=14, # font size font_family=&quot;Rockwell&quot; # font ) ) fig.show() . . . Previous Lesson: Introduction to Data Story Telling . Next Lesson: Coming soon... . . . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: December 2021 . . . . References: . Plotly .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/level-3/chapter-3/matplotlib/data-visualization/2021/12/30/Simple_Bubble_Chart.html",
            "relUrl": "/level-3/chapter-3/matplotlib/data-visualization/2021/12/30/Simple_Bubble_Chart.html",
            "date": " • Dec 30, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "Data Story Telling",
            "content": ". This notebook aims to provide some useful tips for the readers before they begin with their first data visualization. . . Presumptions: . Not applicable. . . Data visualization is essentially the process of translating data, either qualitative or quantitative, into charts, graphs and other visuals, in order to deliver messages or insights as a way of communication. It can reduce large amount of data into more interpretable information, or even map spatial and temporal domain into 2D (or higher dimensional) space for more intuitive communication (Let&#39;s think about how counterintuitive it is to read a list of events in random time orders even with time labels). Human are highly visual creatures. We have learned to interact with the world using visual cues. Hence, by representing text or numberical information in graphical ways, readers can absorb and react to information more effectively. . Nonetheless, there are many factors which can determine if graphics are effective or not. If the graphics or charts are not created properly, we cannot leverage the potential of data visualization to deliver our messages, and might even cause confusions. Since there are already lots of online resources explaining the idea of data visualization, this lesson will mainly direct readers to some existing resources and to summarize using a Chinese historical example. . What are the goals and common methods for data visualization? Some Harvard scholars have categorized the approaches into four directions: . Distribution . | Comparison . | Relationship . | Composition . | . Let&#39;s read more about it yourself. . &gt;&gt;&gt; Ultimate resource for understanding &amp; creating data visualization . Now you have understood some basic approaches for making data visualization. Next step is to think about the structure of a plot. Do you know how do we build a plot and what elements are there? The following paper which builds on the grammar of graphics for R (ggplot2) have shown some nice insights about the components of a good graphic. Although we will not learn ggplot2 in this blog, this article still nicely describes the basic structure of many different Python plotting libraries, which requires users to construct different graphical elements, as well as customized their styles. You do not need to go into all the details: the most important is that you have a big idea about the basic elements in a plotting library, such as parameterization, scale, markers, coordinate systems and layers. . &gt;&gt;&gt; A Layered Grammar of Graphics . It should be clear by now why do we need data visualization and how does the theory being implemented in many plotting libraries. Afterwards, we need to learn about the practices. For example, what are the criterium to select the type of data visualization? How shall we choose the colors and the markers? How many visual elements do we need in a graphic? Let&#39;s learn about them by reading the article below. . These are the key messages quoted from the article below: . Data visualizations should be audience-specific with a clear requirement . | Choose the right visualization for your data . | Keep your visualizations simple . | Label your data visualizations . | Understand the importance of text in charts . | Use colors effectively in data visualizations . | Avoid deceiving with your visualizations . | Make interpretable data visualizations . | . &gt;&gt;&gt; Data Visualization Tips to Improve Data Stories . Until now, let&#39;s check what we have learnt by looking into a simple example of this paper about THE SHORT-LIVED CHINESE EMPERORS. This paper describes the statistics on the ages of death for Chinese emperors, buddhist Monks, and traditional Doctors. What kind of data visualization would fit into this example? . . Age at Death Emperor (n=241) Buddhist Monk (n=140) Traditional Doctor (n=181) . &lt;20, n (%) | 28 (11.6) | 2 (1.4) | 0 (0) | | . 20–29, n (%) | 46 (19.1) | 7 (5.0) | 0 (0) | | . 30–39, n (%) | 47 (19.5) | 12 (8.6) | 3 (1.7) | | . 40–49, n (%) | 38 (15.8) | 5 (3.6) | 3 (1.7) | | . 50–59, n (%) | 42 (17.4) | 19 (13.6) | 20 (11.0) | | . 60–69, n (%) | 29 (12.0) | 27 (19.3) | 34 (18.8) | | . 70–79, n (%) | 7 (2.9) | 39 (27.9) | 56 (30.9) | | . 80–89, n (%) | 4 (1.7) | 14 (10) | 42 (23.2) | | . 90–99, n (%) | 0 (0) | 8 (5.7) | 16 (8.8) | | . ≥100, n (%) | 0 (0) | 7 (5.0) | 7 (3.9) | | . Range | 2–89 | 17–120 | 32–109 | | . Mean ± standard deviation | 41.3 ± 17.9 | 66.9 ± 20.7 | 75.1 ± 13.4 | | . Table retrieved from Zhao, H. L., Zhu, X., &amp; Sui, Y. (2006). . 1. One Key Message Per Graphic . First, it is recommanded to deliver one message per graphic. In this case,it means we might not want to emphasize causes of deaths of the emperors and the longevity comparison between groups in a single graphic. For example, we would focus on the longevity differences between emperors and other groups by creating multiple histograms or boxplots in a graph. . 2. Avoid Redundant Styling . Also, we need to pay attention to the styling. Although multiple colors or marker symbols can be eye-catching, it can create unnecessary confusions if they do not embed meanings. For example, we shall avoid using different colors for the same group. Also, we should either use a different color or marker symbol for different groups, but not both of them. . In this example, we can use different colors for emperor, monk, and traditional doctor in our chart. . 3. Be Careful of your Color scheme . Besides, we need to pay attention to the color scheme. Remember that many elements have intuitive meanings in our brain, so it is the best if we would follow the expected patterns. For example, if we want to show the frequency of war occurred in different periods, it is better to use red-blue to represent more-less frequent wars than to use the reverse order of color scheme. It is the same with other styling elements too. For example, using the same marker symbol with larger size to describe another category will not be sensible. . We also need to think about the color palette. There are color palettes (sequential and diverging palettes) with changing saturation or lightness used to describe data with continuous nature, as well as qualitative color palettes designated for categorical data. We should always make sure the color selected is visually distinguisble (even for color blind audience) and is approperiate for the data nature. . Here in this example, we have three categories that cannot be ordered. So we can use a categorical palette. . 4. Select type of graphics depends on the Nature of your data . We also need to learn about advantages and disadvantages of using different chart types. For example, a circle packing chart provides attractive visuals, but fails to show precise comparisons. A groupped bar chart displays decent comparisons, but it can look messy if we have many groups. A polar bar chart emphasizes the dominant groups, but do not work well with data showing development (eg. time series). . In this example, a boxplot will fit better than a pie chart. It will also fit better than a bar chart if we want to emphasize the general distribution for all ages groups rather than some distinct characteristics of certain age groups. . 5. Pay Attention to your Axis . Finally, your axis are important too. If it is a map, make sure that they have north on the top. Or if it is a scatter plot, make sure to put the dependent variable on the y-axis. If the charts represent any temporal development, make sure that the time dimension shall be put in the x-axis. In this example, the boxplot can be both vertical and horizontal. . Previous Lesson: Pandas Numerical Operation . Next Lesson: Coming soon... . . . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: December 2021 . . . . References: . Zhao, H. L., Zhu, X., &amp; Sui, Y. (2006). THE SHORT‐LIVED CHINESE EMPERORS. Journal of the American Geriatrics Society, 54(8), 1295-1296. .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/level-3/chapter-3/data-visualization/2021/12/06/DataVisualization.html",
            "relUrl": "/level-3/chapter-3/data-visualization/2021/12/06/DataVisualization.html",
            "date": " • Dec 6, 2021"
        }
        
    
  
    
        ,"post6": {
            "title": "Circle Packing using Circlify",
            "content": ". This notebook aims to intrduce users some practical skills on generating a circle packing chart. . . Presumptions: . Not applicable. . . ! pip install circlify . Collecting circlify Downloading circlify-0.14.0-py2.py3-none-any.whl (11 kB) Installing collected packages: circlify Successfully installed circlify-0.14.0 . from pprint import pprint as pp import circlify as circ . surname = &quot;&quot;&quot; 王 李 張 趙 劉 陳 楊 吳 黃 朱 孫 郭 胡 呂 高 宋 徐 程 林 鄭 范 何 韓 曹 馬 許 田 馮 杜 周 曾 汪 蘇 董 方 蔡 梁 石 謝 賈 薛 彭 崔 唐 潘 鄧 任 史 錢 侯 魏 羅 葉 沈 孟 姚 傅 丁 章 蕭 蔣 盧 陸 袁 江 晁 譚 邵 歐陽 孔 俞 尹 廖 閻 洪 夏 雷 葛 文 柳 陶 毛 丘 龔 康 蒲 邢 郝 龐 安 裴 折 施 游 金 鄒 湯 虞 嚴 鍾 &quot;&quot;&quot; import re surname = list(re.sub(&quot; s+&quot;, &quot;&quot;, surname.strip())) . surname[:5] . [&#39;王&#39;, &#39;李&#39;, &#39;張&#39;, &#39;趙&#39;, &#39;劉&#39;] . surname.reverse() . len(surname) . 101 . import pandas as pd import numpy as np df = pd.DataFrame({ &#39;surname&#39;: surname, &#39;weight&#39;: 5*np.arange(1,102) }) . import circlify # compute circle positions: circles = circlify.circlify( df[&#39;weight&#39;].tolist(), target_enclosure=circlify.Circle(x=0, y=0, r=1), show_enclosure=False ) . len(df.weight) . 101 . import math import numpy as np x = np.array([cir.x for cir in circles]) y = np.array([cir.y for cir in circles]) r = np.array([cir.r for cir in circles]) bubble_df = pd.DataFrame({ &#39;x&#39;: x, &#39;y&#39;: y, &#39;r&#39;: r, &#39;l&#39;: df.sort_values(&#39;weight&#39;).surname.values, &#39;s&#39;: (math.pi)*(r**2) }) . !wget -O TaipeiSansTCBeta-Regular.ttf https://drive.google.com/uc?id=1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_&amp;export=download import matplotlib as mpl import matplotlib.pyplot as plt from matplotlib.font_manager import fontManager fontManager.addfont(&#39;TaipeiSansTCBeta-Regular.ttf&#39;) mpl.rc(&#39;font&#39;, family=&#39;Taipei Sans TC Beta&#39;) . import circlify import numpy as np import random import matplotlib.pyplot as plt import seaborn as sns from matplotlib.colors import ListedColormap palette = [&quot;#CD5C5C&quot;,&quot;#F08080&quot;,&quot;#E9967A&quot;,&quot;#FFA07A&quot;,&quot;#C04000&quot;,&quot;#FF5F1F&quot;,&quot;#B22222&quot;,&quot;#660000&quot;,&quot;#C21E56&quot;] # Create just a figure and only one subplot fig, ax = plt.subplots(figsize=(10,10)) # Title ax.set_title(&#39;宋朝人口姓氏期望分佈&#39;, fontsize=26) # Remove axes ax.axis(&#39;off&#39;) # Find axis boundaries lim = max( max( abs(circle.x) + circle.r, abs(circle.y) + circle.r, ) for circle in circles ) plt.xlim(-lim, lim) plt.ylim(-lim, lim) # list of labels labels = df.sort_values(&#39;weight&#39;).surname.values # print circles for circle, label in zip(circles, labels): x, y, r = circle ax.add_patch(plt.Circle((x, y), r, alpha=0.6, linewidth=1, facecolor=random.choice(palette), edgecolor=&quot;white&quot;)) plt.annotate( label, (x,y) , va=&#39;center&#39;, ha=&#39;center&#39;, fontsize=300*r, color=&quot;black&quot; ) . bubble_df[&quot;rank&quot;] = bubble_df.sort_values(by=&quot;r&quot;, ascending=False).index bubble_df.head() . x y r l s rank . 0 -0.157353 | 0.011841 | 0.011880 | 王 | 0.000443 | 101 | . 1 -0.199757 | 0.034318 | 0.016801 | 李 | 0.000887 | 100 | . 2 -0.129251 | -0.004397 | 0.020577 | 張 | 0.001330 | 99 | . 3 -0.225690 | 0.181468 | 0.023760 | 趙 | 0.001774 | 98 | . 4 -0.309487 | 0.366656 | 0.026564 | 劉 | 0.002217 | 97 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; font_size = 250*bubble_df.r.values . import plotly.express as px fig = px.scatter(bubble_df, x=&quot;x&quot;, y=&quot;y&quot;, custom_data=[&quot;l&quot;,&quot;rank&quot;], color=&quot;x&quot;, width=800, height=700, size=&quot;s&quot;, hover_name=&quot;l&quot;, size_max=45, text=&quot;l&quot;) fig.update(layout_coloraxis_showscale=False) fig.update_traces( hovertemplate=&quot;&lt;br&gt;&quot;.join([ &quot;Surname: %{customdata[0]}&quot;, &quot;Ranking: %{customdata[1]}&quot; ]) ) fig.update_layout(showlegend=False) fig.update_xaxes(visible=False) fig.update_yaxes(visible=False) fig.update_yaxes( scaleanchor = &quot;x&quot;, scaleratio = 0.95, ) fig.update_layout({ &#39;plot_bgcolor&#39;: &#39;rgba(0, 0, 0, 0)&#39;, &#39;paper_bgcolor&#39;: &#39;rgba(0, 0, 0, 0)&#39;, }) fig.update_layout( title={ &#39;text&#39;: &quot;&lt;b&gt;宋朝人口姓氏期望分佈&lt;/b&gt;&quot;, &#39;y&#39;:0.97, &#39;x&#39;:0.5, &#39;xanchor&#39;: &#39;center&#39;, &#39;yanchor&#39;: &#39;top&#39;}, font=dict( family=&quot;Courier New, monospace&quot;, size=18, color=&quot;black&quot; ) ) fig.update_traces(textfont_size=font_size) fig.show() . . . . . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: December 2021 . . . . References: . https://github.com/elmotec/circlify .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/level-3/chapter-3/matplotlib/data-visualization/2020/02/02/Circlify.html",
            "relUrl": "/level-3/chapter-3/matplotlib/data-visualization/2020/02/02/Circlify.html",
            "date": " • Feb 2, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "Python for Research Q & A 🖋️",
            "content": ". . Background . Python is getting more and more popular, not only in the field of computer science, but also in the diverse fields when it comes to computation, working with digital resources and data presentation. This notebook aims to give users some basic knowledge about the potential of Python programming language in the context of humanity research. . . Presumption: Not applicable . . . Although Python is a programming language, it is different from other low-level programming languages by being more user-friendly and more close to a interpreter than machine code. It is for general purpose and also relatively beginner-friendly. . Python is not only more readable, it also has less structural rules and usually much shorter. Compared to other languages such as JavaScript, Python has not so much low-level language like syntax so its learning curve is not as steep. . General-purpose Language . Although you might have read other tutorials telling you how you can use very diverse tools to achieve fancy tasks that you wish to perform. You also have to realize that how much time will you need to master that languages or tools before tasks can be done. . Let&#39;s assume that you are not a real web developer here and data analysis or visualization is not your primary profession. It means, you are not making your living by making charts and websites, and for you making creative and fancy new charts is not as important as making a not so time-consuming and presentable bar chart which display your results to the audience or in your paper. . Most often, what you need is then much more simple functionalities which a fancy tool can overkill. You also need to consider that not all digital tools are open and free, so using multiple of them can cost you time and money. . For Qualitative Research . Although Python is a programming language and is often associated with computing and numbers, it can help you with qualitative research too! It includes many functionalities to work with text resources. Although you do not need to do calculation on them, sometimes you do want to find a pattern in them, look for the keywords, or just get them into digital text. . . Data Input . Python can help you to get your qualitative sources. Let&#39;s say you want to look into BDK (Bukkyo Dendo Kyokai) Database for the A Biography of Sakyamuni. And you want to get the text file of certain chapters. What you can do is to use Python to scrap the text and load it in a file for you. Or let&#39;s say you want to have all the Buddhist texts having a particular keywords, then you can filter the text using Python. . . Data Analysis . So now you got the text. But you want to see how does certain keywords distributed inside your text(s), or what is the associated sentiment of the text(s). Then you can perform NLP in Python. Or if you have a database of Buddhist temples and want to analysis what regions are they mostly located in, then you can perform some geospatial analysis in Python too. . . Data Presentation . Let&#39;s say now you got your results already, and you need to present them either in a paper, in a PowerPoint or make a simple webpage that you can shared with your colleagues or your audience. You can also make both static and interactive charts/ text visualization using Python. They can be either a bar chart for comparison, a word cloud for showing key words, or a map showing geolocations of objects. . . Checking out some galleries: . PLOTLY . | SEABORN . | . What can Python do for me? . Python can indeed handle a large variety of tasks, from get data for you (web scraping), to analysis your data (text analysis), to present your results (data visualization). Its high speed allow you to scan and work with a large amount of data and search for the ones that you are interested in! You can then either analyse them with Python or continue by yourself to read the information retrieved. Or Python simply let you present what you have in mind, like a time line, in a digital format. . Geospatial Data ?? . For example, you might have read about Mapbox.js, Leaflet.js, R or GIS for analysing geospatial data, making choropleths and interactive graphics. But Python can do it too using Plotly, Folium and Geoopandas! . Interactive Bubble Chart ?? . Then you read about D3.js for making an interactive bubble chart. But Python can get it done too using Plotly. . Text Optical Recognition (OCR) ?? . Then you read about doing OCR, but Python get give you a ride too using pytesseract. You can even work on it without the need for Bash or Comment Line. . Data Cleaning ?? Manipulation ?? . Then you read about other digital tools for data cleaning and manipulation. You realize you need them too. But you can stick with Python: Pandas library can get the job done! . Data Mining ?? Web Scraping ?? . Then you think of getting information from a digital database? The door of Python Beautiful Soup is open for you! . Web Application ?? App ?? . Want to make a simple web application or app to host your data visualization or presentation? Try out Dash from Plotly which can be run in Python too! . . Next Lesson: Introduction to Jupyter &amp; Colab . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: December 2021 . . . . References: . https://www.bitdegree.org/tutorials/python-vs-javascript/ . https://towardsdatascience.com/a-complete-guide-to-an-interactive-geographical-map-using-python-f4c5197e23e0 .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/level-1/chapter-1/background/2020/01/31/Python_Research_Q&A_Basics.html",
            "relUrl": "/level-1/chapter-1/background/2020/01/31/Python_Research_Q&A_Basics.html",
            "date": " • Jan 31, 2020"
        }
        
    
  
    
        ,"post8": {
            "title": "Introduction to Jupyter Notebooks",
            "content": ". What is Jupyter? . The Jupyter Project is an open source effort that evolved from the IPython project to support interactive data science and computing. Besides Python, it also supports many different programming languages including R and Julia. . Components of Jupyter Notebook . Jupyter Notebook IDE: The application that launches in a web browser like Firefox or Safari and is the environment where you write and run your code. . | Jupyter Notebook Files(.ipynb): The file format that you can use to store code and markdown text for individual projects and workflows. . | Kernels: A kernel runs your code in a specific programming language. In this tutorial, Python kernel is used within the Jupyter Notebook IDE. . | . Jupyter Notebook User Interface . After you create a new notebook file (.ipynb), you will be presented with notebook name, menu bar, tool bar and a code cell as default starting cell. . Notebook Name: if you click at the notebook name, you could rename the file. . | Menu Bar: presents all functions and settings of the notebook file. . | Tool Bar: presents the most used tools as icons. . | Code Cell: it is the default type of cell when you create a new cell; if you want to transfer it to a markdown cell, you could use the drop down box in tool bar or a keyboard shortcut. . | . . . 1. Headers . Note: The more # the title holds, the smaller the title will be. . # This is a Title in Markdown . ## This is a Subtitle in Markdown . ### This is a smaller subtitle in Markdown . . will be rendered as: . This is a Title in Markdown . This is a Subtitle in Markdown . This is a smaller subtitle in Markdown . . . 2. Lists . * This is a bullet list . * This is a bullet list . * This is a bullet list . . 1. This is a numbered list . 2. This is a numbered list . 3. This is a numbered list . . will be rendered as: . This is a bullet list | This is a bullet list | This is a bullet list | . This is a numbered list | This is a numbered list | This is a numbered list | Tip: To render list, you should leave a blank space between 1. and the following texts. . . . 3. Bold and Italic . *These are italic words.* . **These are bold words.** . ***These are bold AND italic words.*** . . will be rendered as . . These are italic words. . These are bold words. . These are bold AND italic words. . . . . 4. Highlight Code . If you want to highlight a funciton or some code in a plain text, you add one backtick on each side of the text (`). . Here is some highlighted text! . . . . 5. Horizontal Lines . You can also create a horizontal line to highlight a block of markdown syntax. . . *** . Here is some important text! . *** . . will be rendered as: . . . Here is some important text! . . . Tip: The *s on both side of the texts should be at the line above and the line below the texts. . . . 6. Hyperlinks . You can use HTML in Markdown cells to create hyperlinks redirecting to other websites. For example, the following syntax. . More infos about our data cube program can be found at &lt;a href=&quot;https://datacube.remote-sensing.org/&quot;&gt;this website&lt;/a&gt; . . will be rendered as: . More infos about our data cube program can be found at this website . . . 7. Images . You can also render images in Markdown cells using the following syntax: . ![alternative text here](url-to-image-here) . . For example, . ![Fotograph of Philip is here](https://i.imgur.com/VGPeJ6s.jpg) . . will be redered like: . . Or if the image need to be resize: . &lt;div&gt; . &lt;img src=https://i.imgur.com/VGPeJ6s.jpg width=&quot;200&quot;&gt; . &lt;/div&gt; . . will be rendered as: . Note: The texts in the rectangle brackets (e.g. &quot;Fotograph of Philip is here&quot;) will appear when the image fails to load. . . . . 8. LaTex . Jupyter notebook markdown cell also supports LaTex. So that the markdown cells interpret your texts as LaTex, surround your input texts with $ signs. . For instance, $c=a+b$ will be rendered as . $c=a+b$ . If you want your texts be centered in the cell, surround your input texts with two $ signs. . For instance, $$C_{g}= frac{H}{ frac{ pi}{2}*Cl_{p}}$$ will be rendered as . $$C_{g}= frac{H}{ frac{ pi}{2}*Cl_{p}}$$ . . and . . |Uppercase| LaTeX |Lowercase| LaTeX | . ||-||-| . |$ Delta$ | Delta|$ delta$ | delta| . |$ Omega$ | Omega|$ omega$ | omega| . . will be rendered as: . . Uppercase LaTeX Lowercase LaTeX . $ Delta$ | Delta | $ delta$ | delta | . $ Omega$ | Omega | $ omega$ | omega | . . 9. Table . A table can be constructed using | (pipe symbol) and — (dash) to mark columns and rows. The first row of the table defines the headers, and the next row defines the alignment of each column. . . For instance, . | Stretch/Untouched | ProbDistribution | Accuracy | . | | | | . | Stretched | Gaussian | .843 | . . will be rendered as: . Stretch/Untouched ProbDistribution Accuracy . Stretched | Gaussian | .843 | . The widths of the columns can also be changed by adding an empty row at the end with defined width. . . | Stretch/Untouched | ProbDistribution | Accuracy | . | | | | . | Stretched | Gaussian | .843 | . |&lt;img width=200/&gt;|&lt;img width=200/&gt;|&lt;img width=200/&gt;| . . will be rendered as: . . Stretch/Untouched ProbDistribution Accuracy . Stretched | Gaussian | .843 | . | | | . What is Colab? . So now we learnt about Jupyter Notebook, then what is Colab? Colab notebooks are Jupyter notebooks that are hosted by Colab. Therefore, the operations are highly similar and it allows you to write and execute Python in your browser, with . Zero configuration required | Free access to GPUs | Easy sharing | . There are limits in the available memory but they are generally sufficient if you are not performing particularly demanding tasks. One of the benefits using Colab is that you do not need to worried about dependencies as much for downloading Python tools and libraries. Many of the libraries are available in the Colab environment by default, eg. Pandas. . To import a library that&#39;s not in Colaboratory by default, you can also use !pip install or !apt-get install. . For example, . !pip install cartopy import cartopy . Collecting cartopy Downloading Cartopy-0.20.1.tar.gz (10.8 MB) |████████████████████████████████| 10.8 MB 5.1 MB/s Installing build dependencies ... done Getting requirements to build wheel ... error WARNING: Discarding https://files.pythonhosted.org/packages/fc/59/aa52698e3838f4cd0e7eaa75bd86837e9e0b05041dbdaee3cda2fffced06/Cartopy-0.20.1.tar.gz#sha256=91f87b130e2574547a20cd634498df97d797abd12dcfd0235bc0cdbcec8b05e3 (from https://pypi.org/simple/cartopy/) (requires-python:&gt;=3.7). Command errored out with exit status 1: /usr/bin/python3 /usr/local/lib/python3.7/dist-packages/pip/_vendor/pep517/in_process/_in_process.py get_requires_for_build_wheel /tmp/tmpvn613tgl Check the logs for full command output. Downloading Cartopy-0.20.0.tar.gz (10.8 MB) |████████████████████████████████| 10.8 MB 20.5 MB/s Installing build dependencies ... done Getting requirements to build wheel ... error WARNING: Discarding https://files.pythonhosted.org/packages/0f/c0/58453b036e79046d211f083880d58dcce787e7e07647ac25dc46c6555099/Cartopy-0.20.0.tar.gz#sha256=eae58aff26806e63cf115b2bce9477cedc4aa9f578c5e477b2c25cfa404f2b7a (from https://pypi.org/simple/cartopy/) (requires-python:&gt;=3.7). Command errored out with exit status 1: /usr/bin/python3 /usr/local/lib/python3.7/dist-packages/pip/_vendor/pep517/in_process/_in_process.py get_requires_for_build_wheel /tmp/tmpcxegil_v Check the logs for full command output. Downloading Cartopy-0.19.0.post1.tar.gz (12.1 MB) |████████████████████████████████| 12.1 MB 19.6 MB/s Installing build dependencies ... done Getting requirements to build wheel ... done Preparing wheel metadata ... done Requirement already satisfied: shapely&gt;=1.5.6 in /usr/local/lib/python3.7/dist-packages (from cartopy) (1.8.0) Collecting pyshp&gt;=2 Downloading pyshp-2.1.3.tar.gz (219 kB) |████████████████████████████████| 219 kB 48.7 MB/s Requirement already satisfied: numpy&gt;=1.13.3 in /usr/local/lib/python3.7/dist-packages (from cartopy) (1.19.5) Building wheels for collected packages: cartopy, pyshp Building wheel for cartopy (PEP 517) ... done Created wheel for cartopy: filename=Cartopy-0.19.0.post1-cp37-cp37m-linux_x86_64.whl size=12516269 sha256=983da772a11f3cba2d78a180f9a2d0136b8d43ba98219da421e264ca5b01d995 Stored in directory: /root/.cache/pip/wheels/98/01/f7/bd10aeb96fe4b518cde5f7c4f5e12c7202f85b7353a5017847 Building wheel for pyshp (setup.py) ... done Created wheel for pyshp: filename=pyshp-2.1.3-py3-none-any.whl size=37325 sha256=1c8e9a249f1f0ed81fac1f63ab6c703038812764fe6dd1b67b62e911ebaab64e Stored in directory: /root/.cache/pip/wheels/43/f8/87/53c8cd41545ba20e536ea29a8fcb5431b5f477ca50d5dffbbe Successfully built cartopy pyshp Installing collected packages: pyshp, cartopy Successfully installed cartopy-0.19.0.post1 pyshp-2.1.3 . Also, because Colab is a cloud environment, you cannot directly assess files in your local environment. If you want to import files, there are two options: . Data Import . Option 1: Upload Files . Remarks: The file name in line pd.read_csv() need to be exactly the same as the name of the file you uploaded to not run into errors. . from google.colab import files # use the google.colab library uploaded = files.upload() # upload it, click choose file after running this cell and pick the file # read your file depends on the file format # Let&#39;s say you have a csv, then you can read them using Pandas (you will learn more about Pandas later) import io import pandas as pd df = pd.read_csv(io.BytesIO(uploaded[&#39;yourfile.csv&#39;])) df # now your data is stored in this data frame . Option 2: Access Files from Google Drive . One of the cons using upload option is that you can only upload one file at a time and it might take sometimes if your files are large. Let&#39;s say your colleague share you a file from Google Drive and you have a copy of it in the Drive. It is probably not the best way to download them to your computer and upload them in Colab again. . What you can do is to directly use files on the drive. . After running the following code, you still need to sign in to your Google Account, and click Allow to permit access to your own Google Drive. . from google.colab import drive drive.mount(&#39;/content/drive/&#39;) . Mounted at /content/drive/ . After successful connection, you can see &quot;Mounted at / content/drive/&quot; under the cell. . Then, you can check your directory. . !ls . drive sample_data . Where to search for your files depends on where do you store them. Let&#39;s say you stored your file inside Google Drive with a folder call yourfolder. You can check if the files are there by: . . Remark: Be carefule there is no space between My and Drive . print(os.popen(&#39;ls /content/drive/MyDrive/yourfolder&#39;).read()) . Your files should appear under the cell after run. . Then you can open your file using the path. You can specify your path in a raw string r&quot;path&quot;. . Then you can open them using different methods depending on the data format. The following example is a Geotiff file and it can be opened using gdal (You do not need to know much about it for now). . path = r&quot;/content/drive/MyDrive/yourfolder/boundary.tif&quot; # import library import gdal # open file ds = gdal.Open(path, gdal.GA_ReadOnly) . # import library import pandas as pd # define your path path = r&quot;/content/drive/MyDrive/yourfolder/city.csv&quot; # open file df = pd.read_csv(path) df # now your data is stored in this data frame . Data Export . It is basically very similar when you need to output a file. . Option: Directly Download Files . Remarks: The file name in the second and third line need to be exactly the same to not run into errors. . from google.colab import files # import library; only need to be done once for the whole notebook df.to_csv(&#39;temple_location.csv&#39;, encoding=&#39;utf_8_sig&#39;, index=False) # suppose df is the dataframe you want to export files.download(&#39;temple_location.csv&#39;) # run this code and the file will be directly downloaded . What you can also do it to run only: . from google.colab import files # import library; only need to be done once for the whole notebook df.to_csv(&#39;temple_location.csv&#39;, encoding=&#39;utf_8_sig&#39;, index=False) # suppose df is the dataframe you want to export # by default they will be in /content . and then click the bar on the left side with the folder icon (Files). Then you can also search for your files in the directory and click on the three dots and then click download. . It is generally recommanded to modify a file already existed in the Google Drive but not to create new files in Google Drive. . . Previous Lesson: Python Research Q&amp;A Basics . Next Lesson: Python Introduction Basics . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: December 2021 . . . . References: . https://colab.research.google.com/?utm_source=scs-index .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/level-1/chapter-1/jupyter/colab/2020/01/30/JupyterNotebook_Colab_Basics.html",
            "relUrl": "/level-1/chapter-1/jupyter/colab/2020/01/30/JupyterNotebook_Colab_Basics.html",
            "date": " • Jan 30, 2020"
        }
        
    
  
    
        ,"post9": {
            "title": "Introduction to Python Programming (Example from 孟浩然诗全集)",
            "content": "Presumptions: . . Here the examples used is Chinese texts from this link. . List . The following is a review of Python basics with presumptions of knowledge in w3school from Python intro to Python Arrays. The following is the a subset of titles from 孟浩然诗全集 卷一百五十九. . String &quot;&quot; is used to save the titles in variables. Pay attention that in Python capital letters and spacing matters. So for example, &quot;CHINA&quot; is not equal to &quot;China&quot;. True and False in Python is called boolean. It is a way to express binary result. . &quot;China&quot; == &quot;China&quot; # == means &quot;is it equal to?&quot; (the opposite is !=) . True . &quot;CHINA&quot; == &quot;China&quot; # This is the way how comments can be written. They will not impacts the code structure itself . False . first = &quot;从张丞相游南纪城猎，戏赠裴迪张参军&quot; second = &quot;登江中孤屿，赠白云先生王迥&quot; third = &quot;晚春卧病寄张八&quot; fourth = &quot;秋登兰山寄张五&quot; fifth = &quot;入峡寄弟&quot; . We can also put them in a list, which is a method to store multiple items in a single variable. There are much more ways to store information that we can retrieve later but list is the most simple form. Also, all text without &quot;&quot; in Python will be understood as a variable and it might cause errors if it is not one. . Be careful, there are some key words that we cannot used to store variables as they are reserved. To understand more about key words: https://www.w3schools.com/python/python_ref_keywords.asp . list_ = [first, second, third, fourth, fifth] . Then we can print them out. . list_ . [&#39;从张丞相游南纪城猎，戏赠裴迪张参军&#39;, &#39;登江中孤屿，赠白云先生王迥&#39;, &#39;晚春卧病寄张八&#39;, &#39;秋登兰山寄张五&#39;, &#39;入峡寄弟&#39;] . Slicing and Basic Manipulation . Sometime we only wish to retrieve selected items. By slicing, we can easily access them. Python start from 0 so [0] always mean the first item. We can also use negetive values, in which the order counted in the reverse order. The last item indicated will be excluded from selection (eg. [0:2] means the 3rd item is excluded). . print(list_[0]) # first element only . 从张丞相游南纪城猎，戏赠裴迪张参军 . print(list_[0:2]) # first two elements only . [&#39;从张丞相游南纪城猎，戏赠裴迪张参军&#39;, &#39;登江中孤屿，赠白云先生王迥&#39;] . print(list_[-1]) # last item . 湖中旅泊，寄阎九司户防 . Using text (inside &quot;&quot;) some of the operation cannot be done as using numbers (eg. division). However, there are multiple ways we can manipulate them. . . For example, we can add them togehter. . add = list_[-1] + &quot;,&quot; + list_[-1] add . &#39;入峡寄弟,入峡寄弟&#39; . We can subtract text (in an indirect way). . add.replace(&quot;,入峡寄弟&quot;,&quot;&quot;) # replace &quot;,入峡寄弟&quot; with nothing &quot;&quot; . &#39;入峡寄弟&#39; . We can also repeat them. . list_[-1] * 10 # * ten times . &#39;入峡寄弟入峡寄弟入峡寄弟入峡寄弟入峡寄弟入峡寄弟入峡寄弟入峡寄弟入峡寄弟入峡寄弟&#39; . We can also insert more items into the list. Let&#39;s put the 6th title into position 5 (Python start from 0). . list_.insert(5, &#39;湖中旅泊，寄阎九司户防&#39;) list_ . [&#39;从张丞相游南纪城猎，戏赠裴迪张参军&#39;, &#39;登江中孤屿，赠白云先生王迥&#39;, &#39;晚春卧病寄张八&#39;, &#39;秋登兰山寄张五&#39;, &#39;入峡寄弟&#39;, &#39;湖中旅泊，寄阎九司户防&#39;] . ## Numpy Array | . We can also put them in numpy array, which make many manipulation easier and faster, but first we need to import the library. It is applied to all functionalities not included in the base library. . After import the numpy library, it is imported as np and later when we need to call a function from the library, eg. min(), we can type np.min(). The item we put in () is called arguments. They are the inputs to compute the outputs. When we use functions, we have to be careful what arguments are needed (sometimes they are compulsory, sometimes they are not necessary, sometimes they are optional but there will be always a default option). . import numpy as np # import library. When we write real code, all libraries will typically be imported all together at the beginning . arr = np.array(list_) arr . array([&#39;从张丞相游南纪城猎，戏赠裴迪张参军&#39;, &#39;登江中孤屿，赠白云先生王迥&#39;, &#39;晚春卧病寄张八&#39;, &#39;秋登兰山寄张五&#39;, &#39;入峡寄弟&#39;], dtype=&#39;&lt;U17&#39;) . Do you see dtype=&#39;&lt;U17&#39;? It means datatype of the elements in the Numpy array. The U indicates that the elements are Unicode strings; Unicode is the standard Python uses to represent strings. . . In fact, it is important when we write code because if the action can be performed always depends on data types. To better understand data type: https://realpython.com/python-data-types/ . . ## Data Type | . If we want to check the data type of any objects, we can use type(). . type(100) # integer . int . type(&quot;list_&quot;) # string . str . type(list_) # list . list . type(np.array(list_)) # array . numpy.ndarray . Other Operations using Numpy Array . We can manipulate the text, for example, by getting the title with the most characters. . sort_arr = sorted(list_,key=len,reverse=False) # first we sort them by length (key = len), default in ascending order sort_arr . [&#39;入峡寄弟&#39;, &#39;晚春卧病寄张八&#39;, &#39;秋登兰山寄张五&#39;, &#39;湖中旅泊，寄阎九司户防&#39;, &#39;登江中孤屿，赠白云先生王迥&#39;, &#39;从张丞相游南纪城猎，戏赠裴迪张参军&#39;] . sort_arr[-1] . &#39;从张丞相游南纪城猎，戏赠裴迪张参军&#39; . We can for example count the number of titles using len(). . len(arr) . 5 . We can also put condition into array. For example, let&#39;s get item with over 5 characters. . # To review list comprehension: https://www.w3schools.com/python/python_lists_comprehension.asp arr_len = [len(i) for i in arr] arr_len . [17, 13, 7, 7, 4] . arr_len = np.array(arr_len) . Get arr with arr_len in the correponding position larger than 5. . To better understand the basic operators: https://www.tutorialspoint.com/python/python_basic_operators.htm . arr[arr_len &gt; 5] # slicing with conditions . array([&#39;从张丞相游南纪城猎，戏赠裴迪张参军&#39;, &#39;登江中孤屿，赠白云先生王迥&#39;, &#39;晚春卧病寄张八&#39;, &#39;秋登兰山寄张五&#39;, &#39;湖中旅泊，寄阎九司户防&#39;], dtype=&#39;&lt;U17&#39;) . Let&#39;s look at the minimum length of titles. . np.min(arr_len) . 4 . Or maximum. . np.max(arr_len) . 17 . Basic Plotting . We can also do some basic plotting using matplotlib. But we first need to import the library. . Understanding more about matplotlib: https://www.youtube.com/watch?v=qErBw-R2Ybk . ### Histogram | . import matplotlib.pyplot as plt # Histogram plt.hist(arr_len, bins=[2, 5, 10, 20], width=1) . (array([1., 2., 3.]), array([ 2, 5, 10, 20]), &lt;a list of 3 Patch objects&gt;) . It might not be helpful using little titles, but the principle is the same if we have thousands of items. . It can be demonstrated by creating some random numbers. . lengths = np.arange(0,30) lengths . array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]) . import random # choose 1000 samples times another 1000 samples list2_ = np.array(random.choices(lengths, k=1000))*np.array(random.choices(lengths, k=1000)) list2_ . import matplotlib.pyplot as plt plt.hist(list2_) . (array([347., 182., 129., 89., 78., 60., 42., 43., 17., 13.]), array([ 0. , 84.1, 168.2, 252.3, 336.4, 420.5, 504.6, 588.7, 672.8, 756.9, 841. ]), &lt;a list of 10 Patch objects&gt;) . ### Bar Chart | . We can improve the layout of the plot, such as adding xlabel, ylabel, a title, and change colors and so on. . plt.figure(figsize=(12,5)) # define the size of the plot plt.hist(list2_, color=&quot;green&quot;, orientation=&#39;horizontal&#39;) # color is an argument for color, this time we make it horizontal plt.grid(color=&#39;r&#39;, linestyle=&#39;--&#39;, linewidth=0.25, alpha=0.8) # add grid lines plt.ylabel(&quot;Numbers&quot;) plt.xlabel(&quot;Frequency&quot;) plt.title(&quot;Title&quot;, fontsize=18) . Text(0.5, 1.0, &#39;Title&#39;) . There are also many more different types for plotting. For example: . plt.bar([1,2,3,4,5], arr_len, width=0.5) plt.xlabel(&quot;ID&quot;) plt.ylabel(&quot;Lengths&quot;) . Text(0, 0.5, &#39;Lengths&#39;) . ### Line Chart | . Year = [1920,1930,1940,1950,1960,1970,1980,1990,2000,2010] Rate = [9.8,12,8,7.2,6.9,7,6.5,6.2,5.5,6.3] plt.plot(Year, Rate, color=&quot;red&quot;) plt.xlabel(&quot;Year&quot;) plt.ylabel(&quot;Rate&quot;) plt.grid(alpha=0.5) # alpha means transparency (0 to 1), the higher, the more visible . ### Table | . fig, ax = plt.subplots(figsize=(20,6)) # Hide axes ax.xaxis.set_visible(False) ax.yaxis.set_visible(False) ax.axis(&#39;tight&#39;) ax.axis(&#39;off&#39;) # Table data = np.random.random((5,3)) label=(&quot;1997&quot;, &quot;1998&quot;, &quot;1999&quot;) ax.table(cellText=data,colLabels=label,loc=&#39;center&#39;) . &lt;matplotlib.table.Table at 0x7f72c6afccd0&gt; . . Previous Lesson: JupyterNotebook Colab Basics . Next Lesson: Coding Practice Basics . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: December 2021 .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/programming/level-1/chapter-1/2020/01/29/Python_Introduction_Basics.html",
            "relUrl": "/programming/level-1/chapter-1/2020/01/29/Python_Introduction_Basics.html",
            "date": " • Jan 29, 2020"
        }
        
    
  
    
        ,"post10": {
            "title": "Good Coding Practice 🖋️",
            "content": ". . Background . Although programming is probably not your primary profession, it is always nice to have good coding practice to avoid unnecessary mistakes and misunderstandings in your projects. Some of the practices are more relevant for professional programmers, but here we mention the more relevant one for users who mostly code for fixed-term research projects. . . Presumption: Not applicable . . . 1) Documentation . RECORD WHAT YOU HAVE DONE &#128195; . Documentation is important. Although you might be really sure what you are doing when you code, most of the time it is not anymore the case when you wake up another morning, after busy time working on other projects or after a nice family trip. Do not need to mentioned if you are looking at your own code from last year. Do always document them, either by writing a comment with #, &quot;&quot;&quot; &quot;&quot;&quot;, or use a Jupyter Notebook and add more texts! . And sometimes you might have a project together with your colleagues, and they also need to understand what you are doing. Or if you are always working alone, then one day you colleagues want to get some insights from the code you wrote. You are not gonna show them and explain everything to them. . So make use of comments! When we write comments, we do not write what is done, we write what is the purpose. For example, if you create a new dataframe with two columns from the old dataframe, it is better to write &quot;extract coordinates and name from historical sites&quot; than &quot;create new dataframe&quot;, bacause the later comment do not give enough context and new information to the readers. . 2) Consistency . KEEP THINGS EASY TO REMEMBER &#129504; . You might not realize it but consistency fits your brain that always search for patterns! If you write your code in a consistent way, it can save you a lot of time running into unnecessary mistakes. . For example, if you name your five dataframes as . dataframe1 | dataframe2 | DataFrame3 | Dataframe4 | Dataframe_5 | . You might forget how did you name your dataframe later, and write dataframe3, or Dataframe_4, which all will run into errors. Consistency applies particularly to capital letters because we have learnt Python is case-sensitive. . You might think you can check it out everytime but it is not handy if you have tens of those variables. It is better that you name them in a consistent way from the first place. . Like: . df1 | df2 | df3 | df4 | df5 | . It also apply when you are writing code instead of naming variable. Because you always have multiple ways to get things done. Stick with the way that is simple and straight-forward! . For example, you have data from three years: . df_2018 = [9.8, 12.6, 15.8] | df_2019 = [5.6, 17.6, 25.1] | df_2020 = np.array([6.5, 11.3, 13.5]) | . . While df_2018 and df_2019 are lists, df_2020 is a Numpy array. Although both data types will work, they are different types and you might not remember it later, and run into errors because you thought the operations that works for df_2018 will also works for df_2020. . So stay consistent! . 3) Naming . KEEP THINGS CLEAN . Also it is important how you name the objects. If you have one dataframe for China, one for Korea and one for Japan. You want to name them in a more informative way, not . df1 | df2 | df3 | . but . df_china | df_japan | df_korea | . . There are different conventions too you would follow, particularly when it comes to combining words. Because Python do not support spaces in variable, you cannot name a data frame &quot;South Korea Data Frame&quot;, but the letters need to be combined in some ways. . . &#128043; Camel Case . Camel case combines words by capitalizing all words following the first word and removing the space, as follows: . Raw: user login count . Camel Case: userLoginCount . . &#128104; Pascal Case . Pascal case combines words by capitalizing all words (even the first word) and removing the space, as follows: . Raw: user login count . Pascal Case: UserLoginCount . . &#128013; Snake Case . Snake case combines words by replacing each space with an underscore (_) and, in the all caps version, all letters are capitalized, as follows: . Raw: user login count . Snake Case: user_login_count . Snake Case (All Caps): USER_LOGIN_COUNT . . &#129369; Kebab Case . Kebab case combines words by replacing each space with a dash (-), as follows: . Raw: user login count . Kebab Case: user-login-count . . There is not the best way how to name your variable, either &quot;dateFrame&quot; or &quot;data-frame&quot;, the more important is that they are used in a consistent way. Also pay attention that abbreviations are recommanded to keep things short but not too much that all others cannot really understand. . 4) Correct Broken Code . GET THINGS FIXED &#128295; . Sometimes things do not work the way we want, they are called bugs. They might not come to your immediate concerns but mark them down and get them fixed as soon as possible. You might even forget in what ways it is broken if you do not fix them timely and it can get worse. . 5) Readability . KEEP THINGS CLEAN, CONCISE AND SIMPLE &#128007; . This is simple. If code does not work, throw them away and do not keep mess. . For example, instead of writing code like below: . urban_history = [&quot;Hong Kong Government Reports Online 1841-1942&quot;,&quot;Policing the Shanghai International Settlement, 1894-1945&quot;,&quot;Virtual Cities Project&quot;] social_history = [&quot;China Families&quot;] # Manchukuo = [&quot;Chinese Posters in Harvard-Yenching Manchukuo Collection&quot;] # try without first # urban_history.insert(social_history,2) (does not work) # # print(urban_history.append(social_history)) (does not work either) urban_history + social_history # this is fine . [&#39;Hong Kong Government Reports Online 1841-1942&#39;, &#39;Policing the Shanghai International Settlement, 1894-1945&#39;, &#39;Virtual Cities Project&#39;, &#39;China Families&#39;] . Keep your &quot;Working Table&quot; clean like this: . urban_history = [&quot;Hong Kong Government Reports Online 1841-1942&quot;,&quot;Policing the Shanghai International Settlement, 1894-1945&quot;,&quot;Virtual Cities Project&quot;] social_history = [&quot;China Families&quot;] # calculation urban_history + social_history . [&#39;Hong Kong Government Reports Online 1841-1942&#39;, &#39;Policing the Shanghai International Settlement, 1894-1945&#39;, &#39;Virtual Cities Project&#39;, &#39;China Families&#39;] . Clean code also mean that your code is readable. For example, try to avoid many operations in one line. Although it also works, it make things hard to read. If there are any small typos, it is often not so easy to spot. . Like: . (NOT recommanded) . import pandas as pd (pd.DataFrame(data={&#39;Name&#39;: [&quot;Hong Kong Government Reports Online 1841-1942&quot;,&quot;Policing the Shanghai International Settlement, 1894-1945&quot;,&quot;Virtual Cities Project&quot;] , &#39;History&#39;: [&quot;urban&quot;,&quot;urban&quot;,&quot;urban&quot;]})).head(1) . Name History . 0 Hong Kong Government Reports Online 1841-1942 | urban | . import pandas as pd (pd.DataFrame(data={&#39;Name&#39;: [&quot;Hong Kong Government Reports Online 1841-1942&quot;,&quot;Policing the Shanghai International Settlement, 1894-1945&quot;,&quot;Virtual Cities Project&quot;] , &#39;History&#39;: [&quot;urban&quot;,&quot;urban&quot;,&quot;urban&quot;]]})).head(1) . File &#34;&lt;ipython-input-10-5139c64437bf&gt;&#34;, line 5 , &#39;History&#39;: [&#34;urban&#34;,&#34;urban&#34;,&#34;urban&#34;]]})).head(1) ^ SyntaxError: invalid syntax . (recommanded) . import pandas as pd # type of history hist_type = [&quot;urban&quot;,&quot;urban&quot;,&quot;urban&quot;] # set up datframe d = {&#39;Name&#39;: urban_history, &#39;History&#39;: hist_type} df = pd.DataFrame(data=d) df.head(1) . Name History . 0 Hong Kong Government Reports Online 1841-1942 | urban | . Happy Coding! . . (Quoted from The Zen of Python, by Tim Peters) . Beautiful is better than ugly. . Explicit is better than implicit. . Simple is better than complex. . Complex is better than complicated. . Readability counts. . If the implementation is hard to explain, it’s a bad idea. . . Previous Lesson: Python Introduction Basics . Next Lesson: Debugging and Understanding Errors Basics . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: December 2021 . . . . References: . https://data-flair.training/blogs/python-best-practices/ . https://betterprogramming.pub/string-case-styles-camel-pascal-snake-and-kebab-case-981407998841 .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/background/level-1/chapter-1/2020/01/28/Coding_Practice_Basics.html",
            "relUrl": "/background/level-1/chapter-1/2020/01/28/Coding_Practice_Basics.html",
            "date": " • Jan 28, 2020"
        }
        
    
  
    
        ,"post11": {
            "title": "Debugging and Understanding Errors 🐞",
            "content": ". . Background . A bug occurs when things do not work the way you want it to, even though Python only give what you ask for. It is because we have a different understandings compared to the programming languages. To resolve this, we need to find out the sources of errors and adjust our code accordingly. In this notebook you will learn different approach to resolve potential issues and some tips to avoid them from happening. . . Presumption: . https://www.w3schools.com/python/python_try_except.asp . https://www.tutorialsteacher.com/python/error-types-in-python . . . 1) Understand Error Messages . As you have seen from the link above, there are many different types of errors in Python which is meant to be helpful to tell user &quot;what is wrong?&quot;. But some errors might be more common than the others. Let&#39;s look at some common errors. . Let&#39;s say you want to add a second collection to the first one (collection). But instead of &quot;collection&quot;, you wrote &quot;Collection&quot;. . In this case Python tells you . NameError: name &#39;Collection&#39; is not defined . It is because Python is searching for &quot;Collection&quot; and cannot find one. . Name Error: Raised when a variable is not found in the local or global scope. . What you need to do it just correct the name. . collection = [&quot;Chinese Posters in Harvard-Yenching Manchukuo Collection&quot;] Collection + [&quot;Linked Archive of Asian Postcards&quot;] . NameError Traceback (most recent call last) &lt;ipython-input-3-cba7c442d3f4&gt; in &lt;module&gt;() 1 collection = [&#34;Chinese Posters in Harvard-Yenching Manchukuo Collection&#34;] 2 -&gt; 3 Collection + [&#34;Linked Archive of Asian Postcards&#34;] NameError: name &#39;Collection&#39; is not defined . Error occurs too when the library is not imported before use. . np.max([1,2]) . NameError Traceback (most recent call last) &lt;ipython-input-6-9be6f90ccf89&gt; in &lt;module&gt;() -&gt; 1 np.arange(1,5) NameError: name &#39;np&#39; is not defined . Or when you have one item in list while you are asking for the second one (Remember Python starts with 0). You get: . IndexError: list index out of range . Index Error: Raised when the index of a sequence is out of range. . Then you need to correct the index. . collection = [&quot;Chinese Posters in Harvard-Yenching Manchukuo Collection&quot;] collection[1] . IndexError Traceback (most recent call last) &lt;ipython-input-4-e10b1e230939&gt; in &lt;module&gt;() 1 collection = [&#34;Chinese Posters in Harvard-Yenching Manchukuo Collection&#34;] 2 -&gt; 3 collection[1] IndexError: list index out of range . There is also Type Error: Raised when a function or operation is applied to an object of an incorrect type. . It occurs because np.max() looks for a number and we input a string. . import numpy as np np.max([3]) # this works . 3 . import numpy as np np.max([collection]) . TypeError Traceback (most recent call last) &lt;ipython-input-11-9da63d4b2b0e&gt; in &lt;module&gt;() 1 import numpy as np -&gt; 2 np.max([collection]) &lt;__array_function__ internals&gt; in amax(*args, **kwargs) /usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py in amax(a, axis, out, keepdims, initial, where) 2704 &#34;&#34;&#34; 2705 return _wrapreduction(a, np.maximum, &#39;max&#39;, axis, None, out, -&gt; 2706 keepdims=keepdims, initial=initial, where=where) 2707 2708 /usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py in _wrapreduction(obj, ufunc, method, axis, dtype, out, **kwargs) 85 return reduction(axis=axis, out=out, **passkwargs) 86 &gt; 87 return ufunc.reduce(obj, axis, dtype, out, **passkwargs) 88 89 TypeError: cannot perform reduce with flexible type . Another error that is really common is that when you type something grammatically wrong in the Python sense. . Syntax Error: Raised by the parser when a syntax error is encountered. . collection = [&quot;Chinese Posters in Harvard-Yenching Manchukuo Collection&quot;] collection[0) # it should be [0], not[0) . File &#34;&lt;ipython-input-18-011172c21475&gt;&#34;, line 3 collection[0) ^ SyntaxError: invalid syntax . 2) Spot the Sources of Errors . In order to make errors easier to spot, it is always a good practice if you run only a small chunk of code in a time. For example, you call separate a long chunk of code into different cells. . Every cell can be used for one main action, for example: . . . . . Another way to spot errors in code is that try to reduce the code you have. For example: . Let&#39;s say you want to find out the length of the first advertisement in the list (商務印書館發行書目介紹), and you built a function for it. But instead of 11 characters, you get 2. . Although there is no problems running this code, as it is not giving you what you want, it is also a bug. . What you can do is to reduce the code and to see if things work the way you want. . ad = [&quot;商務印書館發行書目介紹&quot;,&quot;女界寶、非洲樹皮丸、助肺呼吸香膠、家普魚肝油、清血解毒海波藥、納佛補天汁、良丹(五洲大藥房)&quot;] import re # this you will learn in the notebook web scrapping so you do not need to understand everything for now def number_of_character(text): list_ = list(text) # list() is used to split words into a list of characters length = len(list_) # len() is to check the length return length number_of_character(ad) . 2 . Let&#39;s check the first step: Can we use list to split the characters as we want? . list(ad) . [&#39;商務印書館發行書目介紹&#39;, &#39;女界寶、非洲樹皮丸、助肺呼吸香膠、家普魚肝油、清血解毒海波藥、納佛補天汁、良丹(五洲大藥房)&#39;] . And we realize, we want to split 商務印書館發行書目介紹, but this is not done! . list(&quot;advertisement&quot;) # this is what we want, to split characters . [&#39;a&#39;, &#39;d&#39;, &#39;v&#39;, &#39;e&#39;, &#39;r&#39;, &#39;t&#39;, &#39;i&#39;, &#39;s&#39;, &#39;e&#39;, &#39;m&#39;, &#39;e&#39;, &#39;n&#39;, &#39;t&#39;] . And then we might find out, it only work if we use ad[0] instead. . list(ad[0]) . [&#39;商&#39;, &#39;務&#39;, &#39;印&#39;, &#39;書&#39;, &#39;館&#39;, &#39;發&#39;, &#39;行&#39;, &#39;書&#39;, &#39;目&#39;, &#39;介&#39;, &#39;紹&#39;] . ad = [&quot;商務印書館發行書目介紹&quot;,&quot;女界寶、非洲樹皮丸、助肺呼吸香膠、家普魚肝油、清血解毒海波藥、納佛補天汁、良丹(五洲大藥房)&quot;] import re # this you will learn in the notebook web scrapping so you do not need to understand everything for now def number_of_character(text): list_ = list(text) length = len(list_) return length number_of_character(ad[0]) . 11 . 3) Google and stackoverflow . Sometimes errors are not so clear to you. What you can do is to copy the errors and Google them. Stackoverflow is also another website that can be really helpful. . collection = [&quot;Chinese Posters in Harvard-Yenching Manchukuo Collection&quot;, &quot;Linked Archive of Asian Postcards&quot;] typ = [1,0] collection[typ] . TypeError Traceback (most recent call last) &lt;ipython-input-13-9eca3a76ef67&gt; in &lt;module&gt;() 2 typ = [1,0] 3 -&gt; 4 collection[typ] TypeError: list indices must be integers or slices, not list . Then you might find out what you need to select collection item from typ is to use Numpy array instead of list. . collection = np.array([&quot;Chinese Posters in Harvard-Yenching Manchukuo Collection&quot;, &quot;Linked Archive of Asian Postcards&quot;]) typ = np.array([1,0]) collection[typ] . array([&#39;Linked Archive of Asian Postcards&#39;, &#39;Chinese Posters in Harvard-Yenching Manchukuo Collection&#39;], dtype=&#39;&lt;U56&#39;) . 4) Use Try and Except . In order to avoid errors, what we can also do is to use try and except. It means asking Python to try something out, if it does not work, then do Plan B instead of giving you errors. . Be careful that this method only appy if the errors come from unexpected outliners in inputs. It will not give you any meaningful results if the errors lie in your code itself. . . It works as follow: . try: . (do plan a) # &lt;- indented block . except: . (do plan b) # &lt;- indented block . try: print(1+1) except: print(0) . 2 . . For example, the same function work well for the first and second item, but there is a typo in the third item, so that it is not a string, but an integer. . In this case, the function will not work as it expects a string. . collection = [&quot;Chinese Posters in Harvard-Yenching Manchukuo Collection&quot;, &quot;Linked Archive of Asian Postcards&quot;, 4] . def number_of_character(text): list_ = list(text) length = len(list_) return length number_of_character(collection[2]) . TypeError Traceback (most recent call last) &lt;ipython-input-50-b4200bdffa93&gt; in &lt;module&gt;() 4 return length 5 -&gt; 6 number_of_character(collection[2]) &lt;ipython-input-50-b4200bdffa93&gt; in number_of_character(text) 1 def number_of_character(text): -&gt; 2 list_ = list(text) 3 length = len(list_) 4 return length 5 TypeError: &#39;int&#39; object is not iterable . What we can do is to set up a Plan B: . If the words cannot be split, then use an empty list ([]). . . OUR PLAN B . except: . list_ = [] . def number_of_character(text): try: list_ = list(text) except: list_ = [] length = len(list_) return length number_of_character(collection[2]) . 0 . Now, we do not get the same error anymore. It is particularly useful when we are automating the task: because if we want going through thousands of documents, we do not want the code to crash because of one little typo. . 5) Check Documentation . If the errors come from your code itself, the easiest way to inspect the problems is to check the documentation of the function you used. If you are using Jupyter Notebook, you can always highlight the function you typed and the documentation of this function will appear, illustrating what inputs are expected. . You can also choose to directly Google the function and check the examples. For exmaple, if the following error occurs, by searching the reverse function &quot;python reverse()&quot; we can see from the documentation that the list is expected before the function ad(), not inside the (). . reverse(ad) ad . NameError Traceback (most recent call last) &lt;ipython-input-20-e88da2471207&gt; in &lt;module&gt;() 1 # error -&gt; 2 reverse(ad) 3 ad NameError: name &#39;reverse&#39; is not defined . ad.reverse() ad . [&#39;女界寶、非洲樹皮丸、助肺呼吸香膠、家普魚肝油、清血解毒海波藥、納佛補天汁、良丹(五洲大藥房)&#39;, &#39;商務印書館發行書目介紹&#39;] . . Previous Lesson: Coding Practice Basics . Next Lesson: Functions and Loops Basics . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: December 2021 . . . . References: . https://www.tutorialsteacher.com/python/error-types-in-python .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/level-1/chapter-1/background/2020/01/27/Debugging_and_Understanding_Errors_Basics.html",
            "relUrl": "/level-1/chapter-1/background/2020/01/27/Debugging_and_Understanding_Errors_Basics.html",
            "date": " • Jan 27, 2020"
        }
        
    
  
    
        ,"post12": {
            "title": "Functions and Loops",
            "content": ". . For a larger chunk of text analysis, the workflow might get longer and longer which can be unhandy and prone to mistakes. Both functions and loops are ways to &quot;ask for repeated computation&quot;, either by looping through what you have or refering back to code you already wrote (the function). . This notebook aims to introduce users how to use functions and loops in Python using basic text exmaple from the humanity discipline. It aims to provide users basic skills to automate small chunks of text analysis using text resources. . . Presumption: . Functions . Loops . Enumerate . . It is also recommanded that the user has some basic understandings already with Python. . . . ## Functions | . In Python, a function is a group of related statements that performs a specific task. . Functions break our tasks into smaller chunks and make it more manageable. Furthermore, it avoids repetition and makes the code reusable. It is very helful when the workflow (task) need to be repeated done (Get information from a long list of document or webpages) so the user do not need to specify everything for multiple times to execute the task. It is also less prone to mistakes as users do not need to code everytime. . A function is started with the keyword def. Once the function is defined, it can be called by typing the function name with appropriate parameters. . . Remark: . Both # and &quot;&quot;&quot; &quot;&quot;&quot; in the code are comments and will not run in Python. . . Example of a function: . import datetime # define funciton def getTime(n): # name and input &quot;&quot;&quot; This function acquire future days from now &quot;&quot;&quot; day = datetime.datetime.now() + datetime.timedelta(days=n) # action return str(day) # output # call function getTime(1) . &#39;2021-12-10 20:06:05.499284&#39; . &#23142;&#22899;&#38620;&#35468;&#24291;&#21578; (Advertisements from Chinese Womens Magazine) . This is the subset of the advertisements published in 婦女雜誌1915年 第01期. . Let&#39;s say we want to know if the advertistment is published form a 公司. . ad = [&quot;商務印書館發行書目介紹&quot;,&quot;女界寶、非洲樹皮丸、助肺呼吸香膠、家普魚肝油、清血解毒海波藥、納佛補天汁、良丹(五洲大藥房)&quot;,&quot;泰豐罐頭食品有限公司製造廠攝影&quot;,&quot;武進莊苣史女士菊花寒菜寫生&quot;,&quot;中華眼鏡公司&quot;,&quot;中將湯(東亞公司經理批發)&quot;] . import re # this you will learn in the regular expression notebook so you do not need to understand everything for now def ad_check(text): # but you need to know the function start with def, the name of the function, and a () with/ without argument(s) inside. pattern = re.compile(r&#39;公司&#39;) # inside the function you need to indent every line (with a tab) match = any(pattern.findall(text)) # you somehow get to the result (desired output) return match # and you return them (typically in a variable) . Now we can apply the function using our ad list. We can only pass a string in the function so we need to slice the item. For example, we can check on the first advertisement in list. . ad_check(ad[0]) . False . It returns False, a boolean meaning the word &quot;公司&quot; cannot be found. Now we check on the third item. . ad_check(ad[2]) . True . True is returned, meaning the keyword is found. So now we do not need to type the whole function everytime we want to check for an ad. . . ## Loops | . In fact, we can even automate all ads using a loop. A loop can be very simple, but can get complicated if multiple elements are looped in parallel or when it is nested (loop inside another loop). . Here we use a simple for loop: it is started with a &quot;for (something) in (something):&quot;, and followed by the next line(s) (all operations needed). All lines under the loop needed to be indented. . It basically tells Python: . . For the item (i) in my list (ad), . apply the function using input item (i) . and print the result before the next round (item) . for i in ad: # i is the item you name, ad is our list print(ad_check(i)) # action . False False True False True True . Sometime when we loop, we do not want to loop using the item itself, but the index of our item (For example, here let&#39;s say we want to print the index of the company found). Then we can do it in the following way: . len(ad) # first we found the len of our list . 6 . np.arange(len(ad)) # then we generate a sequence with the same length . array([0, 1, 2, 3, 4, 5]) . This is then the index we loop through instead of the item. . . Remark: . ad_check(ad[i]) is the same as ad_check(ad[i]) == True but the first way is more efficient to run in Python. . (ad_check(ad[i])) == (ad_check(ad[i]) == True) . True . for i in np.arange(len(ad)): # loop tho index if ad_check(ad[i]): # provide a condition: only print when it is true print(i,&quot;. &quot;,ad[i]) # print the index and the item . 2 . 泰豐罐頭食品有限公司製造廠攝影 4 . 中華眼鏡公司 5 . 中將湯(東亞公司經理批發) . Nonetheless, print the results is not very helpful because it is not stored in a variable and we cannot recall them. A helpful way is to stored them in another list. . Before we try to store them into our list, we need to first define it, as an empty list. . check_list = [] # define our output list for i in ad: # for loop again check_list.append(ad_check(i)) # now we use append (adding element at the end of the list) to put our result every round . check_list . [False, False, True, False, True, True] . Now we know the keyword is found in 3rd, 5th, 6th ads. We can print out the company ads. This can be better done using numpy array. so we will first convert both lists to arrays. . import numpy as np # always need to import library first ad = np.array(ad) # convert using np.array() check_list = np.array(check_list) ad[check_list] # slice ad using checklist, it only works when the check_list consists boolean (True and False, or 1 and 0) . array([&#39;泰豐罐頭食品有限公司製造廠攝影&#39;, &#39;中華眼鏡公司&#39;, &#39;中將湯(東亞公司經理批發)&#39;], dtype=&#39;&lt;U46&#39;) . We also need to be careful that looping is considered an inefficient way to get things done in Python, so if we can get the job done without loop, then it is better we do it without. . . ## Enumerate | . Sometimes, we do not only want to loop through the items, but also the indices of the item so we want do some further operations. In the above example we use a loop of index to print all the items with &quot;公司&quot;. . 2 . 泰豐罐頭食品有限公司製造廠攝影 4 . 中華眼鏡公司 5 . 中將湯(東亞公司經理批發) . However, we can use enumerate() instead which is a more efficient approach. It provides us two numbers: the first one is index starting from 0, another one is the item itself. . for count, value in enumerate(ad): print(count, value) . 0 商務印書館發行書目介紹 1 女界寶、非洲樹皮丸、助肺呼吸香膠、家普魚肝油、清血解毒海波藥、納佛補天汁、良丹(五洲大藥房) 2 泰豐罐頭食品有限公司製造廠攝影 3 武進莊苣史女士菊花寒菜寫生 4 中華眼鏡公司 5 中將湯(東亞公司經理批發) . The following code give use exactly the same result as the above example: . In this case, both codes do not seem to make a difference, however, in other case, using enumerate() is much more efficient and allows use to write much shorter code. . for count, value in enumerate(ad): if ad_check(value): print(count, &#39;.&#39;, value) . 2 . 泰豐罐頭食品有限公司製造廠攝影 4 . 中華眼鏡公司 5 . 中將湯(東亞公司經理批發) . . Previous Lesson: Debugging and Understanding Errors Basics . Next Lesson: List Comprehension . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: December 2021 . . . . References: . https://mhdb.mh.sinica.edu.tw/fnzz/view.php?book=1501&amp;str=%E5%A9%A6%E5%A5%B3 .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/programming/chapter-1/level-1/2020/01/26/FunctionsNLoops_Basics.html",
            "relUrl": "/programming/chapter-1/level-1/2020/01/26/FunctionsNLoops_Basics.html",
            "date": " • Jan 26, 2020"
        }
        
    
  
    
        ,"post13": {
            "title": "List Comprehension",
            "content": ". Presumption: . List Comprehension . . Dictionary . Tuples . zip() . . Below we use a short list of local gazetteers from LoGaRT as our example. . gazetteer = [&quot;天下一統志(明)&quot;,&quot;大明一統志(明)&quot;,&quot;嘉善縣志(明)&quot;,&quot;雍大記南畿志(明)&quot;,&quot;上海縣志(明)&quot;,&quot;全遼志(明)&quot;,&quot;喬三石耀州志(明)&quot;,&quot;宣府鎮志(明)&quot;,&quot;雲南通志(明)&quot;,&quot;大明一統志輯錄(明)&quot;,&quot;雲中郡志(清)&quot;] . import re # this you will learn in the regular expression notebook so you do not need to understand everything for now def str_check(text): # but you need to know the function start with def, the name of the function, and a () with/ without argument(s) inside. pattern = re.compile(r&#39;明&#39;) # inside the function you need to indent every line (with a tab) match = any(pattern.findall(text)) # you somehow get to the result (desired output) return match # and you return them (typically in a variable) . Suppose we need all the local gazetteers from 明 only. What we can do is to build a function (there is another easier option using Pandas but now we stick with this function). And then we can print all results which fit the condition. . . The structure of list comprehension is: . [ ] &lt;- in a list &lt;- key components . (name1) for (name2) in &lt;- for and in are keywords, (name2) is the variable name to be assigned for the item in loop, (name1) is the output you want, which should be expressed in terms of (name2) . (list) &lt;- the variable which stores all the items or the list to be loop through . if (condition) &lt;- add a condition, this part is optional . . Remarks: (name1) and (name2) can be the same but do not need to be . [x for x in gazetteer if str_check(x)] # if ad_check(x) is the same as if ad_check(x) == True . [&#39;天下一統志(明)&#39;, &#39;大明一統志(明)&#39;, &#39;嘉善縣志(明)&#39;, &#39;雍大記南畿志(明)&#39;, &#39;上海縣志(明)&#39;, &#39;全遼志(明)&#39;, &#39;喬三石耀州志(明)&#39;, &#39;宣府鎮志(明)&#39;, &#39;雲南通志(明)&#39;, &#39;大明一統志輯錄(明)&#39;] . We can also save the list to another new list. . ming_gazetteer = [x for x in gazetteer if str_check(x)] ming_gazetteer . [&#39;天下一統志(明)&#39;, &#39;大明一統志(明)&#39;, &#39;嘉善縣志(明)&#39;, &#39;雍大記南畿志(明)&#39;, &#39;上海縣志(明)&#39;, &#39;全遼志(明)&#39;, &#39;喬三石耀州志(明)&#39;, &#39;宣府鎮志(明)&#39;, &#39;雲南通志(明)&#39;, &#39;大明一統志輯錄(明)&#39;] . We can also change the outputs: for example, instead of the item itself, we want to get the lengths of the strings which fit the same condition: . [len(x) for x in gazetteer if str_check(x)] . [8, 8, 7, 9, 7, 6, 9, 7, 7, 10] . [x for x in gazetteer if str_check(x)] . [&#39;天下一統志(明)&#39;, &#39;大明一統志(明)&#39;, &#39;嘉善縣志(明)&#39;, &#39;雍大記南畿志(明)&#39;, &#39;上海縣志(明)&#39;, &#39;全遼志(明)&#39;, &#39;喬三石耀州志(明)&#39;, &#39;宣府鎮志(明)&#39;, &#39;雲南通志(明)&#39;, &#39;大明一統志輯錄(明)&#39;] . We can also combine list comprehension with any functions from any library. For example, we want to get the piyin of the items in our list. We can use library pinyin for that. . ! pip install pinyin # install library import pinyin # import library . [pinyin.get(x, format=&quot;strip&quot;, delimiter=&quot; &quot;) for x in gazetteer] # get the pinyin for all items . [&#39;tian xia yi tong zhi ( ming )&#39;, &#39;da ming yi tong zhi ( ming )&#39;, &#39;jia shan xian zhi ( ming )&#39;, &#39;yong da ji nan ji zhi ( ming )&#39;, &#39;shang hai xian zhi ( ming )&#39;, &#39;quan liao zhi ( ming )&#39;, &#39;qiao san shi yao zhou zhi ( ming )&#39;, &#39;xuan fu zhen zhi ( ming )&#39;, &#39;yun nan tong zhi ( ming )&#39;, &#39;da ming yi tong zhi ji lu ( ming )&#39;, &#39;yun zhong jun zhi ( qing )&#39;] . [pinyin.get(x, format=&quot;strip&quot;, delimiter=&quot; &quot;) for x in gazetteer if str_check(x)] # get the pinyin for all items from ming . [&#39;tian xia yi tong zhi ( ming )&#39;, &#39;da ming yi tong zhi ( ming )&#39;, &#39;jia shan xian zhi ( ming )&#39;, &#39;yong da ji nan ji zhi ( ming )&#39;, &#39;shang hai xian zhi ( ming )&#39;, &#39;quan liao zhi ( ming )&#39;, &#39;qiao san shi yao zhou zhi ( ming )&#39;, &#39;xuan fu zhen zhi ( ming )&#39;, &#39;yun nan tong zhi ( ming )&#39;, &#39;da ming yi tong zhi ji lu ( ming )&#39;] . Apart from that, we can also combine the index using enumerate() (we have learnt it from the previous lesson). . Remember that enumerate() return two values as we need two names between the keywords &quot;for&quot; and &quot;in&quot;! . [print(index,pinyin.get(item, format=&quot;strip&quot;, delimiter=&quot; &quot;)) for index, item in enumerate(gazetteer)] # get the pinyin with indices for all items . 0 tian xia yi tong zhi ( ming ) 1 da ming yi tong zhi ( ming ) 2 jia shan xian zhi ( ming ) 3 yong da ji nan ji zhi ( ming ) 4 shang hai xian zhi ( ming ) 5 quan liao zhi ( ming ) 6 qiao san shi yao zhou zhi ( ming ) 7 xuan fu zhen zhi ( ming ) 8 yun nan tong zhi ( ming ) 9 da ming yi tong zhi ji lu ( ming ) 10 yun zhong jun zhi ( qing ) . [None, None, None, None, None, None, None, None, None, None, None] . [print(index,pinyin.get(item, format=&quot;strip&quot;, delimiter=&quot; &quot;)) for index, item in enumerate(gazetteer) if index in [1,3]] . 1 da ming yi tong zhi ( ming ) 3 yong da ji nan ji zhi ( ming ) . [None, None] . [print(index,pinyin.get(item, format=&quot;strip&quot;, delimiter=&quot; &quot;)) for index, item in enumerate(gazetteer) if index not in [0]] . 1 da ming yi tong zhi ( ming ) 2 jia shan xian zhi ( ming ) 3 yong da ji nan ji zhi ( ming ) 4 shang hai xian zhi ( ming ) 5 quan liao zhi ( ming ) 6 qiao san shi yao zhou zhi ( ming ) 7 xuan fu zhen zhi ( ming ) 8 yun nan tong zhi ( ming ) 9 da ming yi tong zhi ji lu ( ming ) 10 yun zhong jun zhi ( qing ) . [None, None, None, None, None, None, None, None, None, None] . There are numerous options what we can do using list comprehension. Another example demonsrating the functionality of list comprehension is word frequency count: searching for the keywords which appears in the top frequencies. . First, we join all the items to a single list and then split all Chinese character using list() after removing () using replace(). . string = &#39;&#39;.join(gazetteer) # join all items in list to a single string string = string.replace(&quot;(&quot;, &quot;&quot;).replace(&quot;)&quot;, &quot;&quot;) # replace &quot;(&quot; and &quot;)&quot; to nothing &quot;&quot; wordlist = list(string) # split all Chinese characters wordlist[:5] # print first 5 characters . [&#39;天&#39;, &#39;下&#39;, &#39;一&#39;, &#39;統&#39;, &#39;志&#39;] . Now we use list comprehension to count all characters. . wordfreq = [wordlist.count(w) for w in wordlist] # list comprehension to count all characters # print the single string print(&quot;String n&quot; + string +&quot; n&quot;) # n means new line # print a list of all characters print(&quot;List n&quot; + str(wordlist) + &quot; n&quot;) # print frequencies print(&quot;Frequencies n&quot; + str(wordfreq) + &quot; n&quot;) # print zip objects by combining characters and occurences print(&quot;Pairs n&quot; + str(list(zip(wordlist, wordfreq)))) . String 天下一統志明大明一統志明嘉善縣志明雍大記南畿志明上海縣志明全遼志明喬三石耀州志明宣府鎮志明雲南通志明大明一統志輯錄明雲中郡志清 List [&#39;天&#39;, &#39;下&#39;, &#39;一&#39;, &#39;統&#39;, &#39;志&#39;, &#39;明&#39;, &#39;大&#39;, &#39;明&#39;, &#39;一&#39;, &#39;統&#39;, &#39;志&#39;, &#39;明&#39;, &#39;嘉&#39;, &#39;善&#39;, &#39;縣&#39;, &#39;志&#39;, &#39;明&#39;, &#39;雍&#39;, &#39;大&#39;, &#39;記&#39;, &#39;南&#39;, &#39;畿&#39;, &#39;志&#39;, &#39;明&#39;, &#39;上&#39;, &#39;海&#39;, &#39;縣&#39;, &#39;志&#39;, &#39;明&#39;, &#39;全&#39;, &#39;遼&#39;, &#39;志&#39;, &#39;明&#39;, &#39;喬&#39;, &#39;三&#39;, &#39;石&#39;, &#39;耀&#39;, &#39;州&#39;, &#39;志&#39;, &#39;明&#39;, &#39;宣&#39;, &#39;府&#39;, &#39;鎮&#39;, &#39;志&#39;, &#39;明&#39;, &#39;雲&#39;, &#39;南&#39;, &#39;通&#39;, &#39;志&#39;, &#39;明&#39;, &#39;大&#39;, &#39;明&#39;, &#39;一&#39;, &#39;統&#39;, &#39;志&#39;, &#39;輯&#39;, &#39;錄&#39;, &#39;明&#39;, &#39;雲&#39;, &#39;中&#39;, &#39;郡&#39;, &#39;志&#39;, &#39;清&#39;] Frequencies [1, 1, 3, 3, 11, 12, 3, 12, 3, 3, 11, 12, 1, 1, 2, 11, 12, 1, 3, 1, 2, 1, 11, 12, 1, 1, 2, 11, 12, 1, 1, 11, 12, 1, 1, 1, 1, 1, 11, 12, 1, 1, 1, 11, 12, 2, 2, 1, 11, 12, 3, 12, 3, 3, 11, 1, 1, 12, 2, 1, 1, 11, 1] Pairs [(&#39;天&#39;, 1), (&#39;下&#39;, 1), (&#39;一&#39;, 3), (&#39;統&#39;, 3), (&#39;志&#39;, 11), (&#39;明&#39;, 12), (&#39;大&#39;, 3), (&#39;明&#39;, 12), (&#39;一&#39;, 3), (&#39;統&#39;, 3), (&#39;志&#39;, 11), (&#39;明&#39;, 12), (&#39;嘉&#39;, 1), (&#39;善&#39;, 1), (&#39;縣&#39;, 2), (&#39;志&#39;, 11), (&#39;明&#39;, 12), (&#39;雍&#39;, 1), (&#39;大&#39;, 3), (&#39;記&#39;, 1), (&#39;南&#39;, 2), (&#39;畿&#39;, 1), (&#39;志&#39;, 11), (&#39;明&#39;, 12), (&#39;上&#39;, 1), (&#39;海&#39;, 1), (&#39;縣&#39;, 2), (&#39;志&#39;, 11), (&#39;明&#39;, 12), (&#39;全&#39;, 1), (&#39;遼&#39;, 1), (&#39;志&#39;, 11), (&#39;明&#39;, 12), (&#39;喬&#39;, 1), (&#39;三&#39;, 1), (&#39;石&#39;, 1), (&#39;耀&#39;, 1), (&#39;州&#39;, 1), (&#39;志&#39;, 11), (&#39;明&#39;, 12), (&#39;宣&#39;, 1), (&#39;府&#39;, 1), (&#39;鎮&#39;, 1), (&#39;志&#39;, 11), (&#39;明&#39;, 12), (&#39;雲&#39;, 2), (&#39;南&#39;, 2), (&#39;通&#39;, 1), (&#39;志&#39;, 11), (&#39;明&#39;, 12), (&#39;大&#39;, 3), (&#39;明&#39;, 12), (&#39;一&#39;, 3), (&#39;統&#39;, 3), (&#39;志&#39;, 11), (&#39;輯&#39;, 1), (&#39;錄&#39;, 1), (&#39;明&#39;, 12), (&#39;雲&#39;, 2), (&#39;中&#39;, 1), (&#39;郡&#39;, 1), (&#39;志&#39;, 11), (&#39;清&#39;, 1)] . In order to produce more useful outputs to inspect the keywords, we can combine functions and list comprehensions to output a dictionary. Click here if you need to review how to build a function. . def wordListToFreqDict(wordlist): &quot;&quot;&quot; This function convert a word list to dictionary displaying frequencies of character occurences &quot;&quot;&quot; wordfreq = [wordlist.count(p) for p in wordlist] # same as what we did above return dict(list(zip(wordlist,wordfreq))) # return a dictionary of zip objects word_count = wordListToFreqDict(wordlist) . Let&#39;s look at our dictionary word_count. . word_count . {&#39;一&#39;: 3, &#39;三&#39;: 1, &#39;上&#39;: 1, &#39;下&#39;: 1, &#39;中&#39;: 1, &#39;全&#39;: 1, &#39;南&#39;: 2, &#39;善&#39;: 1, &#39;喬&#39;: 1, &#39;嘉&#39;: 1, &#39;大&#39;: 3, &#39;天&#39;: 1, &#39;宣&#39;: 1, &#39;州&#39;: 1, &#39;府&#39;: 1, &#39;志&#39;: 11, &#39;明&#39;: 12, &#39;海&#39;: 1, &#39;清&#39;: 1, &#39;畿&#39;: 1, &#39;石&#39;: 1, &#39;統&#39;: 3, &#39;縣&#39;: 2, &#39;耀&#39;: 1, &#39;記&#39;: 1, &#39;輯&#39;: 1, &#39;通&#39;: 1, &#39;遼&#39;: 1, &#39;郡&#39;: 1, &#39;錄&#39;: 1, &#39;鎮&#39;: 1, &#39;雍&#39;: 1, &#39;雲&#39;: 2} . However, as we can see, the data seems to be a bit messy. It would be much easier to read if we order the keywords by frequency. We can do this by building another small function to sort the values. . def sortFreqDict(freqdict): &quot;&quot;&quot; This function sort dictionary by keyword frequencies &quot;&quot;&quot; aux = [(freqdict[key], key) for key in freqdict] # convert dictionary back to a list of tuples aux.sort() # sort the values aux.reverse() # reverse the values so the items are in descending order return aux # return sorted list sortFreqDict(word_count)[:5] # apply our function and print the first 5 items in list . [(12, &#39;明&#39;), (11, &#39;志&#39;), (3, &#39;統&#39;), (3, &#39;大&#39;), (3, &#39;一&#39;)] . . Previous Lesson: Functions and Loops Basics . Next Lesson: Regular Expression . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: December 2021 . . . . References: . https://gist.github.com/acrymble/1065661 .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/chapter-1/level-1/programming/2020/01/25/List_Comprehension_Basics.html",
            "relUrl": "/chapter-1/level-1/programming/2020/01/25/List_Comprehension_Basics.html",
            "date": " • Jan 25, 2020"
        }
        
    
  
    
        ,"post14": {
            "title": "Pandas Numerical Operation",
            "content": "This tutorial is a follow-up from the last Pandas tutorial which introduce functions for working with text. Nonetheless, numerical operations in Pandas is also essential knowledge when it comes to statistics in the data. Here we use an example of UNESCO heritage sites to demonstrate how to work with numbers and datetime in Pandas. It will also cover some basic knowledge about plotting using Matplotlib and Pandas. . . Presumptions: Same as the previous notebook . . import io import pandas as pd import requests # read data url = &#39;https://examples.opendatasoft.com/explore/dataset/world-heritage-unesco-list/download/?format=csv&amp;timezone=Europe/Berlin&amp;lang=en&amp;use_labels_for_header=true&amp;csv_separator=%3B&#39; df = pd.read_csv(url, sep=&quot;;&quot;) . df.head(2) # head() is used for viewing the first few rows of data . Name (EN) Name (FR) Short description (EN) Short Description (FR) Justification (EN) Justification (FR) Date inscribed Danger list Longitude Latitude Area hectares Category Country (EN) Country (FR) Continent (EN) Continent (FR) Geographical coordinates . 0 Architectural, Residential and Cultural Comple... | Ensemble architectural, résidentiel et culture... | The Architectural, Residential and Cultural Co... | L’ensemble architectural, résidentiel et cultu... | Criterion (ii): The architectural, residential... | Critère (ii) : L’ensemble architectural, résid... | 2005-01-01 | NaN | 26.69139 | 53.22278 | 0.0 | Cultural | Belarus | Bélarus | Europe and North America | Europe et Amérique du nord | 53.22278,26.69139 | . 1 Rock Paintings of the Sierra de San Francisco | Peintures rupestres de la Sierra de San Francisco | From c. 100 B.C. to A.D. 1300, the Sierra de S... | Dans la réserve d&#39;El Vizcaíno, en Basse-Califo... | NaN | NaN | 1993-01-01 | NaN | -112.91611 | 27.65556 | 182600.0 | Cultural | Mexico | Mexique | Latin America and the Caribbean | Amérique latine et Caraïbes | 27.65556,-112.91611 | . df[&quot;Country (EN)&quot;] # selecting one column . 0 Belarus 1 Mexico 2 Romania 3 Italy 4 Belgium,France ... 1047 Bosnia and Herzegovina,Croatia,Serbia,Montenegro 1048 China 1049 United Kingdom of Great Britain and Northern I... 1050 Chad 1051 France Name: Country (EN), Length: 1052, dtype: object . By typing .values, we can convert one column in the Pandas dataframe to Numpy array. . country_arr = df[&quot;Country (EN)&quot;].values # to numpy country_arr . array([&#39;Belarus&#39;, &#39;Mexico&#39;, &#39;Romania&#39;, ..., &#39;United Kingdom of Great Britain and Northern Ireland&#39;, &#39;Chad&#39;, &#39;France&#39;], dtype=object) . import numpy as np unique_name = np.unique(country_arr) # the list of country. np.unique() return values only one time no matter how many times do they appear unique_name[:3] # check the first three countries only . array([&#39;Afghanistan&#39;, &#39;Albania&#39;, &#39;Algeria&#39;], dtype=object) . Data Inspection . We can inspect our data fame by filtering, querying, and subsetting. For example, we can check all the entries from China. Let&#39;s first filter the relevant columns (Name, Category and Country) from our data frame. . df.filter(items=[&quot;Name (EN)&quot;,&quot;Category&quot;,&quot;Country (EN)&quot;]) . Name (EN) Category Country (EN) . 0 Architectural, Residential and Cultural Comple... | Cultural | Belarus | . 1 Rock Paintings of the Sierra de San Francisco | Cultural | Mexico | . 2 Monastery of Horezu | Cultural | Romania | . 3 Mount Etna | Natural | Italy | . 4 Belfries of Belgium and France | Cultural | Belgium,France | . ... ... | ... | ... | . 1047 Stećci Medieval Tombstones Graveyards | Cultural | Bosnia and Herzegovina,Croatia,Serbia,Montenegro | . 1048 Jiuzhaigou Valley Scenic and Historic Interest... | Natural | China | . 1049 Blenheim Palace | Cultural | United Kingdom of Great Britain and Northern I... | . 1050 Lakes of Ounianga | Natural | Chad | . 1051 Mont-Saint-Michel and its Bay | Cultural | France | . 1052 rows × 3 columns . What we can also do is to query. For example, we can query heritages that are from China and belong to cultural category. Please remember all operations without assigning back to the dataframe itself is only temporary (except inplace = True). Using query(), we need to input a query string and we need to be careful that we need to use back ticks(`) to enclose column names with space, as well as to use single and double quoatation marks to avoid confusion. . For example, &quot;Country (EN)== &#39;China&#39; &amp; Category == &#39;Cultural&#39;&quot; will be okay but &quot;Country (EN)== &quot;China&quot; &amp; Category == &quot;Cultural&quot;&quot; will run into errors. . df.query(&quot;`Country (EN)` == &#39;China&#39; &amp; Category == &#39;Cultural&#39;&quot;) . Name (EN) Name (FR) Short description (EN) Short Description (FR) Justification (EN) Justification (FR) Date inscribed Danger list Longitude Latitude Area hectares Category Country (EN) Country (FR) Continent (EN) Continent (FR) Geographical coordinates . 32 Tusi Sites | Sites du tusi | Located in the mountainous areas of south-west... | Situé dans les régions montagneuses du sud-oue... | NaN | NaN | 2015-01-01 | NaN | 109.966944 | 28.998611 | 781.2800 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 28.9986111111,109.966944444 | . 38 The Great Wall | La Grande Muraille | In c. 220 B.C., under Qin Shi Huang, sections ... | Vers 220 av. J.-C., Qin Shin Huang entreprit d... | NaN | NaN | 1987-01-01 | NaN | 116.083330 | 40.416670 | 2151.5500 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 40.41667,116.08333 | . 68 Mausoleum of the First Qin Emperor | Mausolée du premier empereur Qin | No doubt thousands of statues still remain to ... | Sur ce site archéologique qui ne fut découvert... | NaN | NaN | 1987-01-01 | NaN | 109.100000 | 34.383333 | 0.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 34.38333333,109.1 | . 81 Site of Xanadu | Site de Xanadu | North of the Great Wall, the Site of Xanadu en... | Situé au nord de la Grande Muraille, ce site d... | NaN | NaN | 2012-01-01 | NaN | 116.185128 | 42.358000 | 25131.2700 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 42.358,116.185127778 | . 127 Temple and Cemetery of Confucius and the Kong ... | Temple et cimetière de Confucius et résidence ... | The temple, cemetery and family mansion of Con... | Le temple, le cimetière et la demeure de famil... | NaN | NaN | 1994-01-01 | NaN | 116.975000 | 35.611670 | 0.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 35.61167,116.975 | . 134 Fujian &lt;em&gt;Tulou&lt;/em&gt; | &lt;em&gt;Tulou&lt;/em&gt; du Fujian | Fujian Tulou is a property of 46 buildings con... | Le site des Tulou du Fujian, comprend 46 maiso... | NaN | NaN | 2008-01-01 | NaN | 117.685833 | 25.023056 | 152.6500 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 25.0230555556,117.685833333 | . 165 Dazu Rock Carvings | Sculptures rupestres de Dazu | The steep hillsides of the Dazu area contain a... | Les montagnes abruptes de la région de Dazu ab... | Criterion (i): The Dazu carvings represent the... | Critère (i) : De par leur grande qualité esthé... | 1999-01-01 | NaN | 105.705000 | 29.701110 | 20.4100 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 29.70111,105.705 | . 219 Lushan National Park | Parc national de Lushan | Mount Lushan, in Jiangxi, is one of the spirit... | Le site du mont Lushan, dans le Jiangxi, const... | The Committee decided to inscribe this propert... | Le Comité a décidé d&#39;inscrire ce bien sur la b... | 1996-01-01 | NaN | 115.866667 | 29.433333 | 0.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 29.43333333,115.8666667 | . 220 Imperial Tombs of the Ming and Qing Dynasties | Tombes impériales des dynasties Ming et Qing | It represents the addition of three Imperial T... | L’extension ajoute trois tombes impériales de ... | Criterion (i): The harmonious integration of r... | Critère (i) : l&#39;intégration harmonieuse d&#39;ense... | 2000-01-01 | NaN | 124.793889 | 41.707222 | 3434.9399 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 41.70722222,124.7938889 | . 449 Imperial Palaces of the Ming and Qing Dynastie... | Palais impériaux des dynasties Ming et Qing à ... | Seat of supreme power for over five centuries ... | Siège du pouvoir suprême pendant plus de cinq ... | Criterion (i): The Imperial Palaces represent ... | Critère (i) : Les Palais impériaux représenten... | 1987-01-01 | NaN | 123.446944 | 41.794167 | 12.9600 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 41.79416667,123.4469444 | . 457 Mountain Resort and its Outlying Temples, Chengde | Résidence de montagne et temples avoisinants à... | The Mountain Resort (the Qing dynasty&#39;s summer... | La résidence de montagne, palais d&#39;été de la d... | NaN | NaN | 1994-01-01 | NaN | 117.938330 | 40.986940 | 0.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 40.98694,117.93833 | . 459 West Lake Cultural Landscape of Hangzhou | Paysage culturel du lac de l’Ouest de Hangzhou | The West Lake Cultural Landscape of Hangzhou, ... | Le paysage inscrit a inspiré des poètes, artis... | NaN | NaN | 2011-01-01 | NaN | 120.140833 | 30.237500 | 3322.8800 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 30.2375,120.140833333 | . 545 Cultural Landscape of Honghe Hani Rice Terraces | Paysage culturel des rizières en terrasse des ... | The Cultural Landscape of Honghe Hani Rice Ter... | Ce site de 16 603 hectares est situé dans le s... | NaN | NaN | 2013-01-01 | NaN | 102.779981 | 23.093278 | 16603.2200 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 23.0932777778,102.779980556 | . 590 Ancient Building Complex in the Wudang Mountains | Ensemble de bâtiments anciens des montagnes de... | The palaces and temples which form the nucleus... | Les palais et temples qui constituent le noyau... | NaN | NaN | 1994-01-01 | NaN | 111.000000 | 32.466670 | 0.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 32.46667,111.0 | . 601 Historic Centre of Macao | Centre historique de Macao | Macao, a lucrative port of strategic importanc... | Macao, riche port marchand d’une grande import... | Criterion (ii): The strategic location of Maca... | Critère (ii) : L’emplacement stratégique de Ma... | 2005-01-01 | NaN | 113.536461 | 22.191292 | 16.1678 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 22.1912919444,113.536461111 | . 605 Yin Xu | Yin Xu | The archaeological site of Yin Xu, close to An... | Le site archéologique de Yin Xu, proche de la ... | NaN | NaN | 2006-01-01 | NaN | 114.313889 | 36.126667 | 414.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 36.1266666666,114.313888889 | . 628 Yungang Grottoes | Grottes de Yungang | The Yungang Grottoes, in Datong city, Shanxi P... | Les grottes de Yungang, à Datong, province du ... | Criterion (i): The assemblage of statuary of t... | Critère (i) : L’ensemble de la statuaire des g... | 2001-01-01 | NaN | 113.122220 | 40.109720 | 348.7500 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 40.10972,113.12222 | . 653 Peking Man Site at Zhoukoudian | Site de l&#39;homme de Pékin à Zhoukoudian | Scientific work at the site, which lies 42 km ... | À 42 km au sud-ouest de Pékin, le site, dont l... | NaN | NaN | 1987-01-01 | NaN | 115.916667 | 39.733333 | 480.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 39.73333333,115.9166667 | . 671 Historic Ensemble of the Potala Palace, Lhasa | Ensemble historique du Palais du Potala, Lhasa | The Potala Palace, winter palace of the Dalai ... | Le palais du Potala, palais d&#39;hiver du dalaï-l... | NaN | NaN | 1994-01-01 | NaN | 91.117170 | 29.657920 | 60.5000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 29.65792,91.11717 | . 739 Summer Palace, an Imperial Garden in Beijing | Palais d&#39;Été, Jardin impérial de Beijing | The Summer Palace in Beijing – first built in ... | Le palais d&#39;Été de Beijing, créé en 1750, détr... | Criterion i: The Summer Palace in Beijing is a... | Critère i : le Palais d&#39;Eté de Beijing est une... | 1998-01-01 | NaN | 116.141111 | 39.910556 | 297.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 39.91055556,116.1411111 | . 743 Mount Qingcheng and the Dujiangyan Irrigation ... | Mont Qingcheng et système d’irrigation de Duji... | Construction of the Dujiangyan irrigation syst... | La construction du système d&#39;irrigation de Duj... | Criterion (ii): The Dujiangyan Irrigation Syst... | Critère (ii) : Le système d’irrigation de Duji... | 2000-01-01 | NaN | 103.605280 | 31.001670 | 0.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 31.00167,103.60528 | . 746 Historic Monuments of Dengfeng in “The Centre ... | Monuments historiques de Dengfeng au « centre ... | Mount Songshang is considered to be the centra... | Songshang est considéré comme le mont sacré ce... | NaN | NaN | 2010-01-01 | NaN | 113.067719 | 34.458747 | 825.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 34.4587472222,113.067719444 | . 769 The Grand Canal | Le Grand Canal | The Grand Canal is a vast waterway system in t... | Ce vaste système de navigation intérieure au s... | NaN | NaN | 2014-01-01 | NaN | 112.468333 | 34.693889 | 20819.1100 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 34.6938888889,112.468333333 | . 772 Old Town of Lijiang | Vieille ville de Lijiang | The Old Town of Lijiang, which is perfectly ad... | La vieille ville de Lijiang, harmonieusement a... | The Committee decided to inscribe this site on... | Le Comité a décidé d’inscrire ce site sur la b... | 1997-01-01 | NaN | 100.233330 | 26.866670 | 145.6000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 26.86667,100.23333 | . 808 Kaiping Diaolou and Villages | Diaolou et villages de Kaiping | Kaiping Diaolou and Villages feature the Diaol... | Les diaolou, maisons fortifiées de village de ... | NaN | NaN | 2007-01-01 | NaN | 112.565861 | 22.285519 | 371.9480 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 22.2855194444,112.565861111 | . 839 Ancient Villages in Southern Anhui – Xidi and ... | Anciens villages du sud du Anhui – Xidi et Hon... | The two traditional villages of Xidi and Hongc... | Les deux villages traditionnels de Xidi et de ... | Criterion (iii): The villages of Xidi and Hong... | Critère (iii) : Les villages de Xidi et de Hon... | 2000-01-01 | NaN | 117.987500 | 29.904444 | 52.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 29.90444444,117.9875 | . 851 Zuojiang Huashan Rock Art Cultural Landscape | Paysage culturel de l’art rupestre de Zuojiang... | Located on the steep cliffs in the border regi... | Situés sur des falaises abruptes dans les régi... | NaN | NaN | 2016-01-01 | NaN | 107.023056 | 22.255556 | 6621.6000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 22.2555555556,107.023055556 | . 883 Classical Gardens of Suzhou | Jardins classiques de Suzhou | Classical Chinese garden design, which seeks t... | Le paysagisme classique chinois, qui cherche à... | The Committee decided to inscribe this propert... | Le Comité a décidé d&#39;inscrire ce bien sur la b... | 1997-01-01 | NaN | 120.450000 | 31.316667 | 11.9220 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 31.31666667,120.45 | . 903 Ancient City of Ping Yao | Vieille ville de Ping Yao | Ping Yao is an exceptionally well-preserved ex... | Ping Yao est un exemple exceptionnellement bie... | The Committee decided to inscribe this propert... | Le Comité a décidé d&#39;inscrire ce bien sur la b... | 1997-01-01 | NaN | 112.154440 | 37.201390 | 245.6200 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 37.20139,112.15444 | . 921 Longmen Grottoes | Grottes de Longmen | The grottoes and niches of Longmen contain the... | Les grottes et niches de Longmen abritent le p... | Criterion (i): The sculptures of the Longmen G... | Critère (i) : Les sculptures des grottes de Lo... | 2000-01-01 | NaN | 112.466667 | 34.466667 | 331.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 34.46666667,112.4666667 | . 930 Temple of Heaven: an Imperial Sacrificial Alta... | Temple du Ciel, autel sacrificiel impérial à B... | The Temple of Heaven, founded in the first hal... | Fondé dans la première moitié du XVe siècle, l... | Criterion i: The Temple of Heaven is a masterp... | Critère i : Le Temple du Ciel est un chef-d&#39;œu... | 1998-01-01 | NaN | 116.444722 | 39.845556 | 215.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 39.84555556,116.4447222 | . 971 Mount Wutai | Mont Wutai | With its five flat peaks, Mount Wutai is a sac... | Avec ses cinq plateaux, le Mont Wutai est une ... | NaN | NaN | 2009-01-01 | NaN | 113.563333 | 39.030556 | 18415.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 39.0305555556,113.563333333 | . 1008 Mogao Caves | Grottes de Mogao | Situated at a strategic point along the Silk R... | Situées en un point stratégique de la Route de... | NaN | NaN | 1987-01-01 | NaN | 94.816670 | 40.133330 | 0.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 40.13333,94.81667 | . 1010 Capital Cities and Tombs of the Ancient Kogury... | Capitales et tombes de l’ancien royaume de Kog... | The site includes archaeological remains of th... | Ce site comprend les vestiges archéologiques d... | Criterion (i): The tombs represent a masterpie... | Critère (i) : Les tombes représentent un chef ... | 2004-01-01 | NaN | 126.187222 | 41.156944 | 4164.8599 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 41.15694444,126.1872222 | . To avoid those confusions, another option is to subset data frame without query string. We can do it simply using []. However, we also need to make use of () to group our query into orders. . For example: . df[&quot;Country (EN)&quot;] == &quot;China&quot; &amp; df[&quot;Category&quot;] == &quot;Cultural&quot; . In the above line, there is no separation between &quot;China&quot; and &amp; so it might be interpreted as: . df[&quot;Country (EN)&quot;] == (&quot;China&quot; &amp; df[&quot;Category&quot;] == &quot;Cultural&quot;) . which will run into errors. . What we need to do is to group them: . (df[&quot;Country (EN)&quot;] == &quot;China&quot;) &amp; (df[&quot;Category&quot;] == &quot;Cultural&quot;) . so we make sure it will be interpreted as: . (col-A == a) &amp; (col-B == b) . df[(df[&quot;Country (EN)&quot;] == &quot;China&quot;) &amp; (df[&quot;Category&quot;] == &quot;Cultural&quot;)] . Name (EN) Name (FR) Short description (EN) Short Description (FR) Justification (EN) Justification (FR) Date inscribed Danger list Longitude Latitude Area hectares Category Country (EN) Country (FR) Continent (EN) Continent (FR) Geographical coordinates . 32 Tusi Sites | Sites du tusi | Located in the mountainous areas of south-west... | Situé dans les régions montagneuses du sud-oue... | NaN | NaN | 2015-01-01 | NaN | 109.966944 | 28.998611 | 781.2800 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 28.9986111111,109.966944444 | . 38 The Great Wall | La Grande Muraille | In c. 220 B.C., under Qin Shi Huang, sections ... | Vers 220 av. J.-C., Qin Shin Huang entreprit d... | NaN | NaN | 1987-01-01 | NaN | 116.083330 | 40.416670 | 2151.5500 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 40.41667,116.08333 | . 68 Mausoleum of the First Qin Emperor | Mausolée du premier empereur Qin | No doubt thousands of statues still remain to ... | Sur ce site archéologique qui ne fut découvert... | NaN | NaN | 1987-01-01 | NaN | 109.100000 | 34.383333 | 0.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 34.38333333,109.1 | . 81 Site of Xanadu | Site de Xanadu | North of the Great Wall, the Site of Xanadu en... | Situé au nord de la Grande Muraille, ce site d... | NaN | NaN | 2012-01-01 | NaN | 116.185128 | 42.358000 | 25131.2700 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 42.358,116.185127778 | . 127 Temple and Cemetery of Confucius and the Kong ... | Temple et cimetière de Confucius et résidence ... | The temple, cemetery and family mansion of Con... | Le temple, le cimetière et la demeure de famil... | NaN | NaN | 1994-01-01 | NaN | 116.975000 | 35.611670 | 0.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 35.61167,116.975 | . 134 Fujian &lt;em&gt;Tulou&lt;/em&gt; | &lt;em&gt;Tulou&lt;/em&gt; du Fujian | Fujian Tulou is a property of 46 buildings con... | Le site des Tulou du Fujian, comprend 46 maiso... | NaN | NaN | 2008-01-01 | NaN | 117.685833 | 25.023056 | 152.6500 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 25.0230555556,117.685833333 | . 165 Dazu Rock Carvings | Sculptures rupestres de Dazu | The steep hillsides of the Dazu area contain a... | Les montagnes abruptes de la région de Dazu ab... | Criterion (i): The Dazu carvings represent the... | Critère (i) : De par leur grande qualité esthé... | 1999-01-01 | NaN | 105.705000 | 29.701110 | 20.4100 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 29.70111,105.705 | . 219 Lushan National Park | Parc national de Lushan | Mount Lushan, in Jiangxi, is one of the spirit... | Le site du mont Lushan, dans le Jiangxi, const... | The Committee decided to inscribe this propert... | Le Comité a décidé d&#39;inscrire ce bien sur la b... | 1996-01-01 | NaN | 115.866667 | 29.433333 | 0.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 29.43333333,115.8666667 | . 220 Imperial Tombs of the Ming and Qing Dynasties | Tombes impériales des dynasties Ming et Qing | It represents the addition of three Imperial T... | L’extension ajoute trois tombes impériales de ... | Criterion (i): The harmonious integration of r... | Critère (i) : l&#39;intégration harmonieuse d&#39;ense... | 2000-01-01 | NaN | 124.793889 | 41.707222 | 3434.9399 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 41.70722222,124.7938889 | . 449 Imperial Palaces of the Ming and Qing Dynastie... | Palais impériaux des dynasties Ming et Qing à ... | Seat of supreme power for over five centuries ... | Siège du pouvoir suprême pendant plus de cinq ... | Criterion (i): The Imperial Palaces represent ... | Critère (i) : Les Palais impériaux représenten... | 1987-01-01 | NaN | 123.446944 | 41.794167 | 12.9600 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 41.79416667,123.4469444 | . 457 Mountain Resort and its Outlying Temples, Chengde | Résidence de montagne et temples avoisinants à... | The Mountain Resort (the Qing dynasty&#39;s summer... | La résidence de montagne, palais d&#39;été de la d... | NaN | NaN | 1994-01-01 | NaN | 117.938330 | 40.986940 | 0.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 40.98694,117.93833 | . 459 West Lake Cultural Landscape of Hangzhou | Paysage culturel du lac de l’Ouest de Hangzhou | The West Lake Cultural Landscape of Hangzhou, ... | Le paysage inscrit a inspiré des poètes, artis... | NaN | NaN | 2011-01-01 | NaN | 120.140833 | 30.237500 | 3322.8800 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 30.2375,120.140833333 | . 545 Cultural Landscape of Honghe Hani Rice Terraces | Paysage culturel des rizières en terrasse des ... | The Cultural Landscape of Honghe Hani Rice Ter... | Ce site de 16 603 hectares est situé dans le s... | NaN | NaN | 2013-01-01 | NaN | 102.779981 | 23.093278 | 16603.2200 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 23.0932777778,102.779980556 | . 590 Ancient Building Complex in the Wudang Mountains | Ensemble de bâtiments anciens des montagnes de... | The palaces and temples which form the nucleus... | Les palais et temples qui constituent le noyau... | NaN | NaN | 1994-01-01 | NaN | 111.000000 | 32.466670 | 0.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 32.46667,111.0 | . 601 Historic Centre of Macao | Centre historique de Macao | Macao, a lucrative port of strategic importanc... | Macao, riche port marchand d’une grande import... | Criterion (ii): The strategic location of Maca... | Critère (ii) : L’emplacement stratégique de Ma... | 2005-01-01 | NaN | 113.536461 | 22.191292 | 16.1678 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 22.1912919444,113.536461111 | . 605 Yin Xu | Yin Xu | The archaeological site of Yin Xu, close to An... | Le site archéologique de Yin Xu, proche de la ... | NaN | NaN | 2006-01-01 | NaN | 114.313889 | 36.126667 | 414.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 36.1266666666,114.313888889 | . 628 Yungang Grottoes | Grottes de Yungang | The Yungang Grottoes, in Datong city, Shanxi P... | Les grottes de Yungang, à Datong, province du ... | Criterion (i): The assemblage of statuary of t... | Critère (i) : L’ensemble de la statuaire des g... | 2001-01-01 | NaN | 113.122220 | 40.109720 | 348.7500 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 40.10972,113.12222 | . 653 Peking Man Site at Zhoukoudian | Site de l&#39;homme de Pékin à Zhoukoudian | Scientific work at the site, which lies 42 km ... | À 42 km au sud-ouest de Pékin, le site, dont l... | NaN | NaN | 1987-01-01 | NaN | 115.916667 | 39.733333 | 480.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 39.73333333,115.9166667 | . 671 Historic Ensemble of the Potala Palace, Lhasa | Ensemble historique du Palais du Potala, Lhasa | The Potala Palace, winter palace of the Dalai ... | Le palais du Potala, palais d&#39;hiver du dalaï-l... | NaN | NaN | 1994-01-01 | NaN | 91.117170 | 29.657920 | 60.5000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 29.65792,91.11717 | . 739 Summer Palace, an Imperial Garden in Beijing | Palais d&#39;Été, Jardin impérial de Beijing | The Summer Palace in Beijing – first built in ... | Le palais d&#39;Été de Beijing, créé en 1750, détr... | Criterion i: The Summer Palace in Beijing is a... | Critère i : le Palais d&#39;Eté de Beijing est une... | 1998-01-01 | NaN | 116.141111 | 39.910556 | 297.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 39.91055556,116.1411111 | . 743 Mount Qingcheng and the Dujiangyan Irrigation ... | Mont Qingcheng et système d’irrigation de Duji... | Construction of the Dujiangyan irrigation syst... | La construction du système d&#39;irrigation de Duj... | Criterion (ii): The Dujiangyan Irrigation Syst... | Critère (ii) : Le système d’irrigation de Duji... | 2000-01-01 | NaN | 103.605280 | 31.001670 | 0.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 31.00167,103.60528 | . 746 Historic Monuments of Dengfeng in “The Centre ... | Monuments historiques de Dengfeng au « centre ... | Mount Songshang is considered to be the centra... | Songshang est considéré comme le mont sacré ce... | NaN | NaN | 2010-01-01 | NaN | 113.067719 | 34.458747 | 825.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 34.4587472222,113.067719444 | . 769 The Grand Canal | Le Grand Canal | The Grand Canal is a vast waterway system in t... | Ce vaste système de navigation intérieure au s... | NaN | NaN | 2014-01-01 | NaN | 112.468333 | 34.693889 | 20819.1100 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 34.6938888889,112.468333333 | . 772 Old Town of Lijiang | Vieille ville de Lijiang | The Old Town of Lijiang, which is perfectly ad... | La vieille ville de Lijiang, harmonieusement a... | The Committee decided to inscribe this site on... | Le Comité a décidé d’inscrire ce site sur la b... | 1997-01-01 | NaN | 100.233330 | 26.866670 | 145.6000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 26.86667,100.23333 | . 808 Kaiping Diaolou and Villages | Diaolou et villages de Kaiping | Kaiping Diaolou and Villages feature the Diaol... | Les diaolou, maisons fortifiées de village de ... | NaN | NaN | 2007-01-01 | NaN | 112.565861 | 22.285519 | 371.9480 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 22.2855194444,112.565861111 | . 839 Ancient Villages in Southern Anhui – Xidi and ... | Anciens villages du sud du Anhui – Xidi et Hon... | The two traditional villages of Xidi and Hongc... | Les deux villages traditionnels de Xidi et de ... | Criterion (iii): The villages of Xidi and Hong... | Critère (iii) : Les villages de Xidi et de Hon... | 2000-01-01 | NaN | 117.987500 | 29.904444 | 52.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 29.90444444,117.9875 | . 851 Zuojiang Huashan Rock Art Cultural Landscape | Paysage culturel de l’art rupestre de Zuojiang... | Located on the steep cliffs in the border regi... | Situés sur des falaises abruptes dans les régi... | NaN | NaN | 2016-01-01 | NaN | 107.023056 | 22.255556 | 6621.6000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 22.2555555556,107.023055556 | . 883 Classical Gardens of Suzhou | Jardins classiques de Suzhou | Classical Chinese garden design, which seeks t... | Le paysagisme classique chinois, qui cherche à... | The Committee decided to inscribe this propert... | Le Comité a décidé d&#39;inscrire ce bien sur la b... | 1997-01-01 | NaN | 120.450000 | 31.316667 | 11.9220 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 31.31666667,120.45 | . 903 Ancient City of Ping Yao | Vieille ville de Ping Yao | Ping Yao is an exceptionally well-preserved ex... | Ping Yao est un exemple exceptionnellement bie... | The Committee decided to inscribe this propert... | Le Comité a décidé d&#39;inscrire ce bien sur la b... | 1997-01-01 | NaN | 112.154440 | 37.201390 | 245.6200 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 37.20139,112.15444 | . 921 Longmen Grottoes | Grottes de Longmen | The grottoes and niches of Longmen contain the... | Les grottes et niches de Longmen abritent le p... | Criterion (i): The sculptures of the Longmen G... | Critère (i) : Les sculptures des grottes de Lo... | 2000-01-01 | NaN | 112.466667 | 34.466667 | 331.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 34.46666667,112.4666667 | . 930 Temple of Heaven: an Imperial Sacrificial Alta... | Temple du Ciel, autel sacrificiel impérial à B... | The Temple of Heaven, founded in the first hal... | Fondé dans la première moitié du XVe siècle, l... | Criterion i: The Temple of Heaven is a masterp... | Critère i : Le Temple du Ciel est un chef-d&#39;œu... | 1998-01-01 | NaN | 116.444722 | 39.845556 | 215.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 39.84555556,116.4447222 | . 971 Mount Wutai | Mont Wutai | With its five flat peaks, Mount Wutai is a sac... | Avec ses cinq plateaux, le Mont Wutai est une ... | NaN | NaN | 2009-01-01 | NaN | 113.563333 | 39.030556 | 18415.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 39.0305555556,113.563333333 | . 1008 Mogao Caves | Grottes de Mogao | Situated at a strategic point along the Silk R... | Situées en un point stratégique de la Route de... | NaN | NaN | 1987-01-01 | NaN | 94.816670 | 40.133330 | 0.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 40.13333,94.81667 | . 1010 Capital Cities and Tombs of the Ancient Kogury... | Capitales et tombes de l’ancien royaume de Kog... | The site includes archaeological remains of th... | Ce site comprend les vestiges archéologiques d... | Criterion (i): The tombs represent a masterpie... | Critère (i) : Les tombes représentent un chef ... | 2004-01-01 | NaN | 126.187222 | 41.156944 | 4164.8599 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 41.15694444,126.1872222 | . So now, let&#39;s filter all Chinese sites regardless of heritage types. . china_site = df[df[&quot;Country (EN)&quot;] == &quot;China&quot;] china_site.head(1) . Name (EN) Name (FR) Short description (EN) Short Description (FR) Justification (EN) Justification (FR) Date inscribed Danger list Longitude Latitude Area hectares Category Country (EN) Country (FR) Continent (EN) Continent (FR) Geographical coordinates . 5 Sichuan Giant Panda Sanctuaries - Wolong, Mt S... | Sanctuaires du grand panda du Sichuan - Wolong... | Sichuan Giant Panda Sanctuaries, home to more ... | Les Sanctuaires du grand panda du Sichuan abri... | NaN | NaN | 2006-01-01 | NaN | 103.0 | 30.833333 | 924500.0 | Natural | China | Chine | Asia and the Pacific | Asie et pacifique | 30.8333333333,103.0 | . Check the number of sites we have in the data frame: . china_site[&#39;Name (EN)&#39;].count() . 49 . As the column namings are a bit confusion with the spacings and capital letters, we will rename the columns: . china_site = china_site[[&quot;Name (EN)&quot;,&quot;Date inscribed&quot;,&quot;Category&quot;]] # select multiple columns in a list [] china_site = china_site.rename(columns={&quot;Name (EN)&quot;: &quot;name&quot;, &quot;Date inscribed&quot;: &quot;date&quot;, &quot;Category&quot;: &quot;type&quot;}) # rename the columns for easy reading china_site.head(1) # check the updates . name date type . 5 Sichuan Giant Panda Sanctuaries - Wolong, Mt S... | 2006-01-01 | Natural | . Date Time . Pandas dataframe also support datetime for time series analysis. But first, we need to read the column as date time using to_datetime(). It is as if we are telling Pandas the date column is not just a string, but datetime objects. . china_site[&#39;date&#39;] = pd.to_datetime(china_site[&quot;date&quot;]) . By converting the column to datetime objects, we can do multiple operations inside the data fame, just as extracting only the year information. It can be done by .year. As the year information for us is more relevant than the month and day, we will remove the original column and add a year column. . china_site[&#39;year&#39;] = pd.DatetimeIndex(china_site[&#39;date&#39;]).year # set up a new year column china_site = china_site.drop(columns=[&#39;date&#39;]) # remove the original date column china_site.head(1) # check the first row . name type year . 5 Sichuan Giant Panda Sanctuaries - Wolong, Mt S... | Natural | 2006 | . UNESCO Sites . Using the china_site variable, we can check on the number of sites for each year using groupby(). After groupby(), we keep only the name column and count the number of rows using count(). Yet, we will get a Pandas series (pandas.core.series.Series) as return, not a data frame. We need to convert it back to data frame using reset_index() and add name=&quot;count&quot; to tell Pandas the new column will be called &quot;count&quot;. . count = china_site.groupby(&quot;year&quot;)[&quot;name&quot;].count() count . year 1987 6 1990 1 1992 3 1994 4 1996 2 1997 3 1998 2 1999 2 2000 4 2001 1 2003 1 2004 1 2005 1 2006 2 2007 2 2008 2 2009 1 2010 2 2011 1 2012 2 2013 2 2014 1 2015 1 2016 2 Name: name, dtype: int64 . count_df = count.reset_index(name=&quot;count&quot;) count_df . year count . 0 1987 | 6 | . 1 1990 | 1 | . 2 1992 | 3 | . 3 1994 | 4 | . 4 1996 | 2 | . 5 1997 | 3 | . 6 1998 | 2 | . 7 1999 | 2 | . 8 2000 | 4 | . 9 2001 | 1 | . 10 2003 | 1 | . 11 2004 | 1 | . 12 2005 | 1 | . 13 2006 | 2 | . 14 2007 | 2 | . 15 2008 | 2 | . 16 2009 | 1 | . 17 2010 | 2 | . 18 2011 | 1 | . 19 2012 | 2 | . 20 2013 | 2 | . 21 2014 | 1 | . 22 2015 | 1 | . 23 2016 | 2 | . ### Cumulative totals of the heritage sites | . The above table displays the number of sites inscribed in China every year, however, what if we want to know the total number of heritage sites in China for every year? We can use cumsum(), standing for cumulative summation. Let&#39;s put the total number of sites into a new column called &quot;total&quot;. . count_df[&quot;total&quot;] = count_df[&quot;count&quot;].cumsum() . ### Set Index | . Let&#39;s reset the index using year. . count_df = count_df.set_index(&quot;year&quot;) count_df.head() . count total . year . 1987 6 | 6 | . 1990 1 | 7 | . 1992 3 | 10 | . 1994 4 | 14 | . 1996 2 | 16 | . Visualization . Plotting using Pandas data frame is fairly easy. We only need to add .plot() after selecting the column(s) we need (multiple column names need to be put in a list using []). To customize the layout, we need to import matplotlib library too. . import matplotlib.pyplot as plt # import library plt.figure(figsize=(15,5)) # optional, define figure size count_df.total.plot(color=&quot;red&quot;) # plot, add color argument plt.xlabel(&quot;Year&quot;) # x label plt.ylabel(&quot;Number of UNESCO sites&quot;) # y label plt.title(&quot;Increasing number of UNESCO sites in China&quot;) # title . Text(0.5, 1.0, &#39;Increasing number of UNESCO sites in China&#39;) . We can also plot a table instead. . data = {&quot;Year&quot;: count_df.index.values, &quot;Total Sites&quot;: count_df.total.values} df = pd.DataFrame(data) fig, ax = plt.subplots(1, 1) # Hide axes ax.xaxis.set_visible(False) ax.yaxis.set_visible(False) ax.axis(&#39;tight&#39;) ax.axis(&#39;off&#39;) ax.table(cellText=df.values, colLabels=df.keys(), loc=&#39;center&#39;) plt.show() . To export the data for further use, we can export them as csv file. . from google.colab import files df.to_csv(&#39;UNESCO.csv&#39;, encoding=&#39;utf_8_sig&#39;, index=False) files.download(&#39;UNESCO.csv&#39;) . Or print it as LaTeX. . print(df.to_latex(index=False)) . begin{tabular}{rr} toprule Year &amp; Total Sites midrule 1987 &amp; 6 1990 &amp; 7 1992 &amp; 10 1994 &amp; 14 1996 &amp; 16 1997 &amp; 19 1998 &amp; 21 1999 &amp; 23 2000 &amp; 27 2001 &amp; 28 2003 &amp; 29 2004 &amp; 30 2005 &amp; 31 2006 &amp; 33 2007 &amp; 35 2008 &amp; 37 2009 &amp; 38 2010 &amp; 40 2011 &amp; 41 2012 &amp; 43 2013 &amp; 45 2014 &amp; 46 2015 &amp; 47 2016 &amp; 49 bottomrule end{tabular} . Plotting . Do some plotting using our data. . Let&#39;s say we are interested in the progress of UNESCO sites application from different countries. We want to do a plot to see which countries are having the largest share of sites and how the trend develops over time. Creating the plot is typically the final step for data visualization. Before that, there are some steps need to be done. . . Typical Workflow for Visualization: . 1) Get data: grab them online or offline . 2) Clean data: get rid of missing data, clean the irrelevant information, groupping parameters, etc. . 3) Design on the type of visualization: what type of chart (depends on your message &amp; purpose &amp; nature of data)? by what parameters (eg. by year or by country or focus on one country only)? . 4) Prepare the data in the format fitting your visualization type (wide or long format?) . . Data Preparation . the first thing we need to do is to collect the top 10 countries having the most UNESCO sites. . df = df[[&#39;Country (EN)&#39;,&quot;Name (EN)&quot;,&quot;Date inscribed&quot;,&quot;Category&quot;]] # select multiple columns in a list [] df = df.rename(columns={&quot;Country (EN)&quot;: &quot;country&quot;,&quot;Name (EN)&quot;: &quot;name&quot;, &quot;Date inscribed&quot;: &quot;date&quot;, &quot;Category&quot;: &quot;type&quot;}) # rename the columns for easy reading . top_10 = df.groupby(df[&quot;country&quot;]).count().sort_values(by=[&#39;name&#39;], ascending=False).head(10) top_10 . name date type . country . China 49 | 49 | 49 | . Italy 47 | 47 | 47 | . Spain 41 | 41 | 41 | . France 38 | 38 | 38 | . Germany 35 | 35 | 35 | . Mexico 34 | 34 | 34 | . India 33 | 33 | 33 | . United Kingdom of Great Britain and Northern Ireland 27 | 27 | 27 | . Russian Federation 21 | 21 | 21 | . Iran (Islamic Republic of) 21 | 21 | 21 | . Then we convert the countries to Numpy array and save it to a variable sub_cnty. . sub_cnty = top_10.index.values sub_cnty . array([&#39;China&#39;, &#39;Italy&#39;, &#39;Spain&#39;, &#39;France&#39;, &#39;Germany&#39;, &#39;Mexico&#39;, &#39;India&#39;, &#39;United Kingdom of Great Britain and Northern Ireland&#39;, &#39;Russian Federation&#39;, &#39;Iran (Islamic Republic of)&#39;], dtype=object) . top_df is the data frame including the top 10 countries only. As we aim to plot number of heritage sites every years for each country, we need to use groupby() grouping both country and date after filtering the rows to the top 10 countries using df[&#39;country&#39;].isin(sub_cnty). . After groupby() we need to indicate the method count(). We will only select the name column only (country and date will also be included as they are the objects used to &quot;groupby&quot;). . In order to get a data frame as output, we need to use reset_index(). . top_df = df[df[&#39;country&#39;].isin(sub_cnty)].groupby([&#39;country&#39;,&#39;date&#39;]).count()[&#39;name&#39;].reset_index() top_df.head(5) . country date name . 0 China | 1987-01-01 | 6 | . 1 China | 1990-01-01 | 1 | . 2 China | 1992-01-01 | 3 | . 3 China | 1994-01-01 | 4 | . 4 China | 1996-01-01 | 2 | . pivot() from Pandas is a function to convert a data frame from long to wide. In this case, it basically display every unique item in the country column into a separate column. . pivot = top_df.pivot(index=&#39;date&#39;, columns=&#39;country&#39;, values=&#39;name&#39;) pivot = pivot.fillna(0) pivot.head(10) . country China France Germany India Iran (Islamic Republic of) Italy Mexico Russian Federation Spain United Kingdom of Great Britain and Northern Ireland . date . 1978-01-01 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1979-01-01 0.0 | 5.0 | 0.0 | 0.0 | 3.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1980-01-01 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1981-01-01 0.0 | 5.0 | 2.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1982-01-01 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1983-01-01 0.0 | 3.0 | 1.0 | 4.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1984-01-01 0.0 | 0.0 | 1.0 | 2.0 | 0.0 | 0.0 | 0.0 | 0.0 | 5.0 | 0.0 | . 1985-01-01 0.0 | 1.0 | 1.0 | 3.0 | 0.0 | 0.0 | 0.0 | 0.0 | 5.0 | 0.0 | . 1986-01-01 0.0 | 0.0 | 1.0 | 4.0 | 0.0 | 0.0 | 0.0 | 0.0 | 4.0 | 7.0 | . 1987-01-01 6.0 | 0.0 | 1.0 | 3.0 | 0.0 | 2.0 | 6.0 | 0.0 | 1.0 | 2.0 | . pivot = pivot.cumsum() pivot.head(10) . country China France Germany India Iran (Islamic Republic of) Italy Mexico Russian Federation Spain United Kingdom of Great Britain and Northern Ireland . date . 1978-01-01 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1979-01-01 0.0 | 5.0 | 1.0 | 0.0 | 3.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1980-01-01 0.0 | 5.0 | 1.0 | 0.0 | 3.0 | 2.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1981-01-01 0.0 | 10.0 | 3.0 | 0.0 | 3.0 | 2.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1982-01-01 0.0 | 11.0 | 3.0 | 0.0 | 3.0 | 3.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1983-01-01 0.0 | 14.0 | 4.0 | 4.0 | 3.0 | 3.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1984-01-01 0.0 | 14.0 | 5.0 | 6.0 | 3.0 | 3.0 | 0.0 | 0.0 | 5.0 | 0.0 | . 1985-01-01 0.0 | 15.0 | 6.0 | 9.0 | 3.0 | 3.0 | 0.0 | 0.0 | 10.0 | 0.0 | . 1986-01-01 0.0 | 15.0 | 7.0 | 13.0 | 3.0 | 3.0 | 0.0 | 0.0 | 14.0 | 7.0 | . 1987-01-01 6.0 | 15.0 | 8.0 | 16.0 | 3.0 | 5.0 | 6.0 | 0.0 | 15.0 | 9.0 | . Visualization . Now we can start plotting. We first plot a chart showing the temporal development of heritage inscriptions for the 10 countries. . import matplotlib.pyplot as plt # import library pivot.plot(figsize=(20,6)) # define plot size plt.xlabel(&quot;Year&quot;, fontsize=14) # x label plt.ylabel(&quot;Count&quot;, fontsize=14) # y label plt.title(&quot;UNESCO Sites&quot;, fontsize=20) # title . Text(0.5, 1.0, &#39;UNESCO Sites&#39;) . Style Use . We can also choose to change style of our plot using seaborn library. What we need to do is to import the library and set the parameters before we call the functions with our Pandas data frame. . . import seaborn as sns # import library custom_params = {&quot;axes.spines.right&quot;: False, &quot;axes.spines.top&quot;: False} # define axes parameters sns.set_theme(style=&quot;ticks&quot;, rc=custom_params, context=&quot;talk&quot;) # define theme plt.style.use(&quot;dark_background&quot;) # define background color (here we try with a dark theme) . Linechart . import matplotlib.dates as mdates # import mdates to plot datae time data plt.figure(figsize=(20, 6)) sns.lineplot(data=pivot) # call lineplot using seaborn library plt.title(&quot;UNESCO Sites&quot;, fontsize=28) plt.xlabel(&quot;Year&quot;) plt.ylabel(&quot;Count&quot;) plt.legend(bbox_to_anchor=(1.02, 0.9), loc=2, borderaxespad=0.) # display a legend at the position out of our plot plt.tight_layout() # adjust spacings of elements . Stacked Area Chart . Apart from line chart, we can also do a stacked area plot to create more visuals. The principle is similar, but this time we will use stackplot together with &quot;sym&quot; baseline (Symmetric around zero and is sometimes called &#39;ThemeRiver&#39;). If you are particularly interested in different plotting types, stick with the tutorials as we will discuss more in the next chapters. . Also, feel free to check out this for a cataloge of data visualization using Python. . fig, ax = plt.subplots(figsize=(15, 6)) # figure size ax.stackplot(pivot.index.values, [pivot[name].values for name in pivot], baseline=&quot;sym&quot;, colors=palette, labels=sub_cnty) # stacked area ax.axhline(0, color=&quot;red&quot;, ls=&quot;--&quot;, linewidth=.8) # red line in the middle plt.title(&quot;UNESCO Sites&quot;, fontsize=25) # title plt.xlabel(&quot;Year&quot;) # labels plt.ylabel(&quot;Count&quot;) plt.legend(bbox_to_anchor=(1.02, 0.9), loc=2, borderaxespad=0.) # legend plt.tight_layout() # adjust spacings . Lollipop Chart . Just another example that we can also do a lollipop chart instead. Here then we will only focus on temporal development of sites in China. . plt.figure(figsize=(24,6)) plt.hlines(y=pivot.index, xmin=0, xmax=pivot[&#39;China&#39;], color=&quot;#FCC700&quot;) plt.plot(pivot[&#39;China&#39;], pivot.index, &quot;o&quot;, markersize=8, color=&quot;#FC4900&quot;) plt.title(&quot;UNESCO Sites in China&quot;, fontsize=26) plt.xlabel(&quot;Count&quot;) plt.ylabel(&quot;Year&quot;) . Text(0, 0.5, &#39;Year&#39;) . . Previous Lesson: Pandas Text Analysis . Next Lesson: Coming soon... . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: December 2021 . . . . References: . https://examples.opendatasoft.com/explore/dataset/world-heritage-unesco-list/table/ .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/data-organization/level-2/chapter-2/pandas/matplotlib/seaborn/data-visualization/2020/01/24/Pandas_NumericalOperation_QuantitativeDataOrganization.html",
            "relUrl": "/data-organization/level-2/chapter-2/pandas/matplotlib/seaborn/data-visualization/2020/01/24/Pandas_NumericalOperation_QuantitativeDataOrganization.html",
            "date": " • Jan 24, 2020"
        }
        
    
  
    
        ,"post15": {
            "title": "Python Pandas Library",
            "content": ". This notebook aims to intrduce users to Pandas library, an useful tool for tabular data manipulation. What it can be done is similar to Excel but allows users to have a much higher flexibility and to manage huge dataset in efficient manner. . . Presumptions: . Dictionary . . . Pandas Series . We have learnt about list, which is a simple way to handle information but Pandas includes many extra features to handle data, such as handling missing data and indexing objects with text. The corresponding form of a list in Pandas is a Pandas series, which acts can also be understood as a column of the Pandas dataframe. A Pandas Series can be created using pd.Series(). . import pandas as pd names = pd.Series([&#39;登江中孤屿，赠白云先生王迥&#39;, &#39;秋登兰山寄张五&#39;,&#39; &#39;,&#39;入峡寄弟&#39;]) names . 0 登江中孤屿，赠白云先生王迥 1 秋登兰山寄张五 2 3 入峡寄弟 dtype: object . Nearly all Python&#39;s built-in string methods are mirrored by a Pandas vectorized string method. Here is a list of Pandas str methods: . . len() | lower() | translate() | islower() | . ljust() | upper() | startswith() | isupper() | . rjust() | find() | endswith() | isnumeric() | . center() | rfind() | isalnum() | isdecimal() | . zfill() | index() | isalpha() | split() | . strip() | rindex() | isdigit() | rsplit() | . rstrip() | capitalize() | isspace() | partition() | . lstrip() | swapcase() | istitle() | rpartition() | . We need to pay attention that although many of the strings method is not applicable in Chinese languages, some functions can still be really helpful. . For example, . names.str.startswith(&#39;秋&#39;) # looking for item that start with a character . 0 False 1 True 2 False 3 False dtype: bool . names.str.isspace() # looking for empty space . 0 False 1 False 2 True 3 False dtype: bool . names.str.find(&#39;秋&#39;) # look for where (index) is a character . 0 -1 1 0 2 -1 3 -1 dtype: int64 . names.str.split(pat=&quot;&quot;) # split characters . 0 [, 登, 江, 中, 孤, 屿, ，, 赠, 白, 云, 先, 生, 王, 迥, ] 1 [, 秋, 登, 兰, 山, 寄, 张, 五, ] 2 [, , ] 3 [, 入, 峡, 寄, 弟, ] dtype: object . names.str.extract(&#39;([A-Za-z]+)&#39;, expand=False) # look for letters (this is called regular expression, you will learn about it later) . 0 NaN 1 NaN 2 NaN 3 NaN dtype: object . names.str.findall(r&#39;^[秋].*$&#39;) # find item with characters . 0 [] 1 [秋登兰山寄张五] 2 [] 3 [] dtype: object . There are also some methods that allows convenient operations: . Method Description . get() | Index each element | . slice() | Slice each element | . slice_replace() | Replace slice in each element with passed value | . cat() | Concatenate strings | . repeat() | Repeat values | . normalize() | Return Unicode form of string | . pad() | Add whitespace to left, right, or both sides of strings | . wrap() | Split long strings into lines with length less than a given width | . join() | Join strings in each element of the Series with passed separator | . get_dummies() | extract dummy variables as a dataframe | . names.str[0:1] # get the first character only . 0 登 1 秋 2 3 入 dtype: object . names.str.split(pat=&#39;，&#39;).str.get(0) # get first clause . 0 登江中孤屿 1 秋登兰山寄张五 2 3 入峡寄弟 dtype: object . We can even get some statistics about the length of our text using describe(). . names.str.len().describe() . count 4.000000 mean 6.250000 std 5.123475 min 1.000000 25% 3.250000 50% 5.500000 75% 8.500000 max 13.000000 dtype: float64 . We can also create a Pandas DataFrame from a dictionary: while the keys will be used as the name of the column in the Pandas DataFrame, the values will be used as the data (rows). . Let&#39;s build a data frame using capital names for Qin and Han dynasties as an example. . dictionary = { &#39;Time&#39;: [&#39;&#39;,&#39;– 677 BC&#39;,&#39;677 BC –&#39;,&#39;– 383 BC&#39;,&#39;383 BC – 250 BC&#39;,&#39;350 BC – 207 BC&#39;,&#39;202 BC&#39;,&#39;202 BC – 200 BC&#39;,&#39;200 BC – 8 BC&#39;], &#39;Dynasty&#39;: [&#39;Qin&#39;,&#39;Qin&#39;,&#39;Qin&#39;,&#39;Qin&#39;,&#39;Qin&#39;,&#39;Qin&#39;,&#39;Han&#39;,&#39;Han&#39;,&#39;Han&#39;], &#39;Capital&#39;: [&#39;Xiquanqiu&#39;,&#39;Pingyang&#39;,&#39;Yong&#39;,&#39;Jingyang&#39;,&#39;Yueyang&#39;,&#39;Xianyang&#39;,&#39;Luoyang&#39;,&#39;Yueyang&#39;,&#39;Changan&#39;] } # remember all column in the data frame have to have the same length df = pd.DataFrame(data=dictionary) # use pd.DataFrame() and put the dict as an argument df . Time Dynasty Capital . 0 | Qin | Xiquanqiu | . 1 – 677 BC | Qin | Pingyang | . 2 677 BC – | Qin | Yong | . 3 – 383 BC | Qin | Jingyang | . 4 383 BC – 250 BC | Qin | Yueyang | . 5 350 BC – 207 BC | Qin | Xianyang | . 6 202 BC | Han | Luoyang | . 7 202 BC – 200 BC | Han | Yueyang | . 8 200 BC – 8 BC | Han | Changan | . df = df.set_index(&#39;Time&#39;) # we can also set text as index df . Dynasty Capital . Time . Qin | Xiquanqiu | . – 677 BC Qin | Pingyang | . 677 BC – Qin | Yong | . – 383 BC Qin | Jingyang | . 383 BC – 250 BC Qin | Yueyang | . 350 BC – 207 BC Qin | Xianyang | . 202 BC Han | Luoyang | . 202 BC – 200 BC Han | Yueyang | . 200 BC – 8 BC Han | Changan | . To view only the first row: . df.head(1) . Dynasty Capital . Time . Qin | Xiquanqiu | . To view only the last row: . df.tail(1) . Dynasty Capital . Time . 200 BC – 8 BC Han | Changan | . In order to understand better the group characteristics, we can also use the groupby option. It is used with a groupby() following with a method(). . For example, we can use groupby(&quot;Dynasty&quot;).count() to count number of rows (number of capital) in each dynasty. . . Remarks: Index cannot be used as the groupby object. . df.groupby(&quot;Dynasty&quot;).count() . Capital . Dynasty . Han 3 | . Qin 6 | . . . Data Manipulation . After understanding what is a Pandas Series and what is a Pandas DataFrame, we can start with some basic manipulation using a data frame. Let&#39;s start with an example to build a Pandas dataframe from a text file. . First, we upload a text and selected titles.txt file. (can be found in the data folder) . from google.colab import files uploaded = files.upload() for f in uploaded.keys(): file = open(f, &#39;r&#39;) titles = file.read() . Upload widget is only available when the cell has been executed in the current browser session. Please rerun this cell to enable. Saving titles.txt to titles (1).txt . Then, we can split the text into paragraphs (separate by two new lines) and sentence (separate by one new line). . titles = titles.split(&quot; n n&quot;) # two new lines titles = [lines.split(&#39; n&#39;) for lines in titles] # one new line, done in a list comprehension . titles[0:2] # check the first two items we have: 卷159_1 and 卷159_2 . [[&#39;卷159_1 「从张丞相游南纪城猎，戏赠裴迪张参军」孟浩然&#39;, &#39; u3000 u3000从禽非吾乐，不好云梦田。岁暮登城望，偏令乡思悬。&#39;, &#39; u3000 u3000公卿有几几，车骑何翩翩。世禄金张贵，官曹幕府贤。&#39;, &#39; u3000 u3000顺时行杀气，飞刃争割鲜。十里届宾馆，征声匝妓筵。&#39;, &#39; u3000 u3000高标回落日，平楚散芳烟。何意狂歌客，从公亦在旃。&#39;], [&#39;卷159_2 「登江中孤屿，赠白云先生王迥」孟浩然&#39;, &#39; u3000 u3000悠悠清江水，水落沙屿出。回潭石下深，绿筱岸傍密。&#39;, &#39; u3000 u3000鲛人潜不见，渔父歌自逸。忆与君别时，泛舟如昨日。&#39;, &#39; u3000 u3000夕阳开返照，中坐兴非一。南望鹿门山，归来恨如失。&#39;]] . We can also check how many titles (卷) are there: . len(titles) . 269 . Then construct our dataframe. . import pandas as pd # In case library is not imported df = pd.DataFrame({&quot;content&quot;: titles}) # construct a data frame using a dictionary df.head() . content . 0 [卷159_1 「从张丞相游南纪城猎，戏赠裴迪张参军」孟浩然, 　　从禽非吾乐，不好云梦田。... | . 1 [卷159_2 「登江中孤屿，赠白云先生王迥」孟浩然, 　　悠悠清江水，水落沙屿出。回潭石下... | . 2 [卷159_3 「晚春卧病寄张八」孟浩然, 　　南陌春将晚，北窗犹卧病。林园久不游，草木一何... | . 3 [卷159_4 「秋登兰山寄张五」孟浩然, 　　北山白云里，隐者自怡悦。相望试登高，心飞逐鸟... | . 4 [卷159_5 「入峡寄弟」孟浩然, 　　吾昔与尔辈，读书常闭门。未尝冒湍险，岂顾垂堂言。,... | . We realize the content column is so messy as it contains different information such as which titles, author name and the content itself. So we want to set up different new columns: . . 1) title: The title . 2) content: The text . 3) index: use the text id (eg. 159_1) as index . We can set up new columns by simply writing . df[&quot;name of the new column&quot;] = [what we plan to put in] . What we plan to put in can be for example, a Numpy array with the same length, or just a number (in this case all rows will have the same value). For example, . import numpy as np df[&quot;test&quot;] = 1 df.head() . content test . 0 [卷159_1 「从张丞相游南纪城猎，戏赠裴迪张参军」孟浩然, 　　从禽非吾乐，不好云梦田。... | 1 | . 1 [卷159_2 「登江中孤屿，赠白云先生王迥」孟浩然, 　　悠悠清江水，水落沙屿出。回潭石下... | 1 | . 2 [卷159_3 「晚春卧病寄张八」孟浩然, 　　南陌春将晚，北窗犹卧病。林园久不游，草木一何... | 1 | . 3 [卷159_4 「秋登兰山寄张五」孟浩然, 　　北山白云里，隐者自怡悦。相望试登高，心飞逐鸟... | 1 | . 4 [卷159_5 「入峡寄弟」孟浩然, 　　吾昔与尔辈，读书常闭门。未尝冒湍险，岂顾垂堂言。,... | 1 | . Or this: . df[&quot;test&quot;] = np.arange(0,269) df.head() . content test . 0 [卷159_1 「从张丞相游南纪城猎，戏赠裴迪张参军」孟浩然, 　　从禽非吾乐，不好云梦田。... | 0 | . 1 [卷159_2 「登江中孤屿，赠白云先生王迥」孟浩然, 　　悠悠清江水，水落沙屿出。回潭石下... | 1 | . 2 [卷159_3 「晚春卧病寄张八」孟浩然, 　　南陌春将晚，北窗犹卧病。林园久不游，草木一何... | 2 | . 3 [卷159_4 「秋登兰山寄张五」孟浩然, 　　北山白云里，隐者自怡悦。相望试登高，心飞逐鸟... | 3 | . 4 [卷159_5 「入峡寄弟」孟浩然, 　　吾昔与尔辈，读书常闭门。未尝冒湍险，岂顾垂堂言。,... | 4 | . We can also add a new row: . df.append({&#39;content&#39;: np.nan, &#39;test&#39;: np.nan}, ignore_index=True) # This is temporary only and will not change the data frame itself # np.nan means missing values . content test . 0 [卷159_1 「从张丞相游南纪城猎，戏赠裴迪张参军」孟浩然, 　　从禽非吾乐，不好云梦田。... | 0.0 | . 1 [卷159_2 「登江中孤屿，赠白云先生王迥」孟浩然, 　　悠悠清江水，水落沙屿出。回潭石下... | 1.0 | . 2 [卷159_3 「晚春卧病寄张八」孟浩然, 　　南陌春将晚，北窗犹卧病。林园久不游，草木一何... | 2.0 | . 3 [卷159_4 「秋登兰山寄张五」孟浩然, 　　北山白云里，隐者自怡悦。相望试登高，心飞逐鸟... | 3.0 | . 4 [卷159_5 「入峡寄弟」孟浩然, 　　吾昔与尔辈，读书常闭门。未尝冒湍险，岂顾垂堂言。,... | 4.0 | . ... ... | ... | . 265 [卷160_181 「渡浙江问舟中人（一题作济江问同舟人。一作崔国辅诗）」孟浩然, 　　潮落... | 265.0 | . 266 [卷160_182 「初秋」孟浩然, 　　不觉初秋夜渐长，清风习习重凄凉。, 　　炎炎暑退茅... | 266.0 | . 267 [卷160_183 「过融上人兰若」孟浩然, 　　山头禅室挂僧衣，窗外无人水鸟飞。, 　　黄... | 267.0 | . 268 [卷160_184 「句」孟浩然, 　　微云淡河汉，疏雨滴梧桐。, 　　逐逐怀良驭，萧萧顾乐... | 268.0 | . 269 NaN | NaN | . 270 rows × 2 columns . df = df.append({&#39;content&#39;: np.nan, &#39;test&#39;: np.nan}, ignore_index=True) # df = &lt;- now the df is replaced df.tail(1) . content test . 269 NaN | NaN | . We can then drop the row (all missing values) and the column again. . df = df.dropna(how=&quot;any&quot;,axis=&quot;index&quot;) # this is for dropping all missing values in the rows df.tail(1) . content test . 268 [卷160_184 「句」孟浩然, 　　微云淡河汉，疏雨滴梧桐。, 　　逐逐怀良驭，萧萧顾乐... | 268.0 | . df = df.drop(columns=&quot;test&quot;) # this is dropping the column named &quot;test&quot; df.head() . content . 0 [卷159_1 「从张丞相游南纪城猎，戏赠裴迪张参军」孟浩然, 　　从禽非吾乐，不好云梦田。... | . 1 [卷159_2 「登江中孤屿，赠白云先生王迥」孟浩然, 　　悠悠清江水，水落沙屿出。回潭石下... | . 2 [卷159_3 「晚春卧病寄张八」孟浩然, 　　南陌春将晚，北窗犹卧病。林园久不游，草木一何... | . 3 [卷159_4 「秋登兰山寄张五」孟浩然, 　　北山白云里，隐者自怡悦。相望试登高，心飞逐鸟... | . 4 [卷159_5 「入峡寄弟」孟浩然, 　　吾昔与尔辈，读书常闭门。未尝冒湍险，岂顾垂堂言。,... | . Now we finally start with our new columns: . Let&#39;s look at one of our data: we can see the first item is the id, title and author name, and the other items are the text. So let&#39;s set the first item as title, and the rest of the items as content. . df[&quot;content&quot;][0] . [&#39;卷159_1 「从张丞相游南纪城猎，戏赠裴迪张参军」孟浩然&#39;, &#39; u3000 u3000从禽非吾乐，不好云梦田。岁暮登城望，偏令乡思悬。&#39;, &#39; u3000 u3000公卿有几几，车骑何翩翩。世禄金张贵，官曹幕府贤。&#39;, &#39; u3000 u3000顺时行杀气，飞刃争割鲜。十里届宾馆，征声匝妓筵。&#39;, &#39; u3000 u3000高标回落日，平楚散芳烟。何意狂歌客，从公亦在旃。&#39;] . df[&quot;title&quot;] = df[&quot;content&quot;].str[0] # the first item df[&quot;content&quot;] = df[&quot;content&quot;].str[1:] # second to last item df[&quot;content&quot;] = df[&quot;content&quot;].str.get(0) # get rid of the [] by extracting the first item from list df.head() . content title . 0 从禽非吾乐，不好云梦田。岁暮登城望，偏令乡思悬。 | 卷159_1 「从张丞相游南纪城猎，戏赠裴迪张参军」孟浩然 | . 1 悠悠清江水，水落沙屿出。回潭石下深，绿筱岸傍密。 | 卷159_2 「登江中孤屿，赠白云先生王迥」孟浩然 | . 2 南陌春将晚，北窗犹卧病。林园久不游，草木一何盛。 | 卷159_3 「晚春卧病寄张八」孟浩然 | . 3 北山白云里，隐者自怡悦。相望试登高，心飞逐鸟灭。 | 卷159_4 「秋登兰山寄张五」孟浩然 | . 4 吾昔与尔辈，读书常闭门。未尝冒湍险，岂顾垂堂言。 | 卷159_5 「入峡寄弟」孟浩然 | . df = df.replace(r&#39; n&#39;,&#39; &#39;, regex=True) # replace the next line symbol &#39; n&#39; with empty space df.head() . content title . 0 从禽非吾乐，不好云梦田。岁暮登城望，偏令乡思悬。 | 卷159_1 「从张丞相游南纪城猎，戏赠裴迪张参军」孟浩然 | . 1 悠悠清江水，水落沙屿出。回潭石下深，绿筱岸傍密。 | 卷159_2 「登江中孤屿，赠白云先生王迥」孟浩然 | . 2 南陌春将晚，北窗犹卧病。林园久不游，草木一何盛。 | 卷159_3 「晚春卧病寄张八」孟浩然 | . 3 北山白云里，隐者自怡悦。相望试登高，心飞逐鸟灭。 | 卷159_4 「秋登兰山寄张五」孟浩然 | . 4 吾昔与尔辈，读书常闭门。未尝冒湍险，岂顾垂堂言。 | 卷159_5 「入峡寄弟」孟浩然 | . type(df.title[0]) # title is type of string . str . Now we can set up a new column &quot;id&quot; and then use it as our index using set_index(). . We learnt in the last notebook. ( d+_ d+) means numbers followed by _ followed by numbers again. This is the pattern used for extract from the title column. . df[&quot;id&quot;] = df.title.str.extract(&#39;( d+_ d+)&#39;) df = df.set_index(&quot;id&quot;) df.head() . content title . id . 159_1 从禽非吾乐，不好云梦田。岁暮登城望，偏令乡思悬。 | 卷159_1 「从张丞相游南纪城猎，戏赠裴迪张参军」孟浩然 | . 159_2 悠悠清江水，水落沙屿出。回潭石下深，绿筱岸傍密。 | 卷159_2 「登江中孤屿，赠白云先生王迥」孟浩然 | . 159_3 南陌春将晚，北窗犹卧病。林园久不游，草木一何盛。 | 卷159_3 「晚春卧病寄张八」孟浩然 | . 159_4 北山白云里，隐者自怡悦。相望试登高，心飞逐鸟灭。 | 卷159_4 「秋登兰山寄张五」孟浩然 | . 159_5 吾昔与尔辈，读书常闭门。未尝冒湍险，岂顾垂堂言。 | 卷159_5 「入峡寄弟」孟浩然 | . Now our data frame looks better. But we still want to get rid of the id, author name, and 「」. To remove them, we replace them with a string of nothing (&quot;&quot;). Save them back to title column. . df[&#39;title&#39;] = df[&#39;title&#39;].str.replace(&#39;卷( d+_ d+)&#39;, &#39;&#39;).str.replace(&#39;孟浩然&#39;, &#39;&#39;) df[&#39;title&#39;] = df[&#39;title&#39;].str.replace(&#39;「&#39;, &#39;&#39;).str.replace(&#39;」&#39;, &#39;&#39;) . Let&#39;s have our df2 now by coping &quot;title&quot; and &quot;content&quot; from our df. And set index using index from df. . df2 = (df[[&#39;title&#39;,&#39;content&#39;]]).set_index(df.index) df2.head() . title content . id . 159_1 从张丞相游南纪城猎，戏赠裴迪张参军 | 从禽非吾乐，不好云梦田。岁暮登城望，偏令乡思悬。 | . 159_2 登江中孤屿，赠白云先生王迥 | 悠悠清江水，水落沙屿出。回潭石下深，绿筱岸傍密。 | . 159_3 晚春卧病寄张八 | 南陌春将晚，北窗犹卧病。林园久不游，草木一何盛。 | . 159_4 秋登兰山寄张五 | 北山白云里，隐者自怡悦。相望试登高，心飞逐鸟灭。 | . 159_5 入峡寄弟 | 吾昔与尔辈，读书常闭门。未尝冒湍险，岂顾垂堂言。 | . Finally, we also need to know that conversion between Pandas column and Numpy array is very simple. We can basically call the column and .values. Then we get our array. . For example, we try to convert our title column to array. . df2.title.values[:5] # first 5 items . array([&#39; 从张丞相游南纪城猎，戏赠裴迪张参军&#39;, &#39; 登江中孤屿，赠白云先生王迥&#39;, &#39; 晚春卧病寄张八&#39;, &#39; 秋登兰山寄张五&#39;, &#39; 入峡寄弟&#39;], dtype=object) . . . Data Analysis . After performing some basic processing of our data, let&#39;s try to do some analysis based on what we have. Let&#39;s say, we want to understand how the key words of season have been used in the text. How many times have they been used and how are they distributed? At the end we want to use the results to make a bar chart and a dispersion plot using matplotlib. We will learn much more about visualization later, but we now we will stick with the simple plots. . In case we still have rows with missing values, we use dropna() again to clean our data frame. . df2 = df2.dropna(how=&quot;any&quot;,axis=&quot;index&quot;) # this is for dropping all missing values in the rows . Then we calculate the word offset. It is done by geting the length of strings in the content column (.len()) and calculate the cumulative sum of it (.cumsum()). It means that now the values in the rows is not the length of the one title, but the word offset starting from the first character of the first title. We use it as our word offset for the plot later. With (.to_numpy()) we get the list to numpy array. . word_count = df2.content.str.len().cumsum().to_numpy() word_count[:5] . array([ 26, 52, 78, 104, 130]) . Now we want to look for the keywords for every season. We do it using the find() function and convert the list to numpy. The same apply to every season. . spring_count = df2.content.str.find(&#39;春&#39;).to_numpy() # for spring spring_count[:5] . array([-1, -1, 4, -1, -1]) . summer_count = df2.content.str.find(&#39;夏&#39;).to_numpy() # for summer summer_count[:5] . array([-1, -1, -1, -1, -1]) . autumn_count = df2.content.str.find(&#39;秋&#39;).to_numpy() # for autumn autumn_count[:5] . array([-1, -1, -1, -1, -1]) . winter_count = df2.content.str.find(&#39;冬&#39;).to_numpy() # for winter winter_count[:5] . array([-1, -1, -1, -1, -1]) . Then, we use list comprehension and enumerate() to loop through all items and the index in the array, and save (index + word offset) that is not equal to one. . The value that printed out can be understood as the total word offset of that character starting from the first title. For example, from the next cell we can tell &quot;春&quot; appears in the 82th, 198th, 660th, ... characters. . spring_occur = np.array([v + word_count[i] for i, v in enumerate(spring_count) if v != -1]) # for spring spring_occur . array([ 82, 198, 660, 826, 1094, 1690, 1749, 2077, 2177, 2183, 2333, 2781, 2853, 3302, 3681, 4091, 4249, 4321, 4351, 5190, 5259, 5297, 5765, 5902, 6065, 6523, 6571, 6805, 6821]) . summer_occur = np.array([v + word_count[i] for i, v in enumerate(summer_count) if v != -1]) # for summer summer_occur . array([ 407, 3204, 3897]) . autumn_occur = np.array([v + word_count[i] for i, v in enumerate(autumn_count) if v != -1]) # for autumn autumn_occur . array([ 366, 1949, 2347, 3455, 3743, 5504, 5649, 6850]) . winter_occur = np.array([v + word_count[i] for i, v in enumerate(winter_count) if v != -1]) # for winter winter_occur . array([], dtype=float64) . . . Basic Data Visualization . Afterwards, we have our arrays which store information about the occurences of season keywords. We can make a plot out of it using matplotlib. The dispersion plot we are making is based on scatter plot. We will thus do a scatter plot for every season with custom marker styles. . import matplotlib.pyplot as plt # import library fig, ax = plt.subplots(figsize=(15,3)) # create an empty plot with defined size # in the scatter plot function (plt.scatter()), we need X for 1st argument and Y for 2nd argument. # for X we will put the word offset values for keyword occurence, for Y we will put a constant value from 1 to 4 # because we want the same season in the same row # np.ones() creates 1 with defined shape, in this case the shape is [length of X,1] spring_y = 1*np.ones([len(spring_occur),1]) # all 1 (1*1) summer_y = 2*np.ones([len(summer_occur),1]) # all 2 (2*1) autumn_y = 3*np.ones([len(autumn_occur),1]) # all 3 (3*1) winter_y = 4*np.ones([len(winter_occur),1]) # all 4 (4*1) # scatter plot plt.scatter(spring_occur,spring_y, marker=5, s=100, alpha=0.8) # first scatter plot for spring, alpha is transparency of the markers plt.scatter(summer_occur,summer_y, marker=5, s=100, alpha=0.8) # for summer plt.scatter(autumn_occur,autumn_y, marker=5, s=100, alpha=0.8) # for autumn plt.scatter(winter_occur,winter_y, marker=5, s=100, alpha=0.8) # for winter # set y limits plt.ylim(0.8, 4.5) # we want our y labels as text, not number. so here we define them. plt.yticks(np.arange(0,5,1)) labels = [&#39;&#39;,&#39;Spring&#39;, &#39;Summer&#39;, &#39;Autumn&#39;, &#39;Winter&#39;] ax.set_yticklabels(labels, fontsize=12) # no plot frame is needed plt.box(False) # labels and title plt.xlabel(&quot;Word Offset&quot;, fontsize=14) plt.ylabel(&quot;Season Keywords&quot;, fontsize=14) plt.title(&quot;Lexical Dispersion&quot;, fontsize=16) . Text(0.5, 1.0, &#39;Lexical Dispersion&#39;) . . On another hand, we can also make a bar chart by simply showing the occurence frequency of keywords. . We use count() of the content column from df2 to count the occurence. We need to add sum() to sum up count for all rows, not single row. . spring = int(df2.content.str.count(&#39;春&#39;).sum()) # spring spring . 29 . summer = int(df2.content.str.count(&#39;夏&#39;).sum()) # summer summer . 3 . autumn = int(df2.content.str.count(&#39;秋&#39;).sum()) # autumn autumn . 8 . winter = int(df2.content.str.count(&#39;冬&#39;).sum()) # winter winter . 0 . Now, we can use our results to make another data frame. We do it because having results in a separate data frame make visualization easier. . count = {&#39;season&#39;: [&quot;spring&quot;, &quot;summer&quot;, &quot;autumn&quot;, &quot;winter&quot;],&#39;count&#39;: [spring, summer, autumn, winter]} season = pd.DataFrame.from_dict(count) # set season as index season = season.set_index(&quot;season&quot;) season.head() . count . season . spring 29 | . summer 3 | . autumn 8 | . winter 0 | . In order to have Chinese characters shown in our plot, we need to download a package and change the font from the Python library. Please just follow the follow code. . !wget -O TaipeiSansTCBeta-Regular.ttf https://drive.google.com/uc?id=1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_&amp;export=download # import library import matplotlib as mpl import matplotlib.pyplot as plt from matplotlib.font_manager import fontManager # change font setting fontManager.addfont(&#39;TaipeiSansTCBeta-Regular.ttf&#39;) mpl.rc(&#39;font&#39;, family=&#39;Taipei Sans TC Beta&#39;) . --2021-12-12 20:09:06-- https://drive.google.com/uc?id=1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_ Resolving drive.google.com (drive.google.com)... 142.250.81.206, 2607:f8b0:4004:82f::200e Connecting to drive.google.com (drive.google.com)|142.250.81.206|:443... connected. HTTP request sent, awaiting response... 302 Moved Temporarily Location: https://doc-0k-9o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/6nfeiuvrhp3la80n9pg1oja3jsktcq6e/1639339725000/02847987870453524430/*/1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_ [following] Warning: wildcards not supported in HTTP. --2021-12-12 20:09:10-- https://doc-0k-9o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/6nfeiuvrhp3la80n9pg1oja3jsktcq6e/1639339725000/02847987870453524430/*/1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_ Resolving doc-0k-9o-docs.googleusercontent.com (doc-0k-9o-docs.googleusercontent.com)... 142.250.73.193, 2607:f8b0:4004:829::2001 Connecting to doc-0k-9o-docs.googleusercontent.com (doc-0k-9o-docs.googleusercontent.com)|142.250.73.193|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 20659344 (20M) [application/x-font-ttf] Saving to: ‘TaipeiSansTCBeta-Regular.ttf’ TaipeiSansTCBeta-Re 100%[===================&gt;] 19.70M 35.2MB/s in 0.6s 2021-12-12 20:09:11 (35.2 MB/s) - ‘TaipeiSansTCBeta-Regular.ttf’ saved [20659344/20659344] . Having a Pandas data frame make visualization simple. We can basically call the dataframe with .plot., followed by the type of plot we want to have. For example, a bar chart is (name of dataframe).plot.bar(). . plt.figure(figsize=(18,6)) # bar chart season.plot.bar(rot=0, color=&quot;#830045&quot;) # labels and title plt.xlabel(&quot;Season&quot;, fontsize=15) plt.ylabel(&quot;Occurence&quot;, fontsize=15) plt.title(&quot;Description of season in n孟浩然诗 卷一百五十九 and 卷一百六十?&quot;, fontsize=15) # remove legend and add keywords in the x-axis ax = plt.gca() ax.set_xticklabels([&#39;春&#39;,&#39;夏&#39;,&#39;秋&#39;,&#39;冬&#39;], fontsize=16) ax.get_legend().remove() # adjust spacing in plot plt.tight_layout() . &lt;Figure size 1296x432 with 0 Axes&gt; . . Previous Lesson: Regular Expression . Next Lesson: Pandas Numerical Operation . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: December 2021 . . . . References: . Jieba . Displaying Chinese characters . Python Data Science Handbook .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/level-2/chapter-2/data-manipulation/pandas/2020/01/23/Pandas_TextAnalysis_TextOriganization.html",
            "relUrl": "/level-2/chapter-2/data-manipulation/pandas/2020/01/23/Pandas_TextAnalysis_TextOriganization.html",
            "date": " • Jan 23, 2020"
        }
        
    
  
    
        ,"post16": {
            "title": "Regular Expression",
            "content": ". This notebook aims to introduce users how to use regular expression to extract useful information from text in Python which would be from documents or websites. . Presumption: . . . Before starting with this tutorial, please watch this video beforehand so that you would already understand: . 1) What is group method in regular expression? . 2) What is a raw string? . 3) How to create a character set? . 4) What is the function of quantifiers? . . . Review . Here is the summary tables from the video: . Syntax Meanings . . | Any Character Except New Line | . d | Digit (0-9) | . D | - Not a Digit (0-9) | . w | - Word Character (a-z, A-Z, 0-9, _) | . W | - Not a Word Character | . s | - Whitespace (space, tab, newline) | . S | - Not Whitespace (space, tab, newline) | . Syntax Meanings . b | Word Boundary | . B | Not a Word Boundary | . ^ | Beginning of a String | . $ | End of a String | . [] | Matches Characters in brackets | . [^ ] | Matches Characters NOT in brackets | . Vertical bar | Either Or | . ( ) | Group | . . Quantifiers Meanings . * | 0 or More | . + | 1 or More | . ? | 0 or One | . {3} | Exact Number | . {3,4} | Range of Numbers (Minimum, Maximum) | . Information Retrieval . ## re | . Before we analysis any text, the relevant information need to be first extracted to exclude all irrelavant information. And sometimes it is not very straight-forward and the text might be mixed with other information, particularly when the text are mined from online sources. . Below we can look at an exmaple of an entry extracted from Historical GIS for Japan. We can see the information are in multiple rows with each row giving different information. If we only aim for one piece of information, it might be easy to copy in one entry but the task gets challenging once we have thousands of them. This is why text mining can be helpful to save us time and effort. . . First of all, we have to import the library. . import re . lord_entry = &quot;&quot;&quot; name: abemasaharu n vernacular name definition kanji: 阿部正春 n alternate vernacular name definition hiragana: あべまさはる n feature type definition feature type: feudal lord 大名 daimyo n date range definition date range: 1664 to 1664 n time slice definition valid as: time slice 年份 n present location definition present location: 岩槻市 iwatsukishi n point id definition point id: jp_dmy_40 n data source definition data source: JP_CHGIS n feature type definition coordinate type: centroid n feature type definition latitude: 35.93 n feature type definition longitude: 139.70 n admin hierarchy definition admin hierarchy: 武蔵国 musashi no kuni &quot;&quot;&quot; . Name . Here we can try to get the kanji name of the entry. . From what we have learnt, we can use the group option to get the first group kanji: at the word boundary ( b) followed with space ( s) and everything (regardless of length) behind it. Using pattern1, we have the name we need in the second group. . We will use re.compile() to define our pattern, then use findall() to look for all matches. . pattern1 = re.compile(r&#39;( bkanji: s)(.*)&#39;) match1 = pattern1.findall(lord_entry) # get all matches match1 # print them out . [(&#39;kanji: t&#39;, &#39;阿部正春&#39;)] . We can then access the first element of list [0] (there is only one element) and second element of the tuple [1]. . match1[0][1] . &#39;阿部正春&#39; . Alternative: Lookaround . However, we can also use lookaround method from re, which mean we use &quot;kanji:&quot; to identify what we search for (behind the keyword) but we do not select &quot;kanji: &quot; itself because it is not important for us. . . Be careful, space might not be obvious, it is also count as the element in the string by Python so we always need to address them too. . . . Given the string &quot;foobarbarfoo&quot;: . . bar(?=bar) finds the 1st bar (&quot;bar&quot; which has &quot;bar&quot; after it) . bar(?!bar) finds the 2nd bar (&quot;bar&quot; which does not have &quot;bar&quot; after it) . (?&lt;=foo)bar finds the 1st bar (&quot;bar&quot; which has &quot;foo&quot; before it) . (?&lt;!foo)bar finds the 2nd bar (&quot;bar&quot; which does not have &quot;foo&quot; before it) . . They can also be combined: . (?&lt;=foo)bar(?=bar) finds the 1st bar (&quot;bar&quot; with &quot;foo&quot; before it and &quot;bar&quot; after it) . . Here we use (?&lt;=text1)text2 to select text 2 from identifying text 1, in which text 1 is before text 2 in the text. . pattern2 = re.compile(r&#39;(?&lt;=kanji: s).*&#39;) match2 = pattern2.findall(lord_entry) match2 . [&#39;阿部正春&#39;] . Coordinates . Now, we can try to get the latitude and longitude from the lord (For example, when we need them for making a map in GIS). Since we have already learnt the principle, the code we need is indeed very similar. . #### Latitude | . lat_pattern = re.compile(r&#39;(?&lt;=latitude: s).*&#39;) match = lat_pattern.findall(lord_entry) match . [&#39;35.93&#39;] . We need to be careful here. Normally when we think of coordinates, we expect a floating number. But here what we get (match) is a list. It will cause errors if we later directly use the list for any geospatial operations. So always check the type. . type(match) # it is a list . list . type(match[0]) # we can get the first item of list to remove [], now it is a string . str . We need to further convert the string into float using float(). . type(float(match[0])) . float . lat = float(match[0]) # save the final result to lat lat . 35.93 . Now we get what we need! Let&#39;s do the same for longitude. . #### Longitude | . lon_pattern = re.compile(r&#39;(?&lt;=longitude: s).*&#39;) match = lon_pattern.findall(lord_entry) match # list . [&#39;139.70&#39;] . lon = float(match[0]) lon # float . 139.7 . Chinese Characters . Here is another small text from 韓愈. Now for Chinese characters, we can use unicode characters to select a specific type of characters. . . The ranges of Unicode characters which are routinely used for Chinese and Japanese text are: . U+3040 - U+30FF: hiragana and katakana (Japanese only) . | U+3400 - U+4DBF: CJK unified ideographs extension A (Chinese, Japanese, and Korean) . | U+4E00 - U+9FFF: CJK unified ideographs (Chinese, Japanese, and Korean) . | U+F900 - U+FAFF: CJK compatibility ideographs (Chinese, Japanese, and Korean) . | U+FF66 - U+FF9F: half-width katakana (Japanese only) . | . text = &quot;或問諫議大夫陽城於愈：可以為有道之士乎哉？學廣而聞多，不求聞於人也，行古人之道，居於晉之鄙，晉之鄙人薰其德而善良者幾千人。大臣聞而薦之，天子以為諫議大夫。人皆以為華，陽子不色喜。居於位，五年矣，視其德如在野，彼豈以富貴移易其心哉！&quot; . pattern = re.compile(r&#39;[ u4e00- u9fff]+&#39;) match = pattern.findall(text) match . [&#39;或問諫議大夫陽城於愈&#39;, &#39;可以為有道之士乎哉&#39;, &#39;學廣而聞多&#39;, &#39;不求聞於人也&#39;, &#39;行古人之道&#39;, &#39;居於晉之鄙&#39;, &#39;晉之鄙人薰其德而善良者幾千人&#39;, &#39;大臣聞而薦之&#39;, &#39;天子以為諫議大夫&#39;, &#39;人皆以為華&#39;, &#39;陽子不色喜&#39;, &#39;居於位&#39;, &#39;五年矣&#39;, &#39;視其德如在野&#39;, &#39;彼豈以富貴移易其心哉&#39;] . We can also look for every character instead: . pattern = re.compile(r&#39;[ u4e00- u9fff]&#39;) match = pattern.findall(text) match[:5] # print first 5 characters only . [&#39;或&#39;, &#39;問&#39;, &#39;諫&#39;, &#39;議&#39;, &#39;大&#39;] . Here is another example entry from 清代檔案. Here let&#39;s say we want to extract the time from the document. . text = &quot;&quot;&quot; 撥給各種工匠銀乾隆01年8月 --內務府奏銷檔 第1筆 事由：撥給各種工匠銀 內文：雍正十三年四月起至 乾隆 元年五月給發匠役工價所用大制錢數目 郎中永保等文開恭畫坤寧宮神像需用外僱畫匠畫短工九十五工每工錢一百三十四文領去大制錢十二串七百三三十文 銀庫郎中邁格等據掌儀司郎中謨爾德等文開恭造坤寧宮祭祀所用鏨花銀香碟八個爵盤二個漏子一個格漏一個箸一雙匙三張小碟二十個鍾十一個大碗五個壺一把大小盤二十四個鑲銀裹楠木肉槽四個三鑲烏木箸二雙畫像上用掛釣三分亭子上用銀面葉一分需用外僱鏨花匠大器匠做短工七百九十一工四分五厘每工錢一百三十四文領去大制錢一百六串五十四文 ... 時間：乾隆01年8月 官司： 官員： 微捲頁數：173-194 冊數：194 資料庫：內務府奏銷檔案 &quot;&quot;&quot; . We can also perform a quick retrieval using what we have just learnt. . pattern = re.compile(r&#39;(?&lt;=時間.).*&#39;) match = pattern.findall(text) match . [&#39;乾隆01年8月&#39;] . Combining with Web Scrapping, which we will learn later, we can then easily get information for text analysis. . . Previous Lesson: List Comprehension . Next Lesson: Pandas Text Analysis . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: December 2021 . . . . References: . https://github.com/CoreyMSchafer/code_snippets/blob/master/Python-Regular-Expressions/snippets.txt . https://stackoverflow.com/questions/2973436/regex-lookahead-lookbehind-and-atomic-groups . https://stackoverflow.com/questions/43418812/check-whether-a-string-contains-japanese-chinese-characters .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/re/level-2/chapter-2/2020/01/22/Regular_Expression_TextExtraction.html",
            "relUrl": "/re/level-2/chapter-2/2020/01/22/Regular_Expression_TextExtraction.html",
            "date": " • Jan 22, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About",
          "content": "Introduction to Python Programming . Hi! This is Ka Hei. This space is created at the end of 2021 for introducing users in the humanities to pick up some basic programming skills📍 for research using digital text resources. You do not need to have any programming knowledge when you start with the tutorials. It covers tasks from data acquisition, analysis to visualization, working with both text📜 and geospatial data🗺️. All tutorials use (historical) Chinese text to demonstrate workflows of relevant tasks (sometimes mixed with examples from other languages, eg. Japanese, Korean, and English). . . Instructions . WHY this space? . 🔎 Instead of introducing users to diverse tools (Javascript, HTML, CSS, Jekyll, R etc.), it only focus on ONE: PYTHON, which can be used to approach a wide range of tasks (without knowledge of other tools) . 🔎 All tutorials can be run in the Colab cloud environment so NO ENVIRONMENT SET UP AND INSTALLATION in the local device needed. It also MINIMIZE UNINSTRUCTED STEPS (eg. downloading and preprocessing files on your own) so that everyone can follow along. . 🔎 Instead of being application-oriented (Network analysis, Geocode data, supervised classification, etc.), it starts from the basics and slowly introduce users different analysis concepts in a SYSTEMATIC manner . 🔎 It focuses on applications in CHINESE language and history to give users in this discipline more concrete instructions . . This is the RIGHT space for you if: . ⭐ You are NEW TO PROGRAMMING and do not know WHERE TO START . ⭐ You want to pick up ONE TOOL FIRST for digital humanity which can handle MOST of the task . ⭐ You find it difficult to follow existing tutorials and want to DO IT BIT BY BIT FROM THE SCRATCH . ⭐ You are STUCK with downloading and installing digital tools . ⭐ You want to learn a tool that DO NOT NEED A LICENSE and is ALWAYS FREELY AVAILABLE . ⭐ You want to have a BIG PICTURE what can you ACHIEVE with the digital tools . . This is NOT the RIGHT space for you if: . 🤔 You MASTER PROGRAMMING already and wish to harness the potential of multiple programming languages . 🤔 You do NOT appreciate FREE OPEN SOURCE TOOLS . 🤔 You prefer a VERY STEEP LEARNING CURVE . 🤔 You are NOT PREPARED for consistent learning for the NEXT MONTHS . . Tutorial Summary: . 🕹️ Introduction to Python Programming . 🕹️ Plotting and Interactive Data Visualization . 🕹️ Data Manipulation using Pandas . 🕹️ Web Scrapping and Text Analysis . 🕹️ Working with Geospatial Data . . Python Libraries covered: . beautifulsoup4, Bokeh, geopandas, folium, matplotlib, networkx, numpy, pandas, seaborn, urllib2, requests, re, SnowNLP, SpaCy, jieba, dash, plotly . . You will be ABLE to: . 👍 Write simple PYTHON CODE that fit your purposes (Oh what is your purposes? 😃) . 👍 Create some INTERACTIVE contents/ graphics to present results . 👍 Have your first WEBMAP! . 👍 Know how to dive into DIGITAL DATABASE yourself without browsing around . . You will NOT be ABLE to: . 🙅‍♀️ Know how to make a dynamic and highly interactive website yourself just by following the tutorials . 🙅‍♀️ Know how to start with a project yourself if you only read the code, but not practice . 🙅‍♀️ Debug all the potential problems just by following the tutorials, use GOOGLE and stackoverflow! . 🙅‍♀️ FLY!! 🐤 . . How to use this Space 🚀: . All code displayed on this webpage is available as Jupyter Notebook and it is highly recommanded that you download them and try it out by yourself. . | If you are new to Colab, pleaese first click on Colab and begin your journey. There are two options to open the notebooks in Colab: . 1) Recommanded Option: Go to the page for the lesson here. Right under the tags, there are four icons. Click on option “Open in Colab”. You will be then able to view the notebook in Colab. . 2) Alternative: Download the notebook you need from this page. Search for the right title, right click and select “save link as”. You will be able to download the Jupyter Notebook with the file extension “.ipynb” (You do not need an account in GitHub but it is recommanded that you sign up). Go back to Colab and click File -&gt; Upload notebook, select the notebook you just downloaded. Now you can run the notebook by yourself and start your coding journey. . | ALL the tutorials provided here is ordered by LEVELS (lv1: the easiest, lv4: the most difficult) and it is recommanded to FOLLOW THE ORDER when you go through them . | There are PREREQUISITES for almost all of the tutorials so please FOLLOW the links before you start with the content . | There are REFERENCES in all the introduced concepts so feel free to read external resources before you continue . | The tutorials do NOT COVER all possibilities or functionalities of the Python libraries so please do not solely depends on them . | PRACTICE is the only way to go! So TYPE THE CODE by yourselves and TRY to change some options and run them again. . | Inputs and potential outputs from the tutorials are available in the data folder. . | Additional notebooks for references only are available in the additional folder. . | . . Please pay attention 💡: . Some chapters are currently still under construction. . | This space is set up volunarily with limited time so please be understanding of the typo and writing mistakes not yet corrected. . | . .",
          "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  
      ,"page2": {
          "title": "Gallery",
          "content": "Here some example figures from the tutorials are displayed. After you follow the tutorials, you will be able to create them. . . Bubble Chart . This is an interactive bubble chart plotted using Plotly together with a simple Pandas data frame. It shows the population (y-axis) and territory size (bubble size) (colored by maximum longevity of emperors) in different Chinese dynasties. . . . . Scatter Plot . This is a simple scatter plot using Matplotlib and customized layout options. It shows how season keywords distribute in 孟浩然诗全集. . . . Network Chart . This is a simple network chart created using NetworkX library in Python. It shows the relationsip between historical figures. . . . Stacked Area Plot . This is a variation of a stacked area plot created using seaborn. It shows development of UNESCO sites over time for the top ten countries having the most UNESCO sites. . . . Bubble Time Line . Using the same UNESCO example, this is a bubble chart showing the same temporal development. Yet, more information is embedded in the interactive hover labels using Plotly. . . . Chinese Word Cloud . This is a word cloud created using wordcloud library together with jieba for processing Chinese texts. It shows the keywords generated from《杯酒释兵权考》by 丁则良. . . . Circle Packing Chart . This is a circle packing chart displaying the distribution of family name in Song Dynasty, created using Circlify. . . . Color Stripes . These are color stripes illustrating the occurences of wars in ancient China, created using Plotly. . . . Wind Rose Chart . These is a polar bar chart created using Plotly. . . . (More coming soon …) . 📊 Happy Coding! .",
          "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/gallery/",
          "relUrl": "/gallery/",
          "date": ""
      }
      
  

  

  
      ,"page4": {
          "title": "Resources",
          "content": "Here you can find some recommanded external resources for further learning. . . Python Programming 🐍 . ➼ Python for Digital Humanity . ➼ Introduction to Cultural Analytics &amp; Python . ➼ Data Camp . ➼ free code camp . ➼ Corey Schafer Youtube Channel . ➼ Data Science for Everyone . . Chinese Digital Database 📙 . ➼ 中國哲學書電子化計劃 . ➼ CBDB . ➼ 皮书数据库 . ➼ 臺灣文獻叢刊資料庫系統 . ➼ 寶卷新集 . ➼ 明實錄、朝鮮王朝實錄、清實錄資料庫合作建置計畫 . ➼ 中国方志库 . ➼ 明淸婦女著作 . ➼ 中研院臺灣史研究所 . ➼ 中研院近史所 . ➼ 清代職官資料庫 . ➼ 維基文庫 . . Chinese GIS 🗺️ . ➼ CHGIS . . Click here for more resources… .",
          "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/resources/",
          "relUrl": "/resources/",
          "date": ""
      }
      
  

  
  

  

  
  

  

  
  

  
  

  

  

  

  
  

  
      ,"page15": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}
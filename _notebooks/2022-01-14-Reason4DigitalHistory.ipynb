{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reason4DigitalHistory.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# \"Seven Reasons to Learn Python for Historical Research\"\n",
        "> \"Knowledge sharing using open-source languages\"\n",
        "\n",
        "- toc: true \n",
        "- badges: true\n",
        "- comments: true\n",
        "- categories: [level-1, chapter-1, background]\n",
        "- image: images/earth.jpg"
      ],
      "metadata": {
        "id": "9pV9ldSHOM_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![]({{site.baseurl}}/images/dh.png \"Workflow for Digital History\")"
      ],
      "metadata": {
        "id": "x6fScwMplHbZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1) Process Text in any Digital Formats** üìú\n",
        "\n",
        "Doing research often requires working with different media formats in this digital age, regardless of what your research interests are. Even you are not working with a large number of data sources, you might either need to work with long texts or sources that offer only in digital formats. Meanwhile, you might want to output your research in a digital format. \n",
        "\n",
        "Either you might want to write your blog for your projects, or you need to process text in pdf format, Python is a useful tool to **READ**, **PROCESS**, and **CONVERT** between different digital formats. Sometimes you might download historical data in Stata Data File Format (.dta), other times what you have is a large CSV file. When you try to do a specific task, you might search for online tools which often is not free or is not convenient (For example, you might need to process the file one by one). Learning Python enable you to gain **multiple skills** working with different data formats, including but not limited to **txt**, **XML**, **csv**, **xlsx**, **json**, **geojson**, **shp**, **pdf**, and **dta**. Reading those format is the first step of everything coming after, such as cleaning them or filtering them.\n",
        "\n",
        "One of the most popular libraries for working with tabular data is **Pandas**. In contrast to Excel, you can use Pandas to work with CSV files with millions of rows in ease. You do not need to manually select any cells or deal with missing values. Similar to Excel, you can also create graphics from the table using Pandas. The difference is that you have way more controls on the layouts and types of visualization.\n",
        "\n",
        "Python is one of the programming languages having the most **readable syntax** and the largest **open source community** to support and contribute. Programming is not an individual task, it requires resources from others: either to fix a bug, find a realistic solution, or use libraries or code written by someone else. It is why having a large community make it easier to get the job done."
      ],
      "metadata": {
        "id": "UTnMGt8s7DB1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2) Access Digital Data without Barriers** üõë\n",
        "\n",
        "With the growth of digital humanities or digital history, more and more historical sources have been stored and published in a digital format, such as [**ÊòéÊ∏ÖÂ¶áÂ•≥Ëëó‰Ωú**](https://digital.library.mcgill.ca/mingqing/chinese/index.php) and [**‰∏≠ÂõΩÂéÜ‰ª£‰∫∫Áâ©‰º†ËÆ∞ËµÑÊñôÂ∫ìCBDB**](https://projects.iq.harvard.edu/chinesecbdb). Depending on the website and the nature of the data, the download format will also change (.mdb, csv, etc.). Sometimes the data you are looking for is not systematically stored, which might also require some **web scraping**, such as grabbing tables on a webpage (In this case you can use **beautifulsoup** or **selenium**). No matter how and in what format your data is stored, you can always access them using Python.\n",
        "\n",
        "Data access does not simply mean copying the resources, but also having them in a structural framework so you can use them effectively. By reading the data in a structured way, you can clean the irrelevant information, filter items that fit your interests without any manual effort. For example, you can clean all the empty rows, or convert your table from long to wide format. Python is even more advantageous when you work with **time series** or **spatial data** owing to its powerful libraries **Pandas** and **Geopandas**. With the geospatial libraries, you can easily perform geospatial operations and **make maps** just like in geographic information system (GIS). "
      ],
      "metadata": {
        "id": "hjw58JVy8Lqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3) Have a Big Picture with Data Collection** üñºÔ∏è\n",
        "\n",
        "Amid the ongoing information explosion, we do not simply have much more information for the current time, but also much more digitalized data from the past with the emerging **digital scholarship** projects. Although big data offers us more material to conduct research, often it is not realistic for us to work with a large amount of data, for instance, thousands of novels/ publications. We might solely want to filter very little information from the data pool or have an overview of all materials. We can achieve it by performing **topic modelling**, counting the frequency of keywords, or computing statistics. \n",
        "\n",
        "Using machine learning, we can also perform unsupervised clustering on the texts for categorization. The mentioned approaches require different skills in **text mining**, **big data analysis**, and **NLP**. With Python, we can smoothly combine multiple domains in a single script. Learning a new tool always takes time. Hence, the best is to select tools that can reasonably perform most tasks. With the aid of Python, you can easily save time for the redundant tasks."
      ],
      "metadata": {
        "id": "mPkysIWe8dFY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4) Understanding Patterns in a Systematical way** üï∏Ô∏è\n",
        "\n",
        "Machine reads differently than human eye. It is also why **distant reading** or **Natural language processing (NLP)** can aid with historical text analysis. By aggregating and analyzing massive amounts of data, we can observe the patterns of texts in a large scale, for example, some formal aspects of literature. It aims to have a more abstract view of the texts by visualizing their global features. One of the technique is **Term Frequency(TF) ‚Äî Inverse Dense Frequency(IDF)** used to classify text resources. Other techniques include **sentiment analysis** and **text similarity metrics**. It can also be combined with different elements such as **geospatial maps** to visualize geographical information. All these can be easily implemented in Python suiting to your research needs. "
      ],
      "metadata": {
        "id": "wwrMWLl-8rB5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5) Visualize Data from Infographics to Map** üó∫Ô∏è\n",
        "\n",
        "Research using historical data does not end with text analysis. Often, particularly if you are an expert of your data, you need to communicate with the audience, either your coworkers, students, fellow researchers, or the funding agencies. To achieve it, you can create **charts for your publication**, **infographics** to put on the social media, or making a simple **web application**, with interactive figures and maps to allow more involvements from the audience. \n",
        "\n",
        "Python provides multiple plotting libraries, from [**Matplotlib**](https://matplotlib.org/2.0.2/index.html), [**Seaborn**](https://seaborn.pydata.org/examples/index.html) to [**Plotly**](https://plotly.com/python/). Not only can they produce publication-quality figures, but also different types of data visualization. You can decide if you wish to have **animation** or **interactive dashboard**. You can even build your web application with embedded text, graphics, and **web map**."
      ],
      "metadata": {
        "id": "nS-lzaxI9VGI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6) Customize to your research needs** üõ†Ô∏è \n",
        "\n",
        "The specific tasks for histircal research are diverse, and often there are not yet tools doing what you exactly need. It is a pain when you realize an online tool is a bit deviated from what you expected, as there is often no way to further customize it. For instance, when you try to create a **word cloud** online, but am not satistified with the color use, the font, or simply that they do not support the language you use. Or you need to filter or clean your data in a way that is not supported.\n",
        "\n",
        "Using Python, however, there are vast choices for **customization** as long as you are willing to get your hand dirty. This does not only apply to **data visualization**, but also **data collection** and **text analysis**. Besides, thanks for the large open source community of Python, tools are available even for a relatively small niche, such as performing NLP on classical Chinese. As Python is free and open, once you learn about how to use a library, you can utilize it fully without the need to worry about licenses or subscriptions. You can also save your script, **reuse** it for another text, and freely **share** your approach with others without any barriers."
      ],
      "metadata": {
        "id": "InSVnKSAHEYH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7) Comparison to Available digital tools**\n",
        "\n",
        "Commercial tools are mostly specialised in a certain domain, and the need of a license makes them difficult to use for reproduction and to share with others. Besides, if you need one task after another, for example, from web scraping to generating word clouds to making a web application for presentation, what you might need to do is jumping from one tool to another. Using open-source programming languages, however, provide you with **FLEXIBILITY** for **CUSTOMIZATION** and **INTEGRATION** so that you can perform all tasks seamlessly.\n",
        "\n",
        "**R** is another programming language very popular among researchers, as it is for statistical computing and research. Similar to Python, it has a large community and can perform similar tasks: data wrangling, data visualization, feature selection web scrapping, app and so on. Both of the languages share many tools, for example, **spacyr** provides a convenient R wrapper around the **Python spaCy** for distant reading and **plotnine** is a Python implementation of **R ggplot**. Many useful libraries also support both languages, for example, **Plotly** for interactive plotting and **Jieba** for Chinese NLP. In fact, **R** and **Python** can even be bridged together using **rpy2** and **reticulate**. \n",
        "\n",
        "It needs to be said in advance that *both R and Python have their strengths and weaknesses*. Different to R, Python is a general-purpose language. It focuses on deployment and production. Hence, while R suits well for ad-hoc analysis, when it comes to building a product from **machine learning**, or **text processing** which is often needed before any data analysis can be done, Python can be a better choice. \n"
      ],
      "metadata": {
        "id": "M92mgbLS_eYD"
      }
    }
  ]
}
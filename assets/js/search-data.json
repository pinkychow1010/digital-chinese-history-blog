{
  
    
        "post0": {
            "title": "Chinese Keyword Extraction using Jieba",
            "content": "Hello. keyword extraction is one of the very popular technique in Natural Language Processing (NLP). It aims to extracting the most relevant words and expressions from text which can be further used to compare or summarize the text. Word clouds is also another example of keyword extraction. In this lesson we will learn about how to extract keywords in Chinese text using Python library Jieba. . As mentioned in the instructions, you can click on the icon &quot;open in Colab&quot; to open the scirpt in a Jupyter notebook to run the code. It is highly recommended to follow the tutorials in the right order. . Set Up Environment . First of all, we have to set up our cloud environment in colab. . Python Library . Download Library . The main library we need, Jieba, can be downloaded in Colab using pip. . ! pip install jieba . Requirement already satisfied: jieba in /usr/local/lib/python3.7/dist-packages (0.42.1) . Import Libraries . We will then import Jieba and other libraries we need. . from __future__ import unicode_literals import sys sys.path.append(&quot;../&quot;) import jieba import jieba.posseg import jieba.analyse import pandas as pd import matplotlib.pyplot as plt import numpy as np from skimage import filters import time . Google Drive . Connect to Google Drive . In order to access resources in your own Google Drive, we have to give the permission by running the following code. . from google.colab import drive drive.mount(&#39;/content/drive/&#39;) . Mounted at /content/drive/ . Download Resources using wget . In this lesson, there are two materials we need to download from the web. The first one is the Chinese font which we need to display characters in plot. The second one is a list of Chinese stopwords which we need for the tokenization. We can access both of them using wget. . Download Chinese Font . !wget -O TaipeiSansTCBeta-Regular.ttf https://drive.google.com/uc?id=1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_&amp;export=download # after download, we have to add the font into the plotting library # we need matplotlib.font_manager for that import matplotlib as mpl import matplotlib.pyplot as plt from matplotlib.font_manager import fontManager fontManager.addfont(&#39;TaipeiSansTCBeta-Regular.ttf&#39;) mpl.rc(&#39;font&#39;, family=&#39;Taipei Sans TC Beta&#39;) . Download Chinese Stopword List . From the github link, we can access the list of stopwords. . ! wget https://github.com/stopwords-iso/stopwords-zh/blob/master/stopwords-zh.txt -P /content/drive/MyDrive/ . Get our text . In this example, we will use the text from 《时差》播客 titled: 宗教学：信仰，魔法，身份，权力. You can find the source here. What we will do first is to count the frequency of keywords using simple statistics. Then, we will extract the keywords once again using TF-IDF, a specific technique for information retrieval with the use of weighing factors. Compared to the simple frequency counting methods, TF-IDF can better rank the relevance of words. . First, let&#39;s start simple. Part of the text is copied below and saved as text. . text = &#39;&#39;&#39; 郭婷：在今天节目开始之前，我想先表达一下沉痛的悼念，前几天有一位宗教学界的前辈，台大的林富士老师（1960-2021）去世了。我本来并不是研究中国宗教的，也不研究传统的中国文史哲，所以并没有和林老师见过面。但我一直从他的研究中得到灵感，所以非常感谢他。这两天也在脸书上，看到很多他过去的同事和学生对他的纪念。虽然学术界很多时候是一个有失公正的地方，但还是有一些地方让人觉得温暖，就好像点亮了一盏灯，而那盏灯一直会亮下去。 这一期我们来谈宗教学，不只是谈学界，也谈它的实践。在座几位虽然是跨学科的研究者或实践者，但也是宗教学出身。那我相信，大家在和别人介绍说自己研究宗教学的时候，通常会听到几个问题：一个是那你有没有宗教信仰？或者你研究哪一种宗教？以前还会听到的一个问题是，那你毕业之后做什么，是不是准备出家等等。 我以前会开玩笑说，对，以后出家给人算命。其实不只是学界之外，包括学界之内，不同学科对宗教学领域都会有一些陌生，因为它确实是一个比较特殊的学科。就我自己而言，我博士的训练在爱丁堡大学的神学院。爱大神学院作为一个新兴科系，比较有抗争精神和创新精神。它设立之初就是为了和传统的神学或者是和宗教有关的学科对抗，所以它非常讲究世俗化和社会科学方法。 我记得大部分宗教系的学者不论男女都打扮得非常不羁。在开会的时候，美国宗教学、尤其是圣经研究的学者尤其男性会打扮得非常闪亮，头发焗过、穿西装、带领带、鞋子都擦得很亮，但是英国宗教系的老师就穿得很随便。 而宗教学学科的训练讲究宗教和社会的关系、宗教和当下社会的关系。虽然我当时的研究是从AI人工智能切入，但其实是研究是英国的世俗化的情况。当然，在神学院也会碰到其他科系的同学，比如有旧约研究、新约研究，神学研究，然后也有一些道学博士或者是教牧学的学位。 那想请几位聊聊，你们的研究背景是怎么样的，也可以跟大家聊一下心路历程。 郑利昕：我接触的这些课程，是所谓的最传统的那种。芝加哥大学神学院的硕士英文是Master of Divinity，它不是一般的学术项目，是比较偏实践的，所以项目培养中有很多的实习、见习。芝加哥大学神学的M.A.，很多人进去的时候，都想着我以后要读宗教学或者相关学科的博士，那么读硕士是一个基本的门槛。 当我进入了项目以后，我发现它有神务硕士的项目，比较偏实践，非常有趣。在进神学院之前，我不知道学院内有这个项目，因为一般来说传统上只有基督教徒才会说以后我要作为神学人员，我需要读这个神学硕士。 但是神学院在最近10年产生了一些变化，它开始接受不同宗教的人进入神务硕士项目。所以我们班上会有基督教、犹太教、佛教、伊斯兰教、印度教，还有以人文主义者，或者人本主义者的身份进入项目的。所以我也算误打误撞进入了宗教学或者宗教实践的领域。 在进入神学院前，我是学物理的，物理博士读到一半发现人生好没有意义，我之后要去当码农了，所以想找一个有意义的专业。在寻找包括哲学、人类学之后，发现我对宗教学最感兴趣，后面又发现我最感兴趣的不是宗教学，而是宗教实践，或者说是以传统的宗教实践为启发的、一种比较广泛的社会实践的形式。 倪湛舸：利昕是在芝加哥大学读的神学硕士，我是在同样一个地方接受的宗教学教育，但是我是读完硕士去那里读的博士，芝加哥大学的神学院比较特别，它其实是一个大的宗教学中心。像刚刚提到的，芝加哥大学的硕士项目也涵盖各个宗教，虽然说起来是各个宗教，但是肯定也不会全部覆盖，只是尽力去吸纳。在博士阶段，很多年前我们是有9个项目，就像系科一样。 刚才郭婷有聊到旧约、新约研究，这些神学院的传统科目，在芝加哥大学还有宗教历史，宗教社会学，宗教人类学，当年还有宗教心理学。 在基督教之外，像宗教历史，当年有J. Z. Smith等一大帮人他们什么都做、什么都比较，现在相对来说走向了衰落，受到了批判，所以后来会有专门的伊斯兰研究。我的专业其实是叫宗教与文学，现在叫做宗教、文学与视觉艺术，又加了一个东西，想把电影包括进来，理论上也包括电影、电视、电子游戏。 不同的学校的神学院的风格也不一样，芝加哥大学可能偏向宗教学，而不是神学。相比之下，杜克、耶鲁和哈佛的神学院更加接近于神学。 郑利昕：我刚查了一下，现在的研究领域变成了11个了。包括宗教社会学，现在已经正式地变为宗教社会学与人类学。 倪湛舸：其实当年就已经很有人类学的痕迹了，我们当时都是一定要读Talal Asad，跟着Bruce Lincoln学。 郭婷：其实芝加哥神学院确实有这个传统，比较讲究宗教学传统，是比较特别的一个神学院。刚才湛舸提到的这些学者，包括芝加哥大学的J.Z. Smith，对于学宗教学的人来说，都是最经典的一些学者，大家都要读。 当然现在越来越多的神学院也好，宗教学研究也好，会去研究世界宗教和不同的宗教传统。在英国，这两年出现了一件非常有争议的事，我们当时神学院的本科课程，它有专门的一门课叫世界宗教，其实是一个殖民思维的产物，以基督教为中心，将“其它”宗教纳入“世界宗教”。这个概念现在非常有争议性，学界在努力解构它的同时提出新的范式。 后来神学院里面也有伊斯兰研究，但是还没有其他例如佛学研究，因为佛学研究跟伊斯兰、犹太教研究很多时候都属于亚洲研究，这就是区域研究和所谓的正式学科研究之间的张力。这也给学院派的研究带来了很多问题。 我们今天的另外两位嘉宾，李纪跟程晓文教授，她们的跨学科研究其实就汇合了汉学、历史学，中国研究，这些其实是存在一些交叉性的。那也想了解一下你们在进入宗教学或者是进入学术研究的时候整个的心路历程。 程晓文：我大学念的是中文系。之后在台大念硕士的时候，主修思想史。到了美国以后，我在华盛顿大学念是历史系博士，跟Patricia Ebrey开始做宋史。 真的开始披上宗教学的外衣，其实是拿到我现在这个研究东亚宗教的工作。然我来宾大的前一年，刚好在哈佛神学院做一年的研究员。所以我就可以谎称自己做的是宗教。我还记得我拿到这个工作之后，所有不管是认识我还是不认识我的人，第一个反应就是——可你又不做宗教。结果我这工作做着做着，我仿佛也做起了宗教现在我每年都教跟宗教有关的课，所以我对宗教这个东西是很感兴趣的。 其实我在大学时代是一个基本教义派的、福音派的基督教徒，是最传统的基督徒。我以前是非常认真的，那时候还去修古希腊文什么的。后来我也有一个过程，慢慢就不去教会了，然后就不认为自己是一个基督徒了。但是我对于宗教信仰这件事情，是非常可以理解的，它是一个大家需要认真看待的事情。我觉得我们不应该仅仅从社会学的角度去分析，它其实是一件非常有趣的东西。它可以让我们重新思考很多我们做研究时候会忽略的一些问题，跟我们常有的一些可能错误的假设。 郭婷：其实大家如果听“新书介绍”（new books network）这个播客的话，大家可能知道程老师最近有一本新书，在播客上有一段非常精彩的访谈，这本书是叫《神，魔，乱：没有男性的宋代女性（Divine, Demonic, and Disordered: Women without Men in Song Dynasty China）》。我当时听这本书觉得讲得非常精彩，也讲到了学术训练的一些心路历程。然后其实我们有一个共同朋友Donovan Schaefer，你们都在宗教系？ 程晓文：我在东亚系，他在宗教系。我纯粹是在东亚系。但是对当初我的职位是一个东亚宗教研究的跨系招聘，它会在不同的系设置一个跟宗教有关的职位。 郭婷：原来如此，其实是我们这种跨学科的研究者在找工作的时候经常要遇到的问题，看似好像什么都可以申请，但工作其实都要看很多机缘巧合，也要看学校现在的方向怎样的。那台湾地区的基督徒，像在台大有自己的学生团契吗？ 程晓文：它有好几个不同的教派。我的那个叫校园团契，在台湾地区也是一个全国性的机构。它的重点就是做学生工作，在中学还有大学去帮学生训练，做组织等等。还有一个团契叫学员团契，性质类似。还有一些可能像比较大的教会组织就会有自己的聚会所，它最早好像是英国的某一个兄弟会的一个分支，和倪柝声有关。当时我在的聚会所思想比较开放，我这辈子第一次听到女性主义是在那个团契里面。 郭婷：原来倪柝声的教会现在在台湾地区以这种方式生长。 我前几天还刚在看连曦老师的书。他之前有写倪柝声，在《浴火得救（Redeemed by Fire）》这本书里。之前还看过另外一本书，关于倪柝声的家人、后辈，那本书叫《上海信徒（Shanghai Faithful）》，讲到林家在福建做传教士家族的厨师，由于他的曾祖父非常聪慧，传教士便资助他的学业，让他去上海读神学院。读的是圣约翰大学，做了林语堂的同学。他的太太是倪柝声的妹妹。这本书写到许多传奇人物的真实历史。 我自己的感觉是，在中国大陆接触宗教和在台湾地区接触宗教是不同的。因为在台湾，宗教可能相对可见程度、能见程度更高，学校也有不同的团契。当然，我记得在2000年后半读大学的时候社会风气比较自由，还可以看到非常多韩国的传教士。有很多华人研究宗教学的朋友，其实都是因为教会的关系接触到宗教。 可惜我不是这样，大家都问我是因为什么原因接触宗教学，其实我是因为一个人工智能的问题。我本科读的也是宗教学，有宗教哲学这门课，课上提到说如果一个人出了车祸，他的脸都被烧毁了，然后医生给他换了一张脸，他在镜子里面不认识自己，他还是不是他？就是一个人格同一性的问题。当时我就说，天哪，世上有那么有趣的问题，如果我出车祸，我还是不是我，我一定要研究这个问题。 当时就问老师，我要研究这个问题，我应该进哪一个学校，进哪一个科系研究。结果当时不知道谁说你应该研究人工智能，这是人工智能哲学的问题。后来我申请学校的时候就选了人工智能哲学方向，谁知道人工智能其实是非常理工科的，我就花了非常多的时间去研究科学史和人工智能哲学，后来才渐渐进入了宗教学的领域。 再请李纪老师来聊一下是怎么从历史学进入宗教学这个领域的。 李纪：谢谢郭婷，刚才晓文老师说她是离宗教最远的，其实我本来也想说这句话。我的求学经历很简单，我从本科、硕士到博士都一直是历史系。我在北京大学历史系读了本科和硕士，我的本科专业是法国史，本科毕业论文是关于法国大革命的。在我那个年代，我的法国史老师是国内法国研究的权威，但是ta接受的法国史的系统训练还是传统的革命史研究，当时宗教是不进入法国大革命研究的。 所以在我到美国去读博士的时候，我的研究计划其实是“性别和革命的比较研究”，那时候读了一些新文化史对法国的心态史、性别研究；在90年代末、2000年初，这些在大陆是很新鲜的新史学，我当时就觉得这是我想做的。在做硕士论文的时候，我已经就开始在思考大革命起源，我做的是关于当时的书籍、沙龙，也有对巴黎的想象，因此写了这样一个研究计划。 到了美国第一年，我在密歇根大学的历史系，主要是研究欧洲史领域，还是想做大革命。我记得第一学期，我参加了一个关于大革命的研讨会，当时在威斯康辛遇到一个做法国研究的一个美国学者，他看我第一眼就对我说，我听说你想做法国大革命，让我想一想还有什么话题没有人碰过。当时才发现200年以来，法国大革命的点点滴滴，你能想到的任何东西，从日常生活到议会，每一个方方面都被人研究过了。所以我当时就想，我该怎么办，而且相对我的同学来说，虽然我也学法语，但是我还没有去过法国，没有真正进入过档案馆，因此我也非常焦虑。 学了两年欧洲的各种课程，到第三年要开题的时候，我就想我还是想做一个跟中国相关的题目。既然法语比不过人家，那我还是做一点能够用到中文材料的研究，当时就看中法之间有什么联络。除了大革命中很局限的一部分以外，那从历史上来看，传教士肯定是一个很大的团体。 所以我就去了法国，大概是第二年还是第三年的暑假，正好那两年有一个巴黎的高等研究院的教授长期在密歇根大学做客座教授。那一位教授他自己是做书籍史的，我到了巴黎的第一天，他就从机场接我直接到了巴黎外方传教会的档案馆。那是一个17世纪的神学院，一个修会。那是我第一次走进一个修院，一个17世纪的建筑。它在巴黎第6区，旁边是当时的巴黎高等研究院，和Bon Marche百货公司。进去以后，先看到了小教堂，穿过大大的楼，进到他们的阅读室。 后来我就一直在那里，第一次去了两个月，接下来4年，基本上一半的时间都在巴黎。之后慢慢地就进入了宗教史，到现在我介绍自己的专业一般都说是宗教史或者社会史，也涉及一些性别研究。 我听了大家的故事，发现还是有很多不一样的地方，一个是我没有任何宗教学或者神学的训练，还有我一直做天主教，而且主要是在中国的法国的天主教传教团体、在华基督教史这样一个领域。如果你研究天主教，这种非常系统性的教会，尤其是在中国的传教，会被保守落后、非常制度化。跟大家现在谈那种宗教、弥撒、宗教生活是很不一样的。 那我来到港大以后，一直在研究所（香港人文社科研究所），后来才有joint appointment到了文学院。在研究所，大部分老师都是做宗教，他们做道教、民间宗教，或者是人类学。我在他们中间，经常都是唯一一个做基督教，而且是做天主教的研究者。我坐在里面，听他们各种各样的讨论，受到的冲击也特别大。 我自己的第一本书《上帝的女儿们：十九世纪东北的天主教女性（God’s Little Daughters: Catholic Women in Nineteenth-Century Manchuria）》，是非常传统的历史题目，是一个教会史，大概是讲法国天主教的传教史，在19世纪中国东北的发展。其中有一些很有趣的材料，特别关注了中国的几个守贞女，天主教的女性写给法国神父的信，从这样一个角度进入研究，但本身的结构还是传统的教会史。&#39;&#39;&#39; . Counting Frequency . Then, we can count the frequency of words (excluding stopwords) using Jieba. We need to read the stopwords from the text document. . Read the text document using a path in Google Drive and split by every new line. We will get a list of words at the end. . path = &quot;/content/drive/MyDrive/stopwords-zh.txt&quot; with open(path, &#39;r&#39;) as file: data = file.read() stopwords = list(data.split(&quot; n&quot;)) . We will add a few other stopwords into the list too. . stopwords.append(&quot; &quot;) stopwords.append(&quot; n&quot;) stopwords.append(&quot;.&quot;) stopwords.append(&quot;,&quot;) . We need to enable paddle to improve performance for Chinese tokenization. Using jieba.lcut_for_search(), we can then segment the text into words. To build a dictionary for word frequency, we can use dictionary comprehension. It is very similar to list comprehension, but use { } instead. We also have to assign both keys and values. You can learn more about this in the previous tutorial. We will save the resulting dictionary to count. . jieba.enable_paddle() words = jieba.posseg.jieba.lcut_for_search(text) count = {i:words.count(i) for i in set(words) if i not in stopwords} count . Paddle enabled successfully...... . {&#39;末&#39;: 1, &#39;其他&#39;: 2, &#39;落后&#39;: 1, &#39;要读&#39;: 2, &#39;结果&#39;: 2, &#39;祖父&#39;: 1, &#39;两年&#39;: 3, &#39;共同&#39;: 1, &#39;看过&#39;: 1, &#39;Daughters&#39;: 1, &#39;许多&#39;: 1, &#39;九世纪&#39;: 1, &#39;除了&#39;: 1, &#39;看中&#39;: 1, &#39;就&#39;: 24, &#39;点点滴滴&#39;: 1, &#39;日常&#39;: 1, &#39;研究员&#39;: 1, &#39;看似&#39;: 1, &#39;学期&#39;: 1, &#39;亚洲&#39;: 1, &#39;19&#39;: 1, &#39;节目&#39;: 1, &#39;聊到&#39;: 1, &#39;和&#39;: 18, &#39;外衣&#39;: 1, &#39;过程&#39;: 1, &#39;如此&#39;: 1, &#39;程晓文&#39;: 4, &#39;；&#39;: 1, &#39;研究所&#39;: 3, &#39;暑假&#39;: 1, &#39;变成&#39;: 1, &#39;产物&#39;: 1, &#39;百货公司&#39;: 1, &#39;本科课程&#39;: 1, &#39;人&#39;: 9, &#39;那里&#39;: 2, &#39;想到&#39;: 1, &#39;Marche&#39;: 1, &#39;好像&#39;: 3, &#39;电影&#39;: 2, &#39;写&#39;: 2, &#39;电视&#39;: 1, &#39;形式&#39;: 1, &#39;一盏灯&#39;: 1, &#39;话题&#39;: 1, &#39;内有&#39;: 1, &#39;一盏&#39;: 1, &#39;可能&#39;: 5, &#39;Disordered&#39;: 1, &#39;书籍&#39;: 2, &#39;材料&#39;: 2, &#39;天主&#39;: 7, &#39;大陆&#39;: 2, &#39;当下&#39;: 1, &#39;算&#39;: 1, &#39;不羁&#39;: 1, &#39;家人&#39;: 1, &#39;启发&#39;: 1, &#39;局限&#39;: 1, &#39;再&#39;: 1, &#39;会亮&#39;: 1, &#39;同学&#39;: 3, &#39;尽力&#39;: 1, &#39;魔&#39;: 1, &#39;系&#39;: 7, &#39;百货&#39;: 1, &#39;在座&#39;: 1, &#39;覆盖&#39;: 1, &#39;威斯&#39;: 1, &#39;东北&#39;: 2, &#39;女&#39;: 1, &#39;论文&#39;: 2, &#39;年代&#39;: 2, &#39;发现&#39;: 6, &#39;学位&#39;: 1, &#39;方向&#39;: 2, &#39;美国&#39;: 5, &#39;怎么办&#39;: 1, &#39;点点&#39;: 1, &#39;这辈子&#39;: 1, &#39;游戏&#39;: 1, &#39;了解&#39;: 1, &#39;用到&#39;: 1, &#39;焦虑&#39;: 1, &#39;前辈&#39;: 1, &#39;Divine&#39;: 1, &#39;心路&#39;: 3, &#39;Manchuria&#39;: 1, &#39;但是&#39;: 9, &#39;做起&#39;: 1, &#39;of&#39;: 1, &#39;过&#39;: 3, &#39;访谈&#39;: 1, &#39;第一眼&#39;: 1, &#39;中有&#39;: 1, &#39;正式&#39;: 2, &#39;进去&#39;: 2, &#39;相关&#39;: 2, &#39;文&#39;: 1, &#39;想一想&#39;: 1, &#39;于&#39;: 1, &#39;来宾&#39;: 1, &#39;点亮&#39;: 1, &#39;温暖&#39;: 1, &#39;去世&#39;: 1, &#39;吸纳&#39;: 1, &#39;日常生活&#39;: 1, &#39;联络&#39;: 1, &#39;第二年&#39;: 1, &#39;福建&#39;: 1, &#39;文学院&#39;: 1, &#39;年&#39;: 4, &#39;appointment&#39;: 1, &#39;一段&#39;: 1, &#39;信徒&#39;: 1, &#39;得&#39;: 4, &#39;生长&#39;: 1, &#39;理工&#39;: 1, &#39;接下&#39;: 1, &#39;人工智能&#39;: 7, &#39;Patricia&#39;: 1, &#39;楼&#39;: 1, &#39;浴火&#39;: 1, &#39;制度&#39;: 1, &#39;进入&#39;: 13, &#39;文学&#39;: 3, &#39;二年&#39;: 1, &#39;把&#39;: 1, &#39;s&#39;: 1, &#39;还&#39;: 9, &#39;碰到&#39;: 1, &#39;硕士&#39;: 12, &#39;误打&#39;: 1, &#39;简单&#39;: 1, &#39;部分&#39;: 3, &#39;关于&#39;: 4, &#39;9&#39;: 1, &#39;团契&#39;: 6, &#39;一门&#39;: 1, &#39;好几个&#39;: 1, &#39;已经&#39;: 3, &#39;个&#39;: 2, &#39;每年&#39;: 1, &#39;Nineteenth&#39;: 1, &#39;机构&#39;: 1, &#39;Song&#39;: 1, &#39;兄弟&#39;: 1, &#39;晓文&#39;: 1, &#39;一期&#39;: 1, &#39;念&#39;: 3, &#39;也&#39;: 28, &#39;角度&#39;: 2, &#39;Demonic&#39;: 1, &#39;芝加哥大学&#39;: 8, &#39;类似&#39;: 1, &#39;偏&#39;: 2, &#39;我该&#39;: 1, &#39;档案&#39;: 2, &#39;申请&#39;: 2, &#39;林&#39;: 2, &#39;客座教授&#39;: 1, &#39;传奇人物&#39;: 1, &#39;可见&#39;: 1, &#39;争议&#39;: 2, &#39;电子游戏&#39;: 1, &#39;辈子&#39;: 1, &#39;智能&#39;: 7, &#39;还会&#39;: 1, &#39;跟&#39;: 9, &#39;阅读&#39;: 1, &#39;大学&#39;: 18, &#39;变为&#39;: 1, &#39;有没有&#39;: 1, &#39;一本&#39;: 1, &#39;开放&#39;: 1, &#39;想象&#39;: 1, &#39;都&#39;: 23, &#39;关注&#39;: 1, &#39;这本&#39;: 1, &#39;M&#39;: 1, &#39;程度&#39;: 2, &#39;Bon&#39;: 1, &#39;Women&#39;: 2, &#39;误打误撞&#39;: 1, &#39;books&#39;: 1, &#39;结构&#39;: 1, &#39;性别&#39;: 3, &#39;学科&#39;: 9, &#39;各样&#39;: 1, &#39;东亚&#39;: 4, &#39;滴滴&#39;: 1, &#39;纯粹&#39;: 1, &#39;1960&#39;: 1, &#39;带领&#39;: 1, &#39;犹太&#39;: 2, &#39;而言&#39;: 1, &#39;宗教学&#39;: 24, &#39;需要&#39;: 2, &#39;系科&#39;: 1, &#39;电子&#39;: 1, &#39;要&#39;: 7, &#39;曾祖&#39;: 1, &#39;台湾&#39;: 5, &#39;没有&#39;: 9, &#39;全部&#39;: 1, &#39;上&#39;: 4, &#39;表达&#39;: 1, &#39;史学&#39;: 3, &#39;中国&#39;: 9, &#39;聊聊&#39;: 1, &#39;学法&#39;: 1, &#39;当&#39;: 1, &#39;上帝&#39;: 1, &#39;原因&#39;: 1, &#39;穿&#39;: 2, &#39;第二&#39;: 1, &#39;请&#39;: 2, &#39;Talal&#39;: 1, &#39;英文&#39;: 1, &#39;意义&#39;: 2, &#39;存在&#39;: 1, &#39;能够&#39;: 1, &#39;以来&#39;: 1, &#39;天主教&#39;: 7, &#39;最&#39;: 5, &#39;and&#39;: 1, &#39;情况&#39;: 1, &#39;宋史&#39;: 1, &#39;教会&#39;: 7, &#39;法国&#39;: 15, &#39;鞋子&#39;: 1, &#39;Lincoln&#39;: 1, &#39;错误&#39;: 1, &#39;因此&#39;: 2, &#39;我们&#39;: 12, &#39;陌生&#39;: 1, &#39;》&#39;: 4, &#39;书&#39;: 1, &#39;人文主义者&#39;: 1, &#39;当年&#39;: 3, &#39;教&#39;: 1, &#39;像&#39;: 5, &#39;区&#39;: 1, &#39;in&#39;: 2, &#39;子游&#39;: 1, &#39;第一天&#39;: 1, &#39;守贞&#39;: 1, &#39;圣经&#39;: 1, &#39;太太&#39;: 1, &#39;寻找&#39;: 1, &#39;任何&#39;: 2, &#39;一大帮&#39;: 1, &#39;刚才&#39;: 3, &#39;不过&#39;: 1, &#39;以前&#39;: 3, &#39;华盛顿大学&#39;: 1, &#39;听说&#39;: 1, &#39;脸&#39;: 3, &#39;相对来说&#39;: 1, &#39;或者说&#39;: 1, &#39;长期&#39;: 1, &#39;接近&#39;: 1, &#39;人文&#39;: 2, &#39;偏向&#39;: 1, &#39;很多&#39;: 11, &#39;某&#39;: 1, &#39;重新&#39;: 1, &#39;问题&#39;: 11, &#39;对于&#39;: 2, &#39;人物&#39;: 1, &#39;神父&#39;: 1, &#39;你们&#39;: 3, &#39;约翰&#39;: 1, &#39;实践者&#39;: 1, &#39;方&#39;: 1, &#39;信仰&#39;: 2, &#39;知道&#39;: 4, &#39;方法&#39;: 1, &#39;伊斯&#39;: 4, &#39;但&#39;: 6, &#39;什么&#39;: 8, &#39;来到&#39;: 1, &#39;文史哲&#39;: 1, &#39;事情&#39;: 2, &#39;一半&#39;: 2, &#39;当然&#39;: 3, &#39;校园&#39;: 1, &#39;人生&#39;: 1, &#39;历史学&#39;: 2, &#39;进&#39;: 4, &#39;教育&#39;: 1, &#39;还是&#39;: 9, &#39;肯定&#39;: 2, &#39;专门&#39;: 2, &#39;佛教&#39;: 1, &#39;学历&#39;: 1, &#39;中间&#39;: 1, &#39;好&#39;: 1, &#39;这个&#39;: 11, &#39;文化史&#39;: 1, &#39;了&#39;: 42, &#39;修会&#39;: 1, &#39;心路历程&#39;: 3, &#39;月&#39;: 1, &#39;有神&#39;: 1, &#39;现在&#39;: 12, &#39;纪念&#39;: 1, &#39;半读&#39;: 1, &#39;科目&#39;: 1, &#39;故事&#39;: 1, &#39;车祸&#39;: 2, &#39;是从&#39;: 1, &#39;参加&#39;: 1, &#39;Shanghai&#39;: 1, &#39;Fire&#39;: 1, &#39;真实&#39;: 1, &#39;by&#39;: 1, &#39;学术&#39;: 4, &#39;Donovan&#39;: 1, &#39;课程&#39;: 3, &#39;奇人&#39;: 1, &#39;原来&#39;: 2, &#39;而是&#39;: 1, &#39;为了&#39;: 1, &#39;一眼&#39;: 1, &#39;汉学&#39;: 1, &#39;大革&#39;: 8, &#39;读完&#39;: 1, &#39;讲&#39;: 3, &#39;道学&#39;: 1, &#39;社科&#39;: 1, &#39;妹妹&#39;: 1, &#39;有&#39;: 36, &#39;分析&#39;: 1, &#39;是因为&#39;: 3, &#39;跨学科&#39;: 3, &#39;新兴&#39;: 1, &#39;精彩&#39;: 2, &#39;一种&#39;: 2, &#39;组织&#39;: 2, &#39;高等&#39;: 2, &#39;一天&#39;: 1, &#39;第一个&#39;: 1, &#39;资助&#39;: 1, &#39;港大&#39;: 1, &#39;’&#39;: 1, &#39;同一&#39;: 1, &#39;北京大学历史系&#39;: 1, &#39;来说&#39;: 4, &#39;华&#39;: 1, &#39;信&#39;: 1, &#39;心理&#39;: 1, &#39;各个&#39;: 2, &#39;原来如此&#39;: 1, &#39;离&#39;: 1, &#39;那&#39;: 15, &#39;90&#39;: 1, &#39;程&#39;: 1, &#39;不会&#39;: 1, &#39;大大的&#39;: 1, &#39;神&#39;: 1, &#39;这种&#39;: 3, &#39;或&#39;: 1, &#39;而&#39;: 3, &#39;花&#39;: 1, &#39;密歇根&#39;: 2, &#39;厨师&#39;: 1, &#39;给&#39;: 3, &#39;一些&#39;: 13, &#39;主教&#39;: 7, &#39;写给&#39;: 1, &#39;Master&#39;: 1, &#39;大家&#39;: 9, &#39;这件&#39;: 1, &#39;天&#39;: 1, &#39;可以&#39;: 6, &#39;基督徒&#39;: 3, &#39;听&#39;: 4, &#39;真正&#39;: 1, &#39;制度化&#39;: 1, &#39;北京&#39;: 1, &#39;法语&#39;: 2, &#39;下来&#39;: 1, &#39;兴趣&#39;: 3, &#39;爱丁堡大学&#39;: 1, &#39;心理学&#39;: 1, &#39;国史&#39;: 3, &#39;17&#39;: 2, &#39;:&#39;: 2, &#39;人出&#39;: 1, &#39;项目&#39;: 9, &#39;灵感&#39;: 1, &#39;出家&#39;: 2, &#39;大部&#39;: 2, &#39;聚会&#39;: 2, &#39;记得&#39;: 4, &#39;学术研究&#39;: 1, &#39;宗教&#39;: 77, &#39;人家&#39;: 1, &#39;这句&#39;: 1, &#39;多年&#39;: 1, &#39;听到&#39;: 3, &#39;斯兰教&#39;: 1, &#39;创新&#39;: 1, &#39;Bruce&#39;: 1, &#39;作为&#39;: 2, &#39;工科&#39;: 1, &#39;4&#39;: 1, &#39;交叉性&#39;: 1, &#39;见过面&#39;: 1, &#39;从&#39;: 8, &#39;准备&#39;: 1, &#39;越来越&#39;: 1, &#39;阶段&#39;: 1, &#39;很多年&#39;: 1, &#39;毕业论文&#39;: 1, &#39;后辈&#39;: 1, &#39;殖民&#39;: 1, &#39;研究者&#39;: 3, &#39;工作&#39;: 6, &#39;郭婷&#39;: 7, &#39;教学&#39;: 24, &#39;纳入&#39;: 1, &#39;被&#39;: 3, &#39;学术界&#39;: 1, &#39;—&#39;: 2, &#39;教士&#39;: 4, &#39;时代&#39;: 1, &#39;求学&#39;: 1, &#39;擦&#39;: 1, &#39;理解&#39;: 1, &#39;概念&#39;: 1, &#39;觉得&#39;: 4, &#39;兄弟会&#39;: 1, &#39;直接&#39;: 1, &#39;一件&#39;: 2, &#39;本身&#39;: 1, &#39;一张&#39;: 1, &#39;男性&#39;: 2, &#39;今天&#39;: 2, &#39;传教士&#39;: 4, &#39;AI&#39;: 1, &#39;A&#39;: 1, &#39;怎样&#39;: 1, &#39;Faithful&#39;: 1, &#39;新书&#39;: 2, &#39;实习&#39;: 1, &#39;将&#39;: 1, &#39;Z&#39;: 2, &#39;6&#39;: 1, &#39;渐渐&#39;: 1, &#39;视觉&#39;: 1, &#39;遇到&#39;: 2, &#39;两天&#39;: 1, &#39;这门&#39;: 1, &#39;研讨&#39;: 1, &#39;外方&#39;: 1, &#39;生活&#39;: 2, &#39;社会史&#39;: 1, &#39;理论&#39;: 1, &#39;来看&#39;: 1, &#39;很感兴趣&#39;: 1, &#39;感谢&#39;: 1, &#39;烧毁&#39;: 1, &#39;广泛&#39;: 1, &#39;中&#39;: 2, &#39;比较&#39;: 13, &#39;思考&#39;: 2, &#39;印度教&#39;: 1, &#39;学院派&#39;: 1, &#39;接触&#39;: 5, &#39;两位&#39;: 1, &#39;社会学&#39;: 4, &#39;而且&#39;: 3, &#39;经常&#39;: 2, &#39;家族&#39;: 1, &#39;十九&#39;: 1, &#39;很亮&#39;: 1, &#39;，&#39;: 264, &#39;者&#39;: 1, &#39;富士&#39;: 1, &#39;那么&#39;: 2, &#39;努力&#39;: 1, &#39;Century&#39;: 1, &#39;性质&#39;: 1, &#39;）&#39;: 7, &#39;。&#39;: 123, &#39;帮&#39;: 1, &#39;虽然&#39;: 5, &#39;下去&#39;: 1, &#39;思维&#39;: 1, &#39;切入&#39;: 1, &#39;杜克&#39;: 1, &#39;一大&#39;: 1, &#39;能&#39;: 2, &#39;只是&#39;: 3, &#39;修&#39;: 1, &#39;招聘&#39;: 1, &#39;方式&#39;: 1, &#39;几个&#39;: 3, &#39;倪柝声&#39;: 5, &#39;旧约&#39;: 2, &#39;学者&#39;: 5, &#39;接下来&#39;: 1, &#39;第一年&#39;: 1, &#39;耶鲁&#39;: 1, &#39;客座&#39;: 1, &#39;Smith&#39;: 2, &#39;人本&#39;: 1, &#39;李纪&#39;: 3, &#39;培养&#39;: 1, &#39;感兴趣&#39;: 3, &#39;革命&#39;: 10, &#39;主要&#39;: 2, &#39;神学院&#39;: 19, &#39;班上&#39;: 1, &#39;女儿&#39;: 1, &#39;西装&#39;: 1, &#39;所谓&#39;: 2, &#39;属于&#39;: 1, &#39;教授&#39;: 4, &#39;说&#39;: 11, &#39;区域&#39;: 1, &#39;接受&#39;: 3, &#39;里面&#39;: 4, &#39;韩国&#39;: 1, &#39;？&#39;: 5, &#39;书上&#39;: 1, &#39;提到&#39;: 3, &#39;艺术&#39;: 1, &#39;阅读室&#39;: 1, &#39;专业&#39;: 4, &#39;教堂&#39;: 1, &#39;例如&#39;: 1, &#39;认真&#39;: 2, &#39;圣约&#39;: 1, &#39;只有&#39;: 1, &#39;问&#39;: 2, &#39;九世&#39;: 1, &#39;世俗化&#39;: 2, &#39;见&#39;: 1, &#39;沙龙&#39;: 1, &#39;爱大&#39;: 1, &#39;在&#39;: 63, &#39;另外&#39;: 2, &#39;便&#39;: 1, &#39;等&#39;: 1, &#39;披上&#39;: 1, &#39;自由&#39;: 1, &#39;女性&#39;: 4, &#39;让&#39;: 4, &#39;大概&#39;: 2, &#39;一下&#39;: 5, &#39;希腊&#39;: 1, &#39;风气&#39;: 1, &#39;课上&#39;: 1, &#39;设置&#39;: 1, &#39;谁&#39;: 2, &#39;当初&#39;: 1, &#39;对抗&#39;: 1, &#39;人工&#39;: 7, &#39;理工科&#39;: 1, &#39;Little&#39;: 1, &#39;见习&#39;: 1, &#39;它&#39;: 17, &#39;务&#39;: 1, &#39;一点&#39;: 1, &#39;点滴&#39;: 1, &#39;课叫&#39;: 1, &#39;是不是&#39;: 3, &#39;学法语&#39;: 1, &#39;同一性&#39;: 1, &#39;对&#39;: 9, &#39;以后&#39;: 7, &#39;人类&#39;: 5, &#39;佛学&#39;: 2, &#39;先&#39;: 2, &#39;世上&#39;: 1, &#39;朋友&#39;: 2, &#39;变化&#39;: 1, &#39;话&#39;: 1, &#39;2021&#39;: 1, &#39;女性主义&#39;: 1, &#39;常有&#39;: 1, &#39;系统&#39;: 2, &#39;那个&#39;: 3, &#39;英国&#39;: 4, &#39;10&#39;: 1, &#39;相对&#39;: 3, &#39;new&#39;: 1, &#39;还有&#39;: 8, &#39;这是&#39;: 1, &#39;-&#39;: 2, &#39;到&#39;: 16, &#39;刚刚&#39;: 1, &#39;提出&#39;: 1, &#39;：&#39;: 16, &#39;有关&#39;: 4, &#39;有失&#39;: 1, &#39;别人&#39;: 1, &#39;历程&#39;: 3, &#39;特别&#39;: 4, &#39;聚会所&#39;: 2, &#39;“&#39;: 4, &#39;China&#39;: 1, &#39;以外&#39;: 1, &#39;讲究&#39;: 3, &#39;训练&#39;: 6, &#39;书写&#39;: 1, &#39;会风&#39;: 1, &#39;既然&#39;: 1, &#39;without&#39;: 1, &#39;由于&#39;: 1, &#39;读&#39;: 12, &#39;前&#39;: 4, &#39;学生&#39;: 4, &#39;时候&#39;: 16, &#39;忽略&#39;: 1, &#39;视觉艺术&#39;: 1, &#39;network&#39;: 1, &#39;本科专业&#39;: 1, &#39;科学&#39;: 2, &#39;感觉&#39;: 1, &#39;嘉宾&#39;: 1, &#39;抗争&#39;: 1, &#39;两个&#39;: 1, &#39;跟着&#39;: 1, &#39;第一&#39;: 9, &#39;学业&#39;: 1, &#39;社会风气&#39;: 1, &#39;时间&#39;: 2, &#39;过去&#39;: 1, &#39;刚&#39;: 1, &#39;主修&#39;: 1, &#39;焗&#39;: 1, &#39;Divinity&#39;: 1, &#39;不是&#39;: 8, &#39;世界&#39;: 3, &#39;领域&#39;: 7, &#39;主义&#39;: 3, &#39;华盛&#39;: 1, &#39;Ebrey&#39;: 1, &#39;刚查&#39;: 1, &#39;重点&#39;: 1, &#39;2000&#39;: 2, &#39;医生&#39;: 1, &#39;仅仅&#39;: 1, &#39;又&#39;: 3, &#39;们&#39;: 1, &#39;中学&#39;: 1, &#39;世俗&#39;: 2, &#39;Schaefer&#39;: 1, &#39;俗化&#39;: 2, &#39;叫做&#39;: 1, &#39;Dynasty&#39;: 1, &#39;科系&#39;: 3, &#39;研究&#39;: 60, &#39;基督&#39;: 10, &#39;聪慧&#39;: 1, &#39;背景&#39;: 1, &#39;盏灯&#39;: 2, &#39;其实&#39;: 21, &#39;谢谢&#39;: 1, &#39;连曦&#39;: 1, &#39;中心&#39;: 2, &#39;精神&#39;: 2, &#39;坐在&#39;: 1, &#39;带来&#39;: 1, &#39;新约&#39;: 2, &#39;它会&#39;: 1, &#39;神学&#39;: 28, &#39;去&#39;: 13, &#39;华盛顿&#39;: 1, &#39;播客&#39;: 2, &#39;巴黎&#39;: 7, &#39;研讨会&#39;: 1, &#39;涉及&#39;: 1, &#39;看&#39;: 4, &#39;当码&#39;: 1, &#39;爱丁堡&#39;: 1, &#39;不同&#39;: 8, &#39;他&#39;: 18, &#39;其它&#39;: 1, &#39;传统&#39;: 13, &#39;第三&#39;: 2, &#39;宋代&#39;: 1, &#39;第三年&#39;: 2, &#39;想着&#39;: 1, &#39;建筑&#39;: 1, &#39;进来&#39;: 1, &#39;十九世纪&#39;: 1, &#39;哈佛&#39;: 2, &#39;历史&#39;: 11, &#39;主义者&#39;: 1, &#39;打扮&#39;: 2, &#39;才&#39;: 4, &#39;”&#39;: 4, &#39;批判&#39;: 1, &#39;一般&#39;: 3, &#39;出车&#39;: 1, &#39;（&#39;: 7, &#39;团体&#39;: 2, &#39;社会科学&#39;: 1, &#39;与&#39;: 3, &#39;确实&#39;: 2, &#39;吗&#39;: 1, &#39;看到&#39;: 3, &#39;关系&#39;: 3, &#39;为&#39;: 2, &#39;包括&#39;: 6, &#39;受到&#39;: 2, &#39;东西&#39;: 4, &#39;出现&#39;: 1, &#39;之间&#39;: 2, &#39;真的&#39;: 1, &#39;男女&#39;: 1, &#39;认为&#39;: 1, &#39;如果&#39;: 4, &#39;然后&#39;: 4, &#39;那本书&#39;: 1, &#39;后&#39;: 1, &#39;宗教史&#39;: 2, &#39;玩笑&#39;: 1, &#39;头发&#39;: 1, &#39;反应&#39;: 1, &#39;三年&#39;: 2, &#39;越来&#39;: 1, &#39;去过&#39;: 1, &#39;争议性&#39;: 1, &#39;通常&#39;: 1, &#39;宗教信仰&#39;: 2, &#39;风格&#39;: 1, &#39;湛舸&#39;: 1, &#39;讲得&#39;: 1, &#39;最早&#39;: 1, &#39;一样&#39;: 4, &#39;《&#39;: 4, &#39;本主&#39;: 1, &#39;基本上&#39;: 1, &#39;哪&#39;: 4, &#39;Catholic&#39;: 1, &#39;威斯康辛&#39;: 1, &#39;乱&#39;: 1, &#39;议会&#39;: 1, &#39;并&#39;: 2, &#39;衰落&#39;: 1, &#39;中文&#39;: 2, &#39;来谈&#39;: 1, &#39;郑利昕&#39;: 2, &#39;其中&#39;: 1, &#39;基本&#39;: 3, &#39;人员&#39;: 1, &#39;历史系&#39;: 4, &#39;相比&#39;: 1, &#39;基督教徒&#39;: 2, &#39;之初&#39;: 1, &#39;教徒&#39;: 2, &#39;所以&#39;: 13, &#39;你&#39;: 8, &#39;机缘&#39;: 1, &#39;之前&#39;: 4, &#39;一个&#39;: 46, &#39;就是&#39;: 5, &#39;林语堂&#39;: 1, &#39;出车祸&#39;: 1, &#39;同时&#39;: 1, &#39;文化&#39;: 1, &#39;同事&#39;: 1, &#39;修院&#39;: 1, &#39;大&#39;: 4, &#39;更加&#39;: 1, &#39;范式&#39;: 1, &#39;她&#39;: 1, &#39;几天&#39;: 2, &#39;学校&#39;: 5, &#39;出身&#39;: 1, &#39;走向&#39;: 1, &#39;解构&#39;: 1, &#39;换&#39;: 1, &#39;不论&#39;: 1, &#39;非常&#39;: 20, &#39;里&#39;: 1, &#39;农了&#39;: 1, &#39;一位&#39;: 2, &#39;整个&#39;: 1, &#39;开题&#39;: 1, &#39;课&#39;: 2, &#39;思想&#39;: 2, &#39;一次&#39;: 3, &#39;我前&#39;: 1, &#39;心态&#39;: 1, &#39;接&#39;: 1, &#39;想&#39;: 11, &#39;弥撒&#39;: 1, &#39;看待&#39;: 1, &#39;计划&#39;: 2, &#39;史&#39;: 7, &#39;后来&#39;: 7, &#39;也好&#39;: 2, &#39;地&#39;: 2, &#39;的话&#39;: 1, &#39;传奇&#39;: 1, &#39;公司&#39;: 1, &#39;Asad&#39;: 1, &#39;分支&#39;: 1, &#39;之外&#39;: 2, &#39;几位&#39;: 2, &#39;学了&#39;: 1, &#39;后面&#39;: 1, &#39;老师&#39;: 10, &#39;巧合&#39;: 1, &#39;道教&#39;: 1, &#39;Men&#39;: 1, &#39;开始&#39;: 5, &#39;痕迹&#39;: 1, &#39;新&#39;: 3, &#39;得救&#39;: 1, &#39;、&#39;: 33, &#39;涵盖&#39;: 1, &#39;慢慢&#39;: 2, &#39;大大&#39;: 1, &#39;穿过&#39;: 1, &#39;全国&#39;: 1, &#39;旁边&#39;: 1, &#39;这&#39;: 10, &#39;聊&#39;: 1, &#39;有趣&#39;: 4, &#39;大部分&#39;: 2, &#39;本书&#39;: 6, &#39;同样&#39;: 1, &#39;芝加哥&#39;: 9, &#39;算命&#39;: 1, &#39;古希腊&#39;: 1, &#39;之后&#39;: 6, &#39;一部分&#39;: 1, &#39;joint&#39;: 1, &#39;事&#39;: 1, &#39;香港&#39;: 1, &#39;地区&#39;: 4, &#39;派&#39;: 2, &#39;学员&#39;: 1, &#39;是&#39;: 87, &#39;一&#39;: 1, &#39;得到&#39;: 1, &#39;做&#39;: 28, &#39;走进&#39;: 1, &#39;圣约翰&#39;: 1, &#39;我&#39;: 104, &#39;各种&#39;: 2, &#39;多&#39;: 3, &#39;本来&#39;: 2, &#39;不&#39;: 15, &#39;找&#39;: 2, &#39;自己&#39;: 11, &#39;碰过&#39;: 1, &#39;这些&#39;: 5, &#39;基督教&#39;: 7, &#39;犹太教&#39;: 2, &#39;他们&#39;: 5, &#39;法&#39;: 1, &#39;仿佛&#39;: 1, &#39;Redeemed&#39;: 1, &#39;保守&#39;: 1, &#39;一直&#39;: 6, &#39;起来&#39;: 1, &#39;本科&#39;: 6, &#39;第&#39;: 1, &#39;汇合&#39;: 1, &#39;上海&#39;: 2, &#39;台大&#39;: 3, &#39;拿到&#39;: 2, &#39;每&#39;: 1, &#39;起源&#39;: 1, &#39;各种各样&#39;: 1, &#39;那种&#39;: 2, &#39;公正&#39;: 1, &#39;开会&#39;: 1, &#39;年初&#39;: 1, &#39;哲学&#39;: 5, &#39;全国性&#39;: 1, &#39;法国史&#39;: 3, &#39;新鲜&#39;: 1, &#39;认识&#39;: 3, &#39;张力&#39;: 1, &#39;林家&#39;: 1, &#39;会所&#39;: 2, &#39;正好&#39;: 1, &#39;硕士论文&#39;: 1, &#39;着&#39;: 2, &#39;God&#39;: 1, &#39;因为&#39;: 7, &#39;学院&#39;: 22, &#39;之下&#39;: 1, &#39;国内&#39;: 1, &#39;特殊&#39;: 1, &#39;伊斯兰教&#39;: 1, &#39;选&#39;: 1, &#39;思想史&#39;: 1, &#39;职位&#39;: 2, &#39;更高&#39;: 1, &#39;地方&#39;: 4, &#39;的&#39;: 233, &#39;毕业&#39;: 2, &#39;身份&#39;: 1, &#39;假设&#39;: 1, &#39;华人&#39;: 1, &#39;来聊&#39;: 1, &#39;题目&#39;: 2, &#39;可惜&#39;: 1, &#39;人类学&#39;: 5, &#39;曾祖父&#39;: 1, &#39;或者&#39;: 11, &#39;文史&#39;: 1, &#39;最远&#39;: 1, &#39;权威&#39;: 1, &#39;200&#39;: 1, &#39;革命史&#39;: 1, &#39;一部&#39;: 1, &#39;经典&#39;: 1, &#39;教牧学&#39;: 1, &#39;人本主义&#39;: 1, &#39;带&#39;: 1, &#39;最近&#39;: 2, &#39;学界&#39;: 5, &#39;开玩笑&#39;: 1, &#39;J&#39;: 2, &#39;福音&#39;: 1, &#39;怎么样&#39;: 1, &#39;谎称&#39;: 1, &#39;所有&#39;: 1, &#39;很&#39;: 7, &#39;那想&#39;: 1, &#39;民间&#39;: 1, &#39;相比之下&#39;: 1, &#39;物理&#39;: 2, &#39;唯一&#39;: 1, &#39;传教&#39;: 8, &#39;发展&#39;: 1, &#39;等等&#39;: 2, &#39;冲击&#39;: 1, &#39;叫&#39;: 5, &#39;机场&#39;: 1, &#39;11&#39;: 1, &#39;教派&#39;: 1, &#39;交叉&#39;: 1, &#39;会&#39;: 13, &#39;中文系&#39;: 1, &#39;ta&#39;: 1, &#39;大革命&#39;: 8, &#39;非常感谢&#39;: 1, &#39;随便&#39;: 1, &#39;比如&#39;: 1, &#39;方面&#39;: 1, &#39;人格&#39;: 1, &#39;小&#39;: 1, &#39;怎么&#39;: 3, &#39;她们&#39;: 1, &#39;第一次&#39;: 3, &#39;常生&#39;: 1, &#39;刚好&#39;: 1, &#39;教义&#39;: 1, &#39;理学&#39;: 1, &#39;相信&#39;: 1, &#39;好几&#39;: 1, &#39;科学史&#39;: 1, &#39;讨论&#39;: 1, &#39;一定&#39;: 2, &#39;产生&#39;: 1, &#39;台湾地区&#39;: 4, &#39;介绍&#39;: 3, &#39;沉痛&#39;: 1, &#39;社会&#39;: 10, &#39;应该&#39;: 3, &#39;镜子&#39;: 1, &#39;博士&#39;: 9, &#39;欧洲&#39;: 2, &#39;档案馆&#39;: 2, &#39;设立&#39;: 1, &#39;悼念&#39;: 1, &#39;学&#39;: 3, &#39;感兴&#39;: 3, &#39;当时&#39;: 16, &#39;倪湛舸&#39;: 2, &#39;利昕&#39;: 1, &#39;然&#39;: 1, &#39;世纪&#39;: 4, &#39;神务&#39;: 1, &#39;我要&#39;: 2, &#39;谈&#39;: 3, &#39;以&#39;: 4, &#39;一般来说&#39;: 1, &#39;经历&#39;: 1, &#39;跨系&#39;: 1, &#39;尤其&#39;: 3, &#39;这样&#39;: 4, &#39;印度&#39;: 1, &#39;系统性&#39;: 1, &#39;不管&#39;: 1, ...} . Nonetheless, it is more convenient to have the word frequency in a Pandas data frame. We can easily do that by taking the items() of count in a list. We will create the data frame using pd.DataFrame(). You can learn more about Pandas in the data organization chapter. . items = count.items() data_list = list(items) df = pd.DataFrame(data=data_list) df.columns = [&quot;word&quot;, &quot;frequency&quot;] df.head() . word frequency . 0 法国 | 21 | . 1 承担 | 1 | . 2 天主教 | 37 | . 3 洞 | 1 | . 4 打扮 | 2 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; To inspect what words most frequently appear in the text, we can also sort the values. We will take the top 10 into a new data frame and set the keyword as index. Now, we start to see some interesting patterns: 宗教, 研究, and 基督 appear the most. Another interesting keyword includes 女性. . df = df.sort_values(by=&#39;frequency&#39;, ascending=False).reset_index() df_top = df.head(10)[[&quot;word&quot;,&quot;frequency&quot;]] df_top.index = df_top.word df_top . word frequency . word . 宗教 宗教 | 264 | . 研究 研究 | 163 | . 基督 基督 | 64 | . 基督教 基督教 | 55 | . 社会 社会 | 54 | . 女性 女性 | 53 | . 历史 历史 | 52 | . 中国 中国 | 51 | . 现在 现在 | 49 | . 可能 可能 | 47 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Data Visualization . We can already do a basic data visualization using matplotlib. In this library, we can select different plotting styles. We will pick &#39;Solarize_Light2&#39; here. . . Checking available styles . print(plt.style.available) . [&#39;Solarize_Light2&#39;, &#39;_classic_test_patch&#39;, &#39;bmh&#39;, &#39;classic&#39;, &#39;dark_background&#39;, &#39;fast&#39;, &#39;fivethirtyeight&#39;, &#39;ggplot&#39;, &#39;grayscale&#39;, &#39;seaborn&#39;, &#39;seaborn-bright&#39;, &#39;seaborn-colorblind&#39;, &#39;seaborn-dark&#39;, &#39;seaborn-dark-palette&#39;, &#39;seaborn-darkgrid&#39;, &#39;seaborn-deep&#39;, &#39;seaborn-muted&#39;, &#39;seaborn-notebook&#39;, &#39;seaborn-paper&#39;, &#39;seaborn-pastel&#39;, &#39;seaborn-poster&#39;, &#39;seaborn-talk&#39;, &#39;seaborn-ticks&#39;, &#39;seaborn-white&#39;, &#39;seaborn-whitegrid&#39;, &#39;tableau-colorblind10&#39;] . Plotting a horizontal bar chart using Pandas. . plt.style.use(&#39;Solarize_Light2&#39;) # plotting with defined figure size and without legend df_top.plot.barh(figsize=(16,6), legend=None) # layout plt.title(&quot;Word Frequency&quot;, fontsize=22, color=&quot;grey&quot;) plt.xlabel(&quot;Frequency&quot;, fontsize=16) plt.ylabel(&quot;Keyword&quot;, fontsize=16) # diplay plt.show() . Chinese Keyword Extraction . TF-IDF . TF-IDF (term frequency-inverse document frequency) is a technique used in automated text analysis. It is a statistical measure which evaluates how relevant a word is in the text. In TF-IDF, two metrics are computed: how many times a word appears in a document, and the inverse document frequency of the word across the document. Keywords are the words that score the highest in a document, which also means they are the most relevant. They are selected because they are not so common in general but commonly appeared in the text. In the Chinese NLP library jieba, it is calculated by comparing the words to a pre-defined document. . Using jieba to extract keywords, we do not need to calculate the frequency of words ourselves, but can simply use the function analyse.extract_tags(). . Let&#39;s extract keywords once again, but this time using extract_tags(). The keywords appear to be slightly different. . tags = jieba.analyse.extract_tags(text, topK=10) # print results print(&quot;,&quot;.join(tags)) . 宗教,宗教学,研究,神学院,一个,其实,硕士,非常,郭婷,团契 . We can get the keywords with weights too. By doing so, we also get a number from 0 to 1, which represents the relevance of words. . for x, w in jieba.analyse.extract_tags(text, withWeight=True): print(x,w) . 宗教 0.18120946434784116 宗教学 0.14646094768094117 研究 0.12716916499852943 神学院 0.11163790487320586 一个 0.07458223161520589 其实 0.06334097453756471 硕士 0.05739566884492941 非常 0.05480139830615294 郭婷 0.04922551324723529 团契 0.04906121524235295 当时 0.044007932553882356 神学 0.04393354675288235 芝加哥大学 0.04258187006145882 传统 0.04093881529086471 时候 0.040364671373552936 大革命 0.03950751113430589 人工智能 0.03894481456966471 博士 0.038879466860223526 法国 0.03784607501089412 老师 0.03749071607411765 . Define Stopwords . But here we have not defined the stopwords yet. By setting a list of stopwords, we can prevent some common words appear to be keywords. It can be done using analyse.set_stop_words(). We need to pass a text file (.txt) [Encoding UTF-8] to this function. You can download it here and edit it as you like. topK is used to define the number of keywords extracted, we will set it to 10 here. . jieba.analyse.set_stop_words(r&quot;/content/drive/MyDrive/NLP/stopwords.txt&quot;) # extract keywords again tags = jieba.analyse.extract_tags(text, topK=10) # print results print(&quot;,&quot;.join(tags)) . 宗教,宗教学,研究,神学院,硕士,团契,神学,芝加哥大学,传统,大革命 . With the weights . for x, w in jieba.analyse.extract_tags(text, withWeight=True): print(x,w) . 宗教 0.24507246570511534 宗教学 0.19807765398377086 研究 0.17198693754773273 神学院 0.15098205114116944 硕士 0.07762341848558472 团契 0.06635168330310262 神学 0.059416889005489255 芝加哥大学 0.05758884574739856 传统 0.05536673507913285 大革命 0.05343100153406524 人工智能 0.05266999583805092 博士 0.05258161786983294 法国 0.05118403143875895 老师 0.050703434626889414 比较 0.04934998856252983 倪柝声 0.04755277447454256 进入 0.04718182956929196 教会 0.04180557540669053 天主教 0.041445008417191724 程晓文 0.038042219579634044 . The results are a little bit different from above compared to just counting the frequency. We get other keywords such as 传统 and 大革命. . Summary . You might have wondered: What if we do not want to copy the long text, but directly get the text from the web, such as from a digital text database? Or to get the text from multiple web pages, such as getting all the blogs published this year? Or, can we further simplify our workflow? . Of course, it can all be achieved using functions, loops, and the powerful web scraping library BeautifulSoup. Another question is, can we search for specific keywords that we are interested in? The answer is also yes. We will learn more about them in further tutorials. Stay tuned! . . . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: February 2022 .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/level-4/chapter-4/jieba/text-mining/2022/02/05/Chinese_Keyword_Extraction_1.html",
            "relUrl": "/level-4/chapter-4/jieba/text-mining/2022/02/05/Chinese_Keyword_Extraction_1.html",
            "date": " • Feb 5, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Creating Chinese Word Clouds",
            "content": ". Background . Hello. In this lesson, you will learn how to create your word clouds in Chinese languages using Python. Different from the online tools, using specific libraries &quot;Jieba&quot; highly improve the performance of tokenizing Chinese text. You can also customize different options such as the colour use or shape mask. If you are running this notebook in Colab, you do not need to download or install any items. We will create the word cloud using predefined images and texts, but you can also change it to any content you like. . . As mentioned in the instructions, all materials can be open in Colab as Jupyter notebooks. In this way, users can run the code in the cloud. It is highly recommended to follow the tutorials in the right order. To optimize your learning experience, you are supposed to know the Python basics, including how to write and use a function. They are all included in the previous tutorials. . Connection to Google Drive . As the resources are in the drive, we need to allow Colab to connect to the Google Drive. It can be done by running the following code. Then a new window will be open for you to sign in and give permission. . from google.colab import drive drive.mount(&#39;/content/drive/&#39;) . Mounted at /content/drive/ . Download Resources . To run all the code, we have to download a few items using wget, which is a way to retrieve content from web servers. To understand more about wget, you can visit here. . Because the library we are going to use do not have a default option to display Chinese, we have to download a Chinese font for proper display. If you run the following code, the resources will be downloaded into your Google Drive. . Chinese Font | . ! wget https://raw.githubusercontent.com/victorgau/wordcloud/master/SourceHanSansTW-Regular.otf -o /dev/null -P /content/drive/MyDrive/ . To prevent common words to be classified as keywords, we need to define stopwords ourselves. There is existing resources for that in Chinese, but you can also create you own. . Stopwords | . ! wget https://github.com/stopwords-iso/stopwords-zh/blob/master/stopwords-zh.txt -P /content/drive/MyDrive/ . Then, we have to download the images, including the ones for the mask and color selection. . Images | . ! wget https://github.com/pinkychow1010/digital-chinese-history-blog/blob/master/images/tree.jpg -P /content/drive/MyDrive/ . ! wget https://github.com/pinkychow1010/digital-chinese-history-blog/blob/master/images/song.png -P /content/drive/MyDrive/ . Set Up Environment . We need to download and import specific libraries to set up our cloud environment by running the following code. We will download the library using pip. . Download Library . ! pip install jieba # The library for Creating Word Cloud ! pip install wordcloud . Import Library . import jieba from wordcloud import WordCloud, ImageColorGenerator # General Library import matplotlib.pyplot as plt import os # Image Manipulation from imageio import imread from PIL import Image import numpy as np # File Management from google.colab import files . Test Processing . To process our text, we can use the following function. What it is doing is to tokenize the text to words using jieba.cut() and clean the list by removing empty strings and stopwords. . def jieba_processing_txt(text,stopwords_path): &quot;&quot;&quot; Creating word list from text text: str The text for generating word list stopwords_path: path A path to stopwords returns: str Word List &quot;&quot;&quot; # assign empty list for words mywordlist = [] # tokenization seg_list = jieba.cut(text, cut_all=False) # join to string liststr = &quot;/ &quot;.join(seg_list) # read stop word text file with open(stopwords_path, encoding=&#39;utf-8&#39;) as f_stop: f_stop_text = f_stop.read() f_stop_seg_list = f_stop_text.splitlines() # remove empty strings and stopwords for myword in liststr.split(&#39;/&#39;): if not (myword.strip() in f_stop_seg_list) and len(myword.strip()) &gt; 1: mywordlist.append(myword) # return final list return &#39; &#39;.join(mywordlist) . We need to define a stopword list and the text for our function. Below is the stopwords path where the downloaded file is stored. We will also copy a part of text from 丁則良文集. . stopwords_path = r&quot;/content/drive/MyDrive/stopwords-zh.txt&quot; . txt = &quot;&quot;&quot; 《宋史》卷二五○《石守信传》云： 建隆二年，移镇郓州，兼侍卫亲军马步军都指挥使， 诏赐本州宅一区。 乾德初，帝因晚朝与守信等饮酒，酒 酣，帝曰： “我非尔曹不及此； 然吾为天子，殊不若为节 度使之乐。 吾终夕未尝安枕而卧。”守信等顿首曰： “今 天命已定，谁复敢有异心？ 陛下何为出此言耶？”帝曰： “人孰不欲富贵，一旦有以黄袍加汝之身，虽欲不为，其 可得乎。”守信等谢曰： “臣愚不及此，唯陛下哀矜之。” 帝曰： “人生驹过隙尔，不如多积金、市田宅，以遗子孙， 歌儿舞女，以终天年。 君臣之间，无所猜嫌，不亦善乎？” 守信谢曰： “陛下念及此，所谓生死而肉骨也。”明日，皆 称病，乞解兵权。 帝从之，皆以散官就第，赏赉甚厚。 良谨按： 此即世传杯酒释兵权一事所本。 杯酒释兵权一 事，世所艳称。 盖五代骄兵悍将，劫持割据，历时五十余年， 雄鸷如梁太祖周世宗辈，曾不能彻底纠正。 而宋太祖乃于杯 酒言欢之际解除诸将兵柄，使干戈拢攘之局，化为雍熙垂拱 之治，是不但为国史平添一大佳话，抑且为宋室奠三百年文 治之基，其关系之重大，不言可喻。 惟实际政治之中，奇迹例 不多有。 石守信辈之解除兵柄，果由太祖推诚感召所致？ 抑 别有其不得不遵行命令之原因？ 此迹近传奇之杯酒释兵权 一事，有无附会夸张之处？ 凡此均为甚可怀疑之问题。 本文旨 在考证杯酒释兵权一事之不可信，并进而推求宋初军队国家化 （或中央化）所以得告成功之根本原因。 大雅君子，幸教正焉。 二 上引《宋史·石守信传》（以下简称《石传》）系此事于乾 德初，今检李焘《续资治通鉴长编》 （以下简称《长编》）乾德 年间诸卷（卷四至卷八）并无此事。 《长编》系此事于建隆二 年秋七月戊辰遣使修北岳庙条之后，与庚午以侍卫都指挥使 归德节度使石守信为天平节度略条合为一条。 （吴廷燮《北 宋经抚年表》引《长编》系此事于建隆三年，吴误。）王偁《东都 事略》卷二六《赵普传》亦系此事于二叛（李筠、李重进）既平 之后。 （彭百川《太平治迹统类》卷二太祖圣政节亦系此事于 建隆二年七月。）是三书之说全合。 司马光《涑水记闻》卷一 及邵伯温《邵氏闻见录》卷一载此事亦均谓在诛二叛之后，与 《长编》、《东都事略》等书亦相同。 《长编》此条下原注谓丁 谓《晋公谈录》及王曾《王文正公笔录》二书亦载此事。 《晋公 谈录》有《历代小史》及《百川学海》二本。 《历代小史》本殊 简略，未记杯酒释兵权一事。 《百川学海》本未著岁时。 《王 文正公笔录》载此事起句“太祖创业，在位历年，石守信、王审 琦等犹分典禁兵如故”云云，未著何年。 玩其语气，似在太祖 即位若干年之后。 “在位历年”一语，殊嫌笼统，与建隆二年 之说，亦未尝不合。 根据以上各项史料，可知建隆二年之说， 证据最多，《长编》系年之法，最为可信。 《石传》系此事于乾 德初，不知何所据而云然。 想系编纂之际，仓卒成书，未暇详 细参考《长编》等书，臆度其为乾德初年，遂率尔误载也。 且《石传》有“建隆二年移镇郓州，兼侍卫亲军马步军都 指挥使”之文。 事实上，所谓释兵权者即此之谓。 按郓州即 天平。 《长编》卷二建隆二年秋七月庚午条云： “以侍卫都指 挥使归德节度使石守信为天平节度使，兼侍卫都指挥使如 故，其实兵权不在也。”据此可知《石传》“建隆二年”云云，即 指此事。 李焘将此条与杯酒释兵权一事合载，自极允当。 《宋史》不察，乃于《石传》中认为系截然两事，且以杯酒释兵 权一事，系于移镇郓州之后，其疏略无识，实甚可笑。 “乾德 初”三字之不可信，至此乃又多得一证。 由以上考证，可知太祖收石守信兵柄在建隆二年，《石 传》所载误，不可置信。 三 《东都事略》卷二六《赵普传》云： 初二叛既平，太祖召普问： “天下自唐季以来，数十 年间，帝王凡易八姓，兵革不息，苍生涂地，其故何也？ 吾欲息天下兵，为国家长久之计，其道何如？”普曰： “陛 下及此言，天地人神之福也。 唐季以来，战斗不息，国家 所以不安者，由节镇太重，君弱臣强而已。 今所以治之， 无他，惟稍夺其权，制其钱谷，收其精兵，则天下自安 矣。”顷之，太祖因晚朝，与石守信、王审琦等饮。 太祖屏 左右，谓曰： “我非汝曹之力，不得至此。 念汝之德，无有 穷已。 然天子亦大艰难，殊不若为节度使之乐也。”守信 等曰： “何故？”太祖曰： “是不难知矣。 居此位者，谁不 欲为之！”守信顿首曰： “陛下何谓出此言？ 今天命已定， 孰敢有异心？”太祖曰： “不然，汝曹虽无异心，其如汝麾 下之人，欲富贵者何？ 一旦以黄袍加汝之身，汝虽欲不 为，其可得乎？”守信等曰： “臣等愚不及此，唯陛下哀矜， 示以可生之途！”太祖曰： “人生如白驹过隙，所为好富贵 者，不过多积金钱，厚自娱乐，使子孙无贫乏之忧。 汝曹 何不释去兵权，择便好田宅，市之为子孙立永久之业？ 多置歌舞，日饮酒相欢，以终天年。 君臣之间，两无猜 嫌，上下相安，不亦善乎？”于是守信等皆称疾，请解军 职，太祖许之。 按此言释兵权之谋出自赵普，《石传》及《宋史》卷二五六 《赵普传》均不载。 《长编》与《东都事略》所载大致相同，以 其关系甚大，特不惮烦，迻录于下。 《长编》卷二建隆二年秋 七月戊辰遣使修北岳庙条后半云： 初，上既诛李筠及重进，一日，召赵普问曰： “天下自 唐季以来，数十年间，帝王凡易八姓，战斗不息，生民涂 地，其故何也？ 吾欲息天下之兵，为国家长久计，其道何 如？”普曰： “陛下之言及此，天地人神之福也。 无非他 故，方镇太重，君弱臣强而已。 今所以治之，亦无他奇 巧，惟稍夺其权，制其钱谷，收其精兵，则天下自安矣。” 语未毕，上曰： “卿无复言，吾已喻矣。”时石守信、王审琦 等皆上故人，各典禁卫。 普数言于上，请授以他职，上不 许。 普乘间即言之。 上曰： “彼等必不吾叛，卿何忧？”普 曰： “臣亦不忧其叛也。 然熟观数人者，皆非统御才，恐 不能制伏其下。 苟不能制伏其下，则军伍间万一有作孽 者，彼临时亦不得自由耳。”上悟，于是召守信等饮，酒 酣，屏左右，谓曰： “我非尔曹之力，不得至此，念尔曹之 德，无有穷尽。 然天子亦大艰难，殊不若为节度使之乐。 吾终夕未尝敢安枕而卧也。”守信等皆曰： “何故？”上 曰： “是不难知矣！ 居此位者，谁不欲为之？”守信等皆顿 首曰： “陛下何为出此言？ 今天命已定，谁敢复有异心？” 上曰： “不然，汝曹虽无异心，其如麾下之人，欲富贵者， 一旦以黄袍加汝之身，汝虽欲不为，其可得乎？”皆顿首 涕泣曰： “臣等愚不及此，惟陛下哀矜，指示可生之途！” 上曰： “人生如白驹之过隙，所为好富贵者，不过欲多积 金钱，厚自娱乐，使子孙无贫乏耳。 尔曹何不释去兵权， 出守大藩，择便好田宅市之，为子孙立永远不可动之业， 多置歌儿舞女，日饮酒相欢，以终其天年。 我且与尔曹 约为婚姻，君臣之间，两无猜疑，上下相安，不亦善乎？” 皆拜谢曰： “陛下念臣等至此，所谓生死而肉骨也。”明日 皆称疾，请罢。 上喜，所以慰抚赐赍之甚厚。 庚午，以侍 卫都指挥使归德节度使石守信为天平节度使，殿前副都点 检忠武节度使高怀德为归德节度使，殿前都指挥使义成节 度使王审琦为忠正节度使，侍卫都虞候、镇安节度使张令 铎为镇安（良按： “安”字误，当作“宁”，据吴廷燮《北宋经 抚年表》改）节度使，皆罢军职。 独守信兼侍卫都指挥使如 故，其实兵权不在也。 殿前副都点检自是亦不复除授云。 （按《太平治迹统类》所载，字句几全同《长编》，兹不赘 录）。 以《长编》此条与《东都事略·赵普传》相较，此条显较该 传为详备。 其可称道者计有四点： 第一，由《长编》此条可知 麾下以黄袍加身之语出自赵普，太祖深韪其意，特用以指点 守信等人。 第二，守信等人此时方典禁卫，所谓解军职交出 兵权，盖专指交出禁军之兵权而言，此点极为重要。 《东都事 略》对此点未加点明，遂使人误解所解除者为其节度使之兵 权。 解除节度使兵权另为一事，本文当另外考证。 要之，建 隆二年所解除者为诸将所典禁军之兵权。 第三，《东都事略》 及《长编》此条均载太祖“为天子不如为节度使之乐”之语，是 &quot;&quot;&quot; . Now, we will use jieba_processing_txt() to create word list for the text. . word_list = jieba_processing_txt(txt, stopwords_path) word_list . &#39; 宋史 二五 石守信 建隆 二年 移镇 郓州 兼侍 卫亲军 马步军 都指挥使 诏赐 本州 一区 乾德初 帝因 晚朝 守信 饮酒 我非 尔曹 不及 然吾为 天子 殊不若 为节 之乐 终夕 未尝 安枕而卧 守信 顿首 天命 复敢 异心 陛下 何为 此言 富贵 一旦 有以 黄袍 加汝之身 虽欲 不为 可得乎 守信 臣愚 不及 陛下 哀矜 人生 过隙尔 不如 积金 田宅 以遗 子孙 歌儿 舞女 以终天年 君臣 之间 猜嫌 不亦善乎 守信 陛下 念及 所谓 生死 而肉 明日 称病 乞解 兵权 帝从 散官 甚厚 良谨 此即 世传 杯酒释兵权 一事 所本 杯酒释兵权 世所 艳称 五代 骄兵悍将 劫持 割据 历时 五十余年 雄鸷 梁太祖 周世宗 不能 彻底 纠正 宋太祖 乃于 酒言欢 之际 解除 干戈 之局 化为 雍熙 垂拱 之治 不但 国史 平添 一大 佳话 抑且 宋室 三百年 治之基 关系 重大 言可喻 实际 政治 之中 奇迹 不多 石守信 解除 果由 太祖 推诚 感召 所致 别有 不得不 遵行 命令 原因 此迹 传奇 杯酒释兵权 一事 有无 附会 夸张 凡此 怀疑 问题 本文 考证 杯酒释兵权 一事 不可 进而 推求 宋初 军队 国家化 中央 所以 得告 成功 根本原因 大雅君子 幸教正 上引 宋史 石守信 以下 简称 石传 此事 德初 今检 李焘 资治通鉴 长编 以下 简称 长编 乾德 年间 诸卷 四至 卷八 此事 长编 此事 于建隆 年秋 七月 戊辰 遣使 北岳 庙条 之后 庚午 侍卫 都指挥使 归德 节度使 石守信 天平 节度 略条 合为 一条 吴廷燮 宋经抚 年表 长编 此事 于建隆 三年 吴误 事略 二六 赵普传 亦系 此事 于二叛 李筠 李重 既平 之后 百川 太平 治迹 统类 太祖 圣政节 此事 建隆 二年 七月 三书 全合 司马光 涑水 记闻 邵伯温 邵氏 闻见 一载 此事 二叛 之后 长编 事略 相同 长编 此条 原注 晋公谈录 及王 文正公 笔录 二书亦载 此事 晋公 谈录 历代 小史 川学海 二本 历代 小史 本殊 简略 未记 杯酒释兵权 一事 川学海 本未 著岁 文正公 笔录 此事 起句 太祖 创业 在位 历年 石守信 王审 犹分典 禁兵 如故 云云 未著 何年 玩其 语气 太祖 即位 若干年 之后 在位 历年 一语 殊嫌 笼统 建隆 二年 未尝 不合 根据 以上 各项 史料 可知 建隆 二年 证据 长编 系年 之法 最为 可信 石传 此事 德初 不知 何所据 云然 想系 编纂 之际 仓卒 成书 未暇 参考 长编 臆度 其为 乾德 初年 率尔 误载 石传 建隆 二年 移镇 郓州 兼侍 卫亲军 马步军 指挥 之文 事实上 所谓 兵权 此之谓 郓州 天平 长编 建隆 二年 七月 庚午 条云 侍卫 挥使 归德 节度使 石守信 天平 节度使 侍卫 都指挥使 其实 兵权 据此 可知 石传 建隆 二年 云云 此事 李焘 此条 杯酒释兵权 一事 合载 自极 允当 宋史 乃于 石传 认为 截然 两事 杯酒 释兵 一事 系于 移镇 郓州 之后 疏略 无识 实甚 可笑 乾德 三字 不可 至此 一证 以上 考证 可知 太祖 石守信 建隆 二年 所载误 不可 置信 事略 二六 赵普传 初二 叛既平 太祖 召普问 天下 唐季 以来 数十 年间 帝王 凡易 八姓 兵革 不息 苍生涂 故何 欲息 天下 国家 长久之计 其道 何如 普曰 下及 此言 天地人 神之福 唐季 以来 战斗 不息 国家 所以 不安 由节 太重 君弱 而已 所以 其权 制其 钱谷 收其 精兵 天下 自安 顷之 太祖 因晚 石守信 王审琦 太祖 左右 曹之力 不得 至此 念汝之德 无有 天子 艰难 殊不若 节度使 之乐 守信 何故 太祖 不难 知矣 居此 位者 守信 顿首 陛下 何谓 此言 今天 已定 孰敢 异心 太祖 不然 无异 其如 下之人 富贵 一旦 黄袍 加汝之身 其可得乎 守信 不及 陛下 哀矜 示以 可生 之途 太祖 人生 白驹过隙 所为 富贵 不过 多积 金钱 厚自 娱乐 子孙 贫乏 之忧 何不 释去 兵权 择便 田宅 市之为 子孙 永久 之业 多置 歌舞 饮酒 相欢 以终天年 君臣 之间 无猜 上下 相安 不亦善乎 于是 守信 解军 太祖 许之 此言 兵权 之谋 出自 赵普 石传 宋史 五六 赵普传 不载 长编 事略 大致相同 关系 甚大 不惮 录于 长编 建隆 二年 七月 戊辰 遣使 北岳 条后 半云 李筠 重进 一日 召赵 普问 天下 唐季 以来 数十年 帝王 凡易 八姓 战斗 不息 生民 故何 欲息 天下 之兵 国家 长久 其道何 普曰 陛下 言及 天地人 神之福 无非 方镇 太重 君弱 而已 所以 其权 制其 钱谷 收其 精兵 天下 自安 语未 无复言 已喻 石守信 王审琦 故人 各典 禁卫 普数言于 请授 乘间 即言 彼等 必不吾叛 何忧 不忧 其叛 然熟 观数 人者 统御 不能 制伏 其下 苟不能 制伏 其下 军伍 万一 作孽 临时 亦不得 自由 上悟 于是 守信 左右 我非 尔曹 之力 不得 至此 尔曹 无有 穷尽 天子 艰难 殊不若 节度使 终夕 未尝 安枕而卧 守信 皆曰 何故 不难 知矣 居此 位者 守信 陛下 何为 此言 今天 已定 复有 异心 不然 无异 其如 麾下 富贵 一旦 黄袍 加汝之身 其可得乎 顿首 涕泣 不及 陛下 哀矜 指示 可生 之途 人生 如白驹 过隙 所为 富贵 不过 多积 金钱 厚自 娱乐 子孙 贫乏 尔曹 何不 释去 兵权 出守大藩 择便 田宅 子孙 永远 不可 动之业 多置 歌儿 舞女 饮酒 相欢 终其天年 我且 尔曹 婚姻 君臣 之间 两无 猜疑 上下 相安 不亦善乎 拜谢 陛下 念臣 至此 所谓 生死 而肉 明日 上喜 所以 慰抚 甚厚 庚午 以侍 都指挥使 归德 节度使 石守信 天平 节度使 殿前 检忠武 节度使 高怀德 归德 节度使 殿前 都指挥使 义成节 王审琦 为忠正 节度使 侍卫 都虞候 镇安 节度使 张令 镇安 字误 当作 吴廷燮 北宋 年表 节度使 军职 守信 侍卫 都指挥使 其实 兵权 殿前 点检 自是 不复 授云 太平 治迹 统类 字句 几全同 长编 不赘 长编 此条 事略 赵普传 此条 显较 详备 称道 计有 四点 第一 长编 此条 可知 麾下 黄袍加身 之语 出自 赵普 太祖 深韪 其意 用以 指点 守信 第二 守信 此时 方典 禁卫 所谓 军职 交出 兵权 专指 交出 禁军 兵权 而言 此点 极为重要 东都事 对此 点未 加点 误解 解除 节度使 之兵 解除 节度使 兵权 一事 本文 另外 考证 二年 解除 所典 禁军 兵权 第三 事略 长编 此条 均载 太祖 天子 不如 节度使 之语&#39; . Creating Word Cloud . To create a customized word cloud, we can define an image from which colours are selected. Here, we will use song.jpg for the colour palette. We will create a mask from the image. . icon_path = r&quot;/content/drive/MyDrive/song.jpg&quot; # convert to RGBA icon = Image.open(icon_path).convert(&quot;RGBA&quot;) # create a mask as array mask = Image.new(&quot;RGB&quot;, icon.size, (255,255,255)) mask.paste(icon,icon) mask = np.array(mask) . Then, we can use another image for the mask. We will first open the image as an array. Then, we can use the WordCloud() from the wordcloud library to create the image. We need to define the background colour, font, and mask. . shape = np.array(Image.open(r&quot;/content/drive/MyDrive/tree.jpg&quot;)) # create word cloud wc = WordCloud(background_color=&quot;#040052&quot;, max_words=2000, font_path=&quot;/content/drive/MyDrive/TaipeiSansTCBeta-Regular.ttf&quot;, mask=shape, max_font_size=100, random_state=42, width=1000, height=860, margin=2) # add word list wc.generate(word_list) . &lt;wordcloud.wordcloud.WordCloud at 0x7f1f32ed10d0&gt; . Then, we will recolor the word cloud using the input image. . wc.recolor(color_func=ImageColorGenerator(mask), random_state=2) # plot figure plt.figure(figsize=(15,10)) # show image plt.imshow(wc, interpolation=&quot;bilinear&quot;) plt.axis(&quot;off&quot;) plt.show() . Well done! Now, we have made a nice word cloud with the shape of a tree. Feel free to play around with different options, such as different background colours, the mask, and the text. . Pay attention: when you select the mask image, the image needs to be large enough for the word cloud, otherwise, you will get an error. . Downloading Image . After having our word cloud, you can right-click and directly download it. Another way to download the image is to use the function provided by google.colab. In the code below, we first convert our word cloud wc to a file called wordcloud.png, and then download it using files.download(). . wc.to_file(&quot;wordcloud.png&quot;) files.download(&quot;wordcloud.png&quot;) . Making a function . To simplify the full workflow, we can also create our function. You can better understand how to write a function here. In this function, we will take the text, stopwords_path, mask_path, color_path, figsize, and font_path, and directly return an image. . def create_wordcloud(txt, stopwords_path, mask_path, color_path, figsize=(15,10), font_path=&quot;/content/drive/MyDrive/TaipeiSansTCBeta-Regular.ttf&quot;): #color img = Image.open(color_path).convert(&quot;RGBA&quot;) color = Image.new(&quot;RGB&quot;, img.size, (255,255,255)) color.paste(img,img) color = np.array(color) #shape shape = np.array(Image.open(mask_path)) # create word cloud wc = WordCloud(background_color=&quot;#040052&quot;, max_words=2000, font_path=font_path, mask=shape, max_font_size=100, random_state=42, width=1000, height=860, margin=2) # create a word list from text word_list = jieba_processing_txt(txt, stopwords_path) # add word list to word cloud wc.generate(word_list) # recolor word cloud using ImageColorGenerator() wc.recolor(color_func=ImageColorGenerator(color), random_state=2) # display image plt.figure(figsize=figsize) plt.imshow(wc, interpolation=&quot;bilinear&quot;) plt.axis(&quot;off&quot;) plt.show() return wc . Now, we can apply the new function to our word cloud! . mask_path=r&quot;/content/drive/MyDrive/tree.jpg&quot; color_path=r&quot;/content/drive/MyDrive/song.jpg&quot; create_wordcloud(txt=txt, stopwords_path=stopwords_path, mask_path=mask_path, color_path=color_path) . &lt;wordcloud.wordcloud.WordCloud at 0x7f1f2dbc9710&gt; . &#127881; . Great that you have made it here 😎. Feel free to play around with functions to make sure you understand how everything works. You might have a question by now: What if we do not want to copy a long text for the word cloud, from either grab it from a website or read it from a pdf file? You will learn more in the future lesson. . . . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: January 2022 . . . . References: . https://github.com/stopwords-iso/stopwords-zh . Yeung Wong &amp; Carrie Lo from cyda .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/level-4/chapter-4/jieba/text-mining/data-visualization/2022/01/31/Simple_Word_Cloud.html",
            "relUrl": "/level-4/chapter-4/jieba/text-mining/data-visualization/2022/01/31/Simple_Word_Cloud.html",
            "date": " • Jan 31, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Adding Historical Base Map in QGIS",
            "content": "Background . If you just started with QGIS, a free and open geographic information system application for working with georeferenced data, you might realize there is only an empty window when you start a new project. Adding a base map is very helpful for you to comprehend and navigate your data. Basemap serves as a reference map on which you overlay data from layers and visualize geographic information. Just as a Google Map, you can zoom in and out for different levels of details in your map. However, the typical open base map such as Open Street Map might not be enough for historical research. In this tutorial, you will learn how to add Chinese historical base maps into your QGIS. Here we will demonstrate with QGIS version 3.16.0-Hannover. . Basic Setup . The first thing you need to do is to open a new project in QGIS. On the left side, you will see a browser panel where you can browse to a directory on your system where you have some GIS data, as well as a layer panel where the opened data will be displayed. The layer panel should be empty by now but our base map will appear there as soon as we add it. . . Add the Basemaps . Adding a historical base map is rather straightforward. It is done via WMS/WMTS (Web Map Service), which is a service hosted on a remote server. Similar to a website, you can access it as long as you have a connection to the server. Using QGIS, you can load a WMS directly into your existing map. The WMS service can be assessed either by right-clicking the WMS/WMTS icon in the browser panel, or clicking layer from the menu bar, browsing to Add Layer and Add WMS/WMTS Layer. Then you can create a new connection by inputting the Name and URL. . Here, we will use the base maps provided by Chinese Civilization in Time and Space (中華文明之時空基礎架構) from Academia Sinica (中央研究院) in Taiwan. For the details of the project, you can visit this page. . In the screenshot below, I use the name 中國歷史地圖. For the URL, input the following: . http://gis.sinica.edu.tw/ccts/wmts?SERVICE=WMTS&amp;REQUEST=GetTile&amp;VERSION=1.0.0&amp;LAYER=%7BLayer_ID%7D&amp;STYLE=_null&amp;TILEMATRIXSET=GoogleMapsCompatible&amp;TILEMATRIX=%7Bz%7D&amp;TILEROW=%7By%7D&amp;TILECOL=%7Bx%7D&amp;FORMAT=image/jpeg . Then click ok. . . . Check the Projection . For all layers correctly displayed, we need to make sure the project projection is consistent with the layer projection. As the base map layer has a projection of EPSG: 3857, we need to change the project projection to the same setting too. We can do that by clicking on the EPSG code in the bottom right of the window, where an earth icon is displayed. Then we will search for EPSG code 3857 and click apply then ok. . . Then we can browse through different base maps. This is the full list of the available maps. . A shortened list: . 唐代各道、州界 : Tang_Admin . | 唐代交通路線圖 : Tang_TrafficRoute . | 西周時期地圖 : Xijhou . | 河西新疆五十萬分一地圖集 : Xinjiang_500K_1943 . | 東漢歷史地圖(E. Han) : ad0140 . | 三國歷史地圖(Sanguo) : ad0262 . | 西晉歷史地圖(W. Jing) : ad0281 . | 東晉歷史地圖(E. Jing) : ad0382 . | 南北朝歷史地圖(South and North) : ad0497 . | 隋代歷史地圖(Sui) : ad0612 . | 唐代歷史地圖(Tang) : ad0741 . | 北宋歷史地圖(N. Song) : ad1111 . | 南宋歷史地圖(S. Song) : ad1208 . | 元代歷史地圖(Yuan) : ad1330 . | 明代歷史地圖(Ming) : ad1582 . | 讀史方輿紀要地名 : ad1582_10_2s . | 清代歷史地圖(Qing) : ad1820 . | 西漢歷史地圖(W. Han) : bc0007 . | 秦代歷史地圖(Qin) : bc0210 . | 明代雲南外邊與軍管政區 : mingbd_yn . | 明代驛站與驛路 : mingtraffic . | 商時期地圖 : shang . | 中華民國新地圖 : spaper . | 春秋時期地圖 : spring_autumn . | 戰國時期地圖 : warring_states . | . Double click on the layer you like in the browser panel. Now, in the layer panel, you will see a new layer being displayed. To better view the layers, we will right-click the base map layer and select Zoom to Layer . . Add Open Street Map . However, the historical base map provided by Academia Sinica do not show fine details for the topography and different provinces. To improve the visuals, I prefer also to add an Open Street Map base map for looking into regional details. To do that, we can use another option for adding a base map: XYZ Tile Layers, which was implemented for tiled services with no plugin required. . In the Browser Panel (or from the browser panel of the “Data Source Manager”), find the XYZ Tiles and right-click it. Select New Connection. Here we need to provide a name (any name will do) and add the URL. The placeholders {z}, {x}, and {y} will be replaced by QGIS with the appropriate information. To add the Open Street Map (OSM), use the following URL: . https://tile.openstreetmap.org/{z}/{x}/{y}.png . . You can also add other options as you like: . Satellite: http://mt0.google.com/vt/lyrs=s&amp;hl=en&amp;x={x}&amp;y={y}&amp;z={z} . Terrain: http://mt0.google.com/vt/lyrs=t&amp;hl=en&amp;x={x}&amp;y={y}&amp;z={z} . Pay attention that the layers are displayed in order, so your historical base map will be hidden by OSM if it is put below the OSM layer. Great! Now, we finish with the set-up and can start to play around with our data. Let’s look at our base maps. . . . . References . https://ccts.sinica.edu.tw/framework.php?lang=zh-tw .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/gis/maps/2022/01/20/historical_base_map.html",
            "relUrl": "/gis/maps/2022/01/20/historical_base_map.html",
            "date": " • Jan 20, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Six Reasons to Learn Python for Historical Research",
            "content": "As mentioned in the instructions, all materials can be open in Colab as Jupyter notebooks. In this way users can run the code in the cloud. It is highly recommanded to follow the tutorials in the right order. . The importance of Python is often written from the perspective of computer science and data science. Nonetheless, the research needs for history are essentially different, so do the criterium for selecting a digital tool. Here, we will explain why Python is still highly relevant for historians. . . 1) Python can Process Text in any Digital Formats &#128220; . Doing research often requires working with different media formats in this digital age, regardless of what your research interests are. Even you are not working with a large number of data sources, you might either need to work with long texts or sources that are only offered in digital formats. Meanwhile, you might want to output your research in a digital format. . Either you might want to write your blog for your projects, or you need to process text in pdf format, Python is a useful tool to READ, PROCESS, and CONVERT between different digital formats. Sometimes you might download historical data in Stata Data File Format (.dta), other times what you have is a large CSV file. When you try to do a specific task, you might search for online tools which often is not free or is not convenient (For example, you might need to process the file one by one). Learning Python enable you to gain multiple skills working with different data formats, including but not limited to txt, XML, csv, xlsx, json, geojson, shp, pdf, and dta. Reading those format is the first step of everything coming after, such as cleaning them or filtering them. . One of the most popular libraries for working with tabular data is Pandas. In contrast to Excel, you can use Pandas to work with CSV files with millions of rows in ease. You do not need to manually select any cells or deal with missing values. Similar to Excel, you can also create graphics from the table using Pandas. The difference is that you have way more controls on the layouts and types of visualization. . Python is one of the programming languages having the most readable syntax and the largest open source community to support and contribute. Programming is not an individual task, it requires resources from others: either to fix a bug, find a realistic solution, or use libraries or code written by someone else. It is why having a large community make it easier to get the job done. . 2) Python gives you Access to Digital Data &#128273; . With the growth of digital humanities or digital history, more and more historical sources have been stored and published in a digital format, such as 明清妇女著作 and 中国历代人物传记资料库CBDB. Depending on the website and the nature of the data, the download format will also change (.mdb, csv, etc.). Sometimes the data you are looking for is not systematically stored, which might also require some web scraping, such as grabbing tables on a webpage (In this case you can use beautifulsoup or selenium). No matter how and in what format your data is stored, you can always access them using Python. . Data access does not simply mean copying the resources, but also having them in a structural framework so you can use them effectively. By reading the data in a structured way, you can clean the irrelevant information, filter items that fit your interests without any manual effort. For example, you can clean all the empty rows, or convert your table from long to wide format. Python is even more advantageous when you work with time series or spatial data owing to its powerful libraries Pandas and Geopandas. With the geospatial libraries, you can easily perform geospatial operations and make maps just like in geographic information system (GIS). . 3) It offers Big Picture of the Data Collection &#128444;&#65039; . Amid the ongoing information explosion, we do not simply have much more information for the current time, but also much more digitalized data from the past with the emerging digital scholarship projects. Although big data offers us more material to conduct research, often it is not realistic for us to work with a large amount of data, for instance, thousands of novels/ publications. We might solely want to filter very little information from the data pool or have an overview of all materials. We can achieve it by performing topic modelling, counting the frequency of keywords, or computing statistics. . Using machine learning, we can also perform unsupervised clustering on the texts for categorization. The mentioned approaches require different skills in text mining, big data analysis, and NLP. With Python, we can smoothly combine multiple domains in a single script. Learning a new tool always takes time. Hence, the best is to select tools that can reasonably perform most tasks. With the aid of Python, you can easily save time for the redundant tasks. . 4) It helps you Understand Patterns in a Systematical way &#128376;&#65039; . Machine reads differently than human eye. It is also why distant reading or Natural language processing (NLP) can aid with historical text analysis. By aggregating and analyzing massive amounts of data, we can observe the patterns of texts in a large scale, for example, some formal aspects of literature. It aims to have a more abstract view of the texts by visualizing their global features. One of the technique is Term Frequency(TF) — Inverse Dense Frequency(IDF) used to classify text resources. Other techniques include sentiment analysis and text similarity metrics. It can also be combined with different elements such as geospatial maps to visualize geographical information. All these can be easily implemented in Python suiting to your research needs. . 5) You can Visualize Data from infographics to map &#128506;&#65039; . Research using historical data does not end with text analysis. Often, particularly if you are an expert of your data, you need to communicate with the audience, either your coworkers, students, fellow researchers, or the funding agencies. To achieve it, you can create charts for your publication, infographics to put on the social media, or making a simple web application, with interactive figures and maps to allow more involvements from the audience. . Python provides multiple plotting libraries, from Matplotlib, Seaborn to Plotly. Not only can they produce publication-quality figures, but also different types of data visualization. You can decide if you wish to have animation or interactive dashboard. You can even build your web application with embedded text, graphics, and web map. . 6) You can Customize to your research needs &#128736;&#65039; . The specific tasks for histircal research are diverse, and often there are not yet tools doing what you exactly need. It is a pain when you realize an online tool is a bit deviated from what you expected, as there is often no way to further customize it. For instance, when you try to create a word cloud online, but am not satistified with the color use, the font, or simply that they do not support the language you use, or you need to filter or clean your data in a way that is not supported. . Using Python, however, there are vast choices for customization as long as you are willing to get your hands dirty. This does not only apply to data visualization, but also data collection and text analysis. Besides, thanks for the large open source community of Python, tools are available even for a relatively small niche, such as performing NLP on classical Chinese. As Python is free and open, once you learn about how to use a library, you can utilize it fully without the need to worry about licenses or subscriptions. You can also save your script, reuse it for another text, and freely share your approach with others without any barriers. . Summary . Commercial tools are mostly specialised in a certain domain, and the need of a license makes them difficult to use for reproduction and to share with others. Besides, if you need one task after another, for example, from web scraping to generating word clouds to making a web application for presentation, what you might need to do is jumping from one tool to another. Using open-source programming languages, however, provide you with flexibility for customization and integration so that you can perform all tasks seamlessly. . R is another programming language very popular among researchers, as it is for statistical computing and research. Similar to Python, it has a large community and can perform similar tasks: data wrangling, data visualization, feature selection web scrapping, app and so on. Both of the languages share many tools, for example, spacyr provides a convenient R wrapper around the Python spaCy for distant reading and plotnine is a Python implementation of R ggplot. Many useful libraries also support both languages, for example, Plotly for interactive plotting and Jieba for Chinese NLP. In fact, R and Python can even be bridged together using rpy2 and reticulate. . It needs to be said in advance that both R and Python have their strengths and weaknesses. Different to R, Python is a general-purpose language. It focuses on deployment and production. Hence, while R suits well for ad-hoc analysis, when it comes to building a product from machine learning, or text processing which is often needed before any data analysis can be done, Python can be a better choice. . . . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: January 2022 .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/level-1/chapter-1/background/2022/01/20/Reason4Py.html",
            "relUrl": "/level-1/chapter-1/background/2022/01/20/Reason4Py.html",
            "date": " • Jan 20, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "Hand Drawn Styling Charts with matplotlib",
            "content": "As mentioned in the instructions, all materials can be open in Colab as Jupyter notebooks. In this way users can run the code in the cloud. It is highly recommanded to follow the tutorials in the right order. . Welcome to the data visualization chapter! After you have done some basic plots using Matplotlib, do you know you can further style your plot beyond the color uses? In this lesson, you will learn how can you make a matplotlib chart with hand drawn style ✍️. To do that you do not need to install any new library. . Let&#39;s try to make a chart using some Chinese historical statistics about taxation and infrastructures (stage station) during Yuan Dynasty (1279-1368) [Source]. . To begin, we need to first import some libraries and install pinyin for converting the Chinese labels. . import matplotlib.pyplot as plt import pandas as pd import numpy as np . ! pip install pinyin import pinyin . We have our locations listed. They are all different Chinese regions in which stage stations are located. Using pinyin.get() we can convert the words into pinyin. . loc_list = [&quot;腹里&quot;,&quot;河南江北&quot;,&quot;辽阳&quot;,&quot;江浙&quot;,&quot;江西&quot;,&quot;湖广&quot;,&quot;陕西&quot;,&quot;四川&quot;,&quot;云南&quot;,&quot;甘肃&quot;] name = [pinyin.get(loc, format=&quot;strip&quot;, delimiter=&quot; &quot;) for loc in loc_list] . Then we will define the type for the stage station, either land transport or water transport. . type_list = np.concatenate((np.repeat(&quot;Lu zhan&quot;,10), np.repeat(&quot;Shui zhan&quot;, 10)), axis=0) . Now, we can construct our data frame. . data = { &quot;Location&quot;: name + name, &quot;Station&quot;: [177,106,120,180,85,100,80,48,74,6,21,90,0,82,69,73,1,84,4,0], &quot;Type&quot;: type_list } df = pd.DataFrame(data=data) df.head() . Location Station Type . 0 fu li | 177 | Lu zhan | . 1 liao yang | 106 | Lu zhan | . 2 he nan | 120 | Lu zhan | . 3 shan xi | 180 | Lu zhan | . 4 si chuan | 85 | Lu zhan | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; We can use seaborn sns.catplot() for making a groupped bar chart easily. We will group the variable using argument hue. For further adjustments, we can add a title, rotate the ticks, and add annotations to the chart. Seaborn is a plotting library based on matplotlib and it is highly compatible with Pandas. This means, you can plot a Pandas dataframe using seaborn which enable users to create stylist chart in different themes. Let&#39;s look at a introduction video. . . Now, Let&#39;s look at how a seaborn chart is like without hand drawn style. . import seaborn as sns sns.set_style(&#39;darkgrid&#39;) # groupped bar chart ax = sns.catplot(x = &quot;Location&quot;, # x variable name y = &quot;Station&quot;, # y variable name hue = &quot;Type&quot;, # group variable name data = df, # dataframe to plot kind = &quot;bar&quot;, height=8) # add a title plt.title(&quot;Count of Stage Stations n in Yuan Dynasty (1279-1368)&quot;,loc=&quot;left&quot;,fontsize=22) # rotate ticks plt.xticks(rotation=30) # add annotations plt.annotate(&#39;FOR WATER TRANSPORT&#39;, xy=(2.9,125), xytext=(4.5,145), arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05, headwidth=20, width=5)) plt.annotate(&#39;FOR LAND TRANSPORT&#39;, xy=(3.1,80), xytext=(4.5,125), arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05, headwidth=20, width=5)) # display plot plt.show() . In fact, we can alter the style of seaborn chart simply using sns.set_style(). Available style includes &quot;darkgrid&quot;,&quot;white&quot;,&quot;ticks&quot;, and &quot;whitegrid&quot;. Let&#39;s look at the same plot in &quot;white&quot; style. . import seaborn as sns sns.set_style(&#39;white&#39;) # groupped bar chart ax = sns.catplot(x = &quot;Location&quot;, # x variable name y = &quot;Station&quot;, # y variable name hue = &quot;Type&quot;, # group variable name data = df, # dataframe to plot kind = &quot;bar&quot;, height=8) # add a title plt.title(&quot;Count of Stage Stations n in Yuan Dynasty (1279-1368)&quot;,loc=&quot;left&quot;,fontsize=22) # rotate ticks plt.xticks(rotation=30) # add annotations plt.annotate(&#39;FOR WATER TRANSPORT&#39;, xy=(2.9,125), xytext=(4.5,145), arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05, headwidth=20, width=5)) plt.annotate(&#39;FOR LAND TRANSPORT&#39;, xy=(3.1,80), xytext=(4.5,125), arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05, headwidth=20, width=5)) # display plot plt.show() . Hand Drawn Style . To plot the chart with hand drawn style, we only need to add plt.xkcd() before the plotting function. Matplotlib xkcd is a sketch-style drawing mode and it will only has effects on things drawn after plt.xkcd() is called. . import seaborn as sns sns.set_style(&#39;white&#39;) # hand drawn chart plt.xkcd() # groupped bar chart ax = sns.catplot(x = &quot;Location&quot;, # x variable name y = &quot;Station&quot;, # y variable name hue = &quot;Type&quot;, # group variable name data = df, # dataframe to plot kind = &quot;bar&quot;, height=8) # add a title plt.title(&quot;Count of Stage Stations n in Yuan Dynasty (1279-1368)&quot;,loc=&quot;left&quot;,fontsize=22) # rotate ticks plt.xticks(rotation=30) # add annotations plt.annotate(&#39;FOR WATER TRANSPORT&#39;, xy=(2.9,125), xytext=(4.5,145), arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05, headwidth=20, width=5)) plt.annotate(&#39;FOR LAND TRANSPORT&#39;, xy=(3.1,80), xytext=(4.5,125), arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05, headwidth=20, width=5)) # display plot plt.show() . We can also try with a different plotting type. Let&#39;s try to do a pie chart using the taxation data from different Chinese regions. The same as above, we need to first creating the pandas data frame, following by the plotting function using plt.subplots() and pie(). As we already use plt.xkcd() above, our plot will be automatically create in the hand drawn style. For the pie function, we will use rotatelabels to avoid label overlapping and labeldistance to define the label locations. . loc_list = [&quot;腹里&quot;,&quot;辽阳&quot;,&quot;河南&quot;,&quot;陕西&quot;,&quot;四川&quot;,&quot;甘肃&quot;,&quot;云南&quot;,&quot;江浙&quot;,&quot;江西&quot;,&quot;湖广&quot;] name = [pinyin.get(loc, format=&quot;strip&quot;, delimiter=&quot; &quot;) for loc in loc_list] # list comprehension to get pinyin for the whole list # create data data = { &quot;Location&quot;: name, &quot;Amount&quot;: [18.75,0.59,21.39,1.86,0.96,0.50,2.29,37.10,9.56,6.97] } # pass data into data frame df = pd.DataFrame(data=data) # plot figure fig1, ax1 = plt.subplots(figsize=(10,10)) # draw pie chart ax1.pie(df.Amount,labels=df.Location, autopct=&#39;%1.1f%%&#39;,labeldistance=1,rotatelabels=True,shadow=True, startangle=90) ax1.axis(&#39;equal&#39;) # Equal aspect ratio ensures that pie is drawn as a circle. # title plt.title(&quot;Yuan Dai Sui Ru Liang Shu n(1279-1368)&quot;, loc=&#39;left&#39;) plt.show() . Great! Now we can style our graphics for more eye-catching presentation of the data. . Previous Lesson: Introduction to Data Visualization . Next Lesson: Simple Bubble Chart . . . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: January 2022 .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/level-3/chapter-3/matplotlib/data-visualization/2022/01/12/Hand_Drawn_Chart.html",
            "relUrl": "/level-3/chapter-3/matplotlib/data-visualization/2022/01/12/Hand_Drawn_Chart.html",
            "date": " • Jan 12, 2022"
        }
        
    
  
    
        ,"post5": {
            "title": "Bubble Timeline using plotly.express",
            "content": "As mentioned in the instructions, all materials can be open in Colab as Jupyter notebooks. In this way users can run the code in the cloud. It is highly recommanded to follow the tutorials in the right order. . plotly.express . Hi there! In the last tutorial, we began to explore the potential of plotly.express, which is a wrapper for Plotly.py to allow more interaction in our graphics. Last time we made a simple scatter plot/ bubble chart. This time we will continue with a variation of bubble chart to represent temporal development of the UNESCO inscriptions in different countries. This timeline is characterised by the bubbles along the x-axis with varied sizes and can be used to contrast temporal trends of multiply categories. . In order to create the timeline, we first have to import needed libraries, and read the data into a pandas data frame. . import io import pandas as pd import requests # read data url = &#39;https://examples.opendatasoft.com/explore/dataset/world-heritage-unesco-list/download/?format=csv&amp;timezone=Europe/Berlin&amp;lang=en&amp;use_labels_for_header=true&amp;csv_separator=%3B&#39; df = pd.read_csv(url, sep=&quot;;&quot;) . df.head() . Name (EN) Name (FR) Short description (EN) Short Description (FR) Justification (EN) Justification (FR) Date inscribed Danger list Longitude Latitude Area hectares Category Country (EN) Country (FR) Continent (EN) Continent (FR) Geographical coordinates . 0 Architectural, Residential and Cultural Comple... | Ensemble architectural, résidentiel et culture... | The Architectural, Residential and Cultural Co... | L’ensemble architectural, résidentiel et cultu... | Criterion (ii): The architectural, residential... | Critère (ii) : L’ensemble architectural, résid... | 2005-01-01 | NaN | 26.691390 | 53.222780 | 0.00 | Cultural | Belarus | Bélarus | Europe and North America | Europe et Amérique du nord | 53.22278,26.69139 | . 1 Rock Paintings of the Sierra de San Francisco | Peintures rupestres de la Sierra de San Francisco | From c. 100 B.C. to A.D. 1300, the Sierra de S... | Dans la réserve d&#39;El Vizcaíno, en Basse-Califo... | NaN | NaN | 1993-01-01 | NaN | -112.916110 | 27.655560 | 182600.00 | Cultural | Mexico | Mexique | Latin America and the Caribbean | Amérique latine et Caraïbes | 27.65556,-112.91611 | . 2 Monastery of Horezu | Monastère de Horezu | Founded in 1690 by Prince Constantine Brancova... | Fondé en 1690 par le prince Constantin Brancov... | NaN | NaN | 1993-01-01 | NaN | 24.016667 | 45.183333 | 22.48 | Cultural | Romania | Roumanie | Europe and North America | Europe et Amérique du nord | 45.18333333,24.01666667 | . 3 Mount Etna | Mont Etna | Mount Etna is an iconic site encompassing 19,2... | Ce site emblématique recouvre une zone inhabit... | NaN | NaN | 2013-01-01 | NaN | 14.996667 | 37.756111 | 19237.00 | Natural | Italy | Italie | Europe and North America | Europe et Amérique du nord | 37.7561111111,14.9966666667 | . 4 Belfries of Belgium and France | Beffrois de Belgique et de France | Twenty-three belfries in the north of France a... | Vingt-trois beffrois, situés dans le nord de l... | NaN | NaN | 1999-01-01 | NaN | 3.231390 | 50.174440 | 0.00 | Cultural | Belgium,France | Belgique,France | Europe and North America | Europe et Amérique du nord | 50.17444,3.23139 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Data Cleaning . We need to start with some preprocessing and data cleaning. We will start with subsetting and renaming the columns, followed by a calculation of total UNESCO sites in the &quot;top 10 countries&quot; using groupby() (we do not need this data frame for the plot, only list of the top 10 countries). We will sort the values using sort_vales(by=[&#39;name&#39;]) to order the countries from the most to the least UNESCO sites. . df = df[[&quot;Name (EN)&quot;,&quot;Date inscribed&quot;,&quot;Category&quot;,&quot;Country (EN)&quot;,&quot;Continent (EN)&quot;]] # select multiple columns in a list [] df = df.rename(columns={&quot;Name (EN)&quot;: &quot;name&quot;, &quot;Date inscribed&quot;: &quot;date&quot;, &quot;Category&quot;: &quot;type&quot;, &quot;Country (EN)&quot;: &quot;country&quot;, &quot;Continent (EN)&quot;: &quot;continent&quot;}) # rename the columns for easy reading . top_10 = df.groupby(df[&quot;country&quot;]).count().sort_values(by=[&#39;name&#39;], ascending=False).head(10) top_10 . name date type continent . country . China 49 | 49 | 49 | 49 | . Italy 47 | 47 | 47 | 47 | . Spain 41 | 41 | 41 | 41 | . France 38 | 38 | 38 | 38 | . Germany 35 | 35 | 35 | 35 | . Mexico 34 | 34 | 34 | 34 | . India 33 | 33 | 33 | 33 | . United Kingdom of Great Britain and Northern Ireland 27 | 27 | 27 | 27 | . Russian Federation 21 | 21 | 21 | 21 | . Iran (Islamic Republic of) 21 | 21 | 21 | 21 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Get the top 10 countries as a numpy array. . sub_cnty = top_10.index.values sub_cnty . array([&#39;China&#39;, &#39;Italy&#39;, &#39;Spain&#39;, &#39;France&#39;, &#39;Germany&#39;, &#39;Mexico&#39;, &#39;India&#39;, &#39;United Kingdom of Great Britain and Northern Ireland&#39;, &#39;Russian Federation&#39;, &#39;Iran (Islamic Republic of)&#39;], dtype=object) . With the information of the top 10 countries, we can now delete all the rows from other countries using isin(sub_cnty). We will then group the rows by country and date and count the rows for every country and every year. We will then reset the index. . top_df = df[df[&#39;country&#39;].isin(sub_cnty)].groupby([&#39;country&#39;,&#39;date&#39;]).count()[&#39;name&#39;].reset_index() top_df.head(5) . country date name . 0 China | 1987-01-01 | 6 | . 1 China | 1990-01-01 | 1 | . 2 China | 1992-01-01 | 3 | . 3 China | 1994-01-01 | 4 | . 4 China | 1996-01-01 | 2 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; As we need only the information of year, not the full date, we will create a new column year. We can extrate the year by first interpreting the date column as date time, then take the year values (simply with .year). . top_df[&#39;year&#39;] = pd.DatetimeIndex(top_df[&#39;date&#39;]).year # set up a new year column top_df.head() . country date name year . 0 China | 1987-01-01 | 6 | 1987 | . 1 China | 1990-01-01 | 1 | 1990 | . 2 China | 1992-01-01 | 3 | 1992 | . 3 China | 1994-01-01 | 4 | 1994 | . 4 China | 1996-01-01 | 2 | 1996 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Now we will group by again with the country and year and get the sum (count of inscriptions every year). . group_df = top_df.groupby([&quot;country&quot;,&quot;year&quot;]).sum() . import numpy as np country_list = np.array(group_df.index.get_level_values(0)) year_list = np.array(group_df.index.get_level_values(1)) . As we want need the country and year column not only as index. We will assign the columns again. . group_df[&#39;country&#39;] = country_list group_df[&#39;year&#39;] = year_list . Renaming the name column to count. . group_df = group_df.rename(columns={&quot;name&quot;: &quot;count&quot;}) group_df.head() . count country year . country year . China 1987 6 | China | 1987 | . 1990 1 | China | 1990 | . 1992 3 | China | 1992 | . 1994 4 | China | 1994 | . 1996 2 | China | 1996 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; To improve the visuals, we will simplified the name of UK. . group_df[&#39;country&#39;] = group_df[&#39;country&#39;].str.replace(&#39;United Kingdom of Great Britain and Northern Ireland&#39;,&#39;United Kingdom&#39;) . Data Visualization . To make a interactive scatter plot in plotly.express, we only need to use px.scatter(). It is highly compatible with pandas, so we can input a pandas data frame, and specify x and y (as well as size and color which are optional) with the column names. . Every changes in layout we can change using update_layout(). All the options can be found here. . import plotly.express as px fig = px.scatter(group_df, x=&quot;year&quot;, y=&quot;country&quot;, size=&quot;count&quot;, color=&quot;country&quot;) fig.update_layout(showlegend=False) fig.show() . . . Almost Done! . Good job! Let&#39;s look at our plot. It is interactive so you can pan around and zoom in/ out. If you put your mouse on the bubbles, you will also get information such as the country name and counts at a specific year. It is the default Plotly option. . However, we can also gain control over what information we want to put in the hover labels, as well as the layout (like the font, fontsize and so on). Isn&#39;t it much cooler if we can show names of all UNESCO sites instead of the count?! . Also, we can control to display hover labels for the whole xaxis instead of an individual bubble, which means, we can display all UNESCO sites inscripted in a year! Let&#39;s say we also want to display a moving yaxis too. . Let&#39;s do all the adjustments mentioned above. . . Customization . df.head() . name date type country continent . 0 Architectural, Residential and Cultural Comple... | 2005-01-01 | Cultural | Belarus | Europe and North America | . 1 Rock Paintings of the Sierra de San Francisco | 1993-01-01 | Cultural | Mexico | Latin America and the Caribbean | . 2 Monastery of Horezu | 1993-01-01 | Cultural | Romania | Europe and North America | . 3 Mount Etna | 2013-01-01 | Natural | Italy | Europe and North America | . 4 Belfries of Belgium and France | 1999-01-01 | Cultural | Belgium,France | Europe and North America | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Adjust Data Frame . As we need the information about UNESCO site name this time, we need to make use of df to make a subset for the top 10 countries then merged with our group_df. Let&#39;s go back to df and do some cleaning. First, we add the year column for df too. We group by country and year, and do a transformation here. . It is a bit tricky. The transformation aims to get all the rows with same country and year, and join all the values from [&#39;name&#39;] separated with a comma (,). This transformation is only done to the top 10 countries df[df[&#39;country&#39;].isin(sub_cnty)]. As this is repeatedly done for every row, we will end up with rows that are duplicated, so we will remove them. . df[&#39;year&#39;] = pd.DatetimeIndex(df[&#39;date&#39;]).year # join the site names df[&#39;site&#39;] = df[df[&#39;country&#39;].isin(sub_cnty)].groupby([&#39;country&#39;,&#39;year&#39;])[&#39;name&#39;].transform(lambda x: &#39;, &#39;.join(x)) # remove duplicates df.drop_duplicates() # look at the rows for China df[df[&quot;country&quot;] == &quot;China&quot;].head(5) . name date type country continent year site . 5 Sichuan Giant Panda Sanctuaries - Wolong, Mt S... | 2006-01-01 | Natural | China | Asia and the Pacific | 2006 | Sichuan Giant Panda Sanctuaries - Wolong, Mt S... | . 32 Tusi Sites | 2015-01-01 | Cultural | China | Asia and the Pacific | 2015 | Tusi Sites | . 38 The Great Wall | 1987-01-01 | Cultural | China | Asia and the Pacific | 1987 | The Great Wall, Mausoleum of the First Qin Emp... | . 68 Mausoleum of the First Qin Emperor | 1987-01-01 | Cultural | China | Asia and the Pacific | 1987 | The Great Wall, Mausoleum of the First Qin Emp... | . 72 Chengjiang Fossil Site | 2012-01-01 | Natural | China | Asia and the Pacific | 2012 | Chengjiang Fossil Site, Site of Xanadu | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Make sure only top 10 countries are included. . df_sub = df[df[&#39;country&#39;].isin(sub_cnty)] df_sub.head(1) . name date type country continent year site . 1 Rock Paintings of the Sierra de San Francisco | 1993-01-01 | Cultural | Mexico | Latin America and the Caribbean | 1993 | Rock Paintings of the Sierra de San Francisco,... | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; group_df.head(1) . count country year . country year . China 1987 6 | China | 1987 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; group_df.reset_index(drop=True, inplace=True) . Now, we have the name information from df_sub. We can merge it to our group_df data frame using the keys &quot;country&quot; and &quot;year&quot;. We select only the relevant columns [[&quot;country&quot;,&quot;year&quot;,&quot;site&quot;,&quot;count&quot;]], and call the new data frame final. . final = df_sub.merge(group_df, left_on=[&quot;country&quot;,&quot;year&quot;], right_on=[&quot;country&quot;,&quot;year&quot;]) final = final[[&quot;country&quot;,&quot;year&quot;,&quot;site&quot;,&quot;count&quot;]] final.head() . country year site count . 0 Mexico | 1993 | Rock Paintings of the Sierra de San Francisco,... | 3 | . 1 Mexico | 1993 | Rock Paintings of the Sierra de San Francisco,... | 3 | . 2 Mexico | 1993 | Rock Paintings of the Sierra de San Francisco,... | 3 | . 3 Italy | 2013 | Mount Etna, Medici Villas and Gardens in Tuscany | 2 | . 4 Italy | 2013 | Mount Etna, Medici Villas and Gardens in Tuscany | 2 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Great! Almost everything is ready. We only need to replace the comma with a &lt;br&gt; to make sure every item will be put in a new line in the hover labels. . final.site = final.site.apply(lambda x: x.replace(&#39;, &#39;, &#39;&lt;br&gt;&#39;)) final.site.head() . 0 Rock Paintings of the Sierra de San Francisco&lt;... 1 Rock Paintings of the Sierra de San Francisco&lt;... 2 Rock Paintings of the Sierra de San Francisco&lt;... 3 Mount Etna&lt;br&gt;Medici Villas and Gardens in Tus... 4 Mount Etna&lt;br&gt;Medici Villas and Gardens in Tus... Name: site, dtype: object . Ploting . Now, let&#39;s do our plot again using px.scatter(). . fig = px.scatter(final, x=&quot;year&quot;, y=&quot;country&quot;, size=&quot;count&quot;, color=&quot;country&quot;, custom_data=[&#39;year&#39;, &#39;site&#39;]) # remove legend fig.update_layout(showlegend=False) # show labels for whole x axis fig.update_layout(hovermode=&#39;x&#39;) # change layout for hover labels fig.update_layout( hoverlabel=dict( bgcolor=&quot;white&quot;, font_size=12, font_family=&quot;Rockwell&quot; ) ) # control info for hover labels using custom_data we specified above in pxscatter() # join items with new line &lt;br&gt; fig.update_traces( hovertemplate=&quot;&lt;br&gt;&quot;.join([ &quot;%{y}&quot;, &quot;Site: %{customdata[1]}&quot; ]) ) # add title, x- and y- labels, and a moving line along x axis # change font styles for the texts inside plot (y ticks and so on) fig.update_layout( title={ &#39;text&#39;: &quot;Timeline of UNESCO Inscriptions&quot;, &#39;y&#39;:0.95, &#39;x&#39;:0.5, &#39;xanchor&#39;: &#39;center&#39;, &#39;yanchor&#39;: &#39;top&#39;}, xaxis_title=&quot;Year of Inscription&quot;, yaxis_title=&quot;Top 10 Countries&quot;, xaxis={&#39;showspikes&#39;: True, &#39;spikemode&#39;: &#39;across&#39;, &#39;spikesnap&#39;: &#39;cursor&#39;, &#39;showline&#39;: True, &#39;showgrid&#39;: True}, font=dict( family=&quot;Rockwell&quot;, size=15, color=&quot;black&quot; ) ) # display out plot fig.show() . . . Cool! That&#39;s it! . Now we have an interactive plot with enhanced visuals and all information we need in the labels. Not only can we clearly see the trends of inscriptions in different countries, we can also clearly see the &quot;inscription peak&quot; of some countries (such as 1997 in Italy). We can tell, for example, countries like Russia and China are late players in the field. . Previous Lesson: Simple Bubble Chart . Next Lesson: Coming soon... . . . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: December 2021 . . . . References: . Plotly .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/level-3/chapter-3/plotly.express/data-visualization/2022/01/10/Plotly_Bubble_Timeline.html",
            "relUrl": "/level-3/chapter-3/plotly.express/data-visualization/2022/01/10/Plotly_Bubble_Timeline.html",
            "date": " • Jan 10, 2022"
        }
        
    
  
    
        ,"post6": {
            "title": "Simple Graphics using Plotly",
            "content": "As mentioned in the instructions, all materials can be open in Colab as Jupyter notebooks. In this way users can run the code in the cloud. It is highly recommanded to follow the tutorials in the right order. . In the last blog, we have created a bubble chart / scatter plot using Plotly. This time we are trying to make other types of plot: a simple bar chart and a lollipop chart using plotly.express and plotly.graph_objects. The creation of both charts begin with a Pandas data frame. Then we pass the data frame into Plotly for a basic plot, and update the layouts afterwards. The bar chart requires only one plotting action .bar(), whereas the lollipop chart requires two plotting actions: first creating the scatter plot, then with add the &quot;stick&quot; using add_shape(). . Set Up Environment . import pandas as pd import numpy as np import plotly.express as px # library for creating random lengths of &quot;stick&quot; in the chart from random import seed from random import random . Bar Chart . Creating Data Frame . In this example, we create a bar chart based on the records for the type of natural disaster recorded in 《臺灣文獻叢刊》臺灣方志. The data frame is created using a dictionary, created by passing column names and values. . data = { &quot;Type of Natural Disaster&quot;: [&quot;Fire&quot;,&quot;Locust&quot;,&quot;Drought&quot;,&quot;Earthquake&quot;,&quot;Flood&quot;,&quot;Typhoon&quot;,&quot;Storm&quot;], &quot;Number of Record&quot;: [63,81,86,13,138,158,8] } df = pd.DataFrame(data=data) . Plotting . Then we can do the plotting by calling px.bar(). We can pass x, y, title and the figure size into the function. This will allow the creation of a simple bar chart in Plotly using default layout options. If we wish to change any parameters, we can update it using update_layout(). . Here, we will update the hover labels by changing the font size and the background color. We will also adjust the width of the bars. Finally, we pass fig.show() for the display of our plot. . First, we define a set of color for the bars by passing them into a list. . color_discrete_sequence = [&#39;#1f77b4&#39;, # muted blue &#39;#ff7f0e&#39;, # safety orange &#39;#2ca02c&#39;, # cooked asparagus green &#39;#d62728&#39;, # brick red &#39;#9467bd&#39;, # muted purple &#39;#bcbd22&#39;, # curry yellow-green &#39;#e377c2&#39;] # raspberry yogurt pink . Then, we plot the chart. With the title, we can pass the html tag &lt;b&gt; &lt;/b&gt; to style the words (bold), and for the color argument, we use &#39;Type of Natural Disaster&#39;, which mean every single column, we use a different colors. By doing so, a legend will be automatically created to explain the implication of colors. We can disable them later using fig.update_layout(showlegend=False). . fig = px.bar(df, y=&#39;Number of Record&#39;, x=&#39;Type of Natural Disaster&#39;, title=&quot;&lt;b&gt;Disaster Records in 臺灣方志&lt;/b&gt;&quot;, width=1000, height=500, color=&quot;Type of Natural Disaster&quot;,color_discrete_sequence=color_discrete_sequence) . Let&#39;s us disable out legend and adjust the width of the bars. . fig.update_layout(showlegend=False) fig.update_traces(width=0.5) . Then, we will adjust the hover labels before displaying out plot using fig.show(). . fig.update_layout( hoverlabel=dict( bgcolor=&quot;white&quot;, font_size=14, font_family=&quot;Courier New&quot; ) ) fig.show() . . . Lollipop Chart . This time, let&#39;s us work with some qualitative data. We will try to plot a simple time line of the articles 胡適 had published in his life time. We want to label the data with the shorten titles while putting the full titles in our hover labels. . Creating Data Frame . Let&#39;s first create our data frame. In order to have a lollipop chart we need to define the y values. We would like the y values to be different for every titles so we can avoid text overlapping. It can be done using random library and random(). . We will also convert the date column to datetime using pd.to_datetime(). . data = { &quot;date&quot;: [&quot;1919-01-01&quot;,&quot;1917-05-01&quot;,&quot;1918-01-01&quot;,&quot;1919-07-20&quot;,&quot;1924-01-01&quot;,&quot;1929-01-01&quot;,&quot;1929-02-01&quot;,&quot;1929-03-01&quot;,&quot;1929-04-01&quot;,&quot;1930-04-10&quot;,&quot;1959-11-20&quot;], &quot;title&quot;: [&quot;文學改良芻議&quot;,&quot;歷史的文學觀念論&quot;,&quot;建設的文學革命論&quot;,&quot;多研究些問題，少談些主義&quot;,&quot;差不多先生傳&quot;,&quot;人權與約法&quot;,&quot;我們什麼時候才可有憲法—對於建國大綱的疑問&quot;,&quot;知難，行亦不易—孫文先生的「行易知難」說述評&quot;,&quot;新文化運動與國民黨&quot;,&quot;我們走那條路&quot;,&quot;容忍與自由&quot;], &quot;sub&quot;: [&quot;文學改良芻議&quot;,&quot;歷史的文學觀念論&quot;,&quot;建設的文學革命論&quot;,&quot;多研究些問題，少談些主義&quot;,&quot;差不多先生傳&quot;,&quot;人權與約法&quot;,&quot;我們什麼時候才可有憲法&quot;,&quot;知難，行亦不易&quot;,&quot;新文化運動與國民黨&quot;,&quot;我們走那條路&quot;,&quot;容忍與自由&quot;], } df = pd.DataFrame(data=data) df[&#39;date&#39;] = pd.to_datetime(df[&#39;date&#39;], format=&#39;%Y-%m-%d&#39;) df[&#39;y&#39;] = [random() for i in range(len(df.title))] . df . date title sub y . 0 1919-01-01 | 文學改良芻議 | 文學改良芻議 | 0.043649 | . 1 1917-05-01 | 歷史的文學觀念論 | 歷史的文學觀念論 | 0.729784 | . 2 1918-01-01 | 建設的文學革命論 | 建設的文學革命論 | 0.281129 | . 3 1919-07-20 | 多研究些問題，少談些主義 | 多研究些問題，少談些主義 | 0.544732 | . 4 1924-01-01 | 差不多先生傳 | 差不多先生傳 | 0.704270 | . 5 1929-01-01 | 人權與約法 | 人權與約法 | 0.699685 | . 6 1929-02-01 | 我們什麼時候才可有憲法—對於建國大綱的疑問 | 我們什麼時候才可有憲法 | 0.651569 | . 7 1929-03-01 | 知難，行亦不易—孫文先生的「行易知難」說述評 | 知難，行亦不易 | 0.262863 | . 8 1929-04-01 | 新文化運動與國民黨 | 新文化運動與國民黨 | 0.116383 | . 9 1930-04-10 | 我們走那條路 | 我們走那條路 | 0.443837 | . 10 1959-11-20 | 容忍與自由 | 容忍與自由 | 0.266778 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Plotting . This time, we create the figure using plotly.graph_objects. We can draw the sticks using fig.add_shape(type=&#39;line&#39;). It will be put in a loop so we can draw mulitple sticks for every row instead. x0, x1, y0, y1 mean the coordinates of the shape. As it is a line, x0 equals x1, and y0 and y1 refers to the beginning (always 0) and ending point (depends on y column) of the stick. Other options include the color of the sticks. . import plotly.graph_objects as go fig = go.Figure() # Draw lines for i in range(0, len(df)): fig.add_shape(type=&#39;line&#39;, # draw line x0 = df[&quot;date&quot;][i], y0 = 0, # our line x1 = df[&quot;date&quot;][i], y1 = df[&quot;y&quot;][i], opacity=0.65, # transparency line=dict(color=&#39;darkblue&#39;, width = 5)) # line color and width . Then we will plot the dots using fig.add_trace(go.Scatter()). We will use the text to indicate the static labels and customdata indicate the full titles. mode=&quot;markers+text&quot; means both markers and static labels will be shown. We will also use other customization options and html tags for our hovertemplate. . fig.add_trace(go.Scatter(x = df[&quot;date&quot;], y = df[&quot;y&quot;], text=df[&quot;sub&quot;], # static labels customdata=df[&quot;title&quot;], # hover labels mode=&quot;markers+text&quot;, # display static labels hovertemplate = # what to shown in hover labels &#39;&lt;extra&gt;&lt;br&gt;&lt;b&gt;Date&lt;/b&gt;: %{x}&lt;br&gt;&lt;/extra&gt;&#39;+ &#39;&lt;extra&gt;&lt;b&gt;%{customdata}&lt;/b&gt;&lt;/extra&gt;&#39;, textposition=&quot;top center&quot;, marker_color =&#39;darkblue&#39;, # layout for the dots marker_size = 16)) . Then, we add a title to our plot, and change other options including template, figure size, and y range. We will also disable y axis and ticks, as well as adjust layout for x axis and ticks. . fig.update_layout(title_text = &quot;胡適 文章與期刊&quot;, title_font_size = 30) fig.layout.template = &quot;simple_white&quot; # layout template fig.update_layout(width=1250, height=400) # figure size fig.update_layout(yaxis_visible=False, yaxis_showticklabels=False) # y axis and ticks fig.update_layout(yaxis_range=[0,1.5]) # y range fig.update_xaxes(tickfont_size=24, ticks=&quot;outside&quot;, ticklen=20, tickwidth=5) # x axis and ticks fig.show() # diaply plot . . . Previous Lesson: Simple Bubble Chart using plotly.express . Next Lesson: Coming soon... . . . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: December 2021 . . . . References: . Plotly .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/level-3/chapter-3/plotly/data-visualization/2022/01/09/Simple_Plotly_Chart.html",
            "relUrl": "/level-3/chapter-3/plotly/data-visualization/2022/01/09/Simple_Plotly_Chart.html",
            "date": " • Jan 9, 2022"
        }
        
    
  
    
        ,"post7": {
            "title": "Simple Bubble Chart using plotly.express",
            "content": ". As mentioned in the instructions, all materials can be open in Colab as Jupyter notebooks. In this way users can run the code in the cloud. It is highly recommanded to follow the tutorials in the right order. . . Plotly&#39;s Python graphing library makes interactive, publication-quality graphs. Compared to the static graphics, Plotly can not only embed more information using the hover tools, it also allow zooming and panning so users can easily look into the details of the graphics. Users can create Plotly graphics in Python using either plotly.graph_objects or plotly.express. While the first option allows more customization for graphical elements, The later option allows a much simpler syntax so it is also easier to learn. . This notebook aims to demonstrate users some simple functionalities of plotly.express library for making simple but interactive bubble charts. To start with the tutorial, users need to have some knowledge of matplotlib and understand the basic grammer of making a plot. In this tutorial, we will use a simple example of some basic statistics of Chinese dynasties, including the year range, territory area, population and maximum longevity of emperors. The statistics are found online with no guarantee of preciseness. It is purely used for plotting demonstration purpose. . . Presumptions: . . Set Up Environment . First, we set up the environment by importing the libraries. . import plotly.express as px import numpy as np import pandas as pd . Then, we will use a dictionary to create a Pandas data frame dyn_df. . dyn = { &quot;dynasty&quot;: [&quot;Qin&quot;,&quot;Han&quot;,&quot;Jin&quot;,&quot;Sui&quot;,&quot;Md Tang&quot;,&quot;S Song&quot;,&quot;Yuan&quot;,&quot;Ming&quot;,&quot;Qing&quot;], # name of dynasty &quot;year&quot;: np.array([-221,2,280,581,726,1223,1341,1570,1887]), # year of begin &quot;area&quot;: 10000*np.array([360,609,543,467,1237,200,1372,997,1316]), # territory &quot;pop&quot;: 10000*np.array([4500,6500,2200,4450,8050,8060,8500,6000,37700]), # population &quot;max emperor longevity&quot;: np.array([50,70,55,64,82,81,79,71,89]) # maximum emperor longevity } dyn_df = pd.DataFrame(data=dyn) # create data frame . Then we look at the first few rows. . dyn_df.head() . dynasty year area pop max emperor longevity . 0 Qin | -221 | 3600000 | 45000000 | 50 | . 1 Han | 2 | 6090000 | 65000000 | 70 | . 2 Jin | 280 | 5430000 | 22000000 | 55 | . 3 Sui | 581 | 4670000 | 44500000 | 64 | . 4 Md Tang | 726 | 12370000 | 80500000 | 82 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Using plotly.express (px) allows the uses of shorter code to make a plot. To create a scatter plot, we only need to input the data frame dyn_df, the columns (variables) for x, y axis, size of the markers, hover names (which information will appear when you point your mouse to the markers) and color of the markers. The argument size_max define the relative size of the bubbles. Typing fig.show() allow the figure to be displayed. . As you can see, a legend will be automatically created on the right side of our plot, and population in the y axis will be displayed in the format of million for better visuals. . fig = px.scatter(dyn_df, x=&quot;year&quot;, y=&quot;pop&quot;, size=&quot;area&quot;, color=&quot;dynasty&quot;, hover_name=&quot;dynasty&quot;, size_max=60) fig.show() . . . The plot looks fine, but there are still many parameters which can be adjusted. First, we want to try out a different theme (plotly_dark) for our figure. Then, we want to create a title, change some colors in layout, and color the bubbles by max emperor longevity. . Also, it would be nice if we can view the name of dynasty on the bubbles instead. Finally, to make the different between dynasties in y axis more distinct, we can use a log scale for the y axis. . To do all those, all we need to do is to customize many parameters of the scatter fucntion and use update_layout. Remember the hierarchy of the parameters is important as we need to, for example, put parameters that belong to xaxis into a single dict. . fig = px.scatter(dyn_df, x=&quot;year&quot;, y=&quot;pop&quot;, size=&quot;area&quot;, color=&quot;max emperor longevity&quot;,opacity=0.85, # changing the color parameter hover_name=&quot;dynasty&quot;, size_max=70, template=&quot;plotly_dark&quot;, title=&quot;Chinese Dynasty Comparison&quot;, # use template option width=1000, height=450, # set size of our plot text=dyn_df.dynasty.values ) fig.update_layout( title=&#39;&lt;b&gt;Chinese Dynasty Comparison&lt;/b&gt;&#39;, # add a title xaxis=dict( title=&#39;Year (CE)&#39;, # x label gridcolor=&#39;rgba(255, 255, 255, 0.6)&#39;, # color for grid gridwidth=0.5, # width of grid line ), yaxis=dict( title=&#39;Population Size&#39;, # y label type=&quot;log&quot;, gridcolor=&#39;rgba(255, 255, 255, 0.6)&#39;, gridwidth=0.5 ), font=dict( family=&quot;Courier New, monospace&quot;, # font style size=18, # font size color=&quot;white&quot; # font color ) ) fig.show() # display plot . . . However, we can also choose to reduce our plot to one dimension so it looks more like a original time line. . dyn_df.head() . dynasty year area pop max emperor longevity . 0 Qin | -221 | 3600000 | 45000000 | 50 | . 1 Han | 2 | 6090000 | 65000000 | 70 | . 2 Jin | 280 | 5430000 | 22000000 | 55 | . 3 Sui | 581 | 4670000 | 44500000 | 64 | . 4 Md Tang | 726 | 12370000 | 80500000 | 82 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; To do this, the main thing we need to change is the y axis. We can, for example, add a new column and set it to 0 for all rows. . dyn_df[&#39;y&#39;] = 0 . Now, we make the new plot again. This time, we want to show more hover info to the readers. We can do it in plotly.express by add custom_data (input columns) and call them using hovertemplate. For example, %{customdata[0]} means the first custom_data which is &quot;dynasty&quot; in this case (if there is only one custom_data, you can write %{customdata} instead). . Pay attention to the difference between customdata and custom_data. Be careful that it will not work the same way in plotly.graph_objects. . fig = px.scatter(dyn_df, x=&quot;year&quot;, y=&quot;y&quot;, # x and y marker location, use column name inside the dataframe size=&quot;area&quot;,opacity=0.85, # marker transparancy hover_name=&quot;dynasty&quot;, size_max=40, # marker size custom_data=[&#39;dynasty&#39;, &#39;area&#39;], # extra hover info template=&quot;simple_white&quot;, title=&quot;Chinese Territory over Time&quot;, # template and plot title width=900, height=300, # plot size text=dyn_df.dynasty.values # the dynasty will be displayed on the bubbles ) fig.update_traces( hovertemplate=&#39;&lt;i&gt;Dynasty&lt;/i&gt;: %{customdata[0]}&#39;+ &#39;&lt;br&gt;&#39; + # what we want to show in labels: you can use HTML tag here. Eg. &lt;br&gt; means next line &#39;&lt;i&gt;Territory&lt;/i&gt;: %{customdata[1]} km²&#39; # &lt;i&gt; means in italic ) fig.update_traces( marker=dict( color=&#39;#0073AE&#39;, # change marker color opacity=0.5, line=dict( color=&#39;gray&#39;, width=1) ) ) fig.update_layout(showlegend=False) # we have our text so we can turn off the legend fig.update_yaxes(visible=False) # no y axis needed fig.update_layout(yaxis_range=[0,0]) # limit y axis range fig.update_layout(hovermode=&quot;x&quot;) # how the plot react with hover # the style of hover labels can be customized too fig.update_layout( hoverlabel=dict( bgcolor=&quot;white&quot;, # background color font_size=14, # font size font_family=&quot;Rockwell&quot; # font ) ) fig.show() . . . Previous Lesson: Introduction to Data Story Telling . Next Lesson: Coming soon... . . . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: December 2021 . . . . References: . Plotly .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/level-3/chapter-3/matplotlib/data-visualization/2021/12/30/Simple_Bubble_Chart.html",
            "relUrl": "/level-3/chapter-3/matplotlib/data-visualization/2021/12/30/Simple_Bubble_Chart.html",
            "date": " • Dec 30, 2021"
        }
        
    
  
    
        ,"post8": {
            "title": "Data Story Telling",
            "content": "As mentioned in the instructions, all materials can be open in Colab as Jupyter notebooks. In this way users can run the code in the cloud. It is highly recommanded to follow the tutorials in the right order. . . This notebook aims to provide some useful tips for the readers before they begin with their first data visualization. . . Presumptions: . Not applicable. . . Data visualization is essentially the process of translating data, either qualitative or quantitative, into charts, graphs and other visuals, in order to deliver messages or insights as a way of communication. It can reduce large amount of data into more interpretable information, or even map spatial and temporal domain into 2D (or higher dimensional) space for more intuitive communication (Let&#39;s think about how counterintuitive it is to read a list of events in random time orders even with time labels). Human are highly visual creatures. We have learned to interact with the world using visual cues. Hence, by representing text or numberical information in graphical ways, readers can absorb and react to information more effectively. . Nonetheless, there are many factors which can determine if graphics are effective or not. If the graphics or charts are not created properly, we cannot leverage the potential of data visualization to deliver our messages, and might even cause confusions. Since there are already lots of online resources explaining the idea of data visualization, this lesson will mainly direct readers to some existing resources and to summarize using a Chinese historical example. . What are the goals and common methods for data visualization? Some Harvard scholars have categorized the approaches into four directions: . Distribution . | Comparison . | Relationship . | Composition . | . Let&#39;s read more about it yourself. . &gt;&gt;&gt; Ultimate resource for understanding &amp; creating data visualization . Now you have understood some basic approaches for making data visualization. Next step is to think about the structure of a plot. Do you know how do we build a plot and what elements are there? The following paper which builds on the grammar of graphics for R (ggplot2) have shown some nice insights about the components of a good graphic. Although we will not learn ggplot2 in this blog, this article still nicely describes the basic structure of many different Python plotting libraries, which requires users to construct different graphical elements, as well as customized their styles. You do not need to go into all the details: the most important is that you have a big idea about the basic elements in a plotting library, such as parameterization, scale, markers, coordinate systems and layers. . &gt;&gt;&gt; A Layered Grammar of Graphics . It should be clear by now why do we need data visualization and how does the theory being implemented in many plotting libraries. Afterwards, we need to learn about the practices. For example, what are the criterium to select the type of data visualization? How shall we choose the colors and the markers? How many visual elements do we need in a graphic? Let&#39;s learn about them by reading the article below. . These are the key messages quoted from the article below: . Data visualizations should be audience-specific with a clear requirement . | Choose the right visualization for your data . | Keep your visualizations simple . | Label your data visualizations . | Understand the importance of text in charts . | Use colors effectively in data visualizations . | Avoid deceiving with your visualizations . | Make interpretable data visualizations . | . &gt;&gt;&gt; Data Visualization Tips to Improve Data Stories . Until now, let&#39;s check what we have learnt by looking into a simple example of this paper about THE SHORT-LIVED CHINESE EMPERORS. This paper describes the statistics on the ages of death for Chinese emperors, buddhist Monks, and traditional Doctors. What kind of data visualization would fit into this example? . . Age at Death Emperor (n=241) Buddhist Monk (n=140) Traditional Doctor (n=181) . &lt;20, n (%) | 28 (11.6) | 2 (1.4) | 0 (0) | | . 20–29, n (%) | 46 (19.1) | 7 (5.0) | 0 (0) | | . 30–39, n (%) | 47 (19.5) | 12 (8.6) | 3 (1.7) | | . 40–49, n (%) | 38 (15.8) | 5 (3.6) | 3 (1.7) | | . 50–59, n (%) | 42 (17.4) | 19 (13.6) | 20 (11.0) | | . 60–69, n (%) | 29 (12.0) | 27 (19.3) | 34 (18.8) | | . 70–79, n (%) | 7 (2.9) | 39 (27.9) | 56 (30.9) | | . 80–89, n (%) | 4 (1.7) | 14 (10) | 42 (23.2) | | . 90–99, n (%) | 0 (0) | 8 (5.7) | 16 (8.8) | | . ≥100, n (%) | 0 (0) | 7 (5.0) | 7 (3.9) | | . Range | 2–89 | 17–120 | 32–109 | | . Mean ± standard deviation | 41.3 ± 17.9 | 66.9 ± 20.7 | 75.1 ± 13.4 | | . Table retrieved from Zhao, H. L., Zhu, X., &amp; Sui, Y. (2006). . 1. One Key Message Per Graphic . First, it is recommanded to deliver one message per graphic. In this case,it means we might not want to emphasize causes of deaths of the emperors and the longevity comparison between groups in a single graphic. For example, we would focus on the longevity differences between emperors and other groups by creating multiple histograms or boxplots in a graph. . 2. Avoid Redundant Styling . Also, we need to pay attention to the styling. Although multiple colors or marker symbols can be eye-catching, it can create unnecessary confusions if they do not embed meanings. For example, we shall avoid using different colors for the same group. Also, we should either use a different color or marker symbol for different groups, but not both of them. . In this example, we can use different colors for emperor, monk, and traditional doctor in our chart. . 3. Be Careful of your Color scheme . Besides, we need to pay attention to the color scheme. Remember that many elements have intuitive meanings in our brain, so it is the best if we would follow the expected patterns. For example, if we want to show the frequency of war occurred in different periods, it is better to use red-blue to represent more-less frequent wars than to use the reverse order of color scheme. It is the same with other styling elements too. For example, using the same marker symbol with larger size to describe another category will not be sensible. . We also need to think about the color palette. There are color palettes (sequential and diverging palettes) with changing saturation or lightness used to describe data with continuous nature, as well as qualitative color palettes designated for categorical data. We should always make sure the color selected is visually distinguisble (even for color blind audience) and is approperiate for the data nature. . Here in this example, we have three categories that cannot be ordered. So we can use a categorical palette. . 4. Select type of graphics depends on the Nature of your data . We also need to learn about advantages and disadvantages of using different chart types. For example, a circle packing chart provides attractive visuals, but fails to show precise comparisons. A groupped bar chart displays decent comparisons, but it can look messy if we have many groups. A polar bar chart emphasizes the dominant groups, but do not work well with data showing development (eg. time series). . In this example, a boxplot will fit better than a pie chart. It will also fit better than a bar chart if we want to emphasize the general distribution for all ages groups rather than some distinct characteristics of certain age groups. . 5. Pay Attention to your Axis . Finally, your axis are important too. If it is a map, make sure that they have north on the top. Or if it is a scatter plot, make sure to put the dependent variable on the y-axis. If the charts represent any temporal development, make sure that the time dimension shall be put in the x-axis. In this example, the boxplot can be both vertical and horizontal. . Previous Lesson: Pandas Numerical Operation . Next Lesson: Coming soon... . . . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: December 2021 . . . . References: . Zhao, H. L., Zhu, X., &amp; Sui, Y. (2006). THE SHORT‐LIVED CHINESE EMPERORS. Journal of the American Geriatrics Society, 54(8), 1295-1296. .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/level-3/chapter-3/data-visualization/2021/12/06/DataVisualization.html",
            "relUrl": "/level-3/chapter-3/data-visualization/2021/12/06/DataVisualization.html",
            "date": " • Dec 6, 2021"
        }
        
    
  
    
        ,"post9": {
            "title": "Circle Packing using Circlify",
            "content": "As mentioned in the instructions, all materials can be open in Colab as Jupyter notebooks. In this way users can run the code in the cloud. It is highly recommanded to follow the tutorials in the right order. . . This notebook aims to introduce users some practical skills on generating a circle packing chart. . . Presumptions: . Not applicable. . . ! pip install circlify . Collecting circlify Downloading circlify-0.14.0-py2.py3-none-any.whl (11 kB) Installing collected packages: circlify Successfully installed circlify-0.14.0 . from pprint import pprint as pp import circlify as circ . surname = &quot;&quot;&quot; 王 李 張 趙 劉 陳 楊 吳 黃 朱 孫 郭 胡 呂 高 宋 徐 程 林 鄭 范 何 韓 曹 馬 許 田 馮 杜 周 曾 汪 蘇 董 方 蔡 梁 石 謝 賈 薛 彭 崔 唐 潘 鄧 任 史 錢 侯 魏 羅 葉 沈 孟 姚 傅 丁 章 蕭 蔣 盧 陸 袁 江 晁 譚 邵 歐陽 孔 俞 尹 廖 閻 洪 夏 雷 葛 文 柳 陶 毛 丘 龔 康 蒲 邢 郝 龐 安 裴 折 施 游 金 鄒 湯 虞 嚴 鍾 &quot;&quot;&quot; import re surname = list(re.sub(&quot; s+&quot;, &quot;&quot;, surname.strip())) . surname[:5] . [&#39;王&#39;, &#39;李&#39;, &#39;張&#39;, &#39;趙&#39;, &#39;劉&#39;] . surname.reverse() . len(surname) . 101 . import pandas as pd import numpy as np df = pd.DataFrame({ &#39;surname&#39;: surname, &#39;weight&#39;: 5*np.arange(1,102) }) . import circlify # compute circle positions: circles = circlify.circlify( df[&#39;weight&#39;].tolist(), target_enclosure=circlify.Circle(x=0, y=0, r=1), show_enclosure=False ) . len(df.weight) . 101 . import math import numpy as np x = np.array([cir.x for cir in circles]) y = np.array([cir.y for cir in circles]) r = np.array([cir.r for cir in circles]) bubble_df = pd.DataFrame({ &#39;x&#39;: x, &#39;y&#39;: y, &#39;r&#39;: r, &#39;l&#39;: df.sort_values(&#39;weight&#39;).surname.values, &#39;s&#39;: (math.pi)*(r**2) }) . !wget -O TaipeiSansTCBeta-Regular.ttf https://drive.google.com/uc?id=1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_&amp;export=download import matplotlib as mpl import matplotlib.pyplot as plt from matplotlib.font_manager import fontManager fontManager.addfont(&#39;TaipeiSansTCBeta-Regular.ttf&#39;) mpl.rc(&#39;font&#39;, family=&#39;Taipei Sans TC Beta&#39;) . import circlify import numpy as np import random import matplotlib.pyplot as plt import seaborn as sns from matplotlib.colors import ListedColormap palette = [&quot;#CD5C5C&quot;,&quot;#F08080&quot;,&quot;#E9967A&quot;,&quot;#FFA07A&quot;,&quot;#C04000&quot;,&quot;#FF5F1F&quot;,&quot;#B22222&quot;,&quot;#660000&quot;,&quot;#C21E56&quot;] # Create just a figure and only one subplot fig, ax = plt.subplots(figsize=(10,10)) # Title ax.set_title(&#39;宋朝人口姓氏期望分佈&#39;, fontsize=26) # Remove axes ax.axis(&#39;off&#39;) # Find axis boundaries lim = max( max( abs(circle.x) + circle.r, abs(circle.y) + circle.r, ) for circle in circles ) plt.xlim(-lim, lim) plt.ylim(-lim, lim) # list of labels labels = df.sort_values(&#39;weight&#39;).surname.values # print circles for circle, label in zip(circles, labels): x, y, r = circle ax.add_patch(plt.Circle((x, y), r, alpha=0.6, linewidth=1, facecolor=random.choice(palette), edgecolor=&quot;white&quot;)) plt.annotate( label, (x,y) , va=&#39;center&#39;, ha=&#39;center&#39;, fontsize=300*r, color=&quot;black&quot; ) . bubble_df[&quot;rank&quot;] = bubble_df.sort_values(by=&quot;r&quot;, ascending=False).index bubble_df.head() . x y r l s rank . 0 -0.157353 | 0.011841 | 0.011880 | 王 | 0.000443 | 101 | . 1 -0.199757 | 0.034318 | 0.016801 | 李 | 0.000887 | 100 | . 2 -0.129251 | -0.004397 | 0.020577 | 張 | 0.001330 | 99 | . 3 -0.225690 | 0.181468 | 0.023760 | 趙 | 0.001774 | 98 | . 4 -0.309487 | 0.366656 | 0.026564 | 劉 | 0.002217 | 97 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; font_size = 250*bubble_df.r.values . import plotly.express as px fig = px.scatter(bubble_df, x=&quot;x&quot;, y=&quot;y&quot;, custom_data=[&quot;l&quot;,&quot;rank&quot;], color=&quot;x&quot;, width=800, height=700, size=&quot;s&quot;, hover_name=&quot;l&quot;, size_max=45, text=&quot;l&quot;) fig.update(layout_coloraxis_showscale=False) fig.update_traces( hovertemplate=&quot;&lt;br&gt;&quot;.join([ &quot;Surname: %{customdata[0]}&quot;, &quot;Ranking: %{customdata[1]}&quot; ]) ) fig.update_layout(showlegend=False) fig.update_xaxes(visible=False) fig.update_yaxes(visible=False) fig.update_yaxes( scaleanchor = &quot;x&quot;, scaleratio = 0.95, ) fig.update_layout({ &#39;plot_bgcolor&#39;: &#39;rgba(0, 0, 0, 0)&#39;, &#39;paper_bgcolor&#39;: &#39;rgba(0, 0, 0, 0)&#39;, }) fig.update_layout( title={ &#39;text&#39;: &quot;&lt;b&gt;宋朝人口姓氏期望分佈&lt;/b&gt;&quot;, &#39;y&#39;:0.97, &#39;x&#39;:0.5, &#39;xanchor&#39;: &#39;center&#39;, &#39;yanchor&#39;: &#39;top&#39;}, font=dict( family=&quot;Courier New, monospace&quot;, size=18, color=&quot;black&quot; ) ) fig.update_traces(textfont_size=font_size) fig.show() . . . . . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: December 2021 . . . . References: . https://github.com/elmotec/circlify .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/level-3/chapter-3/matplotlib/data-visualization/2020/02/02/Circlify.html",
            "relUrl": "/level-3/chapter-3/matplotlib/data-visualization/2020/02/02/Circlify.html",
            "date": " • Feb 2, 2020"
        }
        
    
  
    
        ,"post10": {
            "title": "Python for Research Q & A 🖋️",
            "content": ". As mentioned in the instructions, all materials can be open in Colab as Jupyter notebooks. In this way users can run the code in the cloud. It is highly recommanded to follow the tutorials in the right order. . . Background . Python is getting more and more popular, not only in the field of computer science, but also in the diverse fields when it comes to computation, working with digital resources and data presentation. This notebook aims to give users some basic knowledge about the potential of Python programming language in the context of humanity research. . . Presumption: Not applicable . . . Although Python is a programming language, it is different from other low-level programming languages by being more user-friendly and more close to a interpreter than machine code. It is for general purpose and also relatively beginner-friendly. . Python is not only more readable, it also has less structural rules and usually much shorter. Compared to other languages such as JavaScript, Python has not so much low-level language like syntax so its learning curve is not as steep. . General-purpose Language . Although you might have read other tutorials telling you how you can use very diverse tools to achieve fancy tasks that you wish to perform. You also have to realize that how much time will you need to master that languages or tools before tasks can be done. . Let&#39;s assume that you are not a real web developer here and data analysis or visualization is not your primary profession. It means, you are not making your living by making charts and websites, and for you making creative and fancy new charts is not as important as making a not so time-consuming and presentable bar chart which display your results to the audience or in your paper. . Most often, what you need is then much more simple functionalities which a fancy tool can overkill. You also need to consider that not all digital tools are open and free, so using multiple of them can cost you time and money. . For Qualitative Research . Although Python is a programming language and is often associated with computing and numbers, it can help you with qualitative research too! It includes many functionalities to work with text resources. Although you do not need to do calculation on them, sometimes you do want to find a pattern in them, look for the keywords, or just get them into digital text. . . Data Input . Python can help you to get your qualitative sources. Let&#39;s say you want to look into BDK (Bukkyo Dendo Kyokai) Database for the A Biography of Sakyamuni. And you want to get the text file of certain chapters. What you can do is to use Python to scrap the text and load it in a file for you. Or let&#39;s say you want to have all the Buddhist texts having a particular keywords, then you can filter the text using Python. . . Data Analysis . So now you got the text. But you want to see how does certain keywords distributed inside your text(s), or what is the associated sentiment of the text(s). Then you can perform NLP in Python. Or if you have a database of Buddhist temples and want to analysis what regions are they mostly located in, then you can perform some geospatial analysis in Python too. . . Data Presentation . Let&#39;s say now you got your results already, and you need to present them either in a paper, in a PowerPoint or make a simple webpage that you can shared with your colleagues or your audience. You can also make both static and interactive charts/ text visualization using Python. They can be either a bar chart for comparison, a word cloud for showing key words, or a map showing geolocations of objects. . . Checking out some galleries: . PLOTLY . | SEABORN . | . What can Python do for me? . Python can indeed handle a large variety of tasks, from get data for you (web scraping), to analysis your data (text analysis), to present your results (data visualization). Its high speed allow you to scan and work with a large amount of data and search for the ones that you are interested in! You can then either analyse them with Python or continue by yourself to read the information retrieved. Or Python simply let you present what you have in mind, like a time line, in a digital format. . Geospatial Data ?? . For example, you might have read about Mapbox.js, Leaflet.js, R or GIS for analysing geospatial data, making choropleths and interactive graphics. But Python can do it too using Plotly, Folium and Geoopandas! . Interactive Bubble Chart ?? . Then you read about D3.js for making an interactive bubble chart. But Python can get it done too using Plotly. . Text Optical Recognition (OCR) ?? . Then you read about doing OCR, but Python get give you a ride too using pytesseract. You can even work on it without the need for Bash or Comment Line. . Data Cleaning ?? Manipulation ?? . Then you read about other digital tools for data cleaning and manipulation. You realize you need them too. But you can stick with Python: Pandas library can get the job done! . Data Mining ?? Web Scraping ?? . Then you think of getting information from a digital database? The door of Python Beautiful Soup is open for you! . Web Application ?? App ?? . Want to make a simple web application or app to host your data visualization or presentation? Try out Dash from Plotly which can be run in Python too! . . Next Lesson: Introduction to Jupyter &amp; Colab . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: December 2021 . . . . References: . https://www.bitdegree.org/tutorials/python-vs-javascript/ . https://towardsdatascience.com/a-complete-guide-to-an-interactive-geographical-map-using-python-f4c5197e23e0 .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/level-1/chapter-1/background/2020/01/31/Python_Research_Q&A_Basics.html",
            "relUrl": "/level-1/chapter-1/background/2020/01/31/Python_Research_Q&A_Basics.html",
            "date": " • Jan 31, 2020"
        }
        
    
  
    
        ,"post11": {
            "title": "Introduction to Jupyter Notebooks",
            "content": "As mentioned in the instructions, all materials can be open in Colab as Jupyter notebooks. In this way users can run the code in the cloud. It is highly recommanded to follow the tutorials in the right order. . . What is Jupyter? . The Jupyter Project is an open source effort that evolved from the IPython project to support interactive data science and computing. Besides Python, it also supports many different programming languages including R and Julia. . Components of Jupyter Notebook . Jupyter Notebook IDE: The application that launches in a web browser like Firefox or Safari and is the environment where you write and run your code. . | Jupyter Notebook Files(.ipynb): The file format that you can use to store code and markdown text for individual projects and workflows. . | Kernels: A kernel runs your code in a specific programming language. In this tutorial, Python kernel is used within the Jupyter Notebook IDE. . | . Jupyter Notebook User Interface . After you create a new notebook file (.ipynb), you will be presented with notebook name, menu bar, tool bar and a code cell as default starting cell. . Notebook Name: if you click at the notebook name, you could rename the file. . | Menu Bar: presents all functions and settings of the notebook file. . | Tool Bar: presents the most used tools as icons. . | Code Cell: it is the default type of cell when you create a new cell; if you want to transfer it to a markdown cell, you could use the drop down box in tool bar or a keyboard shortcut. . | . . . 1. Headers . Note: The more # the title holds, the smaller the title will be. . # This is a Title in Markdown . ## This is a Subtitle in Markdown . ### This is a smaller subtitle in Markdown . . will be rendered as: . This is a Title in Markdown . This is a Subtitle in Markdown . This is a smaller subtitle in Markdown . . . 2. Lists . * This is a bullet list . * This is a bullet list . * This is a bullet list . . 1. This is a numbered list . 2. This is a numbered list . 3. This is a numbered list . . will be rendered as: . This is a bullet list | This is a bullet list | This is a bullet list | . This is a numbered list | This is a numbered list | This is a numbered list | Tip: To render list, you should leave a blank space between 1. and the following texts. . . . 3. Bold and Italic . *These are italic words.* . **These are bold words.** . ***These are bold AND italic words.*** . . will be rendered as . . These are italic words. . These are bold words. . These are bold AND italic words. . . . . 4. Highlight Code . If you want to highlight a funciton or some code in a plain text, you add one backtick on each side of the text (`). . Here is some highlighted text! . . . . 5. Horizontal Lines . You can also create a horizontal line to highlight a block of markdown syntax. . . *** . Here is some important text! . *** . . will be rendered as: . . . Here is some important text! . . . Tip: The *s on both side of the texts should be at the line above and the line below the texts. . . . 6. Hyperlinks . You can use HTML in Markdown cells to create hyperlinks redirecting to other websites. For example, the following syntax. . More infos about our data cube program can be found at &lt;a href=&quot;https://datacube.remote-sensing.org/&quot;&gt;this website&lt;/a&gt; . . will be rendered as: . More infos about our data cube program can be found at this website . . . 7. Images . You can also render images in Markdown cells using the following syntax: . ![alternative text here](url-to-image-here) . . For example, . ![Fotograph of Philip is here](https://i.imgur.com/VGPeJ6s.jpg) . . will be redered like: . . Or if the image need to be resize: . &lt;div&gt; . &lt;img src=https://i.imgur.com/VGPeJ6s.jpg width=&quot;200&quot;&gt; . &lt;/div&gt; . . will be rendered as: . Note: The texts in the rectangle brackets (e.g. &quot;Fotograph of Philip is here&quot;) will appear when the image fails to load. . . . . 8. LaTex . Jupyter notebook markdown cell also supports LaTex. So that the markdown cells interpret your texts as LaTex, surround your input texts with $ signs. . For instance, $c=a+b$ will be rendered as . $c=a+b$ . If you want your texts be centered in the cell, surround your input texts with two $ signs. . For instance, $$C_{g}= frac{H}{ frac{ pi}{2}*Cl_{p}}$$ will be rendered as . $$C_{g}= frac{H}{ frac{ pi}{2}*Cl_{p}}$$ . . and . . |Uppercase| LaTeX |Lowercase| LaTeX | . ||-||-| . |$ Delta$ | Delta|$ delta$ | delta| . |$ Omega$ | Omega|$ omega$ | omega| . . will be rendered as: . . Uppercase LaTeX Lowercase LaTeX . $ Delta$ | Delta | $ delta$ | delta | . $ Omega$ | Omega | $ omega$ | omega | . . 9. Table . A table can be constructed using | (pipe symbol) and — (dash) to mark columns and rows. The first row of the table defines the headers, and the next row defines the alignment of each column. . . For instance, . | Stretch/Untouched | ProbDistribution | Accuracy | . | | | | . | Stretched | Gaussian | .843 | . . will be rendered as: . Stretch/Untouched ProbDistribution Accuracy . Stretched | Gaussian | .843 | . The widths of the columns can also be changed by adding an empty row at the end with defined width. . . | Stretch/Untouched | ProbDistribution | Accuracy | . | | | | . | Stretched | Gaussian | .843 | . |&lt;img width=200/&gt;|&lt;img width=200/&gt;|&lt;img width=200/&gt;| . . will be rendered as: . . Stretch/Untouched ProbDistribution Accuracy . Stretched | Gaussian | .843 | . | | | . What is Colab? . So now we learnt about Jupyter Notebook, then what is Colab? Colab notebooks are Jupyter notebooks that are hosted by Colab. Therefore, the operations are highly similar and it allows you to write and execute Python in your browser, with . Zero configuration required | Free access to GPUs | Easy sharing | . There are limits in the available memory but they are generally sufficient if you are not performing particularly demanding tasks. One of the benefits using Colab is that you do not need to worried about dependencies as much for downloading Python tools and libraries. Many of the libraries are available in the Colab environment by default, eg. Pandas. . To import a library that&#39;s not in Colaboratory by default, you can also use !pip install or !apt-get install. . For example, . !pip install cartopy import cartopy . Collecting cartopy Downloading Cartopy-0.20.1.tar.gz (10.8 MB) |████████████████████████████████| 10.8 MB 5.1 MB/s Installing build dependencies ... done Getting requirements to build wheel ... error WARNING: Discarding https://files.pythonhosted.org/packages/fc/59/aa52698e3838f4cd0e7eaa75bd86837e9e0b05041dbdaee3cda2fffced06/Cartopy-0.20.1.tar.gz#sha256=91f87b130e2574547a20cd634498df97d797abd12dcfd0235bc0cdbcec8b05e3 (from https://pypi.org/simple/cartopy/) (requires-python:&gt;=3.7). Command errored out with exit status 1: /usr/bin/python3 /usr/local/lib/python3.7/dist-packages/pip/_vendor/pep517/in_process/_in_process.py get_requires_for_build_wheel /tmp/tmpvn613tgl Check the logs for full command output. Downloading Cartopy-0.20.0.tar.gz (10.8 MB) |████████████████████████████████| 10.8 MB 20.5 MB/s Installing build dependencies ... done Getting requirements to build wheel ... error WARNING: Discarding https://files.pythonhosted.org/packages/0f/c0/58453b036e79046d211f083880d58dcce787e7e07647ac25dc46c6555099/Cartopy-0.20.0.tar.gz#sha256=eae58aff26806e63cf115b2bce9477cedc4aa9f578c5e477b2c25cfa404f2b7a (from https://pypi.org/simple/cartopy/) (requires-python:&gt;=3.7). Command errored out with exit status 1: /usr/bin/python3 /usr/local/lib/python3.7/dist-packages/pip/_vendor/pep517/in_process/_in_process.py get_requires_for_build_wheel /tmp/tmpcxegil_v Check the logs for full command output. Downloading Cartopy-0.19.0.post1.tar.gz (12.1 MB) |████████████████████████████████| 12.1 MB 19.6 MB/s Installing build dependencies ... done Getting requirements to build wheel ... done Preparing wheel metadata ... done Requirement already satisfied: shapely&gt;=1.5.6 in /usr/local/lib/python3.7/dist-packages (from cartopy) (1.8.0) Collecting pyshp&gt;=2 Downloading pyshp-2.1.3.tar.gz (219 kB) |████████████████████████████████| 219 kB 48.7 MB/s Requirement already satisfied: numpy&gt;=1.13.3 in /usr/local/lib/python3.7/dist-packages (from cartopy) (1.19.5) Building wheels for collected packages: cartopy, pyshp Building wheel for cartopy (PEP 517) ... done Created wheel for cartopy: filename=Cartopy-0.19.0.post1-cp37-cp37m-linux_x86_64.whl size=12516269 sha256=983da772a11f3cba2d78a180f9a2d0136b8d43ba98219da421e264ca5b01d995 Stored in directory: /root/.cache/pip/wheels/98/01/f7/bd10aeb96fe4b518cde5f7c4f5e12c7202f85b7353a5017847 Building wheel for pyshp (setup.py) ... done Created wheel for pyshp: filename=pyshp-2.1.3-py3-none-any.whl size=37325 sha256=1c8e9a249f1f0ed81fac1f63ab6c703038812764fe6dd1b67b62e911ebaab64e Stored in directory: /root/.cache/pip/wheels/43/f8/87/53c8cd41545ba20e536ea29a8fcb5431b5f477ca50d5dffbbe Successfully built cartopy pyshp Installing collected packages: pyshp, cartopy Successfully installed cartopy-0.19.0.post1 pyshp-2.1.3 . Also, because Colab is a cloud environment, you cannot directly assess files in your local environment. If you want to import files, there are two options: . Data Import . Option 1: Upload Files . Remarks: The file name in line pd.read_csv() need to be exactly the same as the name of the file you uploaded to not run into errors. . from google.colab import files # use the google.colab library uploaded = files.upload() # upload it, click choose file after running this cell and pick the file # read your file depends on the file format # Let&#39;s say you have a csv, then you can read them using Pandas (you will learn more about Pandas later) import io import pandas as pd df = pd.read_csv(io.BytesIO(uploaded[&#39;yourfile.csv&#39;])) df # now your data is stored in this data frame . Option 2: Access Files from Google Drive . One of the cons using upload option is that you can only upload one file at a time and it might take sometimes if your files are large. Let&#39;s say your colleague share you a file from Google Drive and you have a copy of it in the Drive. It is probably not the best way to download them to your computer and upload them in Colab again. . What you can do is to directly use files on the drive. . After running the following code, you still need to sign in to your Google Account, and click Allow to permit access to your own Google Drive. . from google.colab import drive drive.mount(&#39;/content/drive/&#39;) . Mounted at /content/drive/ . After successful connection, you can see &quot;Mounted at / content/drive/&quot; under the cell. . Then, you can check your directory. . !ls . drive sample_data . Where to search for your files depends on where do you store them. Let&#39;s say you stored your file inside Google Drive with a folder call yourfolder. You can check if the files are there by: . . Remark: Be carefule there is no space between My and Drive . print(os.popen(&#39;ls /content/drive/MyDrive/yourfolder&#39;).read()) . Your files should appear under the cell after run. . Then you can open your file using the path. You can specify your path in a raw string r&quot;path&quot;. . Then you can open them using different methods depending on the data format. The following example is a Geotiff file and it can be opened using gdal (You do not need to know much about it for now). . path = r&quot;/content/drive/MyDrive/yourfolder/boundary.tif&quot; # import library import gdal # open file ds = gdal.Open(path, gdal.GA_ReadOnly) . # import library import pandas as pd # define your path path = r&quot;/content/drive/MyDrive/yourfolder/city.csv&quot; # open file df = pd.read_csv(path) df # now your data is stored in this data frame . Data Export . It is basically very similar when you need to output a file. . Option: Directly Download Files . Remarks: The file name in the second and third line need to be exactly the same to not run into errors. . from google.colab import files # import library; only need to be done once for the whole notebook df.to_csv(&#39;temple_location.csv&#39;, encoding=&#39;utf_8_sig&#39;, index=False) # suppose df is the dataframe you want to export files.download(&#39;temple_location.csv&#39;) # run this code and the file will be directly downloaded . What you can also do it to run only: . from google.colab import files # import library; only need to be done once for the whole notebook df.to_csv(&#39;temple_location.csv&#39;, encoding=&#39;utf_8_sig&#39;, index=False) # suppose df is the dataframe you want to export # by default they will be in /content . and then click the bar on the left side with the folder icon (Files). Then you can also search for your files in the directory and click on the three dots and then click download. . It is generally recommanded to modify a file already existed in the Google Drive but not to create new files in Google Drive. . . Previous Lesson: Python Research Q&amp;A Basics . Next Lesson: Python Introduction Basics . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: December 2021 . . . . References: . https://colab.research.google.com/?utm_source=scs-index .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/level-1/chapter-1/jupyter/colab/2020/01/30/JupyterNotebook_Colab_Basics.html",
            "relUrl": "/level-1/chapter-1/jupyter/colab/2020/01/30/JupyterNotebook_Colab_Basics.html",
            "date": " • Jan 30, 2020"
        }
        
    
  
    
        ,"post12": {
            "title": "Introduction to Python Programming (Example from 孟浩然诗全集)",
            "content": "As mentioned in the instructions, all materials can be open in Colab as Jupyter notebooks. In this way users can run the code in the cloud. It is highly recommanded to follow the tutorials in the right order. . Presumptions: . . Here the examples used is Chinese texts from this link. . List . The following is a review of Python basics with presumptions of knowledge in w3school from Python intro to Python Arrays. The following is the a subset of titles from 孟浩然诗全集 卷一百五十九. . String &quot;&quot; is used to save the titles in variables. Pay attention that in Python capital letters and spacing matters. So for example, &quot;CHINA&quot; is not equal to &quot;China&quot;. True and False in Python is called boolean. It is a way to express binary result. . &quot;China&quot; == &quot;China&quot; # == means &quot;is it equal to?&quot; (the opposite is !=) . True . &quot;CHINA&quot; == &quot;China&quot; # This is the way how comments can be written. They will not impacts the code structure itself . False . first = &quot;从张丞相游南纪城猎，戏赠裴迪张参军&quot; second = &quot;登江中孤屿，赠白云先生王迥&quot; third = &quot;晚春卧病寄张八&quot; fourth = &quot;秋登兰山寄张五&quot; fifth = &quot;入峡寄弟&quot; . We can also put them in a list, which is a method to store multiple items in a single variable. There are much more ways to store information that we can retrieve later but list is the most simple form. Also, all text without &quot;&quot; in Python will be understood as a variable and it might cause errors if it is not one. . Be careful, there are some key words that we cannot used to store variables as they are reserved. To understand more about key words: https://www.w3schools.com/python/python_ref_keywords.asp . list_ = [first, second, third, fourth, fifth] . Then we can print them out. . list_ . [&#39;从张丞相游南纪城猎，戏赠裴迪张参军&#39;, &#39;登江中孤屿，赠白云先生王迥&#39;, &#39;晚春卧病寄张八&#39;, &#39;秋登兰山寄张五&#39;, &#39;入峡寄弟&#39;] . Slicing and Basic Manipulation . Sometime we only wish to retrieve selected items. By slicing, we can easily access them. Python start from 0 so [0] always mean the first item. We can also use negetive values, in which the order counted in the reverse order. The last item indicated will be excluded from selection (eg. [0:2] means the 3rd item is excluded). . print(list_[0]) # first element only . 从张丞相游南纪城猎，戏赠裴迪张参军 . print(list_[0:2]) # first two elements only . [&#39;从张丞相游南纪城猎，戏赠裴迪张参军&#39;, &#39;登江中孤屿，赠白云先生王迥&#39;] . print(list_[-1]) # last item . 湖中旅泊，寄阎九司户防 . Using text (inside &quot;&quot;) some of the operation cannot be done as using numbers (eg. division). However, there are multiple ways we can manipulate them. . . For example, we can add them togehter. . add = list_[-1] + &quot;,&quot; + list_[-1] add . &#39;入峡寄弟,入峡寄弟&#39; . We can subtract text (in an indirect way). . add.replace(&quot;,入峡寄弟&quot;,&quot;&quot;) # replace &quot;,入峡寄弟&quot; with nothing &quot;&quot; . &#39;入峡寄弟&#39; . We can also repeat them. . list_[-1] * 10 # * ten times . &#39;入峡寄弟入峡寄弟入峡寄弟入峡寄弟入峡寄弟入峡寄弟入峡寄弟入峡寄弟入峡寄弟入峡寄弟&#39; . We can also insert more items into the list. Let&#39;s put the 6th title into position 5 (Python start from 0). . list_.insert(5, &#39;湖中旅泊，寄阎九司户防&#39;) list_ . [&#39;从张丞相游南纪城猎，戏赠裴迪张参军&#39;, &#39;登江中孤屿，赠白云先生王迥&#39;, &#39;晚春卧病寄张八&#39;, &#39;秋登兰山寄张五&#39;, &#39;入峡寄弟&#39;, &#39;湖中旅泊，寄阎九司户防&#39;] . ## Numpy Array | . We can also put them in numpy array, which make many manipulation easier and faster, but first we need to import the library. It is applied to all functionalities not included in the base library. . After import the numpy library, it is imported as np and later when we need to call a function from the library, eg. min(), we can type np.min(). The item we put in () is called arguments. They are the inputs to compute the outputs. When we use functions, we have to be careful what arguments are needed (sometimes they are compulsory, sometimes they are not necessary, sometimes they are optional but there will be always a default option). . import numpy as np # import library. When we write real code, all libraries will typically be imported all together at the beginning . arr = np.array(list_) arr . array([&#39;从张丞相游南纪城猎，戏赠裴迪张参军&#39;, &#39;登江中孤屿，赠白云先生王迥&#39;, &#39;晚春卧病寄张八&#39;, &#39;秋登兰山寄张五&#39;, &#39;入峡寄弟&#39;], dtype=&#39;&lt;U17&#39;) . Do you see dtype=&#39;&lt;U17&#39;? It means datatype of the elements in the Numpy array. The U indicates that the elements are Unicode strings; Unicode is the standard Python uses to represent strings. . . In fact, it is important when we write code because if the action can be performed always depends on data types. To better understand data type: https://realpython.com/python-data-types/ . . ## Data Type | . If we want to check the data type of any objects, we can use type(). . type(100) # integer . int . type(&quot;list_&quot;) # string . str . type(list_) # list . list . type(np.array(list_)) # array . numpy.ndarray . Other Operations using Numpy Array . We can manipulate the text, for example, by getting the title with the most characters. . sort_arr = sorted(list_,key=len,reverse=False) # first we sort them by length (key = len), default in ascending order sort_arr . [&#39;入峡寄弟&#39;, &#39;晚春卧病寄张八&#39;, &#39;秋登兰山寄张五&#39;, &#39;湖中旅泊，寄阎九司户防&#39;, &#39;登江中孤屿，赠白云先生王迥&#39;, &#39;从张丞相游南纪城猎，戏赠裴迪张参军&#39;] . sort_arr[-1] . &#39;从张丞相游南纪城猎，戏赠裴迪张参军&#39; . We can for example count the number of titles using len(). . len(arr) . 5 . We can also put condition into array. For example, let&#39;s get item with over 5 characters. . # To review list comprehension: https://www.w3schools.com/python/python_lists_comprehension.asp arr_len = [len(i) for i in arr] arr_len . [17, 13, 7, 7, 4] . arr_len = np.array(arr_len) . Get arr with arr_len in the correponding position larger than 5. . To better understand the basic operators: https://www.tutorialspoint.com/python/python_basic_operators.htm . arr[arr_len &gt; 5] # slicing with conditions . array([&#39;从张丞相游南纪城猎，戏赠裴迪张参军&#39;, &#39;登江中孤屿，赠白云先生王迥&#39;, &#39;晚春卧病寄张八&#39;, &#39;秋登兰山寄张五&#39;, &#39;湖中旅泊，寄阎九司户防&#39;], dtype=&#39;&lt;U17&#39;) . Let&#39;s look at the minimum length of titles. . np.min(arr_len) . 4 . Or maximum. . np.max(arr_len) . 17 . Basic Plotting . We can also do some basic plotting using matplotlib. But we first need to import the library. . Understanding more about matplotlib: https://www.youtube.com/watch?v=qErBw-R2Ybk . ### Histogram | . import matplotlib.pyplot as plt # Histogram plt.hist(arr_len, bins=[2, 5, 10, 20], width=1) . (array([1., 2., 3.]), array([ 2, 5, 10, 20]), &lt;a list of 3 Patch objects&gt;) . It might not be helpful using little titles, but the principle is the same if we have thousands of items. . It can be demonstrated by creating some random numbers. . lengths = np.arange(0,30) lengths . array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]) . import random # choose 1000 samples times another 1000 samples list2_ = np.array(random.choices(lengths, k=1000))*np.array(random.choices(lengths, k=1000)) list2_ . import matplotlib.pyplot as plt plt.hist(list2_) . (array([347., 182., 129., 89., 78., 60., 42., 43., 17., 13.]), array([ 0. , 84.1, 168.2, 252.3, 336.4, 420.5, 504.6, 588.7, 672.8, 756.9, 841. ]), &lt;a list of 10 Patch objects&gt;) . ### Bar Chart | . We can improve the layout of the plot, such as adding xlabel, ylabel, a title, and change colors and so on. . plt.figure(figsize=(12,5)) # define the size of the plot plt.hist(list2_, color=&quot;green&quot;, orientation=&#39;horizontal&#39;) # color is an argument for color, this time we make it horizontal plt.grid(color=&#39;r&#39;, linestyle=&#39;--&#39;, linewidth=0.25, alpha=0.8) # add grid lines plt.ylabel(&quot;Numbers&quot;) plt.xlabel(&quot;Frequency&quot;) plt.title(&quot;Title&quot;, fontsize=18) . Text(0.5, 1.0, &#39;Title&#39;) . There are also many more different types for plotting. For example: . plt.bar([1,2,3,4,5], arr_len, width=0.5) plt.xlabel(&quot;ID&quot;) plt.ylabel(&quot;Lengths&quot;) . Text(0, 0.5, &#39;Lengths&#39;) . ### Line Chart | . Year = [1920,1930,1940,1950,1960,1970,1980,1990,2000,2010] Rate = [9.8,12,8,7.2,6.9,7,6.5,6.2,5.5,6.3] plt.plot(Year, Rate, color=&quot;red&quot;) plt.xlabel(&quot;Year&quot;) plt.ylabel(&quot;Rate&quot;) plt.grid(alpha=0.5) # alpha means transparency (0 to 1), the higher, the more visible . ### Table | . fig, ax = plt.subplots(figsize=(20,6)) # Hide axes ax.xaxis.set_visible(False) ax.yaxis.set_visible(False) ax.axis(&#39;tight&#39;) ax.axis(&#39;off&#39;) # Table data = np.random.random((5,3)) label=(&quot;1997&quot;, &quot;1998&quot;, &quot;1999&quot;) ax.table(cellText=data,colLabels=label,loc=&#39;center&#39;) . &lt;matplotlib.table.Table at 0x7f72c6afccd0&gt; . . Previous Lesson: JupyterNotebook Colab Basics . Next Lesson: Coding Practice Basics . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: December 2021 .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/programming/level-1/chapter-1/2020/01/29/Python_Introduction_Basics.html",
            "relUrl": "/programming/level-1/chapter-1/2020/01/29/Python_Introduction_Basics.html",
            "date": " • Jan 29, 2020"
        }
        
    
  
    
        ,"post13": {
            "title": "Good Coding Practice 🖋️",
            "content": ". As mentioned in the instructions, all materials can be open in Colab as Jupyter notebooks. In this way users can run the code in the cloud. It is highly recommanded to follow the tutorials in the right order. . . Background . Although programming is probably not your primary profession, it is always nice to have good coding practice to avoid unnecessary mistakes and misunderstandings in your projects. Some of the practices are more relevant for professional programmers, but here we mention the more relevant one for users who mostly code for fixed-term research projects. . . Presumption: Not applicable . . . 1) Documentation . RECORD WHAT YOU HAVE DONE &#128195; . Documentation is important. Although you might be really sure what you are doing when you code, most of the time it is not anymore the case when you wake up another morning, after busy time working on other projects or after a nice family trip. Do not need to mentioned if you are looking at your own code from last year. Do always document them, either by writing a comment with #, &quot;&quot;&quot; &quot;&quot;&quot;, or use a Jupyter Notebook and add more texts! . And sometimes you might have a project together with your colleagues, and they also need to understand what you are doing. Or if you are always working alone, then one day you colleagues want to get some insights from the code you wrote. You are not gonna show them and explain everything to them. . So make use of comments! When we write comments, we do not write what is done, we write what is the purpose. For example, if you create a new dataframe with two columns from the old dataframe, it is better to write &quot;extract coordinates and name from historical sites&quot; than &quot;create new dataframe&quot;, bacause the later comment do not give enough context and new information to the readers. . 2) Consistency . KEEP THINGS EASY TO REMEMBER &#129504; . You might not realize it but consistency fits your brain that always search for patterns! If you write your code in a consistent way, it can save you a lot of time running into unnecessary mistakes. . For example, if you name your five dataframes as . dataframe1 | dataframe2 | DataFrame3 | Dataframe4 | Dataframe_5 | . You might forget how did you name your dataframe later, and write dataframe3, or Dataframe_4, which all will run into errors. Consistency applies particularly to capital letters because we have learnt Python is case-sensitive. . You might think you can check it out everytime but it is not handy if you have tens of those variables. It is better that you name them in a consistent way from the first place. . Like: . df1 | df2 | df3 | df4 | df5 | . It also apply when you are writing code instead of naming variable. Because you always have multiple ways to get things done. Stick with the way that is simple and straight-forward! . For example, you have data from three years: . df_2018 = [9.8, 12.6, 15.8] | df_2019 = [5.6, 17.6, 25.1] | df_2020 = np.array([6.5, 11.3, 13.5]) | . . While df_2018 and df_2019 are lists, df_2020 is a Numpy array. Although both data types will work, they are different types and you might not remember it later, and run into errors because you thought the operations that works for df_2018 will also works for df_2020. . So stay consistent! . 3) Naming . KEEP THINGS CLEAN . Also it is important how you name the objects. If you have one dataframe for China, one for Korea and one for Japan. You want to name them in a more informative way, not . df1 | df2 | df3 | . but . df_china | df_japan | df_korea | . . There are different conventions too you would follow, particularly when it comes to combining words. Because Python do not support spaces in variable, you cannot name a data frame &quot;South Korea Data Frame&quot;, but the letters need to be combined in some ways. . . &#128043; Camel Case . Camel case combines words by capitalizing all words following the first word and removing the space, as follows: . Raw: user login count . Camel Case: userLoginCount . . &#128104; Pascal Case . Pascal case combines words by capitalizing all words (even the first word) and removing the space, as follows: . Raw: user login count . Pascal Case: UserLoginCount . . &#128013; Snake Case . Snake case combines words by replacing each space with an underscore (_) and, in the all caps version, all letters are capitalized, as follows: . Raw: user login count . Snake Case: user_login_count . Snake Case (All Caps): USER_LOGIN_COUNT . . &#129369; Kebab Case . Kebab case combines words by replacing each space with a dash (-), as follows: . Raw: user login count . Kebab Case: user-login-count . . There is not the best way how to name your variable, either &quot;dateFrame&quot; or &quot;data-frame&quot;, the more important is that they are used in a consistent way. Also pay attention that abbreviations are recommanded to keep things short but not too much that all others cannot really understand. . 4) Correct Broken Code . GET THINGS FIXED &#128295; . Sometimes things do not work the way we want, they are called bugs. They might not come to your immediate concerns but mark them down and get them fixed as soon as possible. You might even forget in what ways it is broken if you do not fix them timely and it can get worse. . 5) Readability . KEEP THINGS CLEAN, CONCISE AND SIMPLE &#128007; . This is simple. If code does not work, throw them away and do not keep mess. . For example, instead of writing code like below: . urban_history = [&quot;Hong Kong Government Reports Online 1841-1942&quot;,&quot;Policing the Shanghai International Settlement, 1894-1945&quot;,&quot;Virtual Cities Project&quot;] social_history = [&quot;China Families&quot;] # Manchukuo = [&quot;Chinese Posters in Harvard-Yenching Manchukuo Collection&quot;] # try without first # urban_history.insert(social_history,2) (does not work) # # print(urban_history.append(social_history)) (does not work either) urban_history + social_history # this is fine . [&#39;Hong Kong Government Reports Online 1841-1942&#39;, &#39;Policing the Shanghai International Settlement, 1894-1945&#39;, &#39;Virtual Cities Project&#39;, &#39;China Families&#39;] . Keep your &quot;Working Table&quot; clean like this: . urban_history = [&quot;Hong Kong Government Reports Online 1841-1942&quot;,&quot;Policing the Shanghai International Settlement, 1894-1945&quot;,&quot;Virtual Cities Project&quot;] social_history = [&quot;China Families&quot;] # calculation urban_history + social_history . [&#39;Hong Kong Government Reports Online 1841-1942&#39;, &#39;Policing the Shanghai International Settlement, 1894-1945&#39;, &#39;Virtual Cities Project&#39;, &#39;China Families&#39;] . Clean code also mean that your code is readable. For example, try to avoid many operations in one line. Although it also works, it make things hard to read. If there are any small typos, it is often not so easy to spot. . Like: . (NOT recommanded) . import pandas as pd (pd.DataFrame(data={&#39;Name&#39;: [&quot;Hong Kong Government Reports Online 1841-1942&quot;,&quot;Policing the Shanghai International Settlement, 1894-1945&quot;,&quot;Virtual Cities Project&quot;] , &#39;History&#39;: [&quot;urban&quot;,&quot;urban&quot;,&quot;urban&quot;]})).head(1) . Name History . 0 Hong Kong Government Reports Online 1841-1942 | urban | . import pandas as pd (pd.DataFrame(data={&#39;Name&#39;: [&quot;Hong Kong Government Reports Online 1841-1942&quot;,&quot;Policing the Shanghai International Settlement, 1894-1945&quot;,&quot;Virtual Cities Project&quot;] , &#39;History&#39;: [&quot;urban&quot;,&quot;urban&quot;,&quot;urban&quot;]]})).head(1) . File &#34;&lt;ipython-input-10-5139c64437bf&gt;&#34;, line 5 , &#39;History&#39;: [&#34;urban&#34;,&#34;urban&#34;,&#34;urban&#34;]]})).head(1) ^ SyntaxError: invalid syntax . (recommanded) . import pandas as pd # type of history hist_type = [&quot;urban&quot;,&quot;urban&quot;,&quot;urban&quot;] # set up datframe d = {&#39;Name&#39;: urban_history, &#39;History&#39;: hist_type} df = pd.DataFrame(data=d) df.head(1) . Name History . 0 Hong Kong Government Reports Online 1841-1942 | urban | . Happy Coding! . . (Quoted from The Zen of Python, by Tim Peters) . Beautiful is better than ugly. . Explicit is better than implicit. . Simple is better than complex. . Complex is better than complicated. . Readability counts. . If the implementation is hard to explain, it’s a bad idea. . . Previous Lesson: Python Introduction Basics . Next Lesson: Debugging and Understanding Errors Basics . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: December 2021 . . . . References: . https://data-flair.training/blogs/python-best-practices/ . https://betterprogramming.pub/string-case-styles-camel-pascal-snake-and-kebab-case-981407998841 .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/background/level-1/chapter-1/2020/01/28/Coding_Practice_Basics.html",
            "relUrl": "/background/level-1/chapter-1/2020/01/28/Coding_Practice_Basics.html",
            "date": " • Jan 28, 2020"
        }
        
    
  
    
        ,"post14": {
            "title": "Debugging and Understanding Errors 🐞",
            "content": ". As mentioned in the instructions, all materials can be open in Colab as Jupyter notebooks. In this way users can run the code in the cloud. It is highly recommanded to follow the tutorials in the right order. . . Background . A bug occurs when things do not work the way you want it to, even though Python only give what you ask for. It is because we have a different understandings compared to the programming languages. To resolve this, we need to find out the sources of errors and adjust our code accordingly. In this notebook you will learn different approach to resolve potential issues and some tips to avoid them from happening. . . Presumption: . https://www.w3schools.com/python/python_try_except.asp . https://www.tutorialsteacher.com/python/error-types-in-python . . . 1) Understand Error Messages . As you have seen from the link above, there are many different types of errors in Python which is meant to be helpful to tell user &quot;what is wrong?&quot;. But some errors might be more common than the others. Let&#39;s look at some common errors. . Let&#39;s say you want to add a second collection to the first one (collection). But instead of &quot;collection&quot;, you wrote &quot;Collection&quot;. . In this case Python tells you . NameError: name &#39;Collection&#39; is not defined . It is because Python is searching for &quot;Collection&quot; and cannot find one. . Name Error: Raised when a variable is not found in the local or global scope. . What you need to do it just correct the name. . collection = [&quot;Chinese Posters in Harvard-Yenching Manchukuo Collection&quot;] Collection + [&quot;Linked Archive of Asian Postcards&quot;] . NameError Traceback (most recent call last) &lt;ipython-input-3-cba7c442d3f4&gt; in &lt;module&gt;() 1 collection = [&#34;Chinese Posters in Harvard-Yenching Manchukuo Collection&#34;] 2 -&gt; 3 Collection + [&#34;Linked Archive of Asian Postcards&#34;] NameError: name &#39;Collection&#39; is not defined . Error occurs too when the library is not imported before use. . np.max([1,2]) . NameError Traceback (most recent call last) &lt;ipython-input-6-9be6f90ccf89&gt; in &lt;module&gt;() -&gt; 1 np.arange(1,5) NameError: name &#39;np&#39; is not defined . Or when you have one item in list while you are asking for the second one (Remember Python starts with 0). You get: . IndexError: list index out of range . Index Error: Raised when the index of a sequence is out of range. . Then you need to correct the index. . collection = [&quot;Chinese Posters in Harvard-Yenching Manchukuo Collection&quot;] collection[1] . IndexError Traceback (most recent call last) &lt;ipython-input-4-e10b1e230939&gt; in &lt;module&gt;() 1 collection = [&#34;Chinese Posters in Harvard-Yenching Manchukuo Collection&#34;] 2 -&gt; 3 collection[1] IndexError: list index out of range . There is also Type Error: Raised when a function or operation is applied to an object of an incorrect type. . It occurs because np.max() looks for a number and we input a string. . import numpy as np np.max([3]) # this works . 3 . import numpy as np np.max([collection]) . TypeError Traceback (most recent call last) &lt;ipython-input-11-9da63d4b2b0e&gt; in &lt;module&gt;() 1 import numpy as np -&gt; 2 np.max([collection]) &lt;__array_function__ internals&gt; in amax(*args, **kwargs) /usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py in amax(a, axis, out, keepdims, initial, where) 2704 &#34;&#34;&#34; 2705 return _wrapreduction(a, np.maximum, &#39;max&#39;, axis, None, out, -&gt; 2706 keepdims=keepdims, initial=initial, where=where) 2707 2708 /usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py in _wrapreduction(obj, ufunc, method, axis, dtype, out, **kwargs) 85 return reduction(axis=axis, out=out, **passkwargs) 86 &gt; 87 return ufunc.reduce(obj, axis, dtype, out, **passkwargs) 88 89 TypeError: cannot perform reduce with flexible type . Another error that is really common is that when you type something grammatically wrong in the Python sense. . Syntax Error: Raised by the parser when a syntax error is encountered. . collection = [&quot;Chinese Posters in Harvard-Yenching Manchukuo Collection&quot;] collection[0) # it should be [0], not[0) . File &#34;&lt;ipython-input-18-011172c21475&gt;&#34;, line 3 collection[0) ^ SyntaxError: invalid syntax . 2) Spot the Sources of Errors . In order to make errors easier to spot, it is always a good practice if you run only a small chunk of code in a time. For example, you call separate a long chunk of code into different cells. . Every cell can be used for one main action, for example: . . . . . Another way to spot errors in code is that try to reduce the code you have. For example: . Let&#39;s say you want to find out the length of the first advertisement in the list (商務印書館發行書目介紹), and you built a function for it. But instead of 11 characters, you get 2. . Although there is no problems running this code, as it is not giving you what you want, it is also a bug. . What you can do is to reduce the code and to see if things work the way you want. . ad = [&quot;商務印書館發行書目介紹&quot;,&quot;女界寶、非洲樹皮丸、助肺呼吸香膠、家普魚肝油、清血解毒海波藥、納佛補天汁、良丹(五洲大藥房)&quot;] import re # this you will learn in the notebook web scrapping so you do not need to understand everything for now def number_of_character(text): list_ = list(text) # list() is used to split words into a list of characters length = len(list_) # len() is to check the length return length number_of_character(ad) . 2 . Let&#39;s check the first step: Can we use list to split the characters as we want? . list(ad) . [&#39;商務印書館發行書目介紹&#39;, &#39;女界寶、非洲樹皮丸、助肺呼吸香膠、家普魚肝油、清血解毒海波藥、納佛補天汁、良丹(五洲大藥房)&#39;] . And we realize, we want to split 商務印書館發行書目介紹, but this is not done! . list(&quot;advertisement&quot;) # this is what we want, to split characters . [&#39;a&#39;, &#39;d&#39;, &#39;v&#39;, &#39;e&#39;, &#39;r&#39;, &#39;t&#39;, &#39;i&#39;, &#39;s&#39;, &#39;e&#39;, &#39;m&#39;, &#39;e&#39;, &#39;n&#39;, &#39;t&#39;] . And then we might find out, it only work if we use ad[0] instead. . list(ad[0]) . [&#39;商&#39;, &#39;務&#39;, &#39;印&#39;, &#39;書&#39;, &#39;館&#39;, &#39;發&#39;, &#39;行&#39;, &#39;書&#39;, &#39;目&#39;, &#39;介&#39;, &#39;紹&#39;] . ad = [&quot;商務印書館發行書目介紹&quot;,&quot;女界寶、非洲樹皮丸、助肺呼吸香膠、家普魚肝油、清血解毒海波藥、納佛補天汁、良丹(五洲大藥房)&quot;] import re # this you will learn in the notebook web scrapping so you do not need to understand everything for now def number_of_character(text): list_ = list(text) length = len(list_) return length number_of_character(ad[0]) . 11 . 3) Google and stackoverflow . Sometimes errors are not so clear to you. What you can do is to copy the errors and Google them. Stackoverflow is also another website that can be really helpful. . collection = [&quot;Chinese Posters in Harvard-Yenching Manchukuo Collection&quot;, &quot;Linked Archive of Asian Postcards&quot;] typ = [1,0] collection[typ] . TypeError Traceback (most recent call last) &lt;ipython-input-13-9eca3a76ef67&gt; in &lt;module&gt;() 2 typ = [1,0] 3 -&gt; 4 collection[typ] TypeError: list indices must be integers or slices, not list . Then you might find out what you need to select collection item from typ is to use Numpy array instead of list. . collection = np.array([&quot;Chinese Posters in Harvard-Yenching Manchukuo Collection&quot;, &quot;Linked Archive of Asian Postcards&quot;]) typ = np.array([1,0]) collection[typ] . array([&#39;Linked Archive of Asian Postcards&#39;, &#39;Chinese Posters in Harvard-Yenching Manchukuo Collection&#39;], dtype=&#39;&lt;U56&#39;) . 4) Use Try and Except . In order to avoid errors, what we can also do is to use try and except. It means asking Python to try something out, if it does not work, then do Plan B instead of giving you errors. . Be careful that this method only appy if the errors come from unexpected outliners in inputs. It will not give you any meaningful results if the errors lie in your code itself. . . It works as follow: . try: . (do plan a) # &lt;- indented block . except: . (do plan b) # &lt;- indented block . try: print(1+1) except: print(0) . 2 . . For example, the same function work well for the first and second item, but there is a typo in the third item, so that it is not a string, but an integer. . In this case, the function will not work as it expects a string. . collection = [&quot;Chinese Posters in Harvard-Yenching Manchukuo Collection&quot;, &quot;Linked Archive of Asian Postcards&quot;, 4] . def number_of_character(text): list_ = list(text) length = len(list_) return length number_of_character(collection[2]) . TypeError Traceback (most recent call last) &lt;ipython-input-50-b4200bdffa93&gt; in &lt;module&gt;() 4 return length 5 -&gt; 6 number_of_character(collection[2]) &lt;ipython-input-50-b4200bdffa93&gt; in number_of_character(text) 1 def number_of_character(text): -&gt; 2 list_ = list(text) 3 length = len(list_) 4 return length 5 TypeError: &#39;int&#39; object is not iterable . What we can do is to set up a Plan B: . If the words cannot be split, then use an empty list ([]). . . OUR PLAN B . except: . list_ = [] . def number_of_character(text): try: list_ = list(text) except: list_ = [] length = len(list_) return length number_of_character(collection[2]) . 0 . Now, we do not get the same error anymore. It is particularly useful when we are automating the task: because if we want going through thousands of documents, we do not want the code to crash because of one little typo. . 5) Check Documentation . If the errors come from your code itself, the easiest way to inspect the problems is to check the documentation of the function you used. If you are using Jupyter Notebook, you can always highlight the function you typed and the documentation of this function will appear, illustrating what inputs are expected. . You can also choose to directly Google the function and check the examples. For exmaple, if the following error occurs, by searching the reverse function &quot;python reverse()&quot; we can see from the documentation that the list is expected before the function ad(), not inside the (). . reverse(ad) ad . NameError Traceback (most recent call last) &lt;ipython-input-20-e88da2471207&gt; in &lt;module&gt;() 1 # error -&gt; 2 reverse(ad) 3 ad NameError: name &#39;reverse&#39; is not defined . ad.reverse() ad . [&#39;女界寶、非洲樹皮丸、助肺呼吸香膠、家普魚肝油、清血解毒海波藥、納佛補天汁、良丹(五洲大藥房)&#39;, &#39;商務印書館發行書目介紹&#39;] . . Previous Lesson: Coding Practice Basics . Next Lesson: Functions and Loops Basics . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: December 2021 . . . . References: . https://www.tutorialsteacher.com/python/error-types-in-python .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/level-1/chapter-1/background/2020/01/27/Debugging_and_Understanding_Errors_Basics.html",
            "relUrl": "/level-1/chapter-1/background/2020/01/27/Debugging_and_Understanding_Errors_Basics.html",
            "date": " • Jan 27, 2020"
        }
        
    
  
    
        ,"post15": {
            "title": "Functions and Loops",
            "content": ". As mentioned in the instructions, all materials can be open in Colab as Jupyter notebooks. In this way users can run the code in the cloud. It is highly recommanded to follow the tutorials in the right order. . When we perform a larger chunk of text analysis, the workflow might get longer and longer which can be unhandy and prone to mistakes. Both functions and loops are ways to &quot;ask for repeated computation&quot;, either by looping through what you have or refering back to code you already wrote (the function). . This notebook aims to introduce users how to use functions and loops in Python using basic text exmaple from the humanity discipline. It aims to provide users basic skills to automate small chunks of text analysis using text resources. . . Presumption: . Functions . Loops . Enumerate . . It is also recommanded that the user has some basic understandings already with Python. . . . ## Functions | . In Python, a function is a group of related statements that performs a specific task. . Functions break our tasks into smaller chunks and make it more manageable. Furthermore, it avoids repetition and makes the code reusable. It is very helful when the workflow (task) need to be repeated done (Get information from a long list of document or webpages) so the user do not need to specify everything for multiple times to execute the task. It is also less prone to mistakes as users do not need to code everytime. . A function is started with the keyword def. Once the function is defined, it can be called by typing the function name with appropriate parameters. . . Remark: . Both # and &quot;&quot;&quot; &quot;&quot;&quot; in the code are comments and will not run in Python. . . Example of a function: . import datetime # define funciton def getTime(n): # name and input &quot;&quot;&quot; This function acquire future days from now &quot;&quot;&quot; day = datetime.datetime.now() + datetime.timedelta(days=n) # action return str(day) # output # call function getTime(1) . &#39;2021-12-10 20:06:05.499284&#39; . &#23142;&#22899;&#38620;&#35468;&#24291;&#21578; (Advertisements from Chinese Womens Magazine) . This is the subset of the advertisements published in 婦女雜誌1915年 第01期. . Let&#39;s say we want to know if the advertistment is published form a 公司. . ad = [&quot;商務印書館發行書目介紹&quot;,&quot;女界寶、非洲樹皮丸、助肺呼吸香膠、家普魚肝油、清血解毒海波藥、納佛補天汁、良丹(五洲大藥房)&quot;,&quot;泰豐罐頭食品有限公司製造廠攝影&quot;,&quot;武進莊苣史女士菊花寒菜寫生&quot;,&quot;中華眼鏡公司&quot;,&quot;中將湯(東亞公司經理批發)&quot;] . import re # this you will learn in the regular expression notebook so you do not need to understand everything for now def ad_check(text): # but you need to know the function start with def, the name of the function, and a () with/ without argument(s) inside. pattern = re.compile(r&#39;公司&#39;) # inside the function you need to indent every line (with a tab) match = any(pattern.findall(text)) # you somehow get to the result (desired output) return match # and you return them (typically in a variable) . Now we can apply the function using our ad list. We can only pass a string in the function so we need to slice the item. For example, we can check on the first advertisement in list. . ad_check(ad[0]) . False . It returns False, a boolean meaning the word &quot;公司&quot; cannot be found. Now we check on the third item. . ad_check(ad[2]) . True . True is returned, meaning the keyword is found. So now we do not need to type the whole function everytime we want to check for an ad. . . ## Loops | . In fact, we can even automate all ads using a loop. A loop can be very simple, but can get complicated if multiple elements are looped in parallel or when it is nested (loop inside another loop). . Here we use a simple for loop: it is started with a &quot;for (something) in (something):&quot;, and followed by the next line(s) (all operations needed). All lines under the loop needed to be indented. . It basically tells Python: . . For the item (i) in my list (ad), . apply the function using input item (i) . and print the result before the next round (item) . for i in ad: # i is the item you name, ad is our list print(ad_check(i)) # action . False False True False True True . Sometime when we loop, we do not want to loop using the item itself, but the index of our item (For example, here let&#39;s say we want to print the index of the company found). Then we can do it in the following way: . len(ad) # first we found the len of our list . 6 . np.arange(len(ad)) # then we generate a sequence with the same length . array([0, 1, 2, 3, 4, 5]) . This is then the index we loop through instead of the item. . . Remark: . ad_check(ad[i]) is the same as ad_check(ad[i]) == True but the first way is more efficient to run in Python. . (ad_check(ad[i])) == (ad_check(ad[i]) == True) . True . for i in np.arange(len(ad)): # loop tho index if ad_check(ad[i]): # provide a condition: only print when it is true print(i,&quot;. &quot;,ad[i]) # print the index and the item . 2 . 泰豐罐頭食品有限公司製造廠攝影 4 . 中華眼鏡公司 5 . 中將湯(東亞公司經理批發) . Nonetheless, print the results is not very helpful because it is not stored in a variable and we cannot recall them. A helpful way is to stored them in another list. . Before we try to store them into our list, we need to first define it, as an empty list. . check_list = [] # define our output list for i in ad: # for loop again check_list.append(ad_check(i)) # now we use append (adding element at the end of the list) to put our result every round . check_list . [False, False, True, False, True, True] . Now we know the keyword is found in 3rd, 5th, 6th ads. We can print out the company ads. This can be better done using numpy array. so we will first convert both lists to arrays. . import numpy as np # always need to import library first ad = np.array(ad) # convert using np.array() check_list = np.array(check_list) ad[check_list] # slice ad using checklist, it only works when the check_list consists boolean (True and False, or 1 and 0) . array([&#39;泰豐罐頭食品有限公司製造廠攝影&#39;, &#39;中華眼鏡公司&#39;, &#39;中將湯(東亞公司經理批發)&#39;], dtype=&#39;&lt;U46&#39;) . We also need to be careful that looping is considered an inefficient way to get things done in Python, so if we can get the job done without loop, then it is better we do it without. . . ## Enumerate | . Sometimes, we do not only want to loop through the items, but also the indices of the item so we want do some further operations. In the above example we use a loop of index to print all the items with &quot;公司&quot;. . 2 . 泰豐罐頭食品有限公司製造廠攝影 4 . 中華眼鏡公司 5 . 中將湯(東亞公司經理批發) . However, we can use enumerate() instead which is a more efficient approach. It provides us two numbers: the first one is index starting from 0, another one is the item itself. . for count, value in enumerate(ad): print(count, value) . 0 商務印書館發行書目介紹 1 女界寶、非洲樹皮丸、助肺呼吸香膠、家普魚肝油、清血解毒海波藥、納佛補天汁、良丹(五洲大藥房) 2 泰豐罐頭食品有限公司製造廠攝影 3 武進莊苣史女士菊花寒菜寫生 4 中華眼鏡公司 5 中將湯(東亞公司經理批發) . The following code give use exactly the same result as the above example: . In this case, both codes do not seem to make a difference, however, in other case, using enumerate() is much more efficient and allows use to write much shorter code. . for count, value in enumerate(ad): if ad_check(value): print(count, &#39;.&#39;, value) . 2 . 泰豐罐頭食品有限公司製造廠攝影 4 . 中華眼鏡公司 5 . 中將湯(東亞公司經理批發) . . Previous Lesson: Debugging and Understanding Errors Basics . Next Lesson: List Comprehension . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: December 2021 . . . . References: . https://mhdb.mh.sinica.edu.tw/fnzz/view.php?book=1501&amp;str=%E5%A9%A6%E5%A5%B3 .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/programming/chapter-1/level-1/2020/01/26/FunctionsNLoops_Basics.html",
            "relUrl": "/programming/chapter-1/level-1/2020/01/26/FunctionsNLoops_Basics.html",
            "date": " • Jan 26, 2020"
        }
        
    
  
    
        ,"post16": {
            "title": "List Comprehension",
            "content": ". As mentioned in the instructions, all materials can be open in Colab as Jupyter notebooks. In this way users can run the code in the cloud. It is highly recommanded to follow the tutorials in the right order. . Presumption: . List Comprehension . . Dictionary . Tuples . zip() . . Below we use a short list of local gazetteers from LoGaRT as our example. . gazetteer = [&quot;天下一統志(明)&quot;,&quot;大明一統志(明)&quot;,&quot;嘉善縣志(明)&quot;,&quot;雍大記南畿志(明)&quot;,&quot;上海縣志(明)&quot;,&quot;全遼志(明)&quot;,&quot;喬三石耀州志(明)&quot;,&quot;宣府鎮志(明)&quot;,&quot;雲南通志(明)&quot;,&quot;大明一統志輯錄(明)&quot;,&quot;雲中郡志(清)&quot;] . import re # this you will learn in the regular expression notebook so you do not need to understand everything for now def str_check(text): # but you need to know the function start with def, the name of the function, and a () with/ without argument(s) inside. pattern = re.compile(r&#39;明&#39;) # inside the function you need to indent every line (with a tab) match = any(pattern.findall(text)) # you somehow get to the result (desired output) return match # and you return them (typically in a variable) . Suppose we need all the local gazetteers from 明 only. What we can do is to build a function (there is another easier option using Pandas but now we stick with this function). And then we can print all results which fit the condition. . . The structure of list comprehension is: . [ ] &lt;- in a list &lt;- key components . (name1) for (name2) in &lt;- for and in are keywords, (name2) is the variable name to be assigned for the item in loop, (name1) is the output you want, which should be expressed in terms of (name2) . (list) &lt;- the variable which stores all the items or the list to be loop through . if (condition) &lt;- add a condition, this part is optional . . Remarks: (name1) and (name2) can be the same but do not need to be . [x for x in gazetteer if str_check(x)] # if ad_check(x) is the same as if ad_check(x) == True . [&#39;天下一統志(明)&#39;, &#39;大明一統志(明)&#39;, &#39;嘉善縣志(明)&#39;, &#39;雍大記南畿志(明)&#39;, &#39;上海縣志(明)&#39;, &#39;全遼志(明)&#39;, &#39;喬三石耀州志(明)&#39;, &#39;宣府鎮志(明)&#39;, &#39;雲南通志(明)&#39;, &#39;大明一統志輯錄(明)&#39;] . We can also save the list to another new list. . ming_gazetteer = [x for x in gazetteer if str_check(x)] ming_gazetteer . [&#39;天下一統志(明)&#39;, &#39;大明一統志(明)&#39;, &#39;嘉善縣志(明)&#39;, &#39;雍大記南畿志(明)&#39;, &#39;上海縣志(明)&#39;, &#39;全遼志(明)&#39;, &#39;喬三石耀州志(明)&#39;, &#39;宣府鎮志(明)&#39;, &#39;雲南通志(明)&#39;, &#39;大明一統志輯錄(明)&#39;] . We can also change the outputs: for example, instead of the item itself, we want to get the lengths of the strings which fit the same condition: . [len(x) for x in gazetteer if str_check(x)] . [8, 8, 7, 9, 7, 6, 9, 7, 7, 10] . [x for x in gazetteer if str_check(x)] . [&#39;天下一統志(明)&#39;, &#39;大明一統志(明)&#39;, &#39;嘉善縣志(明)&#39;, &#39;雍大記南畿志(明)&#39;, &#39;上海縣志(明)&#39;, &#39;全遼志(明)&#39;, &#39;喬三石耀州志(明)&#39;, &#39;宣府鎮志(明)&#39;, &#39;雲南通志(明)&#39;, &#39;大明一統志輯錄(明)&#39;] . We can also combine list comprehension with any functions from any library. For example, we want to get the piyin of the items in our list. We can use library pinyin for that. . ! pip install pinyin # install library import pinyin # import library . [pinyin.get(x, format=&quot;strip&quot;, delimiter=&quot; &quot;) for x in gazetteer] # get the pinyin for all items . [&#39;tian xia yi tong zhi ( ming )&#39;, &#39;da ming yi tong zhi ( ming )&#39;, &#39;jia shan xian zhi ( ming )&#39;, &#39;yong da ji nan ji zhi ( ming )&#39;, &#39;shang hai xian zhi ( ming )&#39;, &#39;quan liao zhi ( ming )&#39;, &#39;qiao san shi yao zhou zhi ( ming )&#39;, &#39;xuan fu zhen zhi ( ming )&#39;, &#39;yun nan tong zhi ( ming )&#39;, &#39;da ming yi tong zhi ji lu ( ming )&#39;, &#39;yun zhong jun zhi ( qing )&#39;] . [pinyin.get(x, format=&quot;strip&quot;, delimiter=&quot; &quot;) for x in gazetteer if str_check(x)] # get the pinyin for all items from ming . [&#39;tian xia yi tong zhi ( ming )&#39;, &#39;da ming yi tong zhi ( ming )&#39;, &#39;jia shan xian zhi ( ming )&#39;, &#39;yong da ji nan ji zhi ( ming )&#39;, &#39;shang hai xian zhi ( ming )&#39;, &#39;quan liao zhi ( ming )&#39;, &#39;qiao san shi yao zhou zhi ( ming )&#39;, &#39;xuan fu zhen zhi ( ming )&#39;, &#39;yun nan tong zhi ( ming )&#39;, &#39;da ming yi tong zhi ji lu ( ming )&#39;] . Apart from that, we can also combine the index using enumerate() (we have learnt it from the previous lesson). . Remember that enumerate() return two values as we need two names between the keywords &quot;for&quot; and &quot;in&quot;! . [print(index,pinyin.get(item, format=&quot;strip&quot;, delimiter=&quot; &quot;)) for index, item in enumerate(gazetteer)] # get the pinyin with indices for all items . 0 tian xia yi tong zhi ( ming ) 1 da ming yi tong zhi ( ming ) 2 jia shan xian zhi ( ming ) 3 yong da ji nan ji zhi ( ming ) 4 shang hai xian zhi ( ming ) 5 quan liao zhi ( ming ) 6 qiao san shi yao zhou zhi ( ming ) 7 xuan fu zhen zhi ( ming ) 8 yun nan tong zhi ( ming ) 9 da ming yi tong zhi ji lu ( ming ) 10 yun zhong jun zhi ( qing ) . [None, None, None, None, None, None, None, None, None, None, None] . [print(index,pinyin.get(item, format=&quot;strip&quot;, delimiter=&quot; &quot;)) for index, item in enumerate(gazetteer) if index in [1,3]] . 1 da ming yi tong zhi ( ming ) 3 yong da ji nan ji zhi ( ming ) . [None, None] . [print(index,pinyin.get(item, format=&quot;strip&quot;, delimiter=&quot; &quot;)) for index, item in enumerate(gazetteer) if index not in [0]] . 1 da ming yi tong zhi ( ming ) 2 jia shan xian zhi ( ming ) 3 yong da ji nan ji zhi ( ming ) 4 shang hai xian zhi ( ming ) 5 quan liao zhi ( ming ) 6 qiao san shi yao zhou zhi ( ming ) 7 xuan fu zhen zhi ( ming ) 8 yun nan tong zhi ( ming ) 9 da ming yi tong zhi ji lu ( ming ) 10 yun zhong jun zhi ( qing ) . [None, None, None, None, None, None, None, None, None, None] . There are numerous options what we can do using list comprehension. Another example demonsrating the functionality of list comprehension is word frequency count: searching for the keywords which appears in the top frequencies. . First, we join all the items to a single list and then split all Chinese character using list() after removing () using replace(). . string = &#39;&#39;.join(gazetteer) # join all items in list to a single string string = string.replace(&quot;(&quot;, &quot;&quot;).replace(&quot;)&quot;, &quot;&quot;) # replace &quot;(&quot; and &quot;)&quot; to nothing &quot;&quot; wordlist = list(string) # split all Chinese characters wordlist[:5] # print first 5 characters . [&#39;天&#39;, &#39;下&#39;, &#39;一&#39;, &#39;統&#39;, &#39;志&#39;] . Now we use list comprehension to count all characters. . wordfreq = [wordlist.count(w) for w in wordlist] # list comprehension to count all characters # print the single string print(&quot;String n&quot; + string +&quot; n&quot;) # n means new line # print a list of all characters print(&quot;List n&quot; + str(wordlist) + &quot; n&quot;) # print frequencies print(&quot;Frequencies n&quot; + str(wordfreq) + &quot; n&quot;) # print zip objects by combining characters and occurences print(&quot;Pairs n&quot; + str(list(zip(wordlist, wordfreq)))) . String 天下一統志明大明一統志明嘉善縣志明雍大記南畿志明上海縣志明全遼志明喬三石耀州志明宣府鎮志明雲南通志明大明一統志輯錄明雲中郡志清 List [&#39;天&#39;, &#39;下&#39;, &#39;一&#39;, &#39;統&#39;, &#39;志&#39;, &#39;明&#39;, &#39;大&#39;, &#39;明&#39;, &#39;一&#39;, &#39;統&#39;, &#39;志&#39;, &#39;明&#39;, &#39;嘉&#39;, &#39;善&#39;, &#39;縣&#39;, &#39;志&#39;, &#39;明&#39;, &#39;雍&#39;, &#39;大&#39;, &#39;記&#39;, &#39;南&#39;, &#39;畿&#39;, &#39;志&#39;, &#39;明&#39;, &#39;上&#39;, &#39;海&#39;, &#39;縣&#39;, &#39;志&#39;, &#39;明&#39;, &#39;全&#39;, &#39;遼&#39;, &#39;志&#39;, &#39;明&#39;, &#39;喬&#39;, &#39;三&#39;, &#39;石&#39;, &#39;耀&#39;, &#39;州&#39;, &#39;志&#39;, &#39;明&#39;, &#39;宣&#39;, &#39;府&#39;, &#39;鎮&#39;, &#39;志&#39;, &#39;明&#39;, &#39;雲&#39;, &#39;南&#39;, &#39;通&#39;, &#39;志&#39;, &#39;明&#39;, &#39;大&#39;, &#39;明&#39;, &#39;一&#39;, &#39;統&#39;, &#39;志&#39;, &#39;輯&#39;, &#39;錄&#39;, &#39;明&#39;, &#39;雲&#39;, &#39;中&#39;, &#39;郡&#39;, &#39;志&#39;, &#39;清&#39;] Frequencies [1, 1, 3, 3, 11, 12, 3, 12, 3, 3, 11, 12, 1, 1, 2, 11, 12, 1, 3, 1, 2, 1, 11, 12, 1, 1, 2, 11, 12, 1, 1, 11, 12, 1, 1, 1, 1, 1, 11, 12, 1, 1, 1, 11, 12, 2, 2, 1, 11, 12, 3, 12, 3, 3, 11, 1, 1, 12, 2, 1, 1, 11, 1] Pairs [(&#39;天&#39;, 1), (&#39;下&#39;, 1), (&#39;一&#39;, 3), (&#39;統&#39;, 3), (&#39;志&#39;, 11), (&#39;明&#39;, 12), (&#39;大&#39;, 3), (&#39;明&#39;, 12), (&#39;一&#39;, 3), (&#39;統&#39;, 3), (&#39;志&#39;, 11), (&#39;明&#39;, 12), (&#39;嘉&#39;, 1), (&#39;善&#39;, 1), (&#39;縣&#39;, 2), (&#39;志&#39;, 11), (&#39;明&#39;, 12), (&#39;雍&#39;, 1), (&#39;大&#39;, 3), (&#39;記&#39;, 1), (&#39;南&#39;, 2), (&#39;畿&#39;, 1), (&#39;志&#39;, 11), (&#39;明&#39;, 12), (&#39;上&#39;, 1), (&#39;海&#39;, 1), (&#39;縣&#39;, 2), (&#39;志&#39;, 11), (&#39;明&#39;, 12), (&#39;全&#39;, 1), (&#39;遼&#39;, 1), (&#39;志&#39;, 11), (&#39;明&#39;, 12), (&#39;喬&#39;, 1), (&#39;三&#39;, 1), (&#39;石&#39;, 1), (&#39;耀&#39;, 1), (&#39;州&#39;, 1), (&#39;志&#39;, 11), (&#39;明&#39;, 12), (&#39;宣&#39;, 1), (&#39;府&#39;, 1), (&#39;鎮&#39;, 1), (&#39;志&#39;, 11), (&#39;明&#39;, 12), (&#39;雲&#39;, 2), (&#39;南&#39;, 2), (&#39;通&#39;, 1), (&#39;志&#39;, 11), (&#39;明&#39;, 12), (&#39;大&#39;, 3), (&#39;明&#39;, 12), (&#39;一&#39;, 3), (&#39;統&#39;, 3), (&#39;志&#39;, 11), (&#39;輯&#39;, 1), (&#39;錄&#39;, 1), (&#39;明&#39;, 12), (&#39;雲&#39;, 2), (&#39;中&#39;, 1), (&#39;郡&#39;, 1), (&#39;志&#39;, 11), (&#39;清&#39;, 1)] . In order to produce more useful outputs to inspect the keywords, we can combine functions and list comprehensions to output a dictionary. Click here if you need to review how to build a function. . def wordListToFreqDict(wordlist): &quot;&quot;&quot; This function convert a word list to dictionary displaying frequencies of character occurences &quot;&quot;&quot; wordfreq = [wordlist.count(p) for p in wordlist] # same as what we did above return dict(list(zip(wordlist,wordfreq))) # return a dictionary of zip objects word_count = wordListToFreqDict(wordlist) . Let&#39;s look at our dictionary word_count. . word_count . {&#39;一&#39;: 3, &#39;三&#39;: 1, &#39;上&#39;: 1, &#39;下&#39;: 1, &#39;中&#39;: 1, &#39;全&#39;: 1, &#39;南&#39;: 2, &#39;善&#39;: 1, &#39;喬&#39;: 1, &#39;嘉&#39;: 1, &#39;大&#39;: 3, &#39;天&#39;: 1, &#39;宣&#39;: 1, &#39;州&#39;: 1, &#39;府&#39;: 1, &#39;志&#39;: 11, &#39;明&#39;: 12, &#39;海&#39;: 1, &#39;清&#39;: 1, &#39;畿&#39;: 1, &#39;石&#39;: 1, &#39;統&#39;: 3, &#39;縣&#39;: 2, &#39;耀&#39;: 1, &#39;記&#39;: 1, &#39;輯&#39;: 1, &#39;通&#39;: 1, &#39;遼&#39;: 1, &#39;郡&#39;: 1, &#39;錄&#39;: 1, &#39;鎮&#39;: 1, &#39;雍&#39;: 1, &#39;雲&#39;: 2} . However, as we can see, the data seems to be a bit messy. It would be much easier to read if we order the keywords by frequency. We can do this by building another small function to sort the values. . def sortFreqDict(freqdict): &quot;&quot;&quot; This function sort dictionary by keyword frequencies &quot;&quot;&quot; aux = [(freqdict[key], key) for key in freqdict] # convert dictionary back to a list of tuples aux.sort() # sort the values aux.reverse() # reverse the values so the items are in descending order return aux # return sorted list sortFreqDict(word_count)[:5] # apply our function and print the first 5 items in list . [(12, &#39;明&#39;), (11, &#39;志&#39;), (3, &#39;統&#39;), (3, &#39;大&#39;), (3, &#39;一&#39;)] . . Previous Lesson: Functions and Loops Basics . Next Lesson: Regular Expression . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: December 2021 . . . . References: . https://gist.github.com/acrymble/1065661 .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/chapter-1/level-1/programming/2020/01/25/List_Comprehension_Basics.html",
            "relUrl": "/chapter-1/level-1/programming/2020/01/25/List_Comprehension_Basics.html",
            "date": " • Jan 25, 2020"
        }
        
    
  
    
        ,"post17": {
            "title": "Pandas Numerical Operation",
            "content": "As mentioned in the instructions, all materials can be open in Colab as Jupyter notebooks. In this way users can run the code in the cloud. It is highly recommanded to follow the tutorials in the right order. . This tutorial is a follow-up from the last Pandas tutorial which introduce functions for working with text. Nonetheless, numerical operations in Pandas is also essential knowledge when it comes to statistics in the data. Here we use an example of UNESCO heritage sites to demonstrate how to work with numbers and datetime in Pandas. It will also cover some basic knowledge about plotting using Matplotlib and Pandas. . . Presumptions: Same as the previous notebook . . import io import pandas as pd import requests # read data url = &#39;https://examples.opendatasoft.com/explore/dataset/world-heritage-unesco-list/download/?format=csv&amp;timezone=Europe/Berlin&amp;lang=en&amp;use_labels_for_header=true&amp;csv_separator=%3B&#39; df = pd.read_csv(url, sep=&quot;;&quot;) . df.head(2) # head() is used for viewing the first few rows of data . Name (EN) Name (FR) Short description (EN) Short Description (FR) Justification (EN) Justification (FR) Date inscribed Danger list Longitude Latitude Area hectares Category Country (EN) Country (FR) Continent (EN) Continent (FR) Geographical coordinates . 0 Architectural, Residential and Cultural Comple... | Ensemble architectural, résidentiel et culture... | The Architectural, Residential and Cultural Co... | L’ensemble architectural, résidentiel et cultu... | Criterion (ii): The architectural, residential... | Critère (ii) : L’ensemble architectural, résid... | 2005-01-01 | NaN | 26.69139 | 53.22278 | 0.0 | Cultural | Belarus | Bélarus | Europe and North America | Europe et Amérique du nord | 53.22278,26.69139 | . 1 Rock Paintings of the Sierra de San Francisco | Peintures rupestres de la Sierra de San Francisco | From c. 100 B.C. to A.D. 1300, the Sierra de S... | Dans la réserve d&#39;El Vizcaíno, en Basse-Califo... | NaN | NaN | 1993-01-01 | NaN | -112.91611 | 27.65556 | 182600.0 | Cultural | Mexico | Mexique | Latin America and the Caribbean | Amérique latine et Caraïbes | 27.65556,-112.91611 | . df[&quot;Country (EN)&quot;] # selecting one column . 0 Belarus 1 Mexico 2 Romania 3 Italy 4 Belgium,France ... 1047 Bosnia and Herzegovina,Croatia,Serbia,Montenegro 1048 China 1049 United Kingdom of Great Britain and Northern I... 1050 Chad 1051 France Name: Country (EN), Length: 1052, dtype: object . By typing .values, we can convert one column in the Pandas dataframe to Numpy array. . country_arr = df[&quot;Country (EN)&quot;].values # to numpy country_arr . array([&#39;Belarus&#39;, &#39;Mexico&#39;, &#39;Romania&#39;, ..., &#39;United Kingdom of Great Britain and Northern Ireland&#39;, &#39;Chad&#39;, &#39;France&#39;], dtype=object) . import numpy as np unique_name = np.unique(country_arr) # the list of country. np.unique() return values only one time no matter how many times do they appear unique_name[:3] # check the first three countries only . array([&#39;Afghanistan&#39;, &#39;Albania&#39;, &#39;Algeria&#39;], dtype=object) . Data Inspection . We can inspect our data fame by filtering, querying, and subsetting. For example, we can check all the entries from China. Let&#39;s first filter the relevant columns (Name, Category and Country) from our data frame. . df.filter(items=[&quot;Name (EN)&quot;,&quot;Category&quot;,&quot;Country (EN)&quot;]) . Name (EN) Category Country (EN) . 0 Architectural, Residential and Cultural Comple... | Cultural | Belarus | . 1 Rock Paintings of the Sierra de San Francisco | Cultural | Mexico | . 2 Monastery of Horezu | Cultural | Romania | . 3 Mount Etna | Natural | Italy | . 4 Belfries of Belgium and France | Cultural | Belgium,France | . ... ... | ... | ... | . 1047 Stećci Medieval Tombstones Graveyards | Cultural | Bosnia and Herzegovina,Croatia,Serbia,Montenegro | . 1048 Jiuzhaigou Valley Scenic and Historic Interest... | Natural | China | . 1049 Blenheim Palace | Cultural | United Kingdom of Great Britain and Northern I... | . 1050 Lakes of Ounianga | Natural | Chad | . 1051 Mont-Saint-Michel and its Bay | Cultural | France | . 1052 rows × 3 columns . What we can also do is to query. For example, we can query heritages that are from China and belong to cultural category. Please remember all operations without assigning back to the dataframe itself is only temporary (except inplace = True). Using query(), we need to input a query string and we need to be careful that we need to use back ticks(`) to enclose column names with space, as well as to use single and double quoatation marks to avoid confusion. . For example, &quot;Country (EN)== &#39;China&#39; &amp; Category == &#39;Cultural&#39;&quot; will be okay but &quot;Country (EN)== &quot;China&quot; &amp; Category == &quot;Cultural&quot;&quot; will run into errors. . df.query(&quot;`Country (EN)` == &#39;China&#39; &amp; Category == &#39;Cultural&#39;&quot;) . Name (EN) Name (FR) Short description (EN) Short Description (FR) Justification (EN) Justification (FR) Date inscribed Danger list Longitude Latitude Area hectares Category Country (EN) Country (FR) Continent (EN) Continent (FR) Geographical coordinates . 32 Tusi Sites | Sites du tusi | Located in the mountainous areas of south-west... | Situé dans les régions montagneuses du sud-oue... | NaN | NaN | 2015-01-01 | NaN | 109.966944 | 28.998611 | 781.2800 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 28.9986111111,109.966944444 | . 38 The Great Wall | La Grande Muraille | In c. 220 B.C., under Qin Shi Huang, sections ... | Vers 220 av. J.-C., Qin Shin Huang entreprit d... | NaN | NaN | 1987-01-01 | NaN | 116.083330 | 40.416670 | 2151.5500 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 40.41667,116.08333 | . 68 Mausoleum of the First Qin Emperor | Mausolée du premier empereur Qin | No doubt thousands of statues still remain to ... | Sur ce site archéologique qui ne fut découvert... | NaN | NaN | 1987-01-01 | NaN | 109.100000 | 34.383333 | 0.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 34.38333333,109.1 | . 81 Site of Xanadu | Site de Xanadu | North of the Great Wall, the Site of Xanadu en... | Situé au nord de la Grande Muraille, ce site d... | NaN | NaN | 2012-01-01 | NaN | 116.185128 | 42.358000 | 25131.2700 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 42.358,116.185127778 | . 127 Temple and Cemetery of Confucius and the Kong ... | Temple et cimetière de Confucius et résidence ... | The temple, cemetery and family mansion of Con... | Le temple, le cimetière et la demeure de famil... | NaN | NaN | 1994-01-01 | NaN | 116.975000 | 35.611670 | 0.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 35.61167,116.975 | . 134 Fujian &lt;em&gt;Tulou&lt;/em&gt; | &lt;em&gt;Tulou&lt;/em&gt; du Fujian | Fujian Tulou is a property of 46 buildings con... | Le site des Tulou du Fujian, comprend 46 maiso... | NaN | NaN | 2008-01-01 | NaN | 117.685833 | 25.023056 | 152.6500 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 25.0230555556,117.685833333 | . 165 Dazu Rock Carvings | Sculptures rupestres de Dazu | The steep hillsides of the Dazu area contain a... | Les montagnes abruptes de la région de Dazu ab... | Criterion (i): The Dazu carvings represent the... | Critère (i) : De par leur grande qualité esthé... | 1999-01-01 | NaN | 105.705000 | 29.701110 | 20.4100 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 29.70111,105.705 | . 219 Lushan National Park | Parc national de Lushan | Mount Lushan, in Jiangxi, is one of the spirit... | Le site du mont Lushan, dans le Jiangxi, const... | The Committee decided to inscribe this propert... | Le Comité a décidé d&#39;inscrire ce bien sur la b... | 1996-01-01 | NaN | 115.866667 | 29.433333 | 0.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 29.43333333,115.8666667 | . 220 Imperial Tombs of the Ming and Qing Dynasties | Tombes impériales des dynasties Ming et Qing | It represents the addition of three Imperial T... | L’extension ajoute trois tombes impériales de ... | Criterion (i): The harmonious integration of r... | Critère (i) : l&#39;intégration harmonieuse d&#39;ense... | 2000-01-01 | NaN | 124.793889 | 41.707222 | 3434.9399 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 41.70722222,124.7938889 | . 449 Imperial Palaces of the Ming and Qing Dynastie... | Palais impériaux des dynasties Ming et Qing à ... | Seat of supreme power for over five centuries ... | Siège du pouvoir suprême pendant plus de cinq ... | Criterion (i): The Imperial Palaces represent ... | Critère (i) : Les Palais impériaux représenten... | 1987-01-01 | NaN | 123.446944 | 41.794167 | 12.9600 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 41.79416667,123.4469444 | . 457 Mountain Resort and its Outlying Temples, Chengde | Résidence de montagne et temples avoisinants à... | The Mountain Resort (the Qing dynasty&#39;s summer... | La résidence de montagne, palais d&#39;été de la d... | NaN | NaN | 1994-01-01 | NaN | 117.938330 | 40.986940 | 0.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 40.98694,117.93833 | . 459 West Lake Cultural Landscape of Hangzhou | Paysage culturel du lac de l’Ouest de Hangzhou | The West Lake Cultural Landscape of Hangzhou, ... | Le paysage inscrit a inspiré des poètes, artis... | NaN | NaN | 2011-01-01 | NaN | 120.140833 | 30.237500 | 3322.8800 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 30.2375,120.140833333 | . 545 Cultural Landscape of Honghe Hani Rice Terraces | Paysage culturel des rizières en terrasse des ... | The Cultural Landscape of Honghe Hani Rice Ter... | Ce site de 16 603 hectares est situé dans le s... | NaN | NaN | 2013-01-01 | NaN | 102.779981 | 23.093278 | 16603.2200 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 23.0932777778,102.779980556 | . 590 Ancient Building Complex in the Wudang Mountains | Ensemble de bâtiments anciens des montagnes de... | The palaces and temples which form the nucleus... | Les palais et temples qui constituent le noyau... | NaN | NaN | 1994-01-01 | NaN | 111.000000 | 32.466670 | 0.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 32.46667,111.0 | . 601 Historic Centre of Macao | Centre historique de Macao | Macao, a lucrative port of strategic importanc... | Macao, riche port marchand d’une grande import... | Criterion (ii): The strategic location of Maca... | Critère (ii) : L’emplacement stratégique de Ma... | 2005-01-01 | NaN | 113.536461 | 22.191292 | 16.1678 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 22.1912919444,113.536461111 | . 605 Yin Xu | Yin Xu | The archaeological site of Yin Xu, close to An... | Le site archéologique de Yin Xu, proche de la ... | NaN | NaN | 2006-01-01 | NaN | 114.313889 | 36.126667 | 414.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 36.1266666666,114.313888889 | . 628 Yungang Grottoes | Grottes de Yungang | The Yungang Grottoes, in Datong city, Shanxi P... | Les grottes de Yungang, à Datong, province du ... | Criterion (i): The assemblage of statuary of t... | Critère (i) : L’ensemble de la statuaire des g... | 2001-01-01 | NaN | 113.122220 | 40.109720 | 348.7500 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 40.10972,113.12222 | . 653 Peking Man Site at Zhoukoudian | Site de l&#39;homme de Pékin à Zhoukoudian | Scientific work at the site, which lies 42 km ... | À 42 km au sud-ouest de Pékin, le site, dont l... | NaN | NaN | 1987-01-01 | NaN | 115.916667 | 39.733333 | 480.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 39.73333333,115.9166667 | . 671 Historic Ensemble of the Potala Palace, Lhasa | Ensemble historique du Palais du Potala, Lhasa | The Potala Palace, winter palace of the Dalai ... | Le palais du Potala, palais d&#39;hiver du dalaï-l... | NaN | NaN | 1994-01-01 | NaN | 91.117170 | 29.657920 | 60.5000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 29.65792,91.11717 | . 739 Summer Palace, an Imperial Garden in Beijing | Palais d&#39;Été, Jardin impérial de Beijing | The Summer Palace in Beijing – first built in ... | Le palais d&#39;Été de Beijing, créé en 1750, détr... | Criterion i: The Summer Palace in Beijing is a... | Critère i : le Palais d&#39;Eté de Beijing est une... | 1998-01-01 | NaN | 116.141111 | 39.910556 | 297.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 39.91055556,116.1411111 | . 743 Mount Qingcheng and the Dujiangyan Irrigation ... | Mont Qingcheng et système d’irrigation de Duji... | Construction of the Dujiangyan irrigation syst... | La construction du système d&#39;irrigation de Duj... | Criterion (ii): The Dujiangyan Irrigation Syst... | Critère (ii) : Le système d’irrigation de Duji... | 2000-01-01 | NaN | 103.605280 | 31.001670 | 0.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 31.00167,103.60528 | . 746 Historic Monuments of Dengfeng in “The Centre ... | Monuments historiques de Dengfeng au « centre ... | Mount Songshang is considered to be the centra... | Songshang est considéré comme le mont sacré ce... | NaN | NaN | 2010-01-01 | NaN | 113.067719 | 34.458747 | 825.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 34.4587472222,113.067719444 | . 769 The Grand Canal | Le Grand Canal | The Grand Canal is a vast waterway system in t... | Ce vaste système de navigation intérieure au s... | NaN | NaN | 2014-01-01 | NaN | 112.468333 | 34.693889 | 20819.1100 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 34.6938888889,112.468333333 | . 772 Old Town of Lijiang | Vieille ville de Lijiang | The Old Town of Lijiang, which is perfectly ad... | La vieille ville de Lijiang, harmonieusement a... | The Committee decided to inscribe this site on... | Le Comité a décidé d’inscrire ce site sur la b... | 1997-01-01 | NaN | 100.233330 | 26.866670 | 145.6000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 26.86667,100.23333 | . 808 Kaiping Diaolou and Villages | Diaolou et villages de Kaiping | Kaiping Diaolou and Villages feature the Diaol... | Les diaolou, maisons fortifiées de village de ... | NaN | NaN | 2007-01-01 | NaN | 112.565861 | 22.285519 | 371.9480 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 22.2855194444,112.565861111 | . 839 Ancient Villages in Southern Anhui – Xidi and ... | Anciens villages du sud du Anhui – Xidi et Hon... | The two traditional villages of Xidi and Hongc... | Les deux villages traditionnels de Xidi et de ... | Criterion (iii): The villages of Xidi and Hong... | Critère (iii) : Les villages de Xidi et de Hon... | 2000-01-01 | NaN | 117.987500 | 29.904444 | 52.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 29.90444444,117.9875 | . 851 Zuojiang Huashan Rock Art Cultural Landscape | Paysage culturel de l’art rupestre de Zuojiang... | Located on the steep cliffs in the border regi... | Situés sur des falaises abruptes dans les régi... | NaN | NaN | 2016-01-01 | NaN | 107.023056 | 22.255556 | 6621.6000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 22.2555555556,107.023055556 | . 883 Classical Gardens of Suzhou | Jardins classiques de Suzhou | Classical Chinese garden design, which seeks t... | Le paysagisme classique chinois, qui cherche à... | The Committee decided to inscribe this propert... | Le Comité a décidé d&#39;inscrire ce bien sur la b... | 1997-01-01 | NaN | 120.450000 | 31.316667 | 11.9220 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 31.31666667,120.45 | . 903 Ancient City of Ping Yao | Vieille ville de Ping Yao | Ping Yao is an exceptionally well-preserved ex... | Ping Yao est un exemple exceptionnellement bie... | The Committee decided to inscribe this propert... | Le Comité a décidé d&#39;inscrire ce bien sur la b... | 1997-01-01 | NaN | 112.154440 | 37.201390 | 245.6200 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 37.20139,112.15444 | . 921 Longmen Grottoes | Grottes de Longmen | The grottoes and niches of Longmen contain the... | Les grottes et niches de Longmen abritent le p... | Criterion (i): The sculptures of the Longmen G... | Critère (i) : Les sculptures des grottes de Lo... | 2000-01-01 | NaN | 112.466667 | 34.466667 | 331.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 34.46666667,112.4666667 | . 930 Temple of Heaven: an Imperial Sacrificial Alta... | Temple du Ciel, autel sacrificiel impérial à B... | The Temple of Heaven, founded in the first hal... | Fondé dans la première moitié du XVe siècle, l... | Criterion i: The Temple of Heaven is a masterp... | Critère i : Le Temple du Ciel est un chef-d&#39;œu... | 1998-01-01 | NaN | 116.444722 | 39.845556 | 215.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 39.84555556,116.4447222 | . 971 Mount Wutai | Mont Wutai | With its five flat peaks, Mount Wutai is a sac... | Avec ses cinq plateaux, le Mont Wutai est une ... | NaN | NaN | 2009-01-01 | NaN | 113.563333 | 39.030556 | 18415.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 39.0305555556,113.563333333 | . 1008 Mogao Caves | Grottes de Mogao | Situated at a strategic point along the Silk R... | Situées en un point stratégique de la Route de... | NaN | NaN | 1987-01-01 | NaN | 94.816670 | 40.133330 | 0.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 40.13333,94.81667 | . 1010 Capital Cities and Tombs of the Ancient Kogury... | Capitales et tombes de l’ancien royaume de Kog... | The site includes archaeological remains of th... | Ce site comprend les vestiges archéologiques d... | Criterion (i): The tombs represent a masterpie... | Critère (i) : Les tombes représentent un chef ... | 2004-01-01 | NaN | 126.187222 | 41.156944 | 4164.8599 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 41.15694444,126.1872222 | . To avoid those confusions, another option is to subset data frame without query string. We can do it simply using []. However, we also need to make use of () to group our query into orders. . For example: . df[&quot;Country (EN)&quot;] == &quot;China&quot; &amp; df[&quot;Category&quot;] == &quot;Cultural&quot; . In the above line, there is no separation between &quot;China&quot; and &amp; so it might be interpreted as: . df[&quot;Country (EN)&quot;] == (&quot;China&quot; &amp; df[&quot;Category&quot;] == &quot;Cultural&quot;) . which will run into errors. . What we need to do is to group them: . (df[&quot;Country (EN)&quot;] == &quot;China&quot;) &amp; (df[&quot;Category&quot;] == &quot;Cultural&quot;) . so we make sure it will be interpreted as: . (col-A == a) &amp; (col-B == b) . df[(df[&quot;Country (EN)&quot;] == &quot;China&quot;) &amp; (df[&quot;Category&quot;] == &quot;Cultural&quot;)] . Name (EN) Name (FR) Short description (EN) Short Description (FR) Justification (EN) Justification (FR) Date inscribed Danger list Longitude Latitude Area hectares Category Country (EN) Country (FR) Continent (EN) Continent (FR) Geographical coordinates . 32 Tusi Sites | Sites du tusi | Located in the mountainous areas of south-west... | Situé dans les régions montagneuses du sud-oue... | NaN | NaN | 2015-01-01 | NaN | 109.966944 | 28.998611 | 781.2800 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 28.9986111111,109.966944444 | . 38 The Great Wall | La Grande Muraille | In c. 220 B.C., under Qin Shi Huang, sections ... | Vers 220 av. J.-C., Qin Shin Huang entreprit d... | NaN | NaN | 1987-01-01 | NaN | 116.083330 | 40.416670 | 2151.5500 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 40.41667,116.08333 | . 68 Mausoleum of the First Qin Emperor | Mausolée du premier empereur Qin | No doubt thousands of statues still remain to ... | Sur ce site archéologique qui ne fut découvert... | NaN | NaN | 1987-01-01 | NaN | 109.100000 | 34.383333 | 0.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 34.38333333,109.1 | . 81 Site of Xanadu | Site de Xanadu | North of the Great Wall, the Site of Xanadu en... | Situé au nord de la Grande Muraille, ce site d... | NaN | NaN | 2012-01-01 | NaN | 116.185128 | 42.358000 | 25131.2700 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 42.358,116.185127778 | . 127 Temple and Cemetery of Confucius and the Kong ... | Temple et cimetière de Confucius et résidence ... | The temple, cemetery and family mansion of Con... | Le temple, le cimetière et la demeure de famil... | NaN | NaN | 1994-01-01 | NaN | 116.975000 | 35.611670 | 0.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 35.61167,116.975 | . 134 Fujian &lt;em&gt;Tulou&lt;/em&gt; | &lt;em&gt;Tulou&lt;/em&gt; du Fujian | Fujian Tulou is a property of 46 buildings con... | Le site des Tulou du Fujian, comprend 46 maiso... | NaN | NaN | 2008-01-01 | NaN | 117.685833 | 25.023056 | 152.6500 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 25.0230555556,117.685833333 | . 165 Dazu Rock Carvings | Sculptures rupestres de Dazu | The steep hillsides of the Dazu area contain a... | Les montagnes abruptes de la région de Dazu ab... | Criterion (i): The Dazu carvings represent the... | Critère (i) : De par leur grande qualité esthé... | 1999-01-01 | NaN | 105.705000 | 29.701110 | 20.4100 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 29.70111,105.705 | . 219 Lushan National Park | Parc national de Lushan | Mount Lushan, in Jiangxi, is one of the spirit... | Le site du mont Lushan, dans le Jiangxi, const... | The Committee decided to inscribe this propert... | Le Comité a décidé d&#39;inscrire ce bien sur la b... | 1996-01-01 | NaN | 115.866667 | 29.433333 | 0.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 29.43333333,115.8666667 | . 220 Imperial Tombs of the Ming and Qing Dynasties | Tombes impériales des dynasties Ming et Qing | It represents the addition of three Imperial T... | L’extension ajoute trois tombes impériales de ... | Criterion (i): The harmonious integration of r... | Critère (i) : l&#39;intégration harmonieuse d&#39;ense... | 2000-01-01 | NaN | 124.793889 | 41.707222 | 3434.9399 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 41.70722222,124.7938889 | . 449 Imperial Palaces of the Ming and Qing Dynastie... | Palais impériaux des dynasties Ming et Qing à ... | Seat of supreme power for over five centuries ... | Siège du pouvoir suprême pendant plus de cinq ... | Criterion (i): The Imperial Palaces represent ... | Critère (i) : Les Palais impériaux représenten... | 1987-01-01 | NaN | 123.446944 | 41.794167 | 12.9600 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 41.79416667,123.4469444 | . 457 Mountain Resort and its Outlying Temples, Chengde | Résidence de montagne et temples avoisinants à... | The Mountain Resort (the Qing dynasty&#39;s summer... | La résidence de montagne, palais d&#39;été de la d... | NaN | NaN | 1994-01-01 | NaN | 117.938330 | 40.986940 | 0.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 40.98694,117.93833 | . 459 West Lake Cultural Landscape of Hangzhou | Paysage culturel du lac de l’Ouest de Hangzhou | The West Lake Cultural Landscape of Hangzhou, ... | Le paysage inscrit a inspiré des poètes, artis... | NaN | NaN | 2011-01-01 | NaN | 120.140833 | 30.237500 | 3322.8800 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 30.2375,120.140833333 | . 545 Cultural Landscape of Honghe Hani Rice Terraces | Paysage culturel des rizières en terrasse des ... | The Cultural Landscape of Honghe Hani Rice Ter... | Ce site de 16 603 hectares est situé dans le s... | NaN | NaN | 2013-01-01 | NaN | 102.779981 | 23.093278 | 16603.2200 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 23.0932777778,102.779980556 | . 590 Ancient Building Complex in the Wudang Mountains | Ensemble de bâtiments anciens des montagnes de... | The palaces and temples which form the nucleus... | Les palais et temples qui constituent le noyau... | NaN | NaN | 1994-01-01 | NaN | 111.000000 | 32.466670 | 0.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 32.46667,111.0 | . 601 Historic Centre of Macao | Centre historique de Macao | Macao, a lucrative port of strategic importanc... | Macao, riche port marchand d’une grande import... | Criterion (ii): The strategic location of Maca... | Critère (ii) : L’emplacement stratégique de Ma... | 2005-01-01 | NaN | 113.536461 | 22.191292 | 16.1678 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 22.1912919444,113.536461111 | . 605 Yin Xu | Yin Xu | The archaeological site of Yin Xu, close to An... | Le site archéologique de Yin Xu, proche de la ... | NaN | NaN | 2006-01-01 | NaN | 114.313889 | 36.126667 | 414.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 36.1266666666,114.313888889 | . 628 Yungang Grottoes | Grottes de Yungang | The Yungang Grottoes, in Datong city, Shanxi P... | Les grottes de Yungang, à Datong, province du ... | Criterion (i): The assemblage of statuary of t... | Critère (i) : L’ensemble de la statuaire des g... | 2001-01-01 | NaN | 113.122220 | 40.109720 | 348.7500 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 40.10972,113.12222 | . 653 Peking Man Site at Zhoukoudian | Site de l&#39;homme de Pékin à Zhoukoudian | Scientific work at the site, which lies 42 km ... | À 42 km au sud-ouest de Pékin, le site, dont l... | NaN | NaN | 1987-01-01 | NaN | 115.916667 | 39.733333 | 480.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 39.73333333,115.9166667 | . 671 Historic Ensemble of the Potala Palace, Lhasa | Ensemble historique du Palais du Potala, Lhasa | The Potala Palace, winter palace of the Dalai ... | Le palais du Potala, palais d&#39;hiver du dalaï-l... | NaN | NaN | 1994-01-01 | NaN | 91.117170 | 29.657920 | 60.5000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 29.65792,91.11717 | . 739 Summer Palace, an Imperial Garden in Beijing | Palais d&#39;Été, Jardin impérial de Beijing | The Summer Palace in Beijing – first built in ... | Le palais d&#39;Été de Beijing, créé en 1750, détr... | Criterion i: The Summer Palace in Beijing is a... | Critère i : le Palais d&#39;Eté de Beijing est une... | 1998-01-01 | NaN | 116.141111 | 39.910556 | 297.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 39.91055556,116.1411111 | . 743 Mount Qingcheng and the Dujiangyan Irrigation ... | Mont Qingcheng et système d’irrigation de Duji... | Construction of the Dujiangyan irrigation syst... | La construction du système d&#39;irrigation de Duj... | Criterion (ii): The Dujiangyan Irrigation Syst... | Critère (ii) : Le système d’irrigation de Duji... | 2000-01-01 | NaN | 103.605280 | 31.001670 | 0.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 31.00167,103.60528 | . 746 Historic Monuments of Dengfeng in “The Centre ... | Monuments historiques de Dengfeng au « centre ... | Mount Songshang is considered to be the centra... | Songshang est considéré comme le mont sacré ce... | NaN | NaN | 2010-01-01 | NaN | 113.067719 | 34.458747 | 825.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 34.4587472222,113.067719444 | . 769 The Grand Canal | Le Grand Canal | The Grand Canal is a vast waterway system in t... | Ce vaste système de navigation intérieure au s... | NaN | NaN | 2014-01-01 | NaN | 112.468333 | 34.693889 | 20819.1100 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 34.6938888889,112.468333333 | . 772 Old Town of Lijiang | Vieille ville de Lijiang | The Old Town of Lijiang, which is perfectly ad... | La vieille ville de Lijiang, harmonieusement a... | The Committee decided to inscribe this site on... | Le Comité a décidé d’inscrire ce site sur la b... | 1997-01-01 | NaN | 100.233330 | 26.866670 | 145.6000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 26.86667,100.23333 | . 808 Kaiping Diaolou and Villages | Diaolou et villages de Kaiping | Kaiping Diaolou and Villages feature the Diaol... | Les diaolou, maisons fortifiées de village de ... | NaN | NaN | 2007-01-01 | NaN | 112.565861 | 22.285519 | 371.9480 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 22.2855194444,112.565861111 | . 839 Ancient Villages in Southern Anhui – Xidi and ... | Anciens villages du sud du Anhui – Xidi et Hon... | The two traditional villages of Xidi and Hongc... | Les deux villages traditionnels de Xidi et de ... | Criterion (iii): The villages of Xidi and Hong... | Critère (iii) : Les villages de Xidi et de Hon... | 2000-01-01 | NaN | 117.987500 | 29.904444 | 52.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 29.90444444,117.9875 | . 851 Zuojiang Huashan Rock Art Cultural Landscape | Paysage culturel de l’art rupestre de Zuojiang... | Located on the steep cliffs in the border regi... | Situés sur des falaises abruptes dans les régi... | NaN | NaN | 2016-01-01 | NaN | 107.023056 | 22.255556 | 6621.6000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 22.2555555556,107.023055556 | . 883 Classical Gardens of Suzhou | Jardins classiques de Suzhou | Classical Chinese garden design, which seeks t... | Le paysagisme classique chinois, qui cherche à... | The Committee decided to inscribe this propert... | Le Comité a décidé d&#39;inscrire ce bien sur la b... | 1997-01-01 | NaN | 120.450000 | 31.316667 | 11.9220 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 31.31666667,120.45 | . 903 Ancient City of Ping Yao | Vieille ville de Ping Yao | Ping Yao is an exceptionally well-preserved ex... | Ping Yao est un exemple exceptionnellement bie... | The Committee decided to inscribe this propert... | Le Comité a décidé d&#39;inscrire ce bien sur la b... | 1997-01-01 | NaN | 112.154440 | 37.201390 | 245.6200 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 37.20139,112.15444 | . 921 Longmen Grottoes | Grottes de Longmen | The grottoes and niches of Longmen contain the... | Les grottes et niches de Longmen abritent le p... | Criterion (i): The sculptures of the Longmen G... | Critère (i) : Les sculptures des grottes de Lo... | 2000-01-01 | NaN | 112.466667 | 34.466667 | 331.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 34.46666667,112.4666667 | . 930 Temple of Heaven: an Imperial Sacrificial Alta... | Temple du Ciel, autel sacrificiel impérial à B... | The Temple of Heaven, founded in the first hal... | Fondé dans la première moitié du XVe siècle, l... | Criterion i: The Temple of Heaven is a masterp... | Critère i : Le Temple du Ciel est un chef-d&#39;œu... | 1998-01-01 | NaN | 116.444722 | 39.845556 | 215.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 39.84555556,116.4447222 | . 971 Mount Wutai | Mont Wutai | With its five flat peaks, Mount Wutai is a sac... | Avec ses cinq plateaux, le Mont Wutai est une ... | NaN | NaN | 2009-01-01 | NaN | 113.563333 | 39.030556 | 18415.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 39.0305555556,113.563333333 | . 1008 Mogao Caves | Grottes de Mogao | Situated at a strategic point along the Silk R... | Situées en un point stratégique de la Route de... | NaN | NaN | 1987-01-01 | NaN | 94.816670 | 40.133330 | 0.0000 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 40.13333,94.81667 | . 1010 Capital Cities and Tombs of the Ancient Kogury... | Capitales et tombes de l’ancien royaume de Kog... | The site includes archaeological remains of th... | Ce site comprend les vestiges archéologiques d... | Criterion (i): The tombs represent a masterpie... | Critère (i) : Les tombes représentent un chef ... | 2004-01-01 | NaN | 126.187222 | 41.156944 | 4164.8599 | Cultural | China | Chine | Asia and the Pacific | Asie et pacifique | 41.15694444,126.1872222 | . So now, let&#39;s filter all Chinese sites regardless of heritage types. . china_site = df[df[&quot;Country (EN)&quot;] == &quot;China&quot;] china_site.head(1) . Name (EN) Name (FR) Short description (EN) Short Description (FR) Justification (EN) Justification (FR) Date inscribed Danger list Longitude Latitude Area hectares Category Country (EN) Country (FR) Continent (EN) Continent (FR) Geographical coordinates . 5 Sichuan Giant Panda Sanctuaries - Wolong, Mt S... | Sanctuaires du grand panda du Sichuan - Wolong... | Sichuan Giant Panda Sanctuaries, home to more ... | Les Sanctuaires du grand panda du Sichuan abri... | NaN | NaN | 2006-01-01 | NaN | 103.0 | 30.833333 | 924500.0 | Natural | China | Chine | Asia and the Pacific | Asie et pacifique | 30.8333333333,103.0 | . Check the number of sites we have in the data frame: . china_site[&#39;Name (EN)&#39;].count() . 49 . As the column namings are a bit confusion with the spacings and capital letters, we will rename the columns: . china_site = china_site[[&quot;Name (EN)&quot;,&quot;Date inscribed&quot;,&quot;Category&quot;]] # select multiple columns in a list [] china_site = china_site.rename(columns={&quot;Name (EN)&quot;: &quot;name&quot;, &quot;Date inscribed&quot;: &quot;date&quot;, &quot;Category&quot;: &quot;type&quot;}) # rename the columns for easy reading china_site.head(1) # check the updates . name date type . 5 Sichuan Giant Panda Sanctuaries - Wolong, Mt S... | 2006-01-01 | Natural | . Date Time . Pandas dataframe also support datetime for time series analysis. But first, we need to read the column as date time using to_datetime(). It is as if we are telling Pandas the date column is not just a string, but datetime objects. . china_site[&#39;date&#39;] = pd.to_datetime(china_site[&quot;date&quot;]) . By converting the column to datetime objects, we can do multiple operations inside the data fame, just as extracting only the year information. It can be done by .year. As the year information for us is more relevant than the month and day, we will remove the original column and add a year column. . china_site[&#39;year&#39;] = pd.DatetimeIndex(china_site[&#39;date&#39;]).year # set up a new year column china_site = china_site.drop(columns=[&#39;date&#39;]) # remove the original date column china_site.head(1) # check the first row . name type year . 5 Sichuan Giant Panda Sanctuaries - Wolong, Mt S... | Natural | 2006 | . UNESCO Sites . Using the china_site variable, we can check on the number of sites for each year using groupby(). After groupby(), we keep only the name column and count the number of rows using count(). Yet, we will get a Pandas series (pandas.core.series.Series) as return, not a data frame. We need to convert it back to data frame using reset_index() and add name=&quot;count&quot; to tell Pandas the new column will be called &quot;count&quot;. . count = china_site.groupby(&quot;year&quot;)[&quot;name&quot;].count() count . year 1987 6 1990 1 1992 3 1994 4 1996 2 1997 3 1998 2 1999 2 2000 4 2001 1 2003 1 2004 1 2005 1 2006 2 2007 2 2008 2 2009 1 2010 2 2011 1 2012 2 2013 2 2014 1 2015 1 2016 2 Name: name, dtype: int64 . count_df = count.reset_index(name=&quot;count&quot;) count_df . year count . 0 1987 | 6 | . 1 1990 | 1 | . 2 1992 | 3 | . 3 1994 | 4 | . 4 1996 | 2 | . 5 1997 | 3 | . 6 1998 | 2 | . 7 1999 | 2 | . 8 2000 | 4 | . 9 2001 | 1 | . 10 2003 | 1 | . 11 2004 | 1 | . 12 2005 | 1 | . 13 2006 | 2 | . 14 2007 | 2 | . 15 2008 | 2 | . 16 2009 | 1 | . 17 2010 | 2 | . 18 2011 | 1 | . 19 2012 | 2 | . 20 2013 | 2 | . 21 2014 | 1 | . 22 2015 | 1 | . 23 2016 | 2 | . ### Cumulative totals of the heritage sites | . The above table displays the number of sites inscribed in China every year, however, what if we want to know the total number of heritage sites in China for every year? We can use cumsum(), standing for cumulative summation. Let&#39;s put the total number of sites into a new column called &quot;total&quot;. . count_df[&quot;total&quot;] = count_df[&quot;count&quot;].cumsum() . ### Set Index | . Let&#39;s reset the index using year. . count_df = count_df.set_index(&quot;year&quot;) count_df.head() . count total . year . 1987 6 | 6 | . 1990 1 | 7 | . 1992 3 | 10 | . 1994 4 | 14 | . 1996 2 | 16 | . Visualization . Plotting using Pandas data frame is fairly easy. We only need to add .plot() after selecting the column(s) we need (multiple column names need to be put in a list using []). To customize the layout, we need to import matplotlib library too. . import matplotlib.pyplot as plt # import library plt.figure(figsize=(15,5)) # optional, define figure size count_df.total.plot(color=&quot;red&quot;) # plot, add color argument plt.xlabel(&quot;Year&quot;) # x label plt.ylabel(&quot;Number of UNESCO sites&quot;) # y label plt.title(&quot;Increasing number of UNESCO sites in China&quot;) # title . Text(0.5, 1.0, &#39;Increasing number of UNESCO sites in China&#39;) . We can also plot a table instead. . data = {&quot;Year&quot;: count_df.index.values, &quot;Total Sites&quot;: count_df.total.values} df = pd.DataFrame(data) fig, ax = plt.subplots(1, 1) # Hide axes ax.xaxis.set_visible(False) ax.yaxis.set_visible(False) ax.axis(&#39;tight&#39;) ax.axis(&#39;off&#39;) ax.table(cellText=df.values, colLabels=df.keys(), loc=&#39;center&#39;) plt.show() . To export the data for further use, we can export them as csv file. . from google.colab import files df.to_csv(&#39;UNESCO.csv&#39;, encoding=&#39;utf_8_sig&#39;, index=False) files.download(&#39;UNESCO.csv&#39;) . Or print it as LaTeX. . print(df.to_latex(index=False)) . begin{tabular}{rr} toprule Year &amp; Total Sites midrule 1987 &amp; 6 1990 &amp; 7 1992 &amp; 10 1994 &amp; 14 1996 &amp; 16 1997 &amp; 19 1998 &amp; 21 1999 &amp; 23 2000 &amp; 27 2001 &amp; 28 2003 &amp; 29 2004 &amp; 30 2005 &amp; 31 2006 &amp; 33 2007 &amp; 35 2008 &amp; 37 2009 &amp; 38 2010 &amp; 40 2011 &amp; 41 2012 &amp; 43 2013 &amp; 45 2014 &amp; 46 2015 &amp; 47 2016 &amp; 49 bottomrule end{tabular} . Plotting . Do some plotting using our data. . Let&#39;s say we are interested in the progress of UNESCO sites application from different countries. We want to do a plot to see which countries are having the largest share of sites and how the trend develops over time. Creating the plot is typically the final step for data visualization. Before that, there are some steps need to be done. . . Typical Workflow for Visualization: . 1) Get data: grab them online or offline . 2) Clean data: get rid of missing data, clean the irrelevant information, groupping parameters, etc. . 3) Design on the type of visualization: what type of chart (depends on your message &amp; purpose &amp; nature of data)? by what parameters (eg. by year or by country or focus on one country only)? . 4) Prepare the data in the format fitting your visualization type (wide or long format?) . . Data Preparation . the first thing we need to do is to collect the top 10 countries having the most UNESCO sites. . df = df[[&#39;Country (EN)&#39;,&quot;Name (EN)&quot;,&quot;Date inscribed&quot;,&quot;Category&quot;]] # select multiple columns in a list [] df = df.rename(columns={&quot;Country (EN)&quot;: &quot;country&quot;,&quot;Name (EN)&quot;: &quot;name&quot;, &quot;Date inscribed&quot;: &quot;date&quot;, &quot;Category&quot;: &quot;type&quot;}) # rename the columns for easy reading . top_10 = df.groupby(df[&quot;country&quot;]).count().sort_values(by=[&#39;name&#39;], ascending=False).head(10) top_10 . name date type . country . China 49 | 49 | 49 | . Italy 47 | 47 | 47 | . Spain 41 | 41 | 41 | . France 38 | 38 | 38 | . Germany 35 | 35 | 35 | . Mexico 34 | 34 | 34 | . India 33 | 33 | 33 | . United Kingdom of Great Britain and Northern Ireland 27 | 27 | 27 | . Russian Federation 21 | 21 | 21 | . Iran (Islamic Republic of) 21 | 21 | 21 | . Then we convert the countries to Numpy array and save it to a variable sub_cnty. . sub_cnty = top_10.index.values sub_cnty . array([&#39;China&#39;, &#39;Italy&#39;, &#39;Spain&#39;, &#39;France&#39;, &#39;Germany&#39;, &#39;Mexico&#39;, &#39;India&#39;, &#39;United Kingdom of Great Britain and Northern Ireland&#39;, &#39;Russian Federation&#39;, &#39;Iran (Islamic Republic of)&#39;], dtype=object) . top_df is the data frame including the top 10 countries only. As we aim to plot number of heritage sites every years for each country, we need to use groupby() grouping both country and date after filtering the rows to the top 10 countries using df[&#39;country&#39;].isin(sub_cnty). . After groupby() we need to indicate the method count(). We will only select the name column only (country and date will also be included as they are the objects used to &quot;groupby&quot;). . In order to get a data frame as output, we need to use reset_index(). . top_df = df[df[&#39;country&#39;].isin(sub_cnty)].groupby([&#39;country&#39;,&#39;date&#39;]).count()[&#39;name&#39;].reset_index() top_df.head(5) . country date name . 0 China | 1987-01-01 | 6 | . 1 China | 1990-01-01 | 1 | . 2 China | 1992-01-01 | 3 | . 3 China | 1994-01-01 | 4 | . 4 China | 1996-01-01 | 2 | . pivot() from Pandas is a function to convert a data frame from long to wide. In this case, it basically display every unique item in the country column into a separate column. . pivot = top_df.pivot(index=&#39;date&#39;, columns=&#39;country&#39;, values=&#39;name&#39;) pivot = pivot.fillna(0) pivot.head(10) . country China France Germany India Iran (Islamic Republic of) Italy Mexico Russian Federation Spain United Kingdom of Great Britain and Northern Ireland . date . 1978-01-01 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1979-01-01 0.0 | 5.0 | 0.0 | 0.0 | 3.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1980-01-01 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1981-01-01 0.0 | 5.0 | 2.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1982-01-01 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1983-01-01 0.0 | 3.0 | 1.0 | 4.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1984-01-01 0.0 | 0.0 | 1.0 | 2.0 | 0.0 | 0.0 | 0.0 | 0.0 | 5.0 | 0.0 | . 1985-01-01 0.0 | 1.0 | 1.0 | 3.0 | 0.0 | 0.0 | 0.0 | 0.0 | 5.0 | 0.0 | . 1986-01-01 0.0 | 0.0 | 1.0 | 4.0 | 0.0 | 0.0 | 0.0 | 0.0 | 4.0 | 7.0 | . 1987-01-01 6.0 | 0.0 | 1.0 | 3.0 | 0.0 | 2.0 | 6.0 | 0.0 | 1.0 | 2.0 | . pivot = pivot.cumsum() pivot.head(10) . country China France Germany India Iran (Islamic Republic of) Italy Mexico Russian Federation Spain United Kingdom of Great Britain and Northern Ireland . date . 1978-01-01 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1979-01-01 0.0 | 5.0 | 1.0 | 0.0 | 3.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1980-01-01 0.0 | 5.0 | 1.0 | 0.0 | 3.0 | 2.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1981-01-01 0.0 | 10.0 | 3.0 | 0.0 | 3.0 | 2.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1982-01-01 0.0 | 11.0 | 3.0 | 0.0 | 3.0 | 3.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1983-01-01 0.0 | 14.0 | 4.0 | 4.0 | 3.0 | 3.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1984-01-01 0.0 | 14.0 | 5.0 | 6.0 | 3.0 | 3.0 | 0.0 | 0.0 | 5.0 | 0.0 | . 1985-01-01 0.0 | 15.0 | 6.0 | 9.0 | 3.0 | 3.0 | 0.0 | 0.0 | 10.0 | 0.0 | . 1986-01-01 0.0 | 15.0 | 7.0 | 13.0 | 3.0 | 3.0 | 0.0 | 0.0 | 14.0 | 7.0 | . 1987-01-01 6.0 | 15.0 | 8.0 | 16.0 | 3.0 | 5.0 | 6.0 | 0.0 | 15.0 | 9.0 | . Visualization . Now we can start plotting. We first plot a chart showing the temporal development of heritage inscriptions for the 10 countries. . import matplotlib.pyplot as plt # import library pivot.plot(figsize=(20,6)) # define plot size plt.xlabel(&quot;Year&quot;, fontsize=14) # x label plt.ylabel(&quot;Count&quot;, fontsize=14) # y label plt.title(&quot;UNESCO Sites&quot;, fontsize=20) # title . Text(0.5, 1.0, &#39;UNESCO Sites&#39;) . Style Use . We can also choose to change style of our plot using seaborn library. What we need to do is to import the library and set the parameters before we call the functions with our Pandas data frame. . . import seaborn as sns # import library custom_params = {&quot;axes.spines.right&quot;: False, &quot;axes.spines.top&quot;: False} # define axes parameters sns.set_theme(style=&quot;ticks&quot;, rc=custom_params, context=&quot;talk&quot;) # define theme plt.style.use(&quot;dark_background&quot;) # define background color (here we try with a dark theme) . Linechart . import matplotlib.dates as mdates # import mdates to plot datae time data plt.figure(figsize=(20, 6)) sns.lineplot(data=pivot) # call lineplot using seaborn library plt.title(&quot;UNESCO Sites&quot;, fontsize=28) plt.xlabel(&quot;Year&quot;) plt.ylabel(&quot;Count&quot;) plt.legend(bbox_to_anchor=(1.02, 0.9), loc=2, borderaxespad=0.) # display a legend at the position out of our plot plt.tight_layout() # adjust spacings of elements . Stacked Area Chart . Apart from line chart, we can also do a stacked area plot to create more visuals. The principle is similar, but this time we will use stackplot together with &quot;sym&quot; baseline (Symmetric around zero and is sometimes called &#39;ThemeRiver&#39;). If you are particularly interested in different plotting types, stick with the tutorials as we will discuss more in the next chapters. . Also, feel free to check out this for a cataloge of data visualization using Python. . fig, ax = plt.subplots(figsize=(15, 6)) # figure size ax.stackplot(pivot.index.values, [pivot[name].values for name in pivot], baseline=&quot;sym&quot;, colors=palette, labels=sub_cnty) # stacked area ax.axhline(0, color=&quot;red&quot;, ls=&quot;--&quot;, linewidth=.8) # red line in the middle plt.title(&quot;UNESCO Sites&quot;, fontsize=25) # title plt.xlabel(&quot;Year&quot;) # labels plt.ylabel(&quot;Count&quot;) plt.legend(bbox_to_anchor=(1.02, 0.9), loc=2, borderaxespad=0.) # legend plt.tight_layout() # adjust spacings . Lollipop Chart . Just another example that we can also do a lollipop chart instead. Here then we will only focus on temporal development of sites in China. . plt.figure(figsize=(24,6)) plt.hlines(y=pivot.index, xmin=0, xmax=pivot[&#39;China&#39;], color=&quot;#FCC700&quot;) plt.plot(pivot[&#39;China&#39;], pivot.index, &quot;o&quot;, markersize=8, color=&quot;#FC4900&quot;) plt.title(&quot;UNESCO Sites in China&quot;, fontsize=26) plt.xlabel(&quot;Count&quot;) plt.ylabel(&quot;Year&quot;) . Text(0, 0.5, &#39;Year&#39;) . . Previous Lesson: Pandas Text Analysis . Next Lesson: Coming soon... . Additional information . This notebook is provided for educational purpose and feel free to report any issue on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: December 2021 . . . . References: . https://examples.opendatasoft.com/explore/dataset/world-heritage-unesco-list/table/ .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/data-organization/level-2/chapter-2/pandas/matplotlib/seaborn/data-visualization/2020/01/24/Pandas_NumericalOperation_QuantitativeDataOrganization.html",
            "relUrl": "/data-organization/level-2/chapter-2/pandas/matplotlib/seaborn/data-visualization/2020/01/24/Pandas_NumericalOperation_QuantitativeDataOrganization.html",
            "date": " • Jan 24, 2020"
        }
        
    
  
    
        ,"post18": {
            "title": "Python Pandas Library",
            "content": ". As mentioned in the instructions, all materials can be open in Colab as Jupyter notebooks. In this way users can run the code in the cloud. It is highly recommanded to follow the tutorials in the right order. . This notebook aims to intrduce users to the Pandas library, a useful tool for tabular data manipulation. Its capabilities are similar to Excel but it is much more flexible and can manage huge datasets in an efficient manner. . . Presumptions: . Dictionary . . . Pandas Series . We have learnt about lists, which are a simple way to handle information. Pandas however includes many additional features to handle data, such as handling missing data and indexing objects with text. The corresponding form of a list in Pandas is a Pandas series, which can also be understood as a column of the Pandas dataframe. A Pandas Series can be created using pd.Series(). . import pandas as pd names = pd.Series([&#39;登江中孤屿，赠白云先生王迥&#39;, &#39;秋登兰山寄张五&#39;,&#39; &#39;,&#39;入峡寄弟&#39;]) names . 0 登江中孤屿，赠白云先生王迥 1 秋登兰山寄张五 2 3 入峡寄弟 dtype: object . Nearly all of Python&#39;s built-in string methods are mirrored by a Pandas vectorized string method. Here is a list of Pandas str methods: . . len() | lower() | translate() | islower() | . ljust() | upper() | startswith() | isupper() | . rjust() | find() | endswith() | isnumeric() | . center() | rfind() | isalnum() | isdecimal() | . zfill() | index() | isalpha() | split() | . strip() | rindex() | isdigit() | rsplit() | . rstrip() | capitalize() | isspace() | partition() | . lstrip() | swapcase() | istitle() | rpartition() | . Although many of the strings methods are not applicable to Chinese languages, some functions can still be really helpful. . For example, . names.str.startswith(&#39;秋&#39;) # looking for an item that starts with a character . 0 False 1 True 2 False 3 False dtype: bool . names.str.isspace() # looking for whitespace . 0 False 1 False 2 True 3 False dtype: bool . names.str.find(&#39;秋&#39;) # look for where (index) is a character . 0 -1 1 0 2 -1 3 -1 dtype: int64 . names.str.split(pat=&quot;&quot;) # split characters . 0 [, 登, 江, 中, 孤, 屿, ，, 赠, 白, 云, 先, 生, 王, 迥, ] 1 [, 秋, 登, 兰, 山, 寄, 张, 五, ] 2 [, , ] 3 [, 入, 峡, 寄, 弟, ] dtype: object . names.str.extract(&#39;([A-Za-z]+)&#39;, expand=False) # look for letters (this is called regular expression, you will learn about it later) . 0 NaN 1 NaN 2 NaN 3 NaN dtype: object . names.str.findall(r&#39;^[秋].*$&#39;) # find item with characters . 0 [] 1 [秋登兰山寄张五] 2 [] 3 [] dtype: object . There are also some methods that allow convenient operations: . Method Description . get() | Index each element | . slice() | Slice each element | . slice_replace() | Replace slice in each element with passed value | . cat() | Concatenate strings | . repeat() | Repeat values | . normalize() | Return Unicode form of string | . pad() | Add whitespace to left, right, or both sides of strings | . wrap() | Split long strings into lines with length less than a given width | . join() | Join strings in each element of the Series with passed separator | . get_dummies() | extract dummy variables as a dataframe | . names.str[0:1] # get the first character only . 0 登 1 秋 2 3 入 dtype: object . names.str.split(pat=&#39;，&#39;).str.get(0) # get first clause . 0 登江中孤屿 1 秋登兰山寄张五 2 3 入峡寄弟 dtype: object . We can even get some statistics about the length of our text using describe(): . names.str.len().describe() . count 4.000000 mean 6.250000 std 5.123475 min 1.000000 25% 3.250000 50% 5.500000 75% 8.500000 max 13.000000 dtype: float64 . We can also create a Pandas DataFrame from a dictionary: while the keys will be used as the name of the column in the Pandas DataFrame, the values will be used as the data (rows). . Let&#39;s build a data frame using capital names for Qin and Han dynasties as an example. . dictionary = { &#39;Time&#39;: [&#39;&#39;,&#39;– 677 BC&#39;,&#39;677 BC –&#39;,&#39;– 383 BC&#39;,&#39;383 BC – 250 BC&#39;,&#39;350 BC – 207 BC&#39;,&#39;202 BC&#39;,&#39;202 BC – 200 BC&#39;,&#39;200 BC – 8 BC&#39;], &#39;Dynasty&#39;: [&#39;Qin&#39;,&#39;Qin&#39;,&#39;Qin&#39;,&#39;Qin&#39;,&#39;Qin&#39;,&#39;Qin&#39;,&#39;Han&#39;,&#39;Han&#39;,&#39;Han&#39;], &#39;Capital&#39;: [&#39;Xiquanqiu&#39;,&#39;Pingyang&#39;,&#39;Yong&#39;,&#39;Jingyang&#39;,&#39;Yueyang&#39;,&#39;Xianyang&#39;,&#39;Luoyang&#39;,&#39;Yueyang&#39;,&#39;Changan&#39;] } # remember all column in the data frame have to have the same length df = pd.DataFrame(data=dictionary) # use pd.DataFrame() and put the dict as an argument df . Time Dynasty Capital . 0 | Qin | Xiquanqiu | . 1 – 677 BC | Qin | Pingyang | . 2 677 BC – | Qin | Yong | . 3 – 383 BC | Qin | Jingyang | . 4 383 BC – 250 BC | Qin | Yueyang | . 5 350 BC – 207 BC | Qin | Xianyang | . 6 202 BC | Han | Luoyang | . 7 202 BC – 200 BC | Han | Yueyang | . 8 200 BC – 8 BC | Han | Changan | . df = df.set_index(&#39;Time&#39;) # we can also set text as index df . Dynasty Capital . Time . Qin | Xiquanqiu | . – 677 BC Qin | Pingyang | . 677 BC – Qin | Yong | . – 383 BC Qin | Jingyang | . 383 BC – 250 BC Qin | Yueyang | . 350 BC – 207 BC Qin | Xianyang | . 202 BC Han | Luoyang | . 202 BC – 200 BC Han | Yueyang | . 200 BC – 8 BC Han | Changan | . To view only the first row: . df.head(1) . Dynasty Capital . Time . Qin | Xiquanqiu | . To view only the last row: . df.tail(1) . Dynasty Capital . Time . 200 BC – 8 BC Han | Changan | . In order to get a better understanding of the group characteristics, we can also use the groupby function. It is used with a groupby() followed by a method(). . For example, we can use groupby(&quot;Dynasty&quot;).count() to count number of rows (number of capital) in each dynasty. . . Remarks: Index cannot be used as the groupby object. . df.groupby(&quot;Dynasty&quot;).count() . Capital . Dynasty . Han 3 | . Qin 6 | . . . Data Manipulation . After understanding what is a Pandas Series and what is a Pandas DataFrame, we can start with some basic manipulation using a data frame. Let us start with an example to build a Pandas dataframe from a text file. . First, we upload a text and select the titles.txt file (it can be found in the data folder). . from google.colab import files uploaded = files.upload() for f in uploaded.keys(): file = open(f, &#39;r&#39;) titles = file.read() . Upload widget is only available when the cell has been executed in the current browser session. Please rerun this cell to enable. Saving titles.txt to titles (1).txt . Then, we can split the text into paragraphs (separated by two new lines) and sentences (separated by one new line). . titles = titles.split(&quot; n n&quot;) # two new lines titles = [lines.split(&#39; n&#39;) for lines in titles] # one new line, done in a list comprehension . titles[0:2] # check the first two items we have: 卷159_1 and 卷159_2 . [[&#39;卷159_1 「从张丞相游南纪城猎，戏赠裴迪张参军」孟浩然&#39;, &#39; u3000 u3000从禽非吾乐，不好云梦田。岁暮登城望，偏令乡思悬。&#39;, &#39; u3000 u3000公卿有几几，车骑何翩翩。世禄金张贵，官曹幕府贤。&#39;, &#39; u3000 u3000顺时行杀气，飞刃争割鲜。十里届宾馆，征声匝妓筵。&#39;, &#39; u3000 u3000高标回落日，平楚散芳烟。何意狂歌客，从公亦在旃。&#39;], [&#39;卷159_2 「登江中孤屿，赠白云先生王迥」孟浩然&#39;, &#39; u3000 u3000悠悠清江水，水落沙屿出。回潭石下深，绿筱岸傍密。&#39;, &#39; u3000 u3000鲛人潜不见，渔父歌自逸。忆与君别时，泛舟如昨日。&#39;, &#39; u3000 u3000夕阳开返照，中坐兴非一。南望鹿门山，归来恨如失。&#39;]] . We can also check how many titles (卷) are there: . len(titles) . 269 . Then we construct our dataframe: . import pandas as pd # In case library is not imported df = pd.DataFrame({&quot;content&quot;: titles}) # construct a data frame using a dictionary df.head() . content . 0 [卷159_1 「从张丞相游南纪城猎，戏赠裴迪张参军」孟浩然, 　　从禽非吾乐，不好云梦田。... | . 1 [卷159_2 「登江中孤屿，赠白云先生王迥」孟浩然, 　　悠悠清江水，水落沙屿出。回潭石下... | . 2 [卷159_3 「晚春卧病寄张八」孟浩然, 　　南陌春将晚，北窗犹卧病。林园久不游，草木一何... | . 3 [卷159_4 「秋登兰山寄张五」孟浩然, 　　北山白云里，隐者自怡悦。相望试登高，心飞逐鸟... | . 4 [卷159_5 「入峡寄弟」孟浩然, 　　吾昔与尔辈，读书常闭门。未尝冒湍险，岂顾垂堂言。,... | . We realize that the content column is quite messy as it contains different information such as title, author name and the content itself. So we want to set up different new columns: . . 1) title: The title . 2) content: The text . 3) index: Use the text ID (e.g. 159_1) as index . We can set up new columns by simply writing . df[&quot;name of the new column&quot;] = [what we plan to put in] . What we plan to put in can be for example, a NumPy array with the same length, or just a number (in this case all rows will have the same value). For example, . import numpy as np df[&quot;test&quot;] = 1 df.head() . content test . 0 [卷159_1 「从张丞相游南纪城猎，戏赠裴迪张参军」孟浩然, 　　从禽非吾乐，不好云梦田。... | 1 | . 1 [卷159_2 「登江中孤屿，赠白云先生王迥」孟浩然, 　　悠悠清江水，水落沙屿出。回潭石下... | 1 | . 2 [卷159_3 「晚春卧病寄张八」孟浩然, 　　南陌春将晚，北窗犹卧病。林园久不游，草木一何... | 1 | . 3 [卷159_4 「秋登兰山寄张五」孟浩然, 　　北山白云里，隐者自怡悦。相望试登高，心飞逐鸟... | 1 | . 4 [卷159_5 「入峡寄弟」孟浩然, 　　吾昔与尔辈，读书常闭门。未尝冒湍险，岂顾垂堂言。,... | 1 | . Or this: . df[&quot;test&quot;] = np.arange(0,269) df.head() . content test . 0 [卷159_1 「从张丞相游南纪城猎，戏赠裴迪张参军」孟浩然, 　　从禽非吾乐，不好云梦田。... | 0 | . 1 [卷159_2 「登江中孤屿，赠白云先生王迥」孟浩然, 　　悠悠清江水，水落沙屿出。回潭石下... | 1 | . 2 [卷159_3 「晚春卧病寄张八」孟浩然, 　　南陌春将晚，北窗犹卧病。林园久不游，草木一何... | 2 | . 3 [卷159_4 「秋登兰山寄张五」孟浩然, 　　北山白云里，隐者自怡悦。相望试登高，心飞逐鸟... | 3 | . 4 [卷159_5 「入峡寄弟」孟浩然, 　　吾昔与尔辈，读书常闭门。未尝冒湍险，岂顾垂堂言。,... | 4 | . We can also add a new row: . df.append({&#39;content&#39;: np.nan, &#39;test&#39;: np.nan}, ignore_index=True) # This is temporary only and will not change the data frame itself # np.nan means missing values . content test . 0 [卷159_1 「从张丞相游南纪城猎，戏赠裴迪张参军」孟浩然, 　　从禽非吾乐，不好云梦田。... | 0.0 | . 1 [卷159_2 「登江中孤屿，赠白云先生王迥」孟浩然, 　　悠悠清江水，水落沙屿出。回潭石下... | 1.0 | . 2 [卷159_3 「晚春卧病寄张八」孟浩然, 　　南陌春将晚，北窗犹卧病。林园久不游，草木一何... | 2.0 | . 3 [卷159_4 「秋登兰山寄张五」孟浩然, 　　北山白云里，隐者自怡悦。相望试登高，心飞逐鸟... | 3.0 | . 4 [卷159_5 「入峡寄弟」孟浩然, 　　吾昔与尔辈，读书常闭门。未尝冒湍险，岂顾垂堂言。,... | 4.0 | . ... ... | ... | . 265 [卷160_181 「渡浙江问舟中人（一题作济江问同舟人。一作崔国辅诗）」孟浩然, 　　潮落... | 265.0 | . 266 [卷160_182 「初秋」孟浩然, 　　不觉初秋夜渐长，清风习习重凄凉。, 　　炎炎暑退茅... | 266.0 | . 267 [卷160_183 「过融上人兰若」孟浩然, 　　山头禅室挂僧衣，窗外无人水鸟飞。, 　　黄... | 267.0 | . 268 [卷160_184 「句」孟浩然, 　　微云淡河汉，疏雨滴梧桐。, 　　逐逐怀良驭，萧萧顾乐... | 268.0 | . 269 NaN | NaN | . 270 rows × 2 columns . df = df.append({&#39;content&#39;: np.nan, &#39;test&#39;: np.nan}, ignore_index=True) # df = &lt;- now the df is replaced df.tail(1) . content test . 269 NaN | NaN | . We can then drop the row (all missing values) and the column again. . df = df.dropna(how=&quot;any&quot;,axis=&quot;index&quot;) # this is for dropping all missing values in the rows df.tail(1) . content test . 268 [卷160_184 「句」孟浩然, 　　微云淡河汉，疏雨滴梧桐。, 　　逐逐怀良驭，萧萧顾乐... | 268.0 | . df = df.drop(columns=&quot;test&quot;) # this is for dropping the column named &quot;test&quot; df.head() . content . 0 [卷159_1 「从张丞相游南纪城猎，戏赠裴迪张参军」孟浩然, 　　从禽非吾乐，不好云梦田。... | . 1 [卷159_2 「登江中孤屿，赠白云先生王迥」孟浩然, 　　悠悠清江水，水落沙屿出。回潭石下... | . 2 [卷159_3 「晚春卧病寄张八」孟浩然, 　　南陌春将晚，北窗犹卧病。林园久不游，草木一何... | . 3 [卷159_4 「秋登兰山寄张五」孟浩然, 　　北山白云里，隐者自怡悦。相望试登高，心飞逐鸟... | . 4 [卷159_5 「入峡寄弟」孟浩然, 　　吾昔与尔辈，读书常闭门。未尝冒湍险，岂顾垂堂言。,... | . Now we finally start with our new columns: . Let&#39;s look at one of our data sets: we can see the first item is the ID, title and author name, and the other items are the text. So let us set the first item as title, and the rest of the items as content. . df[&quot;content&quot;][0] . [&#39;卷159_1 「从张丞相游南纪城猎，戏赠裴迪张参军」孟浩然&#39;, &#39; u3000 u3000从禽非吾乐，不好云梦田。岁暮登城望，偏令乡思悬。&#39;, &#39; u3000 u3000公卿有几几，车骑何翩翩。世禄金张贵，官曹幕府贤。&#39;, &#39; u3000 u3000顺时行杀气，飞刃争割鲜。十里届宾馆，征声匝妓筵。&#39;, &#39; u3000 u3000高标回落日，平楚散芳烟。何意狂歌客，从公亦在旃。&#39;] . df[&quot;title&quot;] = df[&quot;content&quot;].str[0] # the first item df[&quot;content&quot;] = df[&quot;content&quot;].str[1:] # second to last item df[&quot;content&quot;] = df[&quot;content&quot;].str.get(0) # get rid of the [] by extracting the first item from list df.head() . content title . 0 从禽非吾乐，不好云梦田。岁暮登城望，偏令乡思悬。 | 卷159_1 「从张丞相游南纪城猎，戏赠裴迪张参军」孟浩然 | . 1 悠悠清江水，水落沙屿出。回潭石下深，绿筱岸傍密。 | 卷159_2 「登江中孤屿，赠白云先生王迥」孟浩然 | . 2 南陌春将晚，北窗犹卧病。林园久不游，草木一何盛。 | 卷159_3 「晚春卧病寄张八」孟浩然 | . 3 北山白云里，隐者自怡悦。相望试登高，心飞逐鸟灭。 | 卷159_4 「秋登兰山寄张五」孟浩然 | . 4 吾昔与尔辈，读书常闭门。未尝冒湍险，岂顾垂堂言。 | 卷159_5 「入峡寄弟」孟浩然 | . df = df.replace(r&#39; n&#39;,&#39; &#39;, regex=True) # replace the next line symbol &#39; n&#39; with empty space df.head() . content title . 0 从禽非吾乐，不好云梦田。岁暮登城望，偏令乡思悬。 | 卷159_1 「从张丞相游南纪城猎，戏赠裴迪张参军」孟浩然 | . 1 悠悠清江水，水落沙屿出。回潭石下深，绿筱岸傍密。 | 卷159_2 「登江中孤屿，赠白云先生王迥」孟浩然 | . 2 南陌春将晚，北窗犹卧病。林园久不游，草木一何盛。 | 卷159_3 「晚春卧病寄张八」孟浩然 | . 3 北山白云里，隐者自怡悦。相望试登高，心飞逐鸟灭。 | 卷159_4 「秋登兰山寄张五」孟浩然 | . 4 吾昔与尔辈，读书常闭门。未尝冒湍险，岂顾垂堂言。 | 卷159_5 「入峡寄弟」孟浩然 | . type(df.title[0]) # title is type of string . str . Now we can set up a new column &quot;id&quot; and then use it as our index using set_index(). . We learnt in the last notebook. ( d+_ d+) means a number followed by _ followed by a number again. This is the pattern used for the extraction of the title column. . df[&quot;id&quot;] = df.title.str.extract(&#39;( d+_ d+)&#39;) df = df.set_index(&quot;id&quot;) df.head() . content title . id . 159_1 从禽非吾乐，不好云梦田。岁暮登城望，偏令乡思悬。 | 卷159_1 「从张丞相游南纪城猎，戏赠裴迪张参军」孟浩然 | . 159_2 悠悠清江水，水落沙屿出。回潭石下深，绿筱岸傍密。 | 卷159_2 「登江中孤屿，赠白云先生王迥」孟浩然 | . 159_3 南陌春将晚，北窗犹卧病。林园久不游，草木一何盛。 | 卷159_3 「晚春卧病寄张八」孟浩然 | . 159_4 北山白云里，隐者自怡悦。相望试登高，心飞逐鸟灭。 | 卷159_4 「秋登兰山寄张五」孟浩然 | . 159_5 吾昔与尔辈，读书常闭门。未尝冒湍险，岂顾垂堂言。 | 卷159_5 「入峡寄弟」孟浩然 | . Now our data frame looks better. But we still want to get rid of the ID, author name, and 「」. To remove them, we replace them with an empty string (&quot;&quot;). Save them back to the title column. . df[&#39;title&#39;] = df[&#39;title&#39;].str.replace(&#39;卷( d+_ d+)&#39;, &#39;&#39;).str.replace(&#39;孟浩然&#39;, &#39;&#39;) df[&#39;title&#39;] = df[&#39;title&#39;].str.replace(&#39;「&#39;, &#39;&#39;).str.replace(&#39;」&#39;, &#39;&#39;) . Let&#39;s create df2 now by coping &quot;title&quot; and &quot;content&quot; from df. And set the index using the index from df. . df2 = (df[[&#39;title&#39;,&#39;content&#39;]]).set_index(df.index) df2.head() . title content . id . 159_1 从张丞相游南纪城猎，戏赠裴迪张参军 | 从禽非吾乐，不好云梦田。岁暮登城望，偏令乡思悬。 | . 159_2 登江中孤屿，赠白云先生王迥 | 悠悠清江水，水落沙屿出。回潭石下深，绿筱岸傍密。 | . 159_3 晚春卧病寄张八 | 南陌春将晚，北窗犹卧病。林园久不游，草木一何盛。 | . 159_4 秋登兰山寄张五 | 北山白云里，隐者自怡悦。相望试登高，心飞逐鸟灭。 | . 159_5 入峡寄弟 | 吾昔与尔辈，读书常闭门。未尝冒湍险，岂顾垂堂言。 | . Finally, we also need to know that conversion between Pandas column and Numpy array is very simple. We can basically select the column and then call .values. Then we get our array. . For example, we can try to convert our title column to array: . df2.title.values[:5] # first 5 items . array([&#39; 从张丞相游南纪城猎，戏赠裴迪张参军&#39;, &#39; 登江中孤屿，赠白云先生王迥&#39;, &#39; 晚春卧病寄张八&#39;, &#39; 秋登兰山寄张五&#39;, &#39; 入峡寄弟&#39;], dtype=object) . . . Data Analysis . After performing some basic processing of our data, let us try to do some analysis based on what we have. Let us say, we want to understand how the key words of season have been used in the text. How many times have they been used and how are they distributed? At the end we want to use the results to make a bar chart and a dispersion plot using matplotlib. We will learn much more about visualization later, but for now we will stick to simple plots. . In case we still have rows with missing values, we use dropna() again to clean our data frame. . df2 = df2.dropna(how=&quot;any&quot;,axis=&quot;index&quot;) # this is for dropping all missing values in the rows . Then we calculate the word offset. It is done by geting the length of strings in the content column (.len()) and calculate the cumulative sum of it (.cumsum()). It means that now the values in the rows is not the length of the one title, but the word offset starting from the first character of the first title. We use it as our word offset for the plot later. With (.to_numpy()) we get the list to numpy array. . word_count = df2.content.str.len().cumsum().to_numpy() word_count[:5] . array([ 26, 52, 78, 104, 130]) . Now we want to look for the keywords for every season. We do it using the find() function and convert the list to numpy. The same is done for every season. . spring_count = df2.content.str.find(&#39;春&#39;).to_numpy() # for spring spring_count[:5] . array([-1, -1, 4, -1, -1]) . summer_count = df2.content.str.find(&#39;夏&#39;).to_numpy() # for summer summer_count[:5] . array([-1, -1, -1, -1, -1]) . autumn_count = df2.content.str.find(&#39;秋&#39;).to_numpy() # for autumn autumn_count[:5] . array([-1, -1, -1, -1, -1]) . winter_count = df2.content.str.find(&#39;冬&#39;).to_numpy() # for winter winter_count[:5] . array([-1, -1, -1, -1, -1]) . Then, we use list comprehension and enumerate() to loop through all items and the index in the array, and save (index + word offset) that is not equal to one. . The resultuing value can be understood as the total word offset of that character starting from the first title. For example, from the next cell we can tell &quot;春&quot; appears in the 82th, 198th, 660th, ... characters. . spring_occur = np.array([v + word_count[i] for i, v in enumerate(spring_count) if v != -1]) # for spring spring_occur . array([ 82, 198, 660, 826, 1094, 1690, 1749, 2077, 2177, 2183, 2333, 2781, 2853, 3302, 3681, 4091, 4249, 4321, 4351, 5190, 5259, 5297, 5765, 5902, 6065, 6523, 6571, 6805, 6821]) . summer_occur = np.array([v + word_count[i] for i, v in enumerate(summer_count) if v != -1]) # for summer summer_occur . array([ 407, 3204, 3897]) . autumn_occur = np.array([v + word_count[i] for i, v in enumerate(autumn_count) if v != -1]) # for autumn autumn_occur . array([ 366, 1949, 2347, 3455, 3743, 5504, 5649, 6850]) . winter_occur = np.array([v + word_count[i] for i, v in enumerate(winter_count) if v != -1]) # for winter winter_occur . array([], dtype=float64) . . . Basic Data Visualization . Afterwards, we have our arrays which store information about the occurences of season keywords. We can make a plot out of it using matplotlib. The dispersion plot we are making is based on a scatter plot. We will thus do a scatter plot for every season with custom marker styles. . import matplotlib.pyplot as plt # import library fig, ax = plt.subplots(figsize=(15,3)) # create an empty plot with defined size # in the scatter plot function (plt.scatter()), we need X for 1st argument and Y for 2nd argument. # for X we will put the word offset values for keyword occurence, for Y we will put a constant value from 1 to 4 # because we want the same season in the same row # np.ones() creates 1 with defined shape, in this case the shape is [length of X,1] spring_y = 1*np.ones([len(spring_occur),1]) # all 1 (1*1) summer_y = 2*np.ones([len(summer_occur),1]) # all 2 (2*1) autumn_y = 3*np.ones([len(autumn_occur),1]) # all 3 (3*1) winter_y = 4*np.ones([len(winter_occur),1]) # all 4 (4*1) # scatter plot plt.scatter(spring_occur,spring_y, marker=5, s=100, alpha=0.8) # first scatter plot for spring, alpha is transparency of the markers plt.scatter(summer_occur,summer_y, marker=5, s=100, alpha=0.8) # for summer plt.scatter(autumn_occur,autumn_y, marker=5, s=100, alpha=0.8) # for autumn plt.scatter(winter_occur,winter_y, marker=5, s=100, alpha=0.8) # for winter # set y limits plt.ylim(0.8, 4.5) # we want our y labels as text, not number. so here we define them. plt.yticks(np.arange(0,5,1)) labels = [&#39;&#39;,&#39;Spring&#39;, &#39;Summer&#39;, &#39;Autumn&#39;, &#39;Winter&#39;] ax.set_yticklabels(labels, fontsize=12) # no plot frame is needed plt.box(False) # labels and title plt.xlabel(&quot;Word Offset&quot;, fontsize=14) plt.ylabel(&quot;Season Keywords&quot;, fontsize=14) plt.title(&quot;Lexical Dispersion&quot;, fontsize=16) . Text(0.5, 1.0, &#39;Lexical Dispersion&#39;) . . On another hand, we can also make a bar chart by simply showing the occurence frequency of keywords. . We use count() of the content column from df2 to count the occurence. We need to add sum() to sum up count for all rows, not single row. . spring = int(df2.content.str.count(&#39;春&#39;).sum()) # spring spring . 29 . summer = int(df2.content.str.count(&#39;夏&#39;).sum()) # summer summer . 3 . autumn = int(df2.content.str.count(&#39;秋&#39;).sum()) # autumn autumn . 8 . winter = int(df2.content.str.count(&#39;冬&#39;).sum()) # winter winter . 0 . Now, we can use our results to make another data frame. We do it because having results in a separate data frame makes visualization easier. . count = {&#39;season&#39;: [&quot;spring&quot;, &quot;summer&quot;, &quot;autumn&quot;, &quot;winter&quot;],&#39;count&#39;: [spring, summer, autumn, winter]} season = pd.DataFrame.from_dict(count) # set season as index season = season.set_index(&quot;season&quot;) season.head() . count . season . spring 29 | . summer 3 | . autumn 8 | . winter 0 | . In order to have Chinese characters shown in our plot, we need to download a package and change the font from the Python library. Please just use this code: . !wget -O TaipeiSansTCBeta-Regular.ttf https://drive.google.com/uc?id=1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_&amp;export=download # import library import matplotlib as mpl import matplotlib.pyplot as plt from matplotlib.font_manager import fontManager # change font setting fontManager.addfont(&#39;TaipeiSansTCBeta-Regular.ttf&#39;) mpl.rc(&#39;font&#39;, family=&#39;Taipei Sans TC Beta&#39;) . --2021-12-12 20:09:06-- https://drive.google.com/uc?id=1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_ Resolving drive.google.com (drive.google.com)... 142.250.81.206, 2607:f8b0:4004:82f::200e Connecting to drive.google.com (drive.google.com)|142.250.81.206|:443... connected. HTTP request sent, awaiting response... 302 Moved Temporarily Location: https://doc-0k-9o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/6nfeiuvrhp3la80n9pg1oja3jsktcq6e/1639339725000/02847987870453524430/*/1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_ [following] Warning: wildcards not supported in HTTP. --2021-12-12 20:09:10-- https://doc-0k-9o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/6nfeiuvrhp3la80n9pg1oja3jsktcq6e/1639339725000/02847987870453524430/*/1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_ Resolving doc-0k-9o-docs.googleusercontent.com (doc-0k-9o-docs.googleusercontent.com)... 142.250.73.193, 2607:f8b0:4004:829::2001 Connecting to doc-0k-9o-docs.googleusercontent.com (doc-0k-9o-docs.googleusercontent.com)|142.250.73.193|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 20659344 (20M) [application/x-font-ttf] Saving to: ‘TaipeiSansTCBeta-Regular.ttf’ TaipeiSansTCBeta-Re 100%[===================&gt;] 19.70M 35.2MB/s in 0.6s 2021-12-12 20:09:11 (35.2 MB/s) - ‘TaipeiSansTCBeta-Regular.ttf’ saved [20659344/20659344] . Having a Pandas data frame makes visualization simple. We can basically call the dataframe with .plot., followed by the type of plot we want to have. For example, a bar chart is (name of dataframe).plot.bar(). . plt.figure(figsize=(18,6)) # bar chart season.plot.bar(rot=0, color=&quot;#830045&quot;) # labels and title plt.xlabel(&quot;Season&quot;, fontsize=15) plt.ylabel(&quot;Occurence&quot;, fontsize=15) plt.title(&quot;Description of season in n孟浩然诗 卷一百五十九 and 卷一百六十?&quot;, fontsize=15) # remove legend and add keywords in the x-axis ax = plt.gca() ax.set_xticklabels([&#39;春&#39;,&#39;夏&#39;,&#39;秋&#39;,&#39;冬&#39;], fontsize=16) ax.get_legend().remove() # adjust spacing in plot plt.tight_layout() . &lt;Figure size 1296x432 with 0 Axes&gt; . . Previous Lesson: Regular Expression . Next Lesson: Pandas Numerical Operation . Additional information . This notebook is provided for educational purposes only. Feel free to report any issues on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: December 2021 . . . . References: . Jieba . Displaying Chinese characters . Python Data Science Handbook .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/level-2/chapter-2/data-manipulation/pandas/2020/01/23/Pandas_TextAnalysis_TextOriganization.html",
            "relUrl": "/level-2/chapter-2/data-manipulation/pandas/2020/01/23/Pandas_TextAnalysis_TextOriganization.html",
            "date": " • Jan 23, 2020"
        }
        
    
  
    
        ,"post19": {
            "title": "Regular Expression",
            "content": ". As mentioned in the instructions, all materials can be open in Colab as Jupyter notebooks. In this way users can run the code in the cloud. It is highly recommanded to follow the tutorials in the right order. . This notebook aims to introduce users how to use regular expression to extract useful information from text in Python which would be from documents or websites. . Presumption: . . . Before starting with this tutorial, please watch this video beforehand so that you would already understand: . 1) What is the group method in a regular expression? . 2) What is a raw string? . 3) How to create a character set? . 4) What is the function of quantifiers? . . . Review . Here are the summary tables from the video: . Syntax Meaning . . | Any character except newline | . d | Digit (0-9) | . D | Not a digit (0-9) | . w | Word character (a-z, A-Z, 0-9, _) | . W | Not a word character | . s | Whitespace (space, tab, newline) | . S | Not whitespace (space, tab, newline) | . Syntax Meaning . b | Word boundary | . B | Not a word boundary | . ^ | Beginning of a string | . $ | End of a string | . [] | Matches characters in brackets | . [^ ] | Matches characters NOT in brackets | . | | Either or | . ( ) | Group | . . Quantifiers Meaning . * | 0 or more | . + | 1 or more | . ? | 0 or one | . {3} | Exact number | . {3,4} | Range of numbers (minimum, maximum) | . Information Retrieval . ## re | . Before we analyse any text, the relevant information needs to be first extracted to exclude all irrelavant information. Sometimes this is not very straight-forward since the text might be mixed with other information, particularly when the texts are mined from online sources. . Below we can look at an exmaple of an entry extracted from Historical GIS for Japan. We can see the information is in multiple rows with each row giving different information. If we only aim for one piece of information, it might be easy to copy in one entry but the task gets challenging once we have thousands of them. This is why text mining can be helpful to save us time and effort. . . First of all, we have to import the library. . import re . lord_entry = &quot;&quot;&quot; name: abemasaharu n vernacular name definition kanji: 阿部正春 n alternate vernacular name definition hiragana: あべまさはる n feature type definition feature type: feudal lord 大名 daimyo n date range definition date range: 1664 to 1664 n time slice definition valid as: time slice 年份 n present location definition present location: 岩槻市 iwatsukishi n point id definition point id: jp_dmy_40 n data source definition data source: JP_CHGIS n feature type definition coordinate type: centroid n feature type definition latitude: 35.93 n feature type definition longitude: 139.70 n admin hierarchy definition admin hierarchy: 武蔵国 musashi no kuni &quot;&quot;&quot; . Name . Here we can try to get the kanji name of the entry. . From what we have learnt, we can use the group option to get the first group kanji: at the word boundary ( b) followed by space ( s) and everything (regardless of length) behind it. Using pattern1, we have the name we need in the second group. . We will use re.compile() to compile our pattern (faster if the pattern is frequently used), then use findall() to look for all matches. . pattern1 = re.compile(r&#39;( bkanji: s)(.*)&#39;) match1 = pattern1.findall(lord_entry) # get all matches match1 # print them out . [(&#39;kanji: t&#39;, &#39;阿部正春&#39;)] . We can then access the first element of list [0] (there is only one element) and second element of the tuple [1]. . match1[0][1] . &#39;阿部正春&#39; . Alternative: Lookaround . However, we can also use the lookaround method from re, which means we use kanji: to identify what we search for (behind the keyword) but we do not select kanji: itself because it is not important for us. . . Be careful, space might not be obvious, but it is also counts as character, so we always need to address them too. . . . Given the string foobarbarfoo: . . bar(?=bar) finds the 1st bar (&quot;bar&quot; which has &quot;bar&quot; after it) . bar(?!bar) finds the 2nd bar (&quot;bar&quot; which does not have &quot;bar&quot; after it) . (?&lt;=foo)bar finds the 1st bar (&quot;bar&quot; which has &quot;foo&quot; before it) . (?&lt;!foo)bar finds the 2nd bar (&quot;bar&quot; which does not have &quot;foo&quot; before it) . . They can also be combined: . (?&lt;=foo)bar(?=bar) finds the 1st bar (&quot;bar&quot; with &quot;foo&quot; before it and &quot;bar&quot; after it) . . Here we use (?&lt;=text1)text2 to select text 2 from identifying text 1, in which text 1 is before text 2 in the text. . pattern2 = re.compile(r&#39;(?&lt;=kanji: s).*&#39;) match2 = pattern2.findall(lord_entry) match2 . [&#39;阿部正春&#39;] . Coordinates . Now, we can try to get the latitude and longitude from the lord_entry (for example, to make a map in GIS). Since we have already learnt the principle, the code we need is indeed very similar. . #### Latitude | . lat_pattern = re.compile(r&#39;(?&lt;=latitude: s).*&#39;) match = lat_pattern.findall(lord_entry) match . [&#39;35.93&#39;] . We need to be careful here. Normally when we think of coordinates, we expect a floating number. But here what we get (match) is a list. It will cause errors if we later directly use the list for any geospatial operations. So always check the type. . type(match) # it is a list . list . type(match[0]) # we can get the first item of the list to remove [], now it is a string . str . We need to further convert the string into float using float(). . type(float(match[0])) . float . lat = float(match[0]) # save the final result to lat lat . 35.93 . Now we got what we need! Let&#39;s do the same for longitude. . #### Longitude | . lon_pattern = re.compile(r&#39;(?&lt;=longitude: s).*&#39;) match = lon_pattern.findall(lord_entry) match # list . [&#39;139.70&#39;] . lon = float(match[0]) lon # float . 139.7 . Chinese Characters . Here is another small text from 韓愈. Now for Chinese characters, we can use unicode characters to select a specific type of characters. . . The ranges of Unicode characters which are routinely used for Chinese and Japanese text are: . U+3040 - U+30FF: hiragana and katakana (Japanese only) . | U+3400 - U+4DBF: CJK unified ideographs extension A (Chinese, Japanese, and Korean) . | U+4E00 - U+9FFF: CJK unified ideographs (Chinese, Japanese, and Korean) . | U+F900 - U+FAFF: CJK compatibility ideographs (Chinese, Japanese, and Korean) . | U+FF66 - U+FF9F: half-width katakana (Japanese only) . | . text = &quot;或問諫議大夫陽城於愈：可以為有道之士乎哉？學廣而聞多，不求聞於人也，行古人之道，居於晉之鄙，晉之鄙人薰其德而善良者幾千人。大臣聞而薦之，天子以為諫議大夫。人皆以為華，陽子不色喜。居於位，五年矣，視其德如在野，彼豈以富貴移易其心哉！&quot; . pattern = re.compile(r&#39;[ u4e00- u9fff]+&#39;) match = pattern.findall(text) match . [&#39;或問諫議大夫陽城於愈&#39;, &#39;可以為有道之士乎哉&#39;, &#39;學廣而聞多&#39;, &#39;不求聞於人也&#39;, &#39;行古人之道&#39;, &#39;居於晉之鄙&#39;, &#39;晉之鄙人薰其德而善良者幾千人&#39;, &#39;大臣聞而薦之&#39;, &#39;天子以為諫議大夫&#39;, &#39;人皆以為華&#39;, &#39;陽子不色喜&#39;, &#39;居於位&#39;, &#39;五年矣&#39;, &#39;視其德如在野&#39;, &#39;彼豈以富貴移易其心哉&#39;] . We can also look for every character instead: . pattern = re.compile(r&#39;[ u4e00- u9fff]&#39;) match = pattern.findall(text) match[:5] # print first 5 characters only . [&#39;或&#39;, &#39;問&#39;, &#39;諫&#39;, &#39;議&#39;, &#39;大&#39;] . Here is another example entry from 清代檔案. Here let&#39;s say we want to extract the time from the document. . text = &quot;&quot;&quot; 撥給各種工匠銀乾隆01年8月 --內務府奏銷檔 第1筆 事由：撥給各種工匠銀 內文：雍正十三年四月起至 乾隆 元年五月給發匠役工價所用大制錢數目 郎中永保等文開恭畫坤寧宮神像需用外僱畫匠畫短工九十五工每工錢一百三十四文領去大制錢十二串七百三三十文 銀庫郎中邁格等據掌儀司郎中謨爾德等文開恭造坤寧宮祭祀所用鏨花銀香碟八個爵盤二個漏子一個格漏一個箸一雙匙三張小碟二十個鍾十一個大碗五個壺一把大小盤二十四個鑲銀裹楠木肉槽四個三鑲烏木箸二雙畫像上用掛釣三分亭子上用銀面葉一分需用外僱鏨花匠大器匠做短工七百九十一工四分五厘每工錢一百三十四文領去大制錢一百六串五十四文 ... 時間：乾隆01年8月 官司： 官員： 微捲頁數：173-194 冊數：194 資料庫：內務府奏銷檔案 &quot;&quot;&quot; . We can also perform a quick retrieval using what we have just learnt. . pattern = re.compile(r&#39;(?&lt;=時間.).*&#39;) match = pattern.findall(text) match . [&#39;乾隆01年8月&#39;] . Combining with Web Scrapping, which we will learn later, we can then easily get the required information for text analysis. . . Previous Lesson: List Comprehension . Next Lesson: Pandas Text Analysis . Additional information . This notebook is provided for educational purposes only. Feel free to report any issues on GitHub. . . Author: Ka Hei, Chow . License: The code in this notebook is licensed under the Creative Commons by Attribution 4.0 license. . Last modified: December 2021 . . . . References: . https://github.com/CoreyMSchafer/code_snippets/blob/master/Python-Regular-Expressions/snippets.txt . https://stackoverflow.com/questions/2973436/regex-lookahead-lookbehind-and-atomic-groups . https://stackoverflow.com/questions/43418812/check-whether-a-string-contains-japanese-chinese-characters .",
            "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/re/level-2/chapter-2/2020/01/22/Regular_Expression_TextExtraction.html",
            "relUrl": "/re/level-2/chapter-2/2020/01/22/Regular_Expression_TextExtraction.html",
            "date": " • Jan 22, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About",
          "content": "Introduction to Python Programming . Hi! This is Ka Hei. This space is created at the end of 2021 for introducing users in the humanities to pick up some basic programming skills📍 for research using digital text resources. You do not need to have any programming knowledge when you start with the tutorials. It covers tasks from data acquisition, analysis to visualization, working with both text📜 and geospatial data🗺️. All tutorials use (historical) Chinese text to demonstrate workflows of relevant tasks (sometimes mixed with examples from other languages, eg. Japanese, Korean, and English). . . Instructions . WHY this space? . 🔎 Instead of introducing users to diverse tools (Javascript, HTML, CSS, Jekyll, R etc.), it only focus on ONE: PYTHON, which can be used to approach a wide range of tasks (without knowledge of other tools) . 🔎 All tutorials can be run in the Colab cloud environment so NO ENVIRONMENT SET UP AND INSTALLATION in the local device needed. It also MINIMIZE UNINSTRUCTED STEPS (eg. downloading and preprocessing files on your own) so that everyone can follow along. . 🔎 Instead of being application-oriented (Network analysis, Geocode data, supervised classification, etc.), it starts from the basics and slowly introduce users different analysis concepts in a SYSTEMATIC manner . 🔎 It focuses on applications in CHINESE language and history to give users in this discipline more concrete instructions . . This is the RIGHT space for you if: . ⭐ You are NEW TO PROGRAMMING and do not know WHERE TO START . ⭐ You want to pick up ONE TOOL FIRST for digital humanity which can handle MOST of the task . ⭐ You find it difficult to follow existing tutorials and want to DO IT BIT BY BIT FROM THE SCRATCH . ⭐ You are STUCK with downloading and installing digital tools . ⭐ You want to learn a tool that DO NOT NEED A LICENSE and is ALWAYS FREELY AVAILABLE . ⭐ You want to have a BIG PICTURE what can you ACHIEVE with the digital tools . . This is NOT the RIGHT space for you if: . 🤔 You MASTER PROGRAMMING already and wish to harness the potential of multiple programming languages . 🤔 You do NOT appreciate FREE OPEN SOURCE TOOLS . 🤔 You prefer a VERY STEEP LEARNING CURVE . 🤔 You are NOT PREPARED for consistent learning for the NEXT MONTHS . . Tutorial Summary: . 🕹️ Introduction to Python Programming . 🕹️ Plotting and Interactive Data Visualization . 🕹️ Data Manipulation using Pandas . 🕹️ Web Scrapping and Text Analysis . 🕹️ Working with Geospatial Data . . Python Libraries covered: . beautifulsoup4, Bokeh, geopandas, folium, matplotlib, networkx, numpy, pandas, seaborn, urllib2, requests, re, SnowNLP, SpaCy, jieba, dash, plotly . . You will be ABLE to: . 👍 Write simple PYTHON CODE that fit your purposes (Oh what is your purposes? 😃) . 👍 Create some INTERACTIVE contents/ graphics to present results . 👍 Have your first WEBMAP! . 👍 Know how to dive into DIGITAL DATABASE yourself without browsing around . . You will NOT be ABLE to: . 🙅‍♀️ Know how to make a dynamic and highly interactive website yourself just by following the tutorials . 🙅‍♀️ Know how to start with a project yourself if you only read the code, but not practice . 🙅‍♀️ Debug all the potential problems just by following the tutorials, use GOOGLE and stackoverflow! . 🙅‍♀️ FLY!! 🐤 . . How to use this Space 🚀: . All code displayed on this webpage is available as Jupyter Notebook and it is highly recommanded that you download them and try it out by yourself. . | If you are new to Colab, pleaese first click on Colab and begin your journey. There are two options to open the notebooks in Colab: . 1) Recommanded Option: Go to the page for the lesson here. Right under the tags, there are four icons. Click on option “Open in Colab”. You will be then able to view the notebook in Colab. . 2) Alternative: Download the notebook you need from this page. Search for the right title, right click and select “save link as”. You will be able to download the Jupyter Notebook with the file extension “.ipynb” (You do not need an account in GitHub but it is recommanded that you sign up). Go back to Colab and click File -&gt; Upload notebook, select the notebook you just downloaded. Now you can run the notebook by yourself and start your coding journey. . | ALL the tutorials provided here is ordered by LEVELS (lv1: the easiest, lv4: the most difficult) and it is recommanded to FOLLOW THE ORDER when you go through them . | There are PREREQUISITES for almost all of the tutorials so please FOLLOW the links before you start with the content . | There are REFERENCES in all the introduced concepts so feel free to read external resources before you continue . | The tutorials do NOT COVER all possibilities or functionalities of the Python libraries so please do not solely depends on them . | PRACTICE is the only way to go! So TYPE THE CODE by yourselves and TRY to change some options and run them again. . | Inputs and potential outputs from the tutorials are available in the data folder. . | Additional notebooks for references only are available in the additional folder. . | . . Please pay attention 💡: . Some chapters are currently still under construction. . | This space is set up volunarily with limited time so please be understanding of the typo and writing mistakes not yet corrected. . | . .",
          "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  
      ,"page2": {
          "title": "Gallery",
          "content": "Here some example figures from the tutorials are displayed. After you follow the tutorials, you will be able to create them. . . Bubble Chart . This is an interactive bubble chart plotted using Plotly together with a simple Pandas data frame. It shows the population (y-axis) and territory size (bubble size) (colored by maximum longevity of emperors) in different Chinese dynasties. . . . . Scatter Plot . This is a simple scatter plot using Matplotlib and customized layout options. It shows how season keywords distribute in 孟浩然诗全集. . . . Network Chart . This is a simple network chart created using NetworkX library in Python. It shows the relationsip between historical figures. . . . Stacked Area Plot . This is a variation of a stacked area plot created using seaborn. It shows development of UNESCO sites over time for the top ten countries having the most UNESCO sites. . . . Bubble Time Line . Using the same UNESCO example, this is a bubble chart showing the same temporal development. Yet, more information is embedded in the interactive hover labels using Plotly. . . . Chinese Word Cloud . This is a word cloud created using wordcloud library together with jieba for processing Chinese texts. It shows the keywords generated from《杯酒释兵权考》by 丁则良. . . . Circle Packing Chart . This is a circle packing chart displaying the distribution of family name in Song Dynasty, created using Circlify. . . . Color Stripes . These are color stripes illustrating the occurences of wars in ancient China, created using Plotly. . . . Wind Rose Chart . These is a polar bar chart created using Plotly. . . . (More coming soon …) . 📊 Happy Coding! .",
          "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/gallery/",
          "relUrl": "/gallery/",
          "date": ""
      }
      
  

  

  
      ,"page4": {
          "title": "Resources",
          "content": "Here you can find some recommanded external resources for further learning. . . Python Programming 🐍 . ➼ Python for Digital Humanity . ➼ Introduction to Cultural Analytics &amp; Python . ➼ Data Camp . ➼ free code camp . ➼ Corey Schafer Youtube Channel . ➼ Data Science for Everyone . . Chinese Digital Database 📙 . ➼ 中國哲學書電子化計劃 . ➼ CBDB . ➼ 皮书数据库 . ➼ 臺灣文獻叢刊資料庫系統 . ➼ 寶卷新集 . ➼ 明實錄、朝鮮王朝實錄、清實錄資料庫合作建置計畫 . ➼ 中国方志库 . ➼ 明淸婦女著作 . ➼ 中研院臺灣史研究所 . ➼ 中研院近史所 . ➼ 清代職官資料庫 . ➼ 維基文庫 . . Chinese GIS 🗺️ . ➼ CHGIS . . Click here for more resources… .",
          "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/resources/",
          "relUrl": "/resources/",
          "date": ""
      }
      
  

  
  

  

  
  

  

  
  

  
  

  

  

  

  
  

  
      ,"page15": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://pinkychow1010.github.io/digital-chinese-history-blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}